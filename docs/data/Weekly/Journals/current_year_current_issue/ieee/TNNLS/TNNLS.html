<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TNNLS</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tnnls">TNNLS - 138</h2>
<ul>
<li><details>
<summary>
(2025). Online graph models: Tackling the challenges of non-gaussian noise in adaptive filtering. <em>TNNLS</em>, <em>36</em>(9), 17516-17522. (<a href='https://doi.org/10.1109/TNNLS.2025.3553872'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adaptive filtering faces significant challenges in handling complex non-Gaussian noise, while graph signal processing (GSP) excels at processing data with intricate structures. This brief introduces a novel method for solving non-Gaussian noise from the perspective of the graph domain for the first time. Specifically, we develop an online time-varying graph model based on the filter error signal and propose a corresponding graph topology transformation strategy. Utilizing a graph smoothness measure, we introduce a new adaptive filtering cost function, in which the graph Laplacian matrix plays a direct role in the filter update process. Subsequently, we derive the graph smoothness recursive adaptive filtering (GS-RAF) algorithm, rigorously analyze its theoretical performance, and validate its efficacy through simulations and echo cancellation experiments. The corresponding MATLAB (MathWorks, USA) codes of the simulations are publicly available at: https://github.com/smartXiaoz/GS-RAF.git.},
  archive      = {J_TNNLS},
  author       = {Shan Zhong and Gang Wang and Kah Chan Teh and Jiacheng He and Tee Hiang Cheng and Bei Peng},
  doi          = {10.1109/TNNLS.2025.3553872},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {17516-17522},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Online graph models: Tackling the challenges of non-gaussian noise in adaptive filtering},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Broad critic deep actor reinforcement learning for continuous control. <em>TNNLS</em>, <em>36</em>(9), 17508-17515. (<a href='https://doi.org/10.1109/TNNLS.2025.3554082'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the domain of continuous control, deep reinforcement learning (DRL) demonstrates promising results. However, the dependence of DRL on deep neural networks (DNNs) results in the demand for extensive data and increased computational cost. To address this issue, a novel hybrid actor-critic reinforcement learning (RL) framework is introduced. The proposed framework integrates the broad learning system (BLS) with DNN, aiming to merge the strengths of both distinct architectural paradigms. Specifically, the critic network employs BLS for rapid value estimation via ridge regression, while the actor network retains the DNN structure to optimize policy gradients. This hybrid design is generalizable and can enhance existing actor-critic algorithms. To demonstrate its versatility, the proposed framework is integrated into three widely used actor-critic algorithms—deep deterministic policy gradient (DDPG), soft actor-critic (SAC), and twin delayed DDPG (TD3), resulting in BLS-augmented variants. The experimental results reveal that all BLS-enhanced versions surpass their original counterparts in terms of training efficiency and accuracy. These improvements highlight the suitability of the proposed framework for real-time control scenarios, where computational efficiency and rapid adaptation are critical.},
  archive      = {J_TNNLS},
  author       = {Shiron Thalagala and Pak Kin Wong and Xiaozheng Wang and Tianang Sun},
  doi          = {10.1109/TNNLS.2025.3554082},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {17508-17515},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Broad critic deep actor reinforcement learning for continuous control},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Training dataset curation by l1-norm principal-component analysis for support vector machines. <em>TNNLS</em>, <em>36</em>(9), 17499-17507. (<a href='https://doi.org/10.1109/TNNLS.2025.3568694'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Support vector machines (SVMs) have been the learning model of choice in numerous classification applications. While SVMs are widely successful in real-world deployments, they remain susceptible to mislabeled examples in training datasets where the presence of few faults can severely affect decision boundaries, thereby affecting the model’s performance on unseen data. In this brief, we develop and describe in implementation detail a novel method based on $L_{1}$ -norm principal-component data analysis and geometry that aims to filter out atypical data instances on a class-by-class basis before the training phase of SVMs and thus provide the classifier with robust support-vector candidates for making classification boundaries. The proposed dataset curation method is entirely data-driven (touch-free), unsupervised, and computationally efficient. Extensive experimental studies on real datasets included in this brief illustrate the $L_{1}$ -norm curation method and demonstrate its efficacy in protecting SVM models from data faults during learning.},
  archive      = {J_TNNLS},
  author       = {Shruti Shukla and Dimitris A. Pados and George Sklivanitis and Elizabeth Serena Bentley and Michael J. Medley},
  doi          = {10.1109/TNNLS.2025.3568694},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {17499-17507},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Training dataset curation by l1-norm principal-component analysis for support vector machines},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Strong anti-hebbian plasticity alters the convexity of network attractor landscapes. <em>TNNLS</em>, <em>36</em>(9), 17491-17498. (<a href='https://doi.org/10.1109/TNNLS.2025.3561217'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this brief, we study recurrent neural networks in the presence of pairwise learning rules. We are specifically interested in how the attractor landscapes of such networks become altered as a function of the strength and nature (Hebbian versus anti-Hebbian) of learning, which may have a bearing on the ability of such rules to mediate large-scale optimization problems. Through formal mathematical analysis, we show that a transition from Hebbian to anti-Hebbian learning brings about a pitchfork bifurcation that destroys convexity in the network attractor landscape. In larger scale settings, this implies that anti-Hebbian plasticity will bring about multiple stable equilibria, and such effects may be outsized at interconnection or “choke” points. Furthermore, attractor landscapes are more sensitive to slower learning rates than faster ones. These results provide insight into the types of objective functions that can be encoded via different pairwise plasticity rules.},
  archive      = {J_TNNLS},
  author       = {Lulu Gong and Xudong Chen and ShiNung Ching},
  doi          = {10.1109/TNNLS.2025.3561217},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {17491-17498},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Strong anti-hebbian plasticity alters the convexity of network attractor landscapes},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-based model-free predictive control system under the design philosophy of MPC and zeroing neurodynamics for robotic arm pose tracking. <em>TNNLS</em>, <em>36</em>(9), 17477-17490. (<a href='https://doi.org/10.1109/TNNLS.2025.3553195'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Involving both position and orientation tracking, pose tracking control for the end-effector of a redundant manipulator is a critical problem in robotic motion control. However, existing methods often suffer from dependency on model parameters and lack joint constraints. To remedy these weaknesses, this article proposes a data-based predictive tracking control of position and orientation (DBPTCPO) for redundant manipulators with undetermined parameters. Specifically, in addition to minimizing tracking error, the DBPTCPO scheme can also minimize joint velocity and acceleration to optimize energy efficiency. Furthermore, it directly handles three-level joint constraints, effectively preventing a reduction in the feasible domain of decision variables. As for the uncertain parameters of redundant manipulators, a method based on zeroing neurodynamics (ZNs) is developed to estimate the Jacobian matrix, requiring only the sensory output and control signals. Ultimately, a ZN-based solver is designed to solve the quadratic programming (QP) problem with inequality constraints derived from the DBPTCPO scheme. Necessary theoretical analyses for the control process are provided, and the higher tracking accuracy of the proposed method is numerically validated when compared with other control schemes.},
  archive      = {J_TNNLS},
  author       = {Mengrui Cao and Lin Xiao and Qiuyue Zuo and Linju Li and Xieping Gao},
  doi          = {10.1109/TNNLS.2025.3553195},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {17477-17490},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Data-based model-free predictive control system under the design philosophy of MPC and zeroing neurodynamics for robotic arm pose tracking},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Snippet-aware transformer with multiple action elements for skeleton-based action segmentation. <em>TNNLS</em>, <em>36</em>(9), 17462-17476. (<a href='https://doi.org/10.1109/TNNLS.2025.3563025'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The skeleton-based temporal action segmentation (STAS) aims to densely segment and classify human actions within lengthy untrimmed skeletal motion sequences. Current methods primarily rely on graph convolutional networks (GCNs) for intraframe spatial modeling and temporal convolutional networks (TCNs) for interframe temporal modeling to discern motion patterns. However, these approaches often overlook the distinctive nature of essential action elements across various actions, including engaged core body parts and key subactions. This oversight limits the ability to distinguish different actions within a given sequence. To address these limitations, the snippet-aware Transformer with multiple action element (ME-ST) is proposed to enhance the discrimination and segmentation among actions, which leverages intrasnippet attention along joints and sequences to identify core joints and key subactions at different scales. Specifically, in terms of the spatial domain, the intrasnippet cross-joint attention (CJA) module divides the sequence into distinct snippets and computes attention to establish intricate joint semantic relationships, emphasizing the identification of core motion joints. In terms of the temporal domain, in the encoder, the intrasnippet cross-frame attention (CFA) module segments the sequence in a blockwise expansion manner and establishes interframe relationships to highlight the most discriminative frames. In the decoder, clip-level representations at various temporal scales are initially generated through an hourglass-like sampling process, followed by the intrasnippet cross-scale attention (CSA) module to integrate the key clip information across different time scales. The performance evaluation on five public datasets demonstrates that ME-ST achieves state-of-the-art (SOTA) performance.},
  archive      = {J_TNNLS},
  author       = {Haoyu Ji and Bowen Chen and Wenze Huang and Weihong Ren and Zhiyong Wang and Honghai Liu},
  doi          = {10.1109/TNNLS.2025.3563025},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {17462-17476},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Snippet-aware transformer with multiple action elements for skeleton-based action segmentation},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust controllability of boolean control networks via dynamic programming. <em>TNNLS</em>, <em>36</em>(9), 17448-17461. (<a href='https://doi.org/10.1109/TNNLS.2025.3559207'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a novel dynamic programming approach to determine the robust controllability of Boolean control networks (BCNs) subject to stochastic disturbances. By applying Bellman’s optimality principle, we derive the recurrence relation for computing the optimal time matrix, a crucial concept characterizing robust reachability between two arbitrary states. We develop a finite-termination dynamic programming algorithm to calculate the optimal time matrix exactly and efficiently, with a rigorously certified iteration count. Sufficient and necessary conditions for robust controllability are then established based on the optimal time matrix. Furthermore, for any pair of reachable states, we construct time-optimal state feedback control laws to steer the system from the initial state to the target state, regardless of disturbances. Finally, extensive numerical experiments with biological networks validate the effectiveness of the proposed approach, showing significant improvements in computational efficiency. Additionally, we introduce a Q-learning-based algorithm and compare its performance, highlighting the advantages of our dynamic programming approach in terms of both efficiency and solution quality.},
  archive      = {J_TNNLS},
  author       = {Yakun Li and Shuhua Gao and Yiming Gao and Jianliang Wu and Jun-e Feng and Cheng Xiang},
  doi          = {10.1109/TNNLS.2025.3559207},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {17448-17461},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Robust controllability of boolean control networks via dynamic programming},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multigranularity fuzzy autoencoder for discriminative feature selection in high-dimensional data. <em>TNNLS</em>, <em>36</em>(9), 17433-17447. (<a href='https://doi.org/10.1109/TNNLS.2025.3569893'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biological datasets, such as gene expression data, often suffer from high dimensionality, containing numerous irrelevant or redundant features that can lead to overfitting and increased computational complexity. Effective feature selection is essential for reducing dimensionality, enhancing model performance, and improving interpretability. While deep neural networks, such as autoencoders, have shown promise in feature selection, their performance often diminishes when confronted with noisy data. To address these challenges, we propose a novel feature selection method that leverages multigranularity fuzzy autoencoders (FAEs). This approach integrates fuzzy theory with autoencoder models to effectively manage noise and outliers in data. The FAE method introduces a feature selection layer that approximates discrete feature selection using continuous probability distributions. To further enhance the discriminative power of the selected features, we incorporate a coarse-grained loss function designed to exploit clustering structures. In addition, intuitionistic fuzzy weights are applied to account for uncertainty by computing membership and nonmembership degrees for each sample, thereby mitigating the impact of noise and outliers. Test results validate the effectiveness of our approach, demonstrating significant improvements over existing feature selection techniques across 20 public datasets and a real-world schizophrenia dataset. These findings highlight the potential of our method to enhance classification accuracy and robustness, particularly in the context of schizophrenia research.},
  archive      = {J_TNNLS},
  author       = {Yuepeng Chen and Weiping Ding and Jiashuang Huang and Wei Zhang and Tianyi Zhou},
  doi          = {10.1109/TNNLS.2025.3569893},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {17433-17447},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Multigranularity fuzzy autoencoder for discriminative feature selection in high-dimensional data},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). (δ, ε)–K segmentation for characterizing well-clusterable sets. <em>TNNLS</em>, <em>36</em>(9), 17421-17432. (<a href='https://doi.org/10.1109/TNNLS.2025.3568478'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kleinberg (2002) introduced three axioms to formalize the behavior of clustering algorithms and presented that no clustering algorithm satisfies them. However, this result usually is inconsistent with the practical experience of clustering algorithms. In this article, we reformulate these axioms to fill the gap and verify the existence of clustering algorithms satisfying the modified axioms when the point set is well-clusterable. In particular, the concept of $(\delta ,\varepsilon)$ –K segmentation is proposed to characterize the set that has the potential to be clustered well. Then, we verify the existence and the uniqueness of $(\delta ,\varepsilon)$ –K segmentation of a set, respectively. Next, we demonstrate that the $(\delta ,\varepsilon)$ –K segmentation is compatible with K–means, Min-Cut, DBSCAN, and several clustering internal evaluation (CIE) indexes. In addition, the ratio $\delta / \varepsilon $ can be treated as the measure of not only characterizing well-clusterable sets but also of evaluating the performance of clustering results, respectively.},
  archive      = {J_TNNLS},
  author       = {Xinyu Chen and Jian Wang and Jie Yang and Chao Zhang and Dacheng Tao},
  doi          = {10.1109/TNNLS.2025.3568478},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {17421-17432},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {(δ, ε)–K segmentation for characterizing well-clusterable sets},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generalized cross-domain industrial process monitoring via adaptive discriminative transfer dictionary pair learning with attribute embedding. <em>TNNLS</em>, <em>36</em>(9), 17406-17420. (<a href='https://doi.org/10.1109/TNNLS.2025.3563618'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real industrial process data from various domains often exhibit divergent distributions, may occupy distinct feature spaces, and are occasionally unlabeled, which limits the effectiveness of conventional process monitoring methods. To address these challenges, we propose an adaptive discriminative transfer dictionary pair learning (ADTDPL) method with attribute embedding for generalized cross-domain industrial process monitoring. Specifically, this method aligns the feature spaces of source and target domains by the aligned transfer reconstruction, enabling the transfer of knowledge through a common synthetical dictionary. Concurrently, semantic attributes relevant to process knowledge are seamlessly fused into data information via attribute embedding, enhancing the transferability and interpretability of dictionary pairs. Considering the relative significance of marginal and conditional distributions, an adaptive distribution consistency function is designed to better reduce the distributional discrepancies. And the discriminative structure regularization is developed to ensure the discrimination of the dictionary pairs and their corresponding coding coefficients. Furthermore, in the absence of target domain labels, a novel selective pseudo-labeling strategy is advanced to adaptively update pseudo-labels. The superior performance of our method for cross-domain process monitoring is verified on the Tennessee Eastman platform and in practical aluminum electrolysis processes (AEPs).},
  archive      = {J_TNNLS},
  author       = {Ziqing Deng and Xiaofang Chen and Yongfang Xie and Hongliang Zhang and Weihua Gui},
  doi          = {10.1109/TNNLS.2025.3563618},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {17406-17420},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Generalized cross-domain industrial process monitoring via adaptive discriminative transfer dictionary pair learning with attribute embedding},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prescribed performance path-following control for rotor-assisted vehicles via an improved reinforcement learning mechanism. <em>TNNLS</em>, <em>36</em>(9), 17395-17405. (<a href='https://doi.org/10.1109/TNNLS.2025.3562245'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates an adaptive prescribed performance path-following control algorithm for rotor-assisted vehicles, incorporating reinforcement learning (RL) to execute energy-saving cruising missions. For obtaining a high-performance path-following controller, a concise prescribed performance control (PPC) algorithm is designed to tightly constrain the output errors within the defined boundaries, while a shifting function is introduced to solve the problem of initial condition restrictions. Furthermore, through integrating the Backstepping method and the optimal control technique, an improved RL with the form of actor–critic neural networks (AC-NNs) is proposed to offer an innovative approach to the challenges of the model uncertainties and external disturbances. In this approach, the actor NN is employed to create an appropriate control policy, while the critic NN is aimed at evaluating the cost-to-go function to modify the system action. Semi-global uniform ultimate bounded (SGUUB) stable properties of the proposed algorithm are guaranteed via the Lyapunov theory. Finally, the superiority and feasibility of the proposed algorithm are verified by two numerical experiments.},
  archive      = {J_TNNLS},
  author       = {Guoqing Zhang and Zhihao Li and Jiqiang Li and Weidong Zhang and Bin Qiu},
  doi          = {10.1109/TNNLS.2025.3562245},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {17395-17405},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Prescribed performance path-following control for rotor-assisted vehicles via an improved reinforcement learning mechanism},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unified feature selection approach for complex data based on fuzzy β-covering reduction via information granulation. <em>TNNLS</em>, <em>36</em>(9), 17380-17394. (<a href='https://doi.org/10.1109/TNNLS.2025.3558626'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection, as an important step of data analysis, is widely used in the fields of data mining, machine learning, and artificial intelligence. It can not only effectively alleviate the curse of dimensionality and improve model performance but also enhance model interpretability. In the real world, data is usually complex such as different feature types, the presence of missing values, and so on. However, most existing feature selection approaches are only capable of handling data with a single feature type. To address the issue of feature selection under the environment of complex data, this article proposes a unified feature selection (UFS) approach for complex data based on fuzzy $\beta $ -covering reduction via information granulation. To begin with, several monotonic uncertainty measures for fuzzy $\beta $ -covering are constructed from the viewpoints of algebra and information theory. Based on the proposed measures, two forward heuristic algorithms are designed for fuzzy $\beta $ -covering reduction. Meanwhile, the complex data with multiple features is represented by fuzzy $\beta $ -covering via information granulation. On this basis, a UFS approach is put forward for complex data. Finally, the effectiveness and superiority of the proposed approach are verified through a series of experiments compared with 12 state-of-the-art feature selection approaches.},
  archive      = {J_TNNLS},
  author       = {Xiongtao Zou and Jianhua Dai},
  doi          = {10.1109/TNNLS.2025.3558626},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {17380-17394},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Unified feature selection approach for complex data based on fuzzy β-covering reduction via information granulation},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multilevel distribution alignment for multisource universal domain adaptation. <em>TNNLS</em>, <em>36</em>(9), 17365-17379. (<a href='https://doi.org/10.1109/TNNLS.2025.3561401'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multisource universal domain adaptation (MSUDA) relaxes the constraints between the source and target domains, enabling the transfer of knowledge between domains without any restrictions on the number of source domains and the existence of unknown (private) categories. However, identifying the unknown samples in the target domain is extremely challenging since there are no available samples with the same label in source domains. Another immense challenge lies in extracting domain-invariant features for knowledge transfer since there are distribution discrepancies between each source and target domain. In this article, we propose the multirepresentation DA network (MRDAN) to classify the unlabeled targets by harnessing multiple source domains with nonidentical label sets. First, we propose a threshold-free conflict-based predictions with uncertainty (CPU) module, which comprehensively mines the complementary knowledge from different source domains to identify both known and unknown samples simultaneously. To accurately extract the domain-invariant features for recognizing known and unknown samples, a multilevel distribution alignment (MLDA) strategy is introduced to decrease the distribution discrepancy between multiple domains with nonidentical category spaces progressively. Finally, comprehensive experiments conducted on three commonly used datasets demonstrate the effectiveness of the proposed MRDAN in recognizing both known and unknown samples.},
  archive      = {J_TNNLS},
  author       = {Liangbo Ning and Zuowei Zhang and Weiping Ding and Dian Shao and Yining Zhu},
  doi          = {10.1109/TNNLS.2025.3561401},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {17365-17379},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Multilevel distribution alignment for multisource universal domain adaptation},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward ultralow-power neuromorphic speech enhancement with spiking-FullSubNet. <em>TNNLS</em>, <em>36</em>(9), 17350-17364. (<a href='https://doi.org/10.1109/TNNLS.2025.3566021'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speech enhancement (SE) is critical for improving speech intelligibility and quality in various audio devices. In recent years, deep learning-based methods have significantly improved SE performance, but they often come with a high computational cost, which is prohibitive for a large number of edge devices, such as headsets and hearing aids. This work proposes an ultralow-power SE system based on the brain-inspired spiking neural network (SNN) called Spiking-FullSubNet. Spiking-FullSubNet follows a full-band and subband fusioned approach to effectively capture both global and local spectral information. To enhance the efficiency of computationally expensive subband modeling, we introduce a frequency partitioning method inspired by the sensitivity profile of the human peripheral auditory system. Furthermore, we introduce a novel spiking neuron model that can dynamically control the input information integration and forgetting, enhancing the multiscale temporal processing capability of SNN, which is critical for speech denoising. Experiments conducted on the recent Intel Neuromorphic Deep Noise Suppression (N-DNS) Challenge dataset show that the Spiking-FullSubNet surpasses state-of-the-art (SOTA) methods by large margins in terms of both speech quality and energy efficiency metrics. Notably, our system won the championship of the Intel N-DNS Challenge (algorithmic track), opening up a myriad of opportunities for ultralow-power SE at the edge. Our source code and model checkpoints are publicly available at github.com/haoxiangsnr/spiking-fullsubnet},
  archive      = {J_TNNLS},
  author       = {Xiang Hao and Chenxiang Ma and Qu Yang and Jibin Wu and Kay Chen Tan},
  doi          = {10.1109/TNNLS.2025.3566021},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {17350-17364},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Toward ultralow-power neuromorphic speech enhancement with spiking-FullSubNet},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-correlation-guided anchor learning for scalable incomplete multi-view clustering. <em>TNNLS</em>, <em>36</em>(9), 17336-17349. (<a href='https://doi.org/10.1109/TNNLS.2025.3562297'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficiently learning informative yet compact representations from heterogeneous data remains challenging in incomplete multi-view clustering (IMC). The prevalent resource-efficient IMC models excel in constructing small-size anchors for fast similarity learning and data partition. However, existing anchor-based methods still suffer from shared deficiencies: 1) unstable and less informative anchor generation by random anchor selection or clueless learning and 2) imbalanced coherence and versatility capabilities of the learned anchors among different views. To mitigate these issues, we propose a novel dual-correlation-guided anchor learning (DCGA) method for scalable IMC, which learns informative anchor spaces to simultaneously incorporate both intra-view and inter-view correlations. Specifically, the intra-view anchor space is constructed and stabilized by compressing the view-specific data under the guidance of the conceived anchors as a bottleneck (A3B) strategy, with a strict theoretic analysis. Importantly, we, for the first time, build an unsupervised anchor learning scheme for incomplete multi-view data under the guidance of the bottleneck of information flow with the well-defined IB principle. As such, our model can simultaneously eliminate information redundancy and preserve the versatile knowledge derived from each view. Moreover, to endow the coherence of the learned anchors, an informative anchor constraint (IAC) is imposed to align the anchor spaces across different views. Extensive experiments on seven datasets against 11 state-of-the-art IMC methods validate the effectiveness and efficiency of our method. Code is available at https://github.com/DarrenZZhang/TNNLS25-DCGA},
  archive      = {J_TNNLS},
  author       = {Wen-Jue He and Zheng Zhang and Xiaofeng Zhu},
  doi          = {10.1109/TNNLS.2025.3562297},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {17336-17349},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Dual-correlation-guided anchor learning for scalable incomplete multi-view clustering},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multitask causal contrastive learning. <em>TNNLS</em>, <em>36</em>(9), 17322-17335. (<a href='https://doi.org/10.1109/TNNLS.2025.3555683'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multitask learning (MTL) aims to improve the performance of multiple tasks by sharing knowledge among multiple different tasks, which has attracted increasing interest and shown success in various fields. However, MTL often suffers from negative transfer since the model may utilize useless features and face interference among tasks’ optimization objectives. The utilization of useless features can be attributed to the confounding factors in multitask features, while the interference among tasks’ optimization objectives is due to inadequate measurement of the relationship among tasks. This article proposes a novel multitask causal contrastive learning (MT-CCL) approach to address the above problem. First, we propose a multitask causal inference method, which removes the confounding factors in features via task-aware causal intervention (TACI) and measures the relationship among tasks from a novel causal perspective by quantifying the intertask causal affinity. Then, we build a dual contrastive learning objective to help the model better learn useful features via intratask contrast (Intra-TCS) and mitigate interference among tasks’ optimization objectives via intertask contrast (Inter-TCS). Experiments demonstrate that MT-CCL achieves improved performance over state-of-the-art methods on Multi-MNIST, NYU-v2, CityScapes, and CelebA, verifying the effectiveness of intertask causal affinity.},
  archive      = {J_TNNLS},
  author       = {Chaoyang Li and Heyan Chai and Yan Jia and Ning Hu and Qing Liao},
  doi          = {10.1109/TNNLS.2025.3555683},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {17322-17335},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Multitask causal contrastive learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Broad-ESN based on radical activation function for predicting time series with multiple variables. <em>TNNLS</em>, <em>36</em>(9), 17310-17321. (<a href='https://doi.org/10.1109/TNNLS.2025.3563937'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multidimensional time series (MTS) has the unique characteristics of multidimensionality and multifeature, so it becomes particularly important when choosing a prediction model. Therefore, this article proposes a novel broad echo state network (Broad-ESN) based on radical activation function (RB-ESN). First, a radical activation function is proposed to solve the problem of gradient disappearing in the iterative process and is more conducive to dealing with complex data patterns. Second, the sliding window is used to extract the features of MTS. The number of reservoirs is determined by the number of features. Third, by using Cubic chaotic mapping to initialize the pied kingfisher optimizer (PKO) population, the search space can be effectively expanded, and high-quality random sequences can be generated. Then, the exponential spiral equation is used to optimize the position update equation of the pied kingfisher, which solves the problem of local optimization. Finally, the results show that the model proposed in this article is significantly superior to other models in forecasting performance, with high prediction accuracy and low error.},
  archive      = {J_TNNLS},
  author       = {Yuanpeng Gong and Shuxian Lun and Ming Li},
  doi          = {10.1109/TNNLS.2025.3563937},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {17310-17321},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Broad-ESN based on radical activation function for predicting time series with multiple variables},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightweight and fast time-series anomaly detection via point-level and sequence-level reconstruction discrepancy. <em>TNNLS</em>, <em>36</em>(9), 17295-17309. (<a href='https://doi.org/10.1109/TNNLS.2025.3565807'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised time-series anomaly detection (TSAD) aims to identify anomalies in industrial sensing signals to ensure production safety. As Industry 4.0 emerges, TSAD deployment must migrate from resource-rich cloud to resource-limited edges for real-time and fine-grained control. In this case, it raises new targets with high accuracy, high timeliness, and low consumption for TSAD. However, existing models focus solely on achieving high accuracy by building neural networks with deep structures and large parameters. Consequently, these models demand prohibitive training durations and computational overhead, which makes them unsuitable for edge deployment. To solve this issue, an unsupervised lightweight and fast TSAD model, namely, LFTSAD, is proposed via point-level and sequence-level reconstruction discrepancy in this article. First, to achieve high timeliness and low consumption, LFTSAD uses two two-layer multilayer perceptron networks (MLPs) to construct a lightweight contrastive architecture with few parameters. Second, leveraging the lightweight architecture, a dual-branch reconstruction network is designed to generate corresponding reconstruction discrepancies from point-level and sequence-level perspectives. Finally, a novel anomaly scoring scheme is designed to combine point-level and sequence-level reconstruction discrepancies for more accurate anomaly detection. To the best of our knowledge, this is the first work to develop a lightweight All-MLP-based TSAD model for resource-limited edge devices. Extensive experiments demonstrate that LFTSAD is 3–10 times faster in timeliness, consumes only 1/2 of the resources, and achieves accuracy that is either comparable to or superior to several deep SOTA models. The source code of LFTSAD is here https://github.com/infogroup502/LFTSAD},
  archive      = {J_TNNLS},
  author       = {Lei Chen and Jiajun Tang and Ying Zou and Xuxin Liu and Xingquan Xie and Guangyang Deng},
  doi          = {10.1109/TNNLS.2025.3565807},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {17295-17309},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Lightweight and fast time-series anomaly detection via point-level and sequence-level reconstruction discrepancy},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Boosting memory efficiency in transfer learning for high-resolution medical image classification. <em>TNNLS</em>, <em>36</em>(9), 17280-17294. (<a href='https://doi.org/10.1109/TNNLS.2025.3569797'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The success of large-scale pretrained models has established fine-tuning as a standard method for achieving significant improvements in downstream tasks. However, fine-tuning the entire parameter set of a pretrained model is costly. Parameter-efficient transfer learning (PETL) has recently emerged as a cost-effective alternative for adapting pretrained models to downstream tasks. Despite its advantages, the increasing model size and input resolution present challenges for PETL, as the training memory consumption is not reduced as effectively as the parameter usage. In this article, we introduce fine-grained prompt tuning plus (FPT+), a PETL method designed for high-resolution medical image classification, which significantly reduces the training memory consumption compared to other PETL methods. FPT+ performs transfer learning by training a lightweight side network and accessing pretrained knowledge from a large pretrained model (LPM) through fine-grained prompts and fusion modules. Specifically, we freeze the LPM of interest and construct a learnable lightweight side network. The frozen LPM processes high-resolution images to extract fine-grained features, while the side network employs corresponding downsampled low-resolution images to minimize memory usage. To enable the side network to leverage pretrained knowledge, we propose fine-grained prompts and fusion modules, which collaborate to summarize information through the LPM’s intermediate activations. We evaluate FPT+ on eight medical image datasets of varying sizes, modalities, and complexities. Experimental results demonstrate that FPT+ outperforms other PETL methods, using only 1.03% of the learnable parameters and 3.18% of the memory required for fine-tuning an entire ViT-B model. Our code is available https://github.com/YijinHuang/FPT.},
  archive      = {J_TNNLS},
  author       = {Yijin Huang and Pujin Cheng and Roger Tam and Xiaoying Tang},
  doi          = {10.1109/TNNLS.2025.3569797},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {17280-17294},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Boosting memory efficiency in transfer learning for high-resolution medical image classification},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Grouped vector autoregression reservoir computing based on randomly distributed embedding for multistep-ahead prediction. <em>TNNLS</em>, <em>36</em>(9), 17265-17279. (<a href='https://doi.org/10.1109/TNNLS.2025.3553060'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an efficient recurrent neural network (RNN), reservoir computing (RC) has achieved various applications in time-series forecasting. Nevertheless, a poorly explained phenomenon remains as to why the RC and deep RCs succeed in handling time-series prediction despite completely randomized weights. This study tries to generate a grouped vector autoregressive RC (GVARC) time-series forecasting model based on the randomly distributed embedding (RDE) theory. In RDE-GVARC, the deep structures are constructed by multiple GVARCs, which makes the established RDE-GVARC evolve into a deterministic deep RC model with few hyperparameters. Then, the spatial output information of the GVARC is mapped into the future temporal states of an output variable based on RDE equations. The main advantages of the RDE-GVARC can be summarized as follows: 1) RDE-GVARC solves the problems of uncertainty in the weight matrix and difficulty in large-scale parameter selection in the input and hidden layers of deep RCs; 2) the GVARC can avoid massive deep RC hyperparameter design and make the design of deep RC more straightforward and effective; and 3) the proposed RDE-GVARC shows good performance, strong stability, and robustness in several chaotic and real-world sequences for multistep-ahead prediction. The simulating results confirm that the RDE-GVARC not only outperforms some recently deep RCs and RNNs, but also maintains the rapidity of RC with an interpretable structure.},
  archive      = {J_TNNLS},
  author       = {Heshan Wang and Zhepeng Wang and Mingyuan Yu and Jing Liang and Jinzhu Peng and Yaonan Wang},
  doi          = {10.1109/TNNLS.2025.3553060},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {17265-17279},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Grouped vector autoregression reservoir computing based on randomly distributed embedding for multistep-ahead prediction},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive noise-learning differential neural solution for time-dependent equality-constrained quadratic optimization. <em>TNNLS</em>, <em>36</em>(9), 17253-17264. (<a href='https://doi.org/10.1109/TNNLS.2025.3561415'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article first proposes an adaptive noise-learning differential neural solution (ANLDNS) model, which is able to simultaneously solve the time-dependent equality-constrained quadratic optimization (TD-ECQO) problem and effectively cope with noise disturbances during the solving process. The incorporated noise learning mechanism is designed to enhance the robustness of the ANLDNS model, which is achieved by learning the variation tendency of the involved noise disturbances. Furthermore, the convergence performance and noise-learning capacity of the ANLDNS model are substantiated with theoretical proofs. Finally, the time-dependent numerical examples and an application to the control of a redundant robot are provided to demonstrate the preeminent performance and practicability of the proposed model compared with existing state-of-the-art methods.},
  archive      = {J_TNNLS},
  author       = {Ying Liufu and Long Jin and Shuai Li},
  doi          = {10.1109/TNNLS.2025.3561415},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {17253-17264},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Adaptive noise-learning differential neural solution for time-dependent equality-constrained quadratic optimization},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UBG: An unreal BattleGround benchmark with object-aware hierarchical proximal policy optimization. <em>TNNLS</em>, <em>36</em>(9), 17239-17252. (<a href='https://doi.org/10.1109/TNNLS.2025.3567001'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The deep reinforcement learning (DRL) has made significant progress in various simulation environments. However, applying DRL methods to real-world scenarios poses certain challenges due to limitations in visual fidelity, scene complexity, and task diversity within existing environments. To address limitations and explore the potential ability of DRL, we developed a 3-D open-world first-person shooter (FPS) game called Unreal BattleGround (UBG) using the unreal engine (UE). UBG provides a realistic 3-D environment with variable complexity, random scenes, diverse tasks, and multiple scene interaction methods. This benchmark involves far more complex state-action spaces than classic pseudo-3-D FPS games (e.g., ViZDoom), making it challenging for DRL to learn human-level decision sequences. Then, we propose the object-aware hierarchically proximal policy optimization (OaH-PPO) method in the UBG. It involves a two-level hierarchy, where the high-level controller is tasked with learning option control, and the low-level workers focus on mastering subtasks. To boost the learning of subtasks, we propose three modules: an object-aware module for extracting depth detection information from the environment, potential-based intrinsic reward shaping for efficient exploration, and annealing imitation learning (IL) to guide the initialization. Experimental results have demonstrated the broad applicability of the UBG and the effectiveness of the OaH-PPO. We will release the code of the UBG and OaH-PPO after publication.},
  archive      = {J_TNNLS},
  author       = {Longyu Niu and Baihui Li and Xingjian Fan and Hao Fang and Jun Li and Junliang Xing and Jun Wan and Zhen Lei},
  doi          = {10.1109/TNNLS.2025.3567001},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {17239-17252},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {UBG: An unreal BattleGround benchmark with object-aware hierarchical proximal policy optimization},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Factorization-based broad learning system with time-dependent structure. <em>TNNLS</em>, <em>36</em>(9), 17227-17238. (<a href='https://doi.org/10.1109/TNNLS.2025.3567757'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In response to the increasing complexity of tasks in artificial intelligence, broad learning systems (BLSs) have emerged as essential tools, especially given the limitations of deep neural networks, such as their extensive training and computational demands. This study addresses the computational inefficiencies and numerical instabilities inherent in traditional BLS when handling complex tasks in dynamic environments. To mitigate these challenges, we propose an enhanced version of BLS incorporating QR factorization (QRF), referred to as QRBLS, which is known for improving numerical stability. This framework replaces the traditional method of computing output weights, which typically relies on the Moore-Penrose pseudoinverse. The primary contribution of this article is the integration of QRF into the BLS architecture, thereby improving stability when processing large-scale datasets. QRBLS also features a dynamic updating mechanism that adjusts model parameters efficiently with new data, enabling continuous learning without the need for full-model re-evaluation. In addition, a time-dependent structure (TDS) enhances the model’s responsiveness to temporal data changes, increasing its utility in dynamic environments. Validation through numerical experiments demonstrated that QRBLS outperformed traditional BLS, exhibiting superior stability and adaptability in handling data anomalies and rapid updates. The integration of QRF and TDS significantly improves the adaptability and computational efficiency of BLS, providing a robust solution for large scale and dynamic AI applications. QRBLS effectively addresses challenges related to numerical instability and continuous learning, offering practical improvements in real-world settings.},
  archive      = {J_TNNLS},
  author       = {Chen Li and Zeyi Liu and Xiao He and Pengyu Han},
  doi          = {10.1109/TNNLS.2025.3567757},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {17227-17238},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Factorization-based broad learning system with time-dependent structure},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving the transferability of adversarial examples by feature augmentation. <em>TNNLS</em>, <em>36</em>(9), 17212-17226. (<a href='https://doi.org/10.1109/TNNLS.2025.3563855'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial transferability is a significant property of adversarial examples, which renders the adversarial example capable of attacking unknown models. However, the models with different architectures on the same task would concentrate on different information, which weakens adversarial transferability. To enhance the adversarial transferability, input transformation-based attacks perform random transformation over input to find a better result that can resist such transformations, but these methods ignore the model discrepancy; ensemble attacks fuse multiple models to shrink the search space to ensure that the found adversarial examples work on these models, but ensemble attacks are resource-intensive. In this article, we propose a simple but effective feature augmentation attack (FAUG) method to improve adversarial transferability. We dynamically add random noise to intermediate features of the target model during the generation of adversarial examples, thereby avoiding overfitting the target model. Specifically, we first explore the noise tolerance of the model and disclose the discrepancy under different layers and noise strengths. Then, based on that analysis, we devise a dynamic random noise generation method, which determines noise strength according to the produced features in the mini-batch. Finally, we exploit the gradient-based attack algorithm on featureaugmented models, resulting in better adversarial transferability without introducing extra computation costs. Extensive experiments conducted on the ImageNet dataset across CNN and Transformer models corroborate the efficacy of our method, e.g., we achieve improvement of +30.67% and +5.57% on input transformation-based attacks and combination methods, respectively.},
  archive      = {J_TNNLS},
  author       = {Donghua Wang and Wen Yao and Tingsong Jiang and Xiaohu Zheng and Junqi Wu},
  doi          = {10.1109/TNNLS.2025.3563855},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {17212-17226},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Improving the transferability of adversarial examples by feature augmentation},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AdaptiveFL: Communication-adaptive federated learning under dynamic bandwidth. <em>TNNLS</em>, <em>36</em>(9), 17199-17211. (<a href='https://doi.org/10.1109/TNNLS.2025.3560656'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is a distributed machine learning paradigm that enables heterogeneous devices to train a model collaboratively. Recognizing communication as a bottleneck in FL, existing communication-efficient solutions, e.g., HeteroFL and LotteryFL, etc., utilize gradient sparsification to reduce communication costs. However, existing solutions fail to address the dynamic bandwidth issue in which the bandwidth of each client is constantly changing throughout the training process. In this article, we propose AdaptiveFL, a communication-adaptive FL framework, considering the dynamic constraints of bandwidth. The design of AdaptiveFL follows two key steps: 1) in each round, each device selects a best-fit sub-model for communication per currently available bandwidth; and 2) to guarantee the performance of each sub-model sent under dynamic bandwidth constraints, AdaptiveFL employs a local training method that enables each device to train a “tailorable” local model, which can be tailored to any sparsity with competitive accuracy. We compare AdaptiveFL with several communication-efficient SOTA methods and demonstrate that AdaptiveFL outperforms other baselines by a large margin.},
  archive      = {J_TNNLS},
  author       = {Guozhi Liu and Weiwei Lin and Tiansheng Huang and Fang Shi and Wentai Wu and Li Shen},
  doi          = {10.1109/TNNLS.2025.3560656},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {17199-17211},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {AdaptiveFL: Communication-adaptive federated learning under dynamic bandwidth},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A semantic change detection network based on boundary detection and task interaction for high-resolution remote sensing images. <em>TNNLS</em>, <em>36</em>(9), 17184-17198. (<a href='https://doi.org/10.1109/TNNLS.2025.3570425'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic change detection (CD) not only helps pinpoint the locations where changes occur, but also identifies the specific types of changes in land cover and land use. Currently, the mainstream approach for semantic CD (SCD) decomposes the task into semantic segmentation (SS) and CD tasks. Although these methods have achieved good results, they do not consider the incentive effect of task correlation on the entire model. Given this issue, this article further elucidates the SCD task through the lens of multitask learning theory and proposes a semantic change detection network based on boundary detection and task interaction (BT-SCD). In BT-SCD, the boundary detection (BD) task is introduced to enhance the correlation between the SS task and the CD task in SCD, thereby promoting positive reinforcement between SS and CD tasks. Furthermore, to enhance the communication of information between the SS and CD tasks, the pixel-level interaction strategy and the logit-level interaction strategy are proposed. Finally, to fully capture the temporal change information of the bitemporal features and eliminate their temporal dependency, a bidirectional change feature extraction module is proposed. Extensive experimental results on three commonly used datasets and a nonagriculturalization dataset (NAFZ) show that our BT-SCD achieves state-of-the-art performance. The code is available at https://github.com/TangYJ1229/BT-SCD},
  archive      = {J_TNNLS},
  author       = {Yingjie Tang and Shou Feng and Chunhui Zhao and Yongqi Chen and Zhiyong Lv and Weiwei Sun},
  doi          = {10.1109/TNNLS.2025.3570425},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {17184-17198},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A semantic change detection network based on boundary detection and task interaction for high-resolution remote sensing images},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SacFL: Self-adaptive federated continual learning for resource-constrained end devices. <em>TNNLS</em>, <em>36</em>(9), 17169-17183. (<a href='https://doi.org/10.1109/TNNLS.2025.3565827'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of end devices has led to a distributed computing paradigm, wherein on-device machine learning models continuously process diverse data generated by these devices. The dynamic nature of this data, characterized by continuous changes or data drift, poses significant challenges for on-device models. To address this issue, continual learning (CL) is proposed, enabling machine learning models to incrementally update their knowledge and mitigate catastrophic forgetting. However, the traditional centralized approach to CL is unsuitable for end devices due to privacy and data volume concerns. In this context, federated CL (FCL) emerges as a promising solution, preserving user data locally while enhancing models through collaborative updates. Aiming at the challenges of limited storage resources for CL, poor autonomy in task shift detection, and difficulty in coping with new adversarial tasks in the FCL scenario, we propose a novel FCL framework named self-adaptive federated CL (SacFL). $\rm {SacFL}$ employs an encoder–decoder architecture to separate task-robust and task-sensitive components, significantly reducing storage demands by retaining lightweight task-sensitive components for resource-constrained end devices. Moreover, $\rm {SacFL}$ leverages contrastive learning to introduce an autonomous data shift detection mechanism, enabling it to discern whether a new task has emerged and whether it is a benign task. This capability ultimately allows the device to autonomously trigger CL or attack defense strategy without additional information, which is more practical for end devices. Comprehensive experiments conducted on multiple text and image datasets, such as Cifar100 and THUCNews, have validated the effectiveness of $\rm {SacFL}$ in both class-incremental and domain-incremental scenarios. Furthermore, a demo system has been developed to verify its practicality.},
  archive      = {J_TNNLS},
  author       = {Zhengyi Zhong and Weidong Bao and Ji Wang and Jianguo Chen and Lingjuan Lyu and Wei Yang Bryan Lim},
  doi          = {10.1109/TNNLS.2025.3565827},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {17169-17183},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {SacFL: Self-adaptive federated continual learning for resource-constrained end devices},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unveiling hidden visual information: A reconstruction attack against adversarial visual information hiding. <em>TNNLS</em>, <em>36</em>(9), 17154-17168. (<a href='https://doi.org/10.1109/TNNLS.2025.3555248'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates the security vulnerabilities of adversarial example-based image encryption by executing data reconstruction (DR) attacks on encrypted images. A representative image encryption method is the adversarial visual information hiding (AVIH), which uses type-I adversarial example training to protect gallery datasets used in image recognition tasks. In the AVIH method, the type-I adversarial example approach creates images that appear completely different but are still recognized by machines as the original ones. Additionally, the AVIH method can restore encrypted images to their original forms using a predefined private key generative model. For the best security, assigning a unique key to each image is recommended; however, storage limitations may necessitate some images sharing the same key model. This raises a crucial security question for AVIH: How many images can safely share the same key model without being compromised by a DR attack? To address this question, we introduce a dual-strategy DR attack against the AVIH encryption method by incorporating 1) generative-adversarial loss and 2) augmented identity loss, which prevent DR from overfitting—an issue akin to that in machine learning. Our numerical results validate this approach through image recognition and re-identification benchmarks, demonstrating that our strategy can significantly enhance the quality of reconstructed images, thereby requiring fewer key-sharing encrypted images. The source code to reproduce the results will be available in https://github.com/jonggyujang0123/Hiding_person.},
  archive      = {J_TNNLS},
  author       = {Jonggyu Jang and Hyeonsu Lyu and Seongjin Hwang and Hyun Jong Yang},
  doi          = {10.1109/TNNLS.2025.3555248},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {17154-17168},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Unveiling hidden visual information: A reconstruction attack against adversarial visual information hiding},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nash equilibrium in multiplayer graphical games via reinforcement learning and distributed observers. <em>TNNLS</em>, <em>36</em>(9), 17142-17153. (<a href='https://doi.org/10.1109/TNNLS.2025.3570111'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiplayer game theory has been widely studied, with most existing research focusing on fully connected network structures. In contrast, multiplayer graphical games consider sparser communication topologies, making them more practical for large-scale systems. This article, based on a reinforcement learning (RL) method, investigates the problem of computing Nash equilibrium (NE) strategies in a class of multiplayer graphical games where the system is influenced by an external system. To estimate the unknown states of the external system, we propose a distributed adaptive observer and prove that its observation error asymptotically converges to zero. Furthermore, we derive a range of discount factor values that preserve system stability. To solve for the NE strategy, we develop an off-policy algorithm integrated with the distributed adaptive observer for policy evaluation. To enhance convergence speed, we introduce a distributed policy improvement mechanism, which ensures policy convergence to equilibrium while maintaining system stability. The effectiveness of the proposed algorithm is validated through simulations on a voltage synchronization system.},
  archive      = {J_TNNLS},
  author       = {Gaofu Yang and Ruizhuo Song and Qing Li and Lina Xia},
  doi          = {10.1109/TNNLS.2025.3570111},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {17142-17153},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Nash equilibrium in multiplayer graphical games via reinforcement learning and distributed observers},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bi-PIL: Bidirectional gradient-free learning scheme for multilayer neural networks. <em>TNNLS</em>, <em>36</em>(9), 17128-17141. (<a href='https://doi.org/10.1109/TNNLS.2025.3564654'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Training deep neural networks typically relies on gradient descent learning schemes, which is usually time-consuming, and the design of complex network architectures is often intractable. In this article, we explore the building of multilayer neural networks based on an efficient gradient-free learning scheme offering a potential solution to the architectural design. The proposed learning scheme encompasses both forward and backward training (BT) processes. In the forward process, the pseudoinverse learning (PIL) algorithm is employed to train a multilayer neural network, in which the network is dynamically constructed leveraging a layer-by-layer greedy strategy, enabling the automatic determination of the architecture across different hierarchies in a data-driven manner. The network architecture and connection weights determined in the forward training (FT) process are shared with the backward process which also conducts gradient-free learning to update the connection weights. After the bidirectional learning, a neural network comprising two twin subnetworks is obtained, and the fused features of subnetworks are used as inputs for downstream tasks. Comprehensive experiments and detailed analyses demonstrate the effectiveness and superiority of the proposed learning scheme.},
  archive      = {J_TNNLS},
  author       = {Ke Wang and Binghong Liu and Pandi Liu and Yungao Shi and Ping Guo and Yafei Li and Mingliang Xu},
  doi          = {10.1109/TNNLS.2025.3564654},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {17128-17141},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Bi-PIL: Bidirectional gradient-free learning scheme for multilayer neural networks},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parallel multistep evaluation with efficient data utilization for safe neural critic control and its application to orbital maneuver systems. <em>TNNLS</em>, <em>36</em>(9), 17114-17127. (<a href='https://doi.org/10.1109/TNNLS.2025.3570716'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-driven methods have significantly advanced optimal learning control, but some approaches overlook systematic considerations of data utilization, including safety, efficiency, and error accumulation. To address the neglects in safe neural critic control, this article introduces a parallel multistep evaluation mechanism that combines data from the system interaction with data generated by data-driven models. Based on this evaluation mechanism, we propose a novel parallel multistep Q-learning algorithm that enhances data utilization efficiency and mitigates the error accumulation. Furthermore, we formulate a novel control barrier function (CBF) to ensure safety during learning and control processes, which is capable of dealing with asymmetric constraints and adjusting the constraint strength. In addition, the analysis reveals that multistep information introduced by data-driven models influences the learning performance of actor–critic neural networks (NNs). Finally, parallel multistep Q-learning, which makes use of data in aspects of safety, efficiency, and error bounds, is validated within an orbital maneuver system.},
  archive      = {J_TNNLS},
  author       = {Jiangyu Wang and Ding Wang and Jin Ren and Derong Liu and Junfei Qiao},
  doi          = {10.1109/TNNLS.2025.3570716},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {17114-17127},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Parallel multistep evaluation with efficient data utilization for safe neural critic control and its application to orbital maneuver systems},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modumer: Modulating transformer for image restoration. <em>TNNLS</em>, <em>36</em>(9), 17099-17113. (<a href='https://doi.org/10.1109/TNNLS.2025.3561924'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image restoration aims to recover clean images from degraded counterparts. While Transformer-based approaches have achieved significant advancements in this field, they are limited by high complexity and their inability to capture omni-range dependencies, hindering their overall performance. In this work, we develop Modumer for effective and efficient image restoration by revisiting the Transformer block and modulation design, which processes input through a convolutional block and projection layers and fuses features via elementwise multiplication. Specifically, within each unit of Modumer, we integrate the cascaded modulation design with the downsampled Transformer block to build the attention layers, enabling omni-kernel modulation and mapping inputs into high-dimensional feature spaces. Moreover, we introduce a bioinspired parameter-sharing mechanism to attention layers, which not only enhances efficiency but also improves performance. In addition, a dual-domain feed-forward network (DFFN) strengthens the representational power of the model. Extensive experimental evaluations demonstrate that the proposed Modumer achieves state-of-the-art performance across ten datasets in five single-degradation image restoration tasks, including image motion deblurring, deraining, dehazing, desnowing, and low-light enhancement. Moreover, the model exhibits strong generalization capabilities in all-in-one image restoration tasks. Additionally, it demonstrates competitive performance in composite-degradation image restoration.},
  archive      = {J_TNNLS},
  author       = {Yuning Cui and Mingyu Liu and Wenqi Ren and Alois Knoll},
  doi          = {10.1109/TNNLS.2025.3561924},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {17099-17113},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Modumer: Modulating transformer for image restoration},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MRHGNN: Enhanced multimodal relational hypergraph neural network for synergistic drug combination forecasting. <em>TNNLS</em>, <em>36</em>(9), 17086-17098. (<a href='https://doi.org/10.1109/TNNLS.2025.3553385'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drug combinations are vital for treating complex diseases and advancing drug development, but accurately identifying synergistic combinations remains a significant challenge. Although graph neural networks (GNNs) have recently been used to predict drug combinations, the complex interactions between drugs and multimodal data (e.g., target proteins) and the prevalent high-order relations among drugs have yet to be fully exploited. The hypergraph offers a natural methodology for modeling high-order relations and provides profound insights for multimodal fusion. Here, we introduce the multimodal relational hypergraph neural network (MRHGNN), a novel framework for predicting synergistic drug combinations. Specifically, we design a dual-channel architecture to capture the physicochemical attributes of drugs and their interactive synergies, thereby facilitating the generation of multimodal drug representations. To obtain comprehensive representations of drugs, we use an attention mechanism to explore complementarity among multimodal drug embeddings. In addition, the unified framework jointly learns primary and self-supervised learning tasks, fostering a robust predictive capability. Experimental results demonstrate that MRHGNN accurately predicts synergistic drug combinations, and the effectiveness of the dual-channel setup and motif structures has been validated through ablation studies. Further literature searches illustrate that our model holds significant promise in accelerating the discovery of novel synergistic drug combinations, particularly in cancer therapy. This study not only introduces a novel computational tool but also paves the way for advanced methodologies in drug discovery and development.},
  archive      = {J_TNNLS},
  author       = {Mengjie Chen and Ming Zhang and Guiying Yan and Guanghui Wang and Cunquan Qu},
  doi          = {10.1109/TNNLS.2025.3553385},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {17086-17098},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {MRHGNN: Enhanced multimodal relational hypergraph neural network for synergistic drug combination forecasting},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated aggregation with interlayer personalized contribution: Preference-based optimization between performance and privacy. <em>TNNLS</em>, <em>36</em>(9), 17071-17085. (<a href='https://doi.org/10.1109/TNNLS.2025.3552206'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, due to the different distribution of data for each user, many personalized federated learning (PFL) methods have emerged to meet the personalized needs of different users. However, existing methods have two problems: 1) in the aggregation process, the contribution between the internal layers of the client model is not considered and 2) it is difficult to match the quantitative weight information of both user privacy protection and performance with their qualitative preferences during the training process. Therefore, we first propose a framework for federated aggregation with interlayer personalized contribution named FedIPC, which completes model aggregation based on the contribution of internal layers and improves client model performance. Based on the above framework, we design a multiobjective federated optimization method based on adaptive preference indicators named FedAPI-nondominated sorting genetic algorithm II (NSGA-II). This method can match quantitative weight with qualitative user preferences and adaptively select for Pareto optimal solutions during the optimization process. Extensive experiments on two image datasets and a tabular dataset show that our proposed method not only accelerates model convergence, but also achieves good improvements in model performance. In addition, our proposed method can accurately match the qualitative preferences of users, balancing the performance of the model and privacy protection based on preferences.},
  archive      = {J_TNNLS},
  author       = {Xiaoting Sun and Zhong Li and Changjun Jiang},
  doi          = {10.1109/TNNLS.2025.3552206},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {17071-17085},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Federated aggregation with interlayer personalized contribution: Preference-based optimization between performance and privacy},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Turing instability and hopf bifurcation in 2-D coupled cellular neural networks. <em>TNNLS</em>, <em>36</em>(9), 17059-17070. (<a href='https://doi.org/10.1109/TNNLS.2025.3570972'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dynamics of 2-D two-grid coupled cellular neural networks (CNNs) are considered. Assuming the boundary conditions of zero-flux type, the linearized model is analyzed by using the decoupling method, which is described as matrix operations, such as the Kronecker product and Kronecker sum. Then, the local stability of the zero equilibrium related to system parameters is studied. Based on the results, the sufficient conditions that induce Turing instability are derived. Furthermore, as a special kind of Turing patterns, the occurrence conditions for Hopf bifurcations are considered. In addition, the global stability of the zero equilibrium is analyzed by constructing proper Lyapunov functions. Finally, numerical simulations are given to illustrate the theoretical results.},
  archive      = {J_TNNLS},
  author       = {Xinhui Wang and Zunxian Li},
  doi          = {10.1109/TNNLS.2025.3570972},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {17059-17070},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Turing instability and hopf bifurcation in 2-D coupled cellular neural networks},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A real-time framework for EEG signal decoding with graph neural networks and reinforcement learning. <em>TNNLS</em>, <em>36</em>(9), 17047-17058. (<a href='https://doi.org/10.1109/TNNLS.2025.3558171'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain–computer interfaces (BCIs) rely on accurately decoding electroencephalography (EEG) motor imagery (MI) signals for effective device control. Graph neural networks (GNNs) outperform convolutional neural networks (CNNs) in this regard, by leveraging the spatial relationships between EEG electrodes through adjacency matrices. The EEG graph lottery ticket framework, EEG_GLT-Net, featuring the state-of-the-art (SOTA) EEG_GLT adjacency matrix method, has notably enhanced EEG MI signal classification, evidenced by an average accuracy of 83.95% across 20 subjects on the PhysioNet dataset. This significantly exceeds the 76.10% accuracy rate achieved using the Pearson correlation coefficient (PCC) method in the same framework. In this research, we advance the field by applying a reinforcement learning (RL) approach to the classification of EEG MI signals. Our innovative method empowers the RL agent, enabling not only the classification of EEG MI data points with higher accuracy but effective identification of EEG MI data points that are less distinct. We present the EEG_RL-Net, an enhancement of the EEG_GLT-Net framework, which incorporates the trained EEG_GCN Block from EEG_GLT-Net at an adjacency matrix density of 13.39% alongside the RL-centric dueling deep Q network (Dueling DQN) block. The EEG_RL-Net model showcases exceptional classification performance, achieving an unprecedented average accuracy of 96.40% across 20 subjects within 25 ms. This model illustrates the transformative effect of the RL in EEG MI time point classification.},
  archive      = {J_TNNLS},
  author       = {Htoo Wai Aung and Jiao Jiao Li and Yang An and Steven Weidong Su},
  doi          = {10.1109/TNNLS.2025.3558171},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {17047-17058},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A real-time framework for EEG signal decoding with graph neural networks and reinforcement learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A policy-guided reinforcement learning method for encirclement control in multiobstacle environment. <em>TNNLS</em>, <em>36</em>(9), 17034-17046. (<a href='https://doi.org/10.1109/TNNLS.2025.3566548'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of multiagent encirclement with multiobstacle collision avoidance (EMOCA) has been challenging since it is difficult to balance the tradeoff between surrounding a mobile target and avoiding obstacles simultaneously. To address the EMOCA problem, we proposed a novel policy-guided reinforcement learning (RL) method, namely, multiregulator-assisted RL for encirclement control (MRA-RLEC) which leverages the jump-start learning and curriculum learning (CL) mechanism to enhance training efficiency. MRA-RLEC divides the complex encirclement task into a sequence of subtasks, progressively increasing in difficulty. In this process, multiple regulators are utilized to adjust various training aspects, including encirclement condition, obstacle avoidance, and the transition from guide to learned policy execution. Besides, a global encirclement reward decomposition (GERD) method is presented to alleviate reward sparsity, and we design a bidirectional communication protocol to reduce communication. Extensive experiments are carried out to showcase the robustness and superiority of our method, and the practical applicability of MRA-RLEC is demonstrated through experiments conducted in the robot operating system 2 (ROS2)-based simulation platform, Gazebo, using a self-designed omnidirectional vehicle model.},
  archive      = {J_TNNLS},
  author       = {Fandi Gou and Haikuo Du and Chenyu Zhao and Yunze Cai},
  doi          = {10.1109/TNNLS.2025.3566548},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {17034-17046},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A policy-guided reinforcement learning method for encirclement control in multiobstacle environment},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SGB-net: Scalable graph broad network. <em>TNNLS</em>, <em>36</em>(9), 17019-17033. (<a href='https://doi.org/10.1109/TNNLS.2025.3552129'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the complexity and self-evolutionary property of graph data in reality, graph learning methods require both validity to represent unstructured data and scalability to adapt to evolving graphs. However, current works have representation learning limitations on optimizable graph feature space due to the bottleneck of the structure depth. Moreover, they encounter a complete retraining process when graphs evolve, especially in the case without the assistance of new labels. To address the above issues, we propose a scalable graph broad network (SGB-Net), which contains three proposed modules: the graph feature broad transformation layer (GFBT layer) for enhancing graph embedding and two update algorithms (SGB-Net-U, SGB-Net-S) for endowing scalability. The GFBT layer aims to explicitly expand the graph feature space and broadly build the model. It constructs two expandable feature spaces in various graph scales to embed graphs discriminatively. SGB-Net-U is an exploratory method designed to tackle the label-free graph incremental learning (GIL) problem by leveraging unsupervised incremental knowledge to expand graph representation. SGB-Net-S endows scalability in classical incremental learning scenarios involving labels. Benefiting from its broad construction framework, SGB-Net not only enhances graph embeddings but also seamlessly adapts and improves performance in response to graph expansion without requiring retraining. In the experiments conducted on 15 benchmark datasets, SGB-Net outperforms state-of-the-art GNNs in terms of both effectiveness and scalability.},
  archive      = {J_TNNLS},
  author       = {Yuebin Xu and C. L. Philip Chen and Mengqi Wu and Tong Zhang},
  doi          = {10.1109/TNNLS.2025.3552129},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {17019-17033},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {SGB-net: Scalable graph broad network},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Short-term residential load forecasting framework based on Spatial–Temporal fusion adaptive gated graph convolution networks. <em>TNNLS</em>, <em>36</em>(9), 17004-17018. (<a href='https://doi.org/10.1109/TNNLS.2025.3551778'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Enhancing the prediction of volatile and intermittent electric loads is one of the pivotal elements that contributes to the smooth functioning of modern power grids. However, conventional deep learning-based forecasting techniques fall short in simultaneously taking into account both the temporal dependencies of historical loads and the spatial structure between residential units, resulting in a subpar prediction performance. Furthermore, the representation of the spatial graph structure is frequently inadequate and constrained, along with the complexities inherent in Spatial–Temporal data, impeding the effective learning among different households. To alleviate those shortcomings, this article proposes a novel framework: Spatial–Temporal fusion adaptive gated graph convolution networks (STFAG-GCNs), tailored for residential short-term load forecasting (STLF). Spatial–Temporal fusion graph construction is introduced to compensate for several existing correlations where additional information are not known or unreflected in advance. Through an innovative gated adaptive fusion graph convolution (AFG-Conv) mechanism, Spatial–Temporal fusion graph convolution network (STFGCN) dynamically model the Spatial–Temporal correlations implicitly. Meanwhile, by integrating a gated temporal convolutional network (Gated TCN) and multiple STFGCNs into a unified Spatial–Temporal fusion layer, STFAG-GCN handles long sequences by stacking layers. Experimental results on real-world datasets validate the accuracy and robustness of STFAG-GCN in forecasting short-term residential loads, highlighting its advancements over state-of-the-art methods. Ablation experiments further reveal its effectiveness and superiority.},
  archive      = {J_TNNLS},
  author       = {Tong Zhang and Wenhua Jiao and Jiguo Yu and Yudou Xiong},
  doi          = {10.1109/TNNLS.2025.3551778},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {17004-17018},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Short-term residential load forecasting framework based on Spatial–Temporal fusion adaptive gated graph convolution networks},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online reinforcement learning control designs with acceleration mechanism for unknown multiagent systems through value iteration. <em>TNNLS</em>, <em>36</em>(9), 16990-17003. (<a href='https://doi.org/10.1109/TNNLS.2025.3563155'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, an online reinforcement learning (RL) control method through value iteration (VI) is developed to solve the optimal cooperative control problem for the unknown linear discrete-time multiagent systems (MASs). On the one hand, an online learning scheme with evolving policies is proposed in order to guarantee the stability of the MASs under immature policies generated by VI. Inspired by the event-triggered mechanism, the stability criterion is designed as a trigger to filter the admissible control policies, which eliminates the need to establish a monotonic value function sequence. On the other hand, an acceleration mechanism for the MASs is presented such that the convergence rate of VI can be accelerated. The relationship between the selection of the relaxation factor and the accelerated convergence process is elaborated. Simple backpropagation (BP) neural networks (NNs) are applied for the implementation. Two classical examples are introduced and simulation results are provided in order to substantiate the validity of the designed method.},
  archive      = {J_TNNLS},
  author       = {Yuan Li and Yiyan Han and Chongyang Chen and Zhigang Zeng and Jiankun Sun},
  doi          = {10.1109/TNNLS.2025.3563155},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16990-17003},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Online reinforcement learning control designs with acceleration mechanism for unknown multiagent systems through value iteration},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedSI: Federated subnetwork inference for efficient uncertainty quantification. <em>TNNLS</em>, <em>36</em>(9), 16975-16989. (<a href='https://doi.org/10.1109/TNNLS.2025.3562164'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While deep neural networks (DNNs)-based personalized federated learning (PFL) is demanding for addressing data heterogeneity and shows promising performance, existing methods for federated learning (FL) suffer from efficient systematic uncertainty quantification. The Bayesian DNNs-based PFL is usually questioned of either oversimplified model structures or high computational and memory costs. In this article, we introduce FedSI, a novel Bayesian DNNs-based subnetwork inference (SI) PFL framework. FedSI is simple and scalable by leveraging Bayesian methods to incorporate systematic uncertainties effectively. It implements a client-specific SI mechanism, selects network parameters with large variance to be inferred through posterior distributions, and fixes the rest as deterministic ones. FedSI achieves fast and scalable inference while preserving the systematic uncertainties to the fullest extent. Extensive experiments on four different benchmark datasets demonstrate that FedSI outperforms existing Bayesian and non-Bayesian FL baselines in heterogeneous FL scenarios.},
  archive      = {J_TNNLS},
  author       = {Hui Chen and Hengyu Liu and Zhangkai Wu and Xuhui Fan and Longbing Cao},
  doi          = {10.1109/TNNLS.2025.3562164},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16975-16989},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {FedSI: Federated subnetwork inference for efficient uncertainty quantification},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust unsupervised deep learning for nonblind image deconvolution with inaccurate kernels. <em>TNNLS</em>, <em>36</em>(9), 16960-16974. (<a href='https://doi.org/10.1109/TNNLS.2025.3556867'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonblind image deconvolution/deblurring aims at restoring sharp images from their noisy blurred versions using an associated blur kernel with potential inaccuracy. Current deep learning (DL) models of nonblind image deconvolution (NBID) predominantly reply on ground truth (GT) images for supervision, which restricts their applicability to certain real-world scenarios such as scientific imaging. This article proposes a fully unsupervised DL approach for NBID, utilizing a GT-free end-to-end training process that adeptly handles both measurement noise and kernel error. Specifically, in the absence of GT images, a self-reconstruction loss is proposed to handle measurement noise, by effectively emulating its supervised counterpart. Recognizing the likely occurrence of kernel error during both training and testing data, we introduce a self-ensemble loss function and an ensemble inference scheme, anchored by a phase-keeping kernel perturbation strategy. Furthermore, a shifting mechanism is integrated so as to the loss functions to resolve the shift ambiguity caused by kernel error. Extensive experiments show the superiority of our proposed approach over existing unsupervised NBID methods, as well as its competitive performance against some of the recent supervised methods.},
  archive      = {J_TNNLS},
  author       = {Xinran Qin and Yuhui Quan and Zhuojie Chen and Hui Ji},
  doi          = {10.1109/TNNLS.2025.3556867},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16960-16974},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Robust unsupervised deep learning for nonblind image deconvolution with inaccurate kernels},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Time-series contrastive learning against false negatives and class imbalance. <em>TNNLS</em>, <em>36</em>(9), 16946-16959. (<a href='https://doi.org/10.1109/TNNLS.2025.3568387'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-supervised contrastive learning (SCL) has driven significant advancements in time-series representation learning. While recent studies built upon the information noise contrastive estimation (InfoNCE) loss framework focus on constructing appropriate positives and negatives, we theoretically analyze and identify two overlooked issues inherent in this approach: false negatives and class imbalance. To address these challenges, we propose a simple yet effective modification based on the SimCLR framework, integrating a multi-instance discrimination task to mitigate false negatives. Additionally, we introduce a graph-based interactive projection head and semantic consistency regularization, which enhances minority-class representations with minimal annotation cost. Extensive experiments on six real-world time-series datasets demonstrate that our approach consistently outperforms state-of-the-art methods, achieving up to 3.96% higher accuracy and 10.73% improvement in $F1$ -score, particularly benefiting imbalanced data scenarios.},
  archive      = {J_TNNLS},
  author       = {Xiyuan Jin and Jing Wang and Xiaoyu Ou and Lei Liu and Youfang Lin},
  doi          = {10.1109/TNNLS.2025.3568387},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16946-16959},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Time-series contrastive learning against false negatives and class imbalance},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge-guided label distribution calibration for federated affective computing. <em>TNNLS</em>, <em>36</em>(9), 16931-16945. (<a href='https://doi.org/10.1109/TNNLS.2025.3568458'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The federated learning (FL) paradigm can significantly solve the rising public concern about data privacy in affective computing. However, conventional FL methods perform poorly due to the uniqueness of the task, as the personalized emotion data vary from client to client. To resolve the privacy-utility paradox, this work proposes a framework that largely improves federated affective computing (FAC) via calibrating the global feature space and communicating privacy-agnostic auxiliary information. The framework consists of two components: first, an emotion hemisphere (EH) representation structure is proposed, which utilizes emotional prior knowledge to unify the emotion global feature space of different clients. Second, the server uses the normalized parameter importance matrix to guide the model aggregation. It retains crucial parameters for individual local models, thereby alleviating the slow convergence problem in the global model caused by the skewed label distribution. The proposed framework yields significant performance gains, and extensive experiments on three emotion datasets demonstrate the effectiveness and the practicality of our approach.},
  archive      = {J_TNNLS},
  author       = {Zixin Zhang and Fan Qi and Changsheng Xu},
  doi          = {10.1109/TNNLS.2025.3568458},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16931-16945},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Knowledge-guided label distribution calibration for federated affective computing},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Chest X-ray visual saliency modeling: Eye-tracking dataset and saliency prediction model. <em>TNNLS</em>, <em>36</em>(9), 16920-16930. (<a href='https://doi.org/10.1109/TNNLS.2025.3564292'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radiologists’ eye movements during medical image interpretation reflect their perceptual-cognitive processes of diagnostic decisions. The eye movement data can be modeled to represent clinically relevant regions in a medical image and potentially integrated into an artificial intelligence (AI) system for automatic diagnosis in medical imaging. In this article, we first conduct a large-scale eye-tracking study involving 13 radiologists interpreting 191 chest X-ray (CXR) images, establishing a best-of-its-kind CXR visual saliency benchmark. We then perform analysis to quantify the reliability and clinical relevance of saliency maps (SMs) generated for CXR images. We develop CXR image saliency prediction method (CXRSalNet), a novel saliency prediction model that leverages radiologists’ gaze information to optimize the use of unlabeled CXR images, enhancing training and mitigating data scarcity. We also demonstrate the application of our CXR saliency model in enhancing the performance of AI-powered diagnostic imaging systems.},
  archive      = {J_TNNLS},
  author       = {Jianxun Lou and Huasheng Wang and Xinbo Wu and John Cho Hui Ng and Richard White and Kaveri A. Thakoor and Padraig Corcoran and Ying Chen and Hantao Liu},
  doi          = {10.1109/TNNLS.2025.3564292},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16920-16930},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Chest X-ray visual saliency modeling: Eye-tracking dataset and saliency prediction model},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scale-wise semantic alignment enhanced multigrained adaptive fusion for virtual try-on. <em>TNNLS</em>, <em>36</em>(9), 16909-16919. (<a href='https://doi.org/10.1109/TNNLS.2025.3554826'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image-based virtual try-on aims to fit garments onto a target person accurately and naturally while preserving the textural details of the garment. Inspired by the dynamic perception process of the human visual system, which transitions from global perception to local details, we propose a novel multigrained adaptive fusion network for virtual try-on framework named MA-VITON. MA-VITON precisely aligns clothing semantic features with human body parts across different scales, reduces unrealistic textures caused by garment distortion, and employs coarse-to-fine clothing features to progressively guide the generation of try-on results. To achieve this, we introduce a scale-wise semantic alignment (SSA) module that extracts local features of clothing and the target person at various scales using flexible query strategies. It learns semantic correspondences between garments and the human body in the latent space through parallel bidirectional interactions, ensuring accurate feature alignment. Additionally, we propose a multigrained adaptive fusion (MAF) module, which identifies critical garment regions using a polyscale attention mechanism and allocates more tokens to adaptively preserve intricate textural details. Extensive experiments on multiple widely used public datasets demonstrate that MA-VITON achieves outstanding performance and surpasses state-of-the-art methods. The code is publicly available at https://github.com/Max-Teapot/MA-VITON.},
  archive      = {J_TNNLS},
  author       = {Jing Zhang and Yumo Kang and Wenxuan Liu and Zhe Wang},
  doi          = {10.1109/TNNLS.2025.3554826},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16909-16919},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Scale-wise semantic alignment enhanced multigrained adaptive fusion for virtual try-on},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). S4DL: Shift-sensitive Spatial–Spectral disentangling learning for hyperspectral image unsupervised domain adaptation. <em>TNNLS</em>, <em>36</em>(9), 16894-16908. (<a href='https://doi.org/10.1109/TNNLS.2025.3556386'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised domain adaptation (UDA) techniques, extensively studied in hyperspectral image (HSI) classification, aim to use labeled source domain data and unlabeled target domain data to learn domain invariant features for cross-scene classification. Compared to natural images, numerous spectral bands of HSIs provide abundant semantic information, but they also increase the domain shift significantly. In most existing methods, both explicit alignment and implicit alignment simply align feature distribution, ignoring domain information in the spectrum. We noted that when the spectral channel between source and target domains is distinguished obviously, the transfer performance of these methods tends to deteriorate. Additionally, their performance fluctuates greatly owing to the varying domain shifts across various datasets. To address these problems, a novel shift-sensitive spatial-spectral disentangling learning (S4DL) approach is proposed. In S4DL, gradient-guided spatial-spectral decomposition (GSSD) is designed to separate domain-specific and domain-invariant representations by generating tailored masks under the guidance of the gradient from domain classification. A shift-sensitive adaptive monitor is defined to adjust the intensity of disentangling according to the magnitude of domain shift. Furthermore, a reversible neural network is constructed to retain domain information that lies not only in semantic but also the shallow-level detailed information. Extensive experimental results on several cross-scene HSI datasets consistently verified that S4DL is better than the state-of-the-art UDA methods. Our source code will be available at https://github.com/xdu-jjgs/IEEE_TNNLS_S4DL.},
  archive      = {J_TNNLS},
  author       = {Jie Feng and Tianshu Zhang and Junpeng Zhang and Ronghua Shang and Weisheng Dong and Guangming Shi and Licheng Jiao},
  doi          = {10.1109/TNNLS.2025.3556386},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16894-16908},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {S4DL: Shift-sensitive Spatial–Spectral disentangling learning for hyperspectral image unsupervised domain adaptation},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RSME: Respiration-driven synchronized motion estimator for real-time thoracic 3-D CT reconstruction using low-rank motion fields and dose-free surface imaging. <em>TNNLS</em>, <em>36</em>(9), 16879-16893. (<a href='https://doi.org/10.1109/TNNLS.2025.3564947'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time 3-D CT reconstruction during radiotherapy, based on planning 4-D CT, has emerged as a central area of interest in the field of image-guided radiotherapy (IGRT). However, current methodologies still rely on time-consuming patient-specific training, real-time registration, or additional radiation doses. Our contribution, respiration-driven synchronized motion estimator (RSME), represents a novel and efficient forward propagation network, leveraging an explicit spatial-temporal low-rank decomposition of displacement fields and surface imaging to enable real-time 3-D CT reconstruction during respiration. RSME is derived from a well-designed, interpretable inverse optimization problem, mapping static spatial components and dynamic skin depth images to dynamic temporal components for reconstruction. In RSME, we customize two core transformer-based encoders: the motion former (M-Former) and the motion pattern former (P-Former), and incorporate customized cross attention mechanism to effectively gauge the interdependencies between the two encoders. Strategically, we input skin depth images into M-Former to inquire about motion information, thus circumventing the requirement for real-time registration. In P-Former, we introduce static spatial components that integrate explicit respiratory pattern details to distinguish between patients without the necessity for patient-specific training, and harness the static nature to evade additional inference latency. Extensive experimental results demonstrate that RSME achieves comparable or even superior accuracy than state-of-the-art methods, with a cumulative latency of 96 ms. Notably, RSME accomplishes this without necessitating additional radiation dosage, time-consuming patient-specific training or real-time registration.},
  archive      = {J_TNNLS},
  author       = {Ziwen Wei and Xiaolong Wu and Qi Wang and Yunbiao Zhou and Shaozhuang Zhai and Tao Jiang and Zhihua Liu and Yang Zhang and Hongcang Gu and Shuanghu Yuan and Junchao Qian},
  doi          = {10.1109/TNNLS.2025.3564947},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16879-16893},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {RSME: Respiration-driven synchronized motion estimator for real-time thoracic 3-D CT reconstruction using low-rank motion fields and dose-free surface imaging},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A two-stage selective experience replay for double-actor deep reinforcement learning. <em>TNNLS</em>, <em>36</em>(9), 16864-16878. (<a href='https://doi.org/10.1109/TNNLS.2025.3557930'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep reinforcement learning (DRL) has been widely applied to various applications, but improving the exploration and the accuracy of Q-value estimation remain key challenges. Recently, the double-actor architecture has emerged as a promising DRL framework that can enhance both exploration and Q-value estimation. Existing double-actor DRL methods sample from the replay buffer to update the two actors; however, the samples used to update each actor are generated by its previous versions and the other actor, resulting in a different data distribution compared with the current actor being updated, which can negatively impact the actor’s update and lead to suboptimal policies. To this end, this work proposes a generic solution that can be seamlessly integrated into existing double-actor DRL methods to mitigate the adverse effects of data distribution differences on actor updates, thereby learning better policies. Specifically, we decompose the updates of double-actor DRL methods into two stages, each of which uses the same sampling approach to train a pair of actor-critic. This sampling approach classifies the samples in the replay buffer into distinct categories using a clustering technique, such as K-means, and subsequently employs the Jensen-Shannon (JS) divergence to evaluate the distributional differences between each sample category and the actor currently being updated. Samples are then prioritized from the categories with smaller distribution differences to the current actor to update it. In this way, we can effectively mitigate the distribution difference between the samples and the current actor being updated. Experiments demonstrate that our method enhances the performance of five state-of-the-art (SOTA) double-actor DRL methods and outperforms eight SOTA single-actor DRL methods across eight tasks.},
  archive      = {J_TNNLS},
  author       = {Meng Xu and Xinhong Chen and Zihao Wen and Weiwei Fu and Jianping Wang},
  doi          = {10.1109/TNNLS.2025.3557930},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16864-16878},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A two-stage selective experience replay for double-actor deep reinforcement learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multistate temporal difference target for model-free reinforcement learning. <em>TNNLS</em>, <em>36</em>(9), 16854-16863. (<a href='https://doi.org/10.1109/TNNLS.2025.3564078'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal difference (TD) learning is a fundamental technique in reinforcement learning that updates value function estimates for states or state-action pairs using a TD target. This target represents an improved estimate of the true value by incorporating both immediate rewards and the estimated value of subsequent states. We propose an enhanced multistate TD (MSTD) target that utilizes multiple subsequent states for a more accurate value function estimation compared to traditional TD learning, which relies on a single subsequent state. Building on this new MSTD concept, we develop actor-critic algorithms that include the management of replay buffers in two modes and integrate with deep deterministic policy optimization (DDPG) and soft actor-critic (SAC). Numerical experiment results demonstrate that algorithms employing the MSTD target improve learning performance compared to traditional methods. In addition, we analyze the convergence of Q-learning with MSTD.},
  archive      = {J_TNNLS},
  author       = {Wuhao Wang and Zhiyong Chen and Lepeng Zhang},
  doi          = {10.1109/TNNLS.2025.3564078},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16854-16863},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Multistate temporal difference target for model-free reinforcement learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Guarding graph neural networks for unsupervised graph anomaly detection. <em>TNNLS</em>, <em>36</em>(9), 16840-16853. (<a href='https://doi.org/10.1109/TNNLS.2025.3569526'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised graph anomaly detection aims at identifying rare patterns that deviate from the majority in a graph without the aid of labels, which is important for a variety of real-world applications. Recent advances have utilized graph neural networks (GNNs) to learn effective node representations by aggregating information from neighborhoods. This is motivated by the hypothesis that nodes in the graph tend to exhibit consistent behaviors with their neighborhoods. However, such consistency can be disrupted by graph anomalies in multiple ways. Most existing methods directly employ GNNs to learn representations, disregarding the negative impact of graph anomalies on GNNs, resulting in suboptimal node representations and anomaly detection performance. While a few recent approaches have redesigned GNNs for graph anomaly detection under semi-supervised label guidance, how to address the adverse effects of graph anomalies on GNNs in unsupervised scenarios and learn effective representations for anomaly detection are still underexplored. To bridge this gap, in this article, we propose a simple, yet effective framework for guarding GNNs for unsupervised graph anomaly detection (G3AD). Specifically, G3AD first introduces two auxiliary networks along with correlation constraints to guard the GNNs against inconsistent information encoding. Furthermore, G3AD introduces an adaptive caching (AC) module to guard the GNNs from directly reconstructing the observed graph data that contains anomalies. Extensive experiments demonstrate that our G3AD can outperform 20 state-of-the-art methods on both synthetic and real-world graph anomaly datasets, with flexible generalization ability in different GNN backbones.},
  archive      = {J_TNNLS},
  author       = {Yuanchen Bei and Sheng Zhou and Jinke Shi and Yao Ma and Haishuai Wang and Jiajun Bu},
  doi          = {10.1109/TNNLS.2025.3569526},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16840-16853},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Guarding graph neural networks for unsupervised graph anomaly detection},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semi-heterogeneous graph-perception network with gradient-weighted class activation mapping for class-incremental industrial fault recognition and root cause diagnosis. <em>TNNLS</em>, <em>36</em>(9), 16825-16839. (<a href='https://doi.org/10.1109/TNNLS.2025.3567475'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern industrial systems often operate under complex dynamics and strict reliability constraints, demanding a timely and precise fault diagnosis with efficient root cause analysis to ensure operational safety and minimize downtime. However, the inherent uncertainties and complexities of industrial processes present significant challenges for conventional diagnostic approaches. Specifically, even minor anomalies can escalate into critical incidents, while process uncertainties frequently induce distribution shifts, leading to novel fault types that complicate fault detection and diagnosis. To address these challenges, this article proposes a novel industrial flow topology-induced semi-heterogeneous graph perception network (IFT-SHGPN) model for class-incremental fault diagnosis of complex industrial processes. By embedding the physical topology of industrial processes into a semi-heterogeneous graph perception network (SHGPN) and incorporating gradient-weighted class activation mapping (Grad-CAM), the proposed approach demonstrates strong capability in effective class-incremental fault recognition and interpretable root cause analysis. Rigorous experiments on the Tennessee Eastman process (TEP) and a multiphase flow facility process under various operation conditions showcase the superiority of IFT-SHGPN over existing methods. The proposed approach achieves high diagnostic accuracy for both historical and emerging fault categories while enabling efficient root cause identification with low computational overhead, making it particularly suitable for deployment in resource-constrained industrial environments.},
  archive      = {J_TNNLS},
  author       = {Jinping Liu and Sheng Chen and Meiling Cai and Haidong Shao and Weihua Gui},
  doi          = {10.1109/TNNLS.2025.3567475},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16825-16839},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Semi-heterogeneous graph-perception network with gradient-weighted class activation mapping for class-incremental industrial fault recognition and root cause diagnosis},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient variants of wasserstein distance in hyperbolic space via space-filling curve projection. <em>TNNLS</em>, <em>36</em>(9), 16814-16824. (<a href='https://doi.org/10.1109/TNNLS.2025.3551275'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperbolic spaces have been considered pervasively for embedding hierarchically structured data in the recent decade. However, there is a lack of studies focusing on efficient distance metrics for comparing probability distributions in hyperbolic spaces. To bridge the gap, we propose a novel metric called the hyperbolic space-filling curve projection Wasserstein (SFW) distance. The idea is to first project two probability distributions onto a space-filling curve to obtain a closed-form coupling between them and then calculate the transport distance between these two distributions in the hyperbolic space accordingly. Theoretically, we show the SFW distance is a proper metric and is well-defined for probability measures with bounded supports. Statistical convergence rates for the proposed estimator are provided as well. Moreover, we propose two variants of the SFW distance based on geodesic and horospherical projections, respectively, to combat the curse-of-dimensionality. Empirical results on synthetic and real-world data indicate that the SFW distance can effectively serve as a surrogate of the popular Wasserstein distance with low complexity.},
  archive      = {J_TNNLS},
  author       = {Tao Li and Cheng Meng and Hongteng Xu and Jun Zhu},
  doi          = {10.1109/TNNLS.2025.3551275},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16814-16824},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Efficient variants of wasserstein distance in hyperbolic space via space-filling curve projection},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SCMix: Stochastic compound mixing for open compound domain adaptation in semantic segmentation. <em>TNNLS</em>, <em>36</em>(9), 16803-16813. (<a href='https://doi.org/10.1109/TNNLS.2025.3560318'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Open compound domain adaptation (OCDA) aims to transfer knowledge from a labeled source domain to a mix of unlabeled homogeneous compound target domains while generalizing to open unseen domains. Existing OCDA methods solve the intradomain gaps by a divide-and-conquer strategy, which decomposes the problem into several individual and parallel domain adaptation (DA) tasks. In this work, starting from the general DA theory, we establish a novel generalization bound for the setting of OCDA. Built upon this, we argue that conventional OCDA approaches may substantially underestimate the inherent variance inside the compound target domains for model generalization, constraining the model’s performance. We subsequently present stochastic compound mixing (SCMix), an augmentation strategy with the primary objective of mitigating the divergence between the source and mixed target distributions. Theoretical analyses are conducted to substantiate the superiority of SCMix, proving that single-target mixing is a subgroup of our method. Extensive experiments show that our method attains a lower empirical risk on OCDA semantic segmentation tasks, thus supporting our theories. In particular, combining the transformer architecture, SCMix achieves a notable performance boost compared to SoTA results.},
  archive      = {J_TNNLS},
  author       = {Kai Yao and Zhaorui Tan and Zixian Su and Xi Yang and Jie Sun and Kaizhu Huang},
  doi          = {10.1109/TNNLS.2025.3560318},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16803-16813},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {SCMix: Stochastic compound mixing for open compound domain adaptation in semantic segmentation},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Converting high-performance and low-latency SNNs through explicit modeling of residual error in ANNs. <em>TNNLS</em>, <em>36</em>(9), 16788-16802. (<a href='https://doi.org/10.1109/TNNLS.2025.3567567'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural networks (SNNs) have garnered interest due to their energy efficiency and superior effectiveness on neuromorphic chips compared with traditional artificial neural networks (ANNs). One of the mainstream approaches to implementing deep SNNs is the ANN–SNN conversion, which integrates the efficient training strategy of ANNs with the energy-saving potential and fast inference capability of SNNs. However, under extremely low-latency conditions, the existing conversion theory suggests that the problem of SNNs’ neurons firing more or fewer spikes within each layer, i.e., residual error, leads to a performance gap in the converted SNNs compared with the original ANNs. This severely limits the possibility of the practical application of SNNs on delay-sensitive edge devices. Existing conversion methods addressing this problem usually involve modifying the state of the conversion spiking neurons. However, these methods do not consider their adaptability and compatibility with neuromorphic chips. We propose a new approach based on explicit modeling of residual errors as additive noise. The noise is incorporated into the activation function of the source ANN, effectively reducing the impact of residual error on SNN performance. Our experiments on the CIFAR10/100 and Tiny-ImageNet datasets verify that our approach exceeds the prevailing ANN–SNN conversion methods and directly trained SNNs concerning accuracy and the required time steps. Overall, our method provides new ideas for improving SNN performance under ultralow-latency conditions and is expected to promote practical neuromorphic hardware applications for further development. The code for our NQ framework is available at https://github.com/hzp2022/ANN2SNN_NQ},
  archive      = {J_TNNLS},
  author       = {Zhipeng Huang and Jianhao Ding and Zhiyu Pan and Haoran Li and Ying Fang and Zhaofei Yu and Jian K. Liu},
  doi          = {10.1109/TNNLS.2025.3567567},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16788-16802},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Converting high-performance and low-latency SNNs through explicit modeling of residual error in ANNs},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic Modality–Camera-invariant clustering for unsupervised Visible–Infrared person re-identification. <em>TNNLS</em>, <em>36</em>(9), 16774-16787. (<a href='https://doi.org/10.1109/TNNLS.2025.3563645'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised learning visible–infrared person re-identification (USL-VI-ReID) offers a more flexible and cost-effective alternative compared to supervised methods. This field has gained increasing attention due to its promising potential. Existing methods simply cluster modality-specific samples and employ strong association techniques to achieve instance-to-cluster or cluster-to-cluster cross-modality associations. However, they ignore cross-camera differences, leading to noticeable issues with excessive splitting of identities. Consequently, this undermines the accuracy and reliability of cross-modal associations. To address these issues, we propose a novel dynamic modality–camera-invariant clustering (DMIC) framework for USL-VI-ReID. Specifically, our DMIC naturally integrates modality–camera-invariant expansion (MIE), dynamic neighborhood clustering (DNC), and hybrid modality contrastive learning (HMCL) into a unified framework, which eliminates both the cross-modality and cross-camera discrepancies in clustering. MIE fuses intermodal and intercamera distance coding to bridge the gaps between modalities and cameras at the clustering level. DNC employs two dynamic search strategies to refine the network’s optimization objective, transitioning from improving discriminability to enhancing cross-modal and cross-camera generalizability. Moreover, HMCL is designed to optimize instance- and cluster-level distributions. Memories for intramodality and intermodality training are updated using randomly selected samples, facilitating real-time exploration of modality-invariant representations. Extensive experiments have demonstrated that our DMIC addresses the limitations present in current clustering approaches and achieves competitive performance, which significantly reduces the performance gap with supervised methods.},
  archive      = {J_TNNLS},
  author       = {Yiming Yang and Weipeng Hu and Qiaolin He and Haifeng Hu},
  doi          = {10.1109/TNNLS.2025.3563645},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16774-16787},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Dynamic Modality–Camera-invariant clustering for unsupervised Visible–Infrared person re-identification},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bridging task-specific and task-interactive features with opportune branching and adaptive attention for object detection. <em>TNNLS</em>, <em>36</em>(9), 16760-16773. (<a href='https://doi.org/10.1109/TNNLS.2025.3562588'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection is a fundamental task that usually requires the optimization of two sub-tasks (i.e., localization and classification). However, there exists a lack of understanding regarding the changing pattern of their preferred interest locations. Existing work adopts alternating detection head designs in terms of handling task-interactive and task-specific features. To tackle this issue, we conduct a thorough analysis to investigate the contradicting focus-shifting patterns of these sub-tasks. Specifically, we first collect data points on the MS-COCO dataset and conduct numerical analysis to pinpoint the optimal branching point by evaluating the effect size metrics of feature similarity and by calculating the 2-D inter-cluster distances between features among potential branching points. Then, qualitative analysis regarding the feature representation is carried out to further justify the results. At last, we demonstrate the potential generalizability of our analysis pipelines across various architectures, label assignment methods, training techniques, and datasets. In light of the above finding, we propose the opportune branching head that leverages the conflict between task-interactive and task-specific features by decoupling the sub-tasks at the condign point to maximize the preference. We further extend the concept of opportune branching and propose the adaptive attention mechanism to enable more effective attention allocation in a laconic manner, magnifying the effect of opportune branching. We conduct extensive experiments on the MS-COCO benchmark, the PASCAL VOC benchmark, and the Cityscape benchmark, where our method achieves competitive results. We achieve 50.0 AP with the ResNeXt-101-4d-64 backbone and 59.8 AP with the Swin-L transformer backbone on the MS-COCO benchmark, representing the best performance among nontransformer-based methods while also outperforming many state-of-the-art transformer-based methods by a clear margin.},
  archive      = {J_TNNLS},
  author       = {Yuxuan Wen and Yunfei Yin},
  doi          = {10.1109/TNNLS.2025.3562588},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16760-16773},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Bridging task-specific and task-interactive features with opportune branching and adaptive attention for object detection},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TRG-net: An interpretable and controllable rain generator. <em>TNNLS</em>, <em>36</em>(9), 16745-16759. (<a href='https://doi.org/10.1109/TNNLS.2025.3565726'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exploring and modeling the rain generation mechanism is critical for augmenting paired data to ease the training of rainy image processing models. Most of the conventional methods handle this task in an artificial physical rendering manner, through elaborately designing fundamental elements constituting rains. These kinds of methods, however, are over-dependent on human subjectivity, which limits their adaptability to real rains. In contrast, recent deep learning (DL) methods have achieved great success by training a neural network-based generator from pre-collected rainy image data. However, current methods usually design the generator in a “closed box” manner, increasing the learning difficulty and data requirements. To address these issues, this study proposes a novel DL-based rain generator, which fully takes the physical generation mechanism underlying rains into consideration and well encodes the learning of the fundamental rain factors (i.e., shape, orientation, length, width, and sparsity) explicitly into the deep network. Its significance lies in that the generator not only elaborately designs essential elements of the rain to simulate expected rains, like conventional artificial strategies, but also finely adapts to complicated and diverse practical rainy images, like DL methods. By rationally adopting the filter parameterization technique, the proposed rain generator is finely controllable with respect to rain factors and able to learn the distribution of these factors purely from data without the need for rain factor labels. Our unpaired generation experiments demonstrate that the rain generated by the proposed rain generator is not only of higher quality but also more effective for deraining and downstream tasks compared to current state-of-the-art rain generation methods. Besides, the paired data augmentation experiments, including both in-distribution and out-of-distribution (OOD), further validate the diversity of samples generated by our model for in-distribution deraining and OOD generalization tasks.},
  archive      = {J_TNNLS},
  author       = {Zhiqiang Pang and Hong Wang and Qi Xie and Deyu Meng and Zongben Xu},
  doi          = {10.1109/TNNLS.2025.3565726},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16745-16759},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {TRG-net: An interpretable and controllable rain generator},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mapping tracking control to cascading optimization in discrete strict-feedback systems: A hierarchical learning approach. <em>TNNLS</em>, <em>36</em>(9), 16733-16744. (<a href='https://doi.org/10.1109/TNNLS.2025.3558811'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article introduces a hierarchical learning (HL) framework for discrete-time (DT) systems with strict feedback structures to enable tracking control. Unlike the backstepping approach, our method creates dynamically adjustable virtual targets (VTs) for state variables at each layer, forming a cascading optimization structure. This innovative framework enables each layer to learn by approximating the solution to the DT Hamilton-Jacobi–Bellman (HJB) equation, thereby facilitating inter-layer self-optimization and directing the modification of adjacent VTs. To tackle the noncausal problem, we implement an iterative predictive learning framework that maps the current measurable state and known reference trajectories to VTs. This process allows the VTs to gradually align with the optimal trajectory during policy evaluation and update, achieving indirect tracking of state variables toward the desired targets. Additionally, the action network is transformed into a tracking network, incorporating future tracking errors to optimize its weights. This approach reduces tracking costs in the subsequent policy update while improving tracking performance. Rigorous convergence analysis and numerical simulations confirm the effectiveness of our method, highlighting its considerable potential in adaptive control.},
  archive      = {J_TNNLS},
  author       = {Ying Yan and Jiayue Sun and Huaguang Zhang and Xin Liu and Jian Pan},
  doi          = {10.1109/TNNLS.2025.3558811},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16733-16744},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Mapping tracking control to cascading optimization in discrete strict-feedback systems: A hierarchical learning approach},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning discriminative representation for co-salient object detection. <em>TNNLS</em>, <em>36</em>(9), 16721-16732. (<a href='https://doi.org/10.1109/TNNLS.2025.3567213'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Co-salient object detection (CoSOD) is the task of identifying and emphasizing the common salient objects in a collection of images. The current co-salient object detection frameworks often extract features and model interimage relations separately. Although these methods achieve promising performance in many scenes, separating the feature extraction and relation modeling falls short of obtaining discriminative features for co-salient objects, resulting in subperformance, especially in some complex and cluttered real-world scenes. In this article, we introduce a novel CoSOD framework to unify feature extraction and interimage relation modeling. We design an early token interaction module (ETIM) that bridges information flow between branches to simultaneously realize feature extraction and interimage information interaction. To further enhance our network’s capability to distinguish co-salient objects from other irrelevant foreground objects, we introduce a pixel-to-group contrastive (PGC) learning method. This approach aids in eliminating the need for additional interaction modules while preserving features’ discriminative power for co-salient objects. Our proposed CoSOD framework only includes a backbone embedded with ETIM, a decoder without interaction modules and a project head only used during the training phase. Extensive experiments on three challenging benchmarks, that is, CoCA, CoSOD3k, and Cosal2015, demonstrate that our proposed method can outperform current leading-edge models and achieve the new state-of-the-art. The source code is available at https://github.com/zhiwang98/LDRNet},
  archive      = {J_TNNLS},
  author       = {Yongri Piao and Zhi Wang and Tingwei Liu and Jihao Yin and Miao Zhang and Huchuan Lu},
  doi          = {10.1109/TNNLS.2025.3567213},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16721-16732},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Learning discriminative representation for co-salient object detection},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic erasing network with adaptive temporal modeling for weakly supervised video anomaly detection. <em>TNNLS</em>, <em>36</em>(9), 16706-16720. (<a href='https://doi.org/10.1109/TNNLS.2025.3553556'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The weakly supervised video anomaly detection aims to learn a detection model using only video-level labeled data. Prior studies ignore the complexity or duration of anomalies present in abnormal videos during temporal modeling. Moreover, existing works usually detect the most abnormal segments, potentially overlooking the completeness of anomalies. We propose a dynamic erasing network (DE-Net) for weakly supervised video anomaly detection, which learns video-specific temporal features via adaptive temporal modeling (ATM) to address these limitations. Specifically, to handle duration variations of abnormal events, we propose an ATM module capable of adaptively selecting and aggregating the most appropriate K temporal scale features for each video. Then, we design a dynamic erasing (DE) strategy that dynamically assesses the completeness of the detected anomalies and erases prominent abnormal segments to encourage the model to discover gentle abnormal segments. The proposed method achieves favorable performance compared to several state-of-the-art approaches on the widely used XD-Violence, TAD, and UCF-Crime datasets.},
  archive      = {J_TNNLS},
  author       = {Chen Zhang and Guorong Li and Yuankai Qi and Hanhua Ye and Laiyun Qing and Ming-Hsuan Yang and Qingming Huang},
  doi          = {10.1109/TNNLS.2025.3553556},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16706-16720},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Dynamic erasing network with adaptive temporal modeling for weakly supervised video anomaly detection},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). OR-gate mixup multiscale spectral graph neural network for node anomaly detection. <em>TNNLS</em>, <em>36</em>(9), 16692-16705. (<a href='https://doi.org/10.1109/TNNLS.2025.3569413'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph node anomaly detection has important applications in practical scenarios. Although many graph neural networks (GNNs) have been proposed, how to design tailored spectral filters for node anomaly detection to fully mine high-frequency signals in the graph is still a challenge. Most GNNs are equivalent to low-pass filters and mine multiorder signals through a series structure. The computational cost increases as the number of layers increases and further leads to an over-smoothing problem. They mainly focus on low-frequency signals and suppress high-frequency signals, thus smoothing the differences between abnormal and normal nodes, making them indistinguishable. Due to the difficulty in mining high-frequency signals, the poorly distinguishable feature representations learned by low-pass GNNs can even harm the performance of data augmentation. To solve the above challenges, in this article, we propose a or-gate mixup multiscale spectral GNN (MMGNN) from the spectral domain. Specifically, we design multiorder multiscale bandpass filters through the superposition of polynomial spectral filters and then decompose them into preprocessing parts and training parts to form a double-parallel structure, which can effectively mine high-frequency signals in the graph and reduce computational cost. Finally, we propose or-gate mixup to perform data augmentation in the spectral space to improve model generalization. Experimental results on four real-world datasets demonstrate the effectiveness of the proposed MMGNN against the state-of-the-art methods.},
  archive      = {J_TNNLS},
  author       = {Zekang Li and Ruonan Liu and Dongyue Chen and Qinghua Hu},
  doi          = {10.1109/TNNLS.2025.3569413},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16692-16705},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {OR-gate mixup multiscale spectral graph neural network for node anomaly detection},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Route-and-aggregate decentralized federated learning under communication errors. <em>TNNLS</em>, <em>36</em>(9), 16675-16691. (<a href='https://doi.org/10.1109/TNNLS.2025.3552406'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decentralized federated learning (D-FL) allows clients to aggregate learning models locally, offering flexibility and scalability. Existing D-FL methods use gossip protocols, which are inefficient when not all nodes in the network are D-FL clients. This article puts forth a new D-FL strategy, termed route-and-aggregate (R&A) D-FL, where participating clients exchange models with their peers through established routes (as opposed to flooding) and adaptively normalize their aggregation coefficients to compensate for communication errors. The impact of routing and imperfect links on the convergence of R&A D-FL is analyzed, revealing that convergence is minimized when routes with the minimum end-to-end (E2E) packet error rates (PERs) are employed to deliver models. Our analysis is experimentally validated through three image classification tasks and two next-word prediction tasks, utilizing widely recognized datasets and models. R&A D-FL outperforms the flooding-based D-FL method in terms of training accuracy by 35% in our tested ten-client network, and shows strong synergy between D-FL and networking. In another test with ten D-FL clients, the training accuracy of R&A D-FL with communication errors approaches that of the ideal centralized federated learning (C-FL) without communication errors, as the number of routing nodes (i.e., nodes that do not participate in the training of D-FL) rises to 28.},
  archive      = {J_TNNLS},
  author       = {Weicai Li and Tiejun Lv and Wei Ni and Jingbo Zhao and Ekram Hossain and H. Vincent Poor},
  doi          = {10.1109/TNNLS.2025.3552406},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16675-16691},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Route-and-aggregate decentralized federated learning under communication errors},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reconciling attribute and structural anomalies for improved graph anomaly detection. <em>TNNLS</em>, <em>36</em>(9), 16661-16674. (<a href='https://doi.org/10.1109/TNNLS.2025.3561172'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph anomaly detection is critical in domains such as healthcare and economics, where identifying deviations can prevent substantial losses. Existing unsupervised approaches strive to learn a single model capable of detecting both attribute and structural anomalies. However, they confront the tug-of-war problem between two distinct types of anomalies, resulting in suboptimal performance. This work presents TripleAD, a mutual distillation-based triple-channel graph anomaly detection framework. It includes three estimation modules to identify the attribute, structural, and mixed anomalies while mitigating the interference between different types of anomalies. In the first channel, we design a multiscale attribute estimation module to capture extensive node interactions and ameliorate the over-smoothing issue. To better identify structural anomalies, we introduce a link-enhanced structure estimation module in the second channel that facilitates information flow to topologically isolated nodes. The third channel is powered by an attribute-mixed curvature, a new indicator that encapsulates both attribute and structural information for discriminating mixed anomalies. Moreover, a mutual distillation strategy is introduced to encourage communication and collaboration between the three channels. Extensive experiments demonstrate the effectiveness of the proposed TripleAD model against strong baselines.},
  archive      = {J_TNNLS},
  author       = {Chunjing Xiao and Jiahui Lu and Xovee Xu and Fan Zhou and Tianshu Xie and Wei Lu and Lifeng Xu},
  doi          = {10.1109/TNNLS.2025.3561172},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16661-16674},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Reconciling attribute and structural anomalies for improved graph anomaly detection},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning to detect industrial time-series anomalies from imputation consistency with sparse observations. <em>TNNLS</em>, <em>36</em>(9), 16648-16660. (<a href='https://doi.org/10.1109/TNNLS.2025.3568019'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time-series anomaly detection plays an important role in ensuring industrial safety. Currently, many anomaly detection methods mainly target complete time series and ignore the widespread problem of data missing in the real world. Therefore, this article proposes a novel anomaly detection method for time series with sparse observations based on imputation consistency using a mixture of patch information inference network (MoPIN). Due to the robustness of the imputation method modeling to the random mask, different imputed series of the same normal time series with different random masks should have consistency. Then, a novel imputation consistency is used to detect anomalies in sparse observation series. Moreover, the MoPIN imputes series by a two-step imputation and multiscale modeling of patch information. Meanwhile, the similarity of imputed series under different masks is used to measure imputation consistency, which well constructs the relationship between sparse observation series and anomaly scores. Finally, the MoPIN can accurately detect anomalies while imputing series. Extensive experiments on four real-world benchmarks in different domains of imputation and anomaly detection tasks and a real fluid catalytic cracking (FCC) process case demonstrate the effectiveness of the proposed method. Specifically, the MoPIN achieved at least 8.05% mean absolute error (MAE) relative improvement in imputation and 3.74% $F1$ relative improvement in anomaly detection.},
  archive      = {J_TNNLS},
  author       = {Zhen Zhang and Yongming Han and Zhiqiang Geng},
  doi          = {10.1109/TNNLS.2025.3568019},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16648-16660},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Learning to detect industrial time-series anomalies from imputation consistency with sparse observations},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deterministic convergence analysis and application of elman neural network via sparse mechanism and entropy error function. <em>TNNLS</em>, <em>36</em>(9), 16633-16647. (<a href='https://doi.org/10.1109/TNNLS.2025.3562223'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we employed the batch gradient method to investigate the monotonicity and convergence of the Elman neural network (ENN) based on the entropy error function (EEF) and regularization methods. This enhances network stability and sparsity while also boosting its ability to generalize. Traditional mean square error (mse) functions in complex networks often result in slower convergence during training, prone-to-local minima, and even incorrect saturation issues. To address this drawback, we propose a novel EEF for training ENN, effectively avoiding the problem of learning speed degradation. Furthermore, by leveraging smoothing group $L_{1/2}$ regularization $(\text {SGL}_{1/2})$ methods in studying ENN based on EEF, we effectively overcome the drawbacks of traditional group $L_{1/2}$ regularization $(\text {GL}_{1/2})$ leading to error function oscillations. In addition, we optimize the network architecture effectively in two key ways: reducing redundant nodes to near 0 and driving redundant weights toward 0 for remaining nodes, further boosting network sparsity. This article rigorously proves the monotonicity of the error function, alongside presenting strong and weak convergence outcomes for the novel method. The effectiveness and correctness of our approach are clearly illustrated through experimental results. The simulation results align with the theoretical findings.},
  archive      = {J_TNNLS},
  author       = {Qian Kang and Dengxiu Yu and Bowen Xu and Zhen Wang},
  doi          = {10.1109/TNNLS.2025.3562223},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16633-16647},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Deterministic convergence analysis and application of elman neural network via sparse mechanism and entropy error function},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward targeted mining of RFM patterns. <em>TNNLS</em>, <em>36</em>(9), 16619-16632. (<a href='https://doi.org/10.1109/TNNLS.2025.3565548'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s era of information overload, leveraging data mining techniques to understand and analyze customer behavior has become essential for businesses. Among these techniques, the recency, frequency, and monetary value analysis model serves as a powerful tool for customer segmentation, enabling companies to identify high-value customers. However, traditional recency, frequency, and monetary (RFM) models do not focus on user-specific targets, often struggling to meet the increasing demands for personalization and efficiency. To address this challenge, this article introduces the concept of target RFM patterns, which must satisfy the three dimensions of recency, frequency, and utility while aligning with user interests. Based on this concept, we formulate the problem of mining target RFM patterns. More importantly, we define a mining order, called TaRFM order, and propose an efficient algorithm called TaRFM. This new algorithm is optimized through three pruning strategies based on the TaRFM order, which not only eliminates a significant number of invalid operations, thereby reducing pattern generation, but also accurately extracts all TaRFM patterns without requiring postprocessing techniques. Finally, extensive experiments conducted on multiple datasets demonstrate the accuracy and efficiency of the TaRFM algorithm.},
  archive      = {J_TNNLS},
  author       = {Xiaoye Chen and Wensheng Gan and Zefeng Chen and Jian Zhu and Ruichu Cai and Philip S. Yu},
  doi          = {10.1109/TNNLS.2025.3565548},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16619-16632},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Toward targeted mining of RFM patterns},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pleno-alignment framework for stock trend prediction. <em>TNNLS</em>, <em>36</em>(9), 16604-16618. (<a href='https://doi.org/10.1109/TNNLS.2025.3561811'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting stock trends is a highly rewarding but high-risk endeavor due to the complex interplay of market dynamics, irrational behaviors, and diverse sentiments. Previous studies have used time-series analysis on historical prices or sentiment analysis on textual information. However, these methods often fail to capture the dynamic interactions between text and time-series modalities and overlook the different perspectives embedded in textual data. To address these limitations, we propose the pleno-alignment framework (PAFrame) that enhances multimodal stock information through intermodal and intramodal alignment to capture market dynamics. Our framework first integrates textual and time-series data in a shared representation space to learn modal-invariant information. To tackle divergent sentiments in textual data, we employ a contrastive learning approach to extract abstract semantic meanings from objective and subjective perspectives, thereby improving the robustness of language representations. Finally, we use a hybrid approach that explicitly combines cross-attention mechanisms to create a unified representation and utilizes prompts to implicitly guide language models with numerical financial indicators for final prediction. Our comprehensive experiments on five real-world datasets show that PAFrame outperforms existing methods in predicting stock trends.},
  archive      = {J_TNNLS},
  author       = {Yongcan Luo and Jiahao Zheng and Zhengjie Yang and Ning Chen and Dapeng Wu},
  doi          = {10.1109/TNNLS.2025.3561811},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16604-16618},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Pleno-alignment framework for stock trend prediction},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heterogeneous mutual knowledge distillation for wearable human activity recognition. <em>TNNLS</em>, <em>36</em>(9), 16589-16603. (<a href='https://doi.org/10.1109/TNNLS.2025.3556317'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, numerous deep learning algorithms have addressed wearable human activity recognition (HAR), but they often struggle with efficient knowledge transfer to lightweight models for mobile devices. Knowledge distillation (KD) is a popular technique for model compression, transferring knowledge from a complex teacher to a compact student. Most existing KD algorithms consider homogeneous architectures, hindering performance in heterogeneous setups. This is an under-explored area in wearable HAR. To bridge this gap, we propose a heterogeneous mutual KD (HMKD) framework for wearable HAR. HMKD establishes mutual learning within the intermediate and output layers of both teacher and student models. To accommodate substantial structural differences between teacher and student, we employ a weighted ensemble feature approach to merge the features from their intermediate layers, enhancing knowledge exchange within them. Experimental results on the HAPT, WISDM, and UCI_HAR datasets show HMKD outperforms ten state-of-the-art KD algorithms in terms of classification accuracy. Notably, with ResNetLSTMaN as the teacher and MLP as the student, HMKD increases by 9.19% in MLP’s $F_{1}$ score on the HAPT dataset.},
  archive      = {J_TNNLS},
  author       = {Zhiwen Xiao and Huanlai Xing and Rong Qu and Hui Li and Xinzhou Cheng and Lexi Xu and Li Feng and Qian Wan},
  doi          = {10.1109/TNNLS.2025.3556317},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16589-16603},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Heterogeneous mutual knowledge distillation for wearable human activity recognition},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Few-shot learning based on multimodal information processing. <em>TNNLS</em>, <em>36</em>(9), 16577-16588. (<a href='https://doi.org/10.1109/TNNLS.2025.3561503'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot learning aims to develop models with strong generalization capabilities using a small number of training samples. However, most learning methods rely solely on the visual features of a few samples to represent entire categories, leading to poor category representativeness. In contrast, humans can utilize multimodal information to learn category features, thereby making them more representative. Hence, this article emulates the human multimodal learning mechanism by integrating visual features with textual information, thereby facilitating the model’s acquisition of more representative and robust category features. Specifically, this article introduces a novel multimodal fusion mechanism—the visual-semantic fusion selection mechanism (VSFSM)—which comprises a fusion selection module (FS-Module) and a category enhancement module (CE-Module). These two modules collaboratively enhance the model’s classification performance. The FS-Module aligns and fuses semantic information with visual features across both channel and spatial dimensions, performing feature selection and reconstruction. This process not only generates representative category features but also mitigates the impact of noise. The CE-Module guides the model to emphasize category-specific features in the query images, ultimately yielding representative visual-semantic category features while reducing the interference of noise in the query images. Additionally, to better facilitate few-shot learning, this article introduces a novel objective loss function for optimized training. Extensive comparative and ablation experiments conducted on multiple datasets further validate the effectiveness of the proposed method.},
  archive      = {J_TNNLS},
  author       = {Yuheng Wang and Zhenping Lan and Yanguo Sun and Nan Wang and Jiansong Li and Xincheng Yang},
  doi          = {10.1109/TNNLS.2025.3561503},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16577-16588},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Few-shot learning based on multimodal information processing},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Staged self-supervised learning for raven progressive matrices. <em>TNNLS</em>, <em>36</em>(9), 16564-16576. (<a href='https://doi.org/10.1109/TNNLS.2025.3561069'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents and investigates abstract compositional transformers (ACTs), a class of deep learning (DL) architectures based on the transformer blueprint, designed to handle abstract reasoning tasks that require completing spatial visual patterns. We combine ACTs with choice-making modules and apply them to Raven progressive matrices (RPMs), logical puzzles that require selecting the correct image from the available answers. We devise a number of ACT variants, train them in several modes and with additional augmentations, subject them to ablations, demonstrate their data scalability, and analyze their behavior and latent representations that emerged in the process. Using self-supervision allows us to successfully train ACTs on relatively small training sets, mitigate several biases identified in RPMs in past studies, and achieve SotA results on the two most popular RPM benchmarks.},
  archive      = {J_TNNLS},
  author       = {Jakub Kwiatkowski and Krzysztof Krawiec},
  doi          = {10.1109/TNNLS.2025.3561069},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16564-16576},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Staged self-supervised learning for raven progressive matrices},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RSF-conv: Rotation-and-scale equivariant fourier parameterized convolution for retinal vessel segmentation. <em>TNNLS</em>, <em>36</em>(9), 16549-16563. (<a href='https://doi.org/10.1109/TNNLS.2025.3560082'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retinal vessel segmentation is of great clinical significance for the diagnosis of many eye-related diseases, but it is still a formidable challenge due to the intricate vascular morphology. With the skillful characterization of the translation symmetry existing in retinal vessels, convolutional neural networks (CNNs) have achieved great success in retinal vessel segmentation. However, the rotation-and-scale symmetry, as a more widespread image prior in retinal vessels, fails to be characterized by CNNs. Therefore, we propose a rotation-and-scale equivariant Fourier parameterized convolution (RSF-Conv) specifically for retinal vessel segmentation and provide the corresponding equivariance analysis. As a general module, RSF-Conv can be integrated into existing networks in a plug-and-play manner while significantly reducing the number of parameters. For instance, we replace the traditional convolution filters in U-Net, Iter-Net, DE-DCGCN-EE, and FR-UNet, with RSF-Convs, and faithfully conduct comprehensive experiments. RSF-Conv-enhanced methods not only have slight advantages under in-domain evaluation but also, more importantly, outperform all comparison methods by a significant margin under out-of-domain evaluation. It indicates that the remarkable generalization of RSF-Conv holds greater practical clinical significance for the prevalent cross-device and cross-hospital challenges in clinical practice. To comprehensively demonstrate the effectiveness of RSF-Conv, we also apply RSF-Conv + U-Net and RSF-Conv + Iter-Net to retinal artery/vein classification and achieve promising performance as well, indicating its clinical application potential. The code is available at https://github.com/szhc0gk/RSF-Conv},
  archive      = {J_TNNLS},
  author       = {Zihong Sun and Hong Wang and Qi Xie and Yefeng Zheng and Deyu Meng},
  doi          = {10.1109/TNNLS.2025.3560082},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16549-16563},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {RSF-conv: Rotation-and-scale equivariant fourier parameterized convolution for retinal vessel segmentation},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A robust three-way classifier with shadowed granular balls based on justifiable granularity. <em>TNNLS</em>, <em>36</em>(9), 16534-16548. (<a href='https://doi.org/10.1109/TNNLS.2025.3563889'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The granular-ball (GB)-based classifier introduced by Xia exhibits adaptability in creating coarse-grained information granules for input, thereby enhancing its generality and flexibility. Nevertheless, the current GB-based classifiers rigidly assign a specific class label to each data instance and lack the necessary strategies to address uncertain instances. These far-fetched certain classification approaches toward uncertain instances may suffer considerable risks. To solve this problem, we construct a robust three-way classifier with shadowed GBs (3WC-SGBs) for uncertain data. First, combined with information entropy, we propose an enhanced GB generation method with the principle of justifiable granularity. Subsequently, based on minimum uncertainty, a shadowed mapping is utilized to partition a GB into core region (COR), important region (IMP), and unessential region (UNE). Based on the constructed shadowed GBs, we establish a three-way classifier to categorize data instances into certain classes and uncertain case. Finally, extensive comparative experiments are conducted with two three-way classifiers, three state-of-the-art GB-based classifiers, and three classical machine learning classifiers on 12 public benchmark datasets. The results show that our model demonstrates robustness in managing uncertain data and effectively mitigates classification risks. Furthermore, our model almost outperforms the other comparison methods in both effectiveness and efficiency.},
  archive      = {J_TNNLS},
  author       = {Jie Yang and Lingyun Xiaodiao and Guoyin Wang and Witold Pedrycz and Shuyin Xia and Qinghua Zhang and Di Wu},
  doi          = {10.1109/TNNLS.2025.3563889},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16534-16548},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A robust three-way classifier with shadowed granular balls based on justifiable granularity},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A reinforcement learning control framework based on scalable graph transformer for large-scale fuzzy job shop scheduling problems. <em>TNNLS</em>, <em>36</em>(9), 16521-16533. (<a href='https://doi.org/10.1109/TNNLS.2025.3569868'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The job shop scheduling problem (JSSP) is a classic NP-hard problem. This article focuses on a realistic variant of the JSSP incorporating fuzzy processing times, with the objective of minimizing the maximum completion time. We propose a proximal policy optimization with graph transformer (GT-PPO) algorithm, which leverages proximal policy optimization (PPO) as the foundational framework, to address this problem for the first time. First, the intricate variability in states and actions often leads to suboptimal scheduling outcomes. To address this, we refine the representation of states and actions for improved performance. Second, to overcome inherent limitations of conventional graph neural networks (GNNs)—including difficulty in handling heterogeneity, over-squashing, and limited ability to capture long-range dependencies—we employ a graph transformer (GT) architecture for the first time in this study. These transformers effectively capture both the topological relationships in fuzzy disjunctive graph models and the long-range dependencies in large-scale JSSP instances. Additionally, we also reduce the computational complexity of the GT to $O(n)$ , enabling the agent to derive optimal scheduling solutions for large disjunctive graphs more efficiently, with reduced memory usage. Finally, the testing results demonstrate the strong robustness of our model across various scales of generated instances and public datasets after a single training session. Notably, on large-scale DMU and Taillard public datasets, the model exhibited exceptional robustness, further validating its effectiveness in addressing large-scale fuzzy JSSP.},
  archive      = {J_TNNLS},
  author       = {Wenquan Zhang and Fei Zhao and Bo Feng and Xuesong Mei},
  doi          = {10.1109/TNNLS.2025.3569868},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16521-16533},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A reinforcement learning control framework based on scalable graph transformer for large-scale fuzzy job shop scheduling problems},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heterogeneous riemannian few-shot learning network. <em>TNNLS</em>, <em>36</em>(9), 16507-16520. (<a href='https://doi.org/10.1109/TNNLS.2025.3561930'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How to learn and accurately distinguish new concepts from few samples, as humans do, is a long-standing concern in artificial intelligence (AI). Studies in brain science and neuroscience have shown that human brain perception is based on nonlinear manifolds, and high-dimensional manifolds can facilitate concept learning in neural circuits. Based on this inspiration, in this paper, we propose a heterogeneous Riemannian few-shot learning network (HRFL-Net), which is the first few-shot learning method to perform end-to-end deep learning on heterogeneous Riemannian manifolds. Specifically, to enhance the geometric invariance of the image representation, the image features are projected into three heterogeneous Riemannian manifold spaces. Then, the implicit Riemannian kernel function maps the manifolds to the separable high-dimensional reproducing Hilbert space. It is assumed that the embedded kernel features of the complementary manifolds are mapped to the same common subspace. Thus, a novel neural network-based Riemannian metric learning method is designed to solve the subspace feature vectors by imposing orthogonal normalized projection, which overcomes the data extension limitation of the Riemannian metric. Finally, with the optimization objective of increasing the interclass distance and decreasing the intraclass distance in Hilbert space, the HRFL-Net is trained with end-to-end stochastic optimization, and the optimal aggregation subspace is learned during the gradient descent process. Thus, the proposed HRFL-Net can be easily generalized to challenging nonconvex data. The evaluation of four public datasets shows that the proposed HRFL-Net has significant superiority and also achieves competitive results compared with the state-of-the-art methods.},
  archive      = {J_TNNLS},
  author       = {Jie Chen and Lingling Li and Licheng Jiao and Fang Liu and Xu Liu and Yuwei Guo and Puhua Chen and Wenping Ma},
  doi          = {10.1109/TNNLS.2025.3561930},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16507-16520},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Heterogeneous riemannian few-shot learning network},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing multiparty dialog discourse parsing with dynamic task-adaptive graph transformer and difficulty-aware task scheduling. <em>TNNLS</em>, <em>36</em>(9), 16492-16506. (<a href='https://doi.org/10.1109/TNNLS.2025.3568211'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiparty dialog discourse parsing (MDDP) aims to identify the links between pairs of utterances and recognize their discourse relations. Previous research has attempted to address data sparsity in discourse parsing through multitask learning, but these efforts often relied on manually annotated fine-grained information, limiting their practical applicability. In this study, we propose dynamic task-adaptive graph transformer with difficulty-aware task scheduling (DTGT-DTS), an innovative multitask approach that enhances discourse parsing by leveraging neighboring tasks like addressee recognition and speaker identification, without requiring additional annotations. These tasks share common discourse links with discourse parsing but also possess distinct private links. To tackle this, we design a dynamic task-adaptive graph transformer (DTGT) that captures shared links between discourse parsing and its neighboring tasks while distinguishing the private links of neighboring tasks. In addition, we develop a difficulty-aware task scheduling (DTS) strategy that promotes multitask learning by dynamically adjusting training priorities based on the relative difficulty of different tasks. Experimental results on two widely used discourse datasets—Molweni (78 245 links and relations) and STAC (12 691 links and relations)—show that our DTGT-DTS model achieves a 6.07% and 5.31% performance improvement in link identification, respectively, and a 7.27% and 6.02% improvement in relation recognition.},
  archive      = {J_TNNLS},
  author       = {Yaxin Fan and Peifeng Li and Fang Kong and Qiaoming Zhu},
  doi          = {10.1109/TNNLS.2025.3568211},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16492-16506},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Enhancing multiparty dialog discourse parsing with dynamic task-adaptive graph transformer and difficulty-aware task scheduling},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Driving risk assessment for intelligent vehicles based on entropy-informed graph neural networks and gaussian distributions. <em>TNNLS</em>, <em>36</em>(9), 16478-16491. (<a href='https://doi.org/10.1109/TNNLS.2025.3569826'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a novel framework based on an entropy-informed graph neural network (EIGNN) integrated with Gaussian distribution (GD) to assess the driving risk of intelligent vehicles in typical traffic scenarios. Existing research often overlooks comprehensive spatiotemporal modeling of vehicle interaction characteristics and the quantification of uncertainty in dynamic risk assessments. In this work, vehicle speed and acceleration are probabilistically modeled using GD, while entropy theory is introduced to quantify risk uncertainty. A risk assessment model based on graph neural networks (GNNs) is then designed to capture the spatiotemporal dynamics of multivehicle interactions and predict the potential risk levels of driving strategies. The results demonstrate that the framework accurately quantifies collision risks in multivehicle interactions in complex traffic scenarios, with high accuracy and robustness across typical situations such as cruising, cut-ins, lane changes, overtaking, and different density traffic. By thoroughly analyzing traffic risk characteristics and incorporating them into intelligent driving decision-making, this study provides significant technical insights and theoretical support for enhancing the safety and decision-making efficiency of autonomous driving systems.},
  archive      = {J_TNNLS},
  author       = {Hongbo Gao and Chengbo Wang and Runda Niu and Xiaozhao Fang and Jinpeng Chen and Yining Sun and Huiqing Jin and Danwei Wang},
  doi          = {10.1109/TNNLS.2025.3569826},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16478-16491},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Driving risk assessment for intelligent vehicles based on entropy-informed graph neural networks and gaussian distributions},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Single hidden layer neural networks with random weights based on nondifferentiable functions. <em>TNNLS</em>, <em>36</em>(9), 16463-16477. (<a href='https://doi.org/10.1109/TNNLS.2025.3555178'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computational algorithms that utilize nondifferentiable functions have proven highly effective in machine learning applications. This study introduces a novel framework for incorporating nondifferentiable functions into the objective functions of random-weight neural networks, specifically focusing on functional link random vector functional-link (RVFL) networks and extreme learning machines (ELMs). Our framework explores six nondifferentiable functions: the norms $ L_{1,1}$ , $ L_{1,2}$ , and $ L_{2,2}$ and the functions AbsMin, AbsMax, and a seminorm MaxMin. To enhance robustness, Fourier random assignments are applied as activation functions within these networks. The integration of these nondifferentiable functions into the objective functions of RVFL and ELM aims to reduce computational time in both training and testing stages, without compromising accuracy. We conducted extensive experiments on 12 benchmark datasets, encompassing small, medium, and large datasets, to evaluate the proposed algorithms against the $L_{2,1}$ -regularized random Fourier feature ELM ( $L_{2,1}$ -RF-ELM), which uses joint-norm regularization ( $L_{r,p}$ ) as documented in previous studies. Our findings indicate that the algorithms based on nondifferentiable functions not only achieve high accuracy but also significantly reduce computation time compared to the $L_{2,1}$ -based algorithm and other standard machine learning approaches.},
  archive      = {J_TNNLS},
  author       = {Yoleidy Huérfano-Maldonado and Karina Vilches-Ponce and Marco Mora and Clovis Tauber and Miguel Vera},
  doi          = {10.1109/TNNLS.2025.3555178},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16463-16477},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Single hidden layer neural networks with random weights based on nondifferentiable functions},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Similarity-agnostic contrastive learning with alterable self-supervision. <em>TNNLS</em>, <em>36</em>(9), 16449-16462. (<a href='https://doi.org/10.1109/TNNLS.2025.3570784'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-supervised contrastive learning (CL) seeks to learn generalizable feature representations via the self-supervision of pairwise similarities, where existing CL approaches usually build definite similarity labels (e.g., positive or negative) for model training. Yet in practice, the same pair of instances may have opposite similarity labels in different scenarios, e.g., two interclass images from CIFAR-100 can be a similar pair in CIFAR-20. Learning with definite similarities can hardly obtain an ideal representation that simultaneously characterizes the similar and dissimilar patterns (e.g., the contexts and details) between each two instances. Therefore, pairwise similarities used for CL should be agnostic, and we argue that simultaneously considering both the similarity and dissimilarity for each data pair could learn more generalizable representations. To this end, we propose similarity-agnostic CL (SACL), which generalizes the instance discrimination strategy of conventional CL to a new multiobjective programming (MOP) form. In SACL, we build multiple projection layers with corresponding regularizers to constrain the distance matrix to have different sparsity in different objectives so that we can obtain alterable pairwise distances to capture both the similarity and dissimilarity between each pair of instances. We show that SACL can be equivalently converted to a single learning objective, easily solved by stochastic optimization with convergence guarantees. Theoretically, we prove a tighter error bound than conventional CL approaches; empirically, our method improves the downstream task performance for image, text, and graph data.},
  archive      = {J_TNNLS},
  author       = {Shuo Chen and Chen Gong and Jun Li and Jian Yang},
  doi          = {10.1109/TNNLS.2025.3570784},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16449-16462},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Similarity-agnostic contrastive learning with alterable self-supervision},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unified optimal transport framework for cross-modal retrieval with noisy labels. <em>TNNLS</em>, <em>36</em>(9), 16435-16448. (<a href='https://doi.org/10.1109/TNNLS.2025.3559533'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-modal retrieval (CMR) aims to establish interaction between different modalities, among which supervised CMR is emerging due to its flexibility in learning semantic category discrimination. Despite the remarkable performance of previous supervised CMR methods, much of their success can be attributed to the well-annotated data. However, even for unimodal data, precise annotation is expensive and time-consuming, and it becomes more challenging with the multimodal scenario. In practice, massive multimodal data are collected from the Internet with coarse annotation, which inevitably introduces noisy labels. Training with such misleading labels would bring two key challenges—enforcing the multimodal samples to align incorrect semantics and widen the heterogeneous gap, resulting in poor retrieval performance. To tackle these challenges, this work proposes UOT-RCL, a unified framework based on optimal transport (OT) for robust CMR. First, we propose a semantic alignment based on partial OT to progressively correct the noisy labels, where a novel cross-modal consistent cost function is designed to blend different modalities and provide precise transport cost. Second, to narrow the discrepancy in multimodal data, an OT-based relation alignment is proposed to infer the semantic-level cross-modal matching. Both of these components leverage the inherent correlation among multimodal data to facilitate effective cost function. The experiments on three widely used CMR datasets demonstrate that our UOT-RCL surpasses the state-of-the-art approaches and significantly improves the robustness against noisy labels.},
  archive      = {J_TNNLS},
  author       = {Haochen Han and Minnan Luo and Huan Liu and Fang Nan and Jun Liu},
  doi          = {10.1109/TNNLS.2025.3559533},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16435-16448},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A unified optimal transport framework for cross-modal retrieval with noisy labels},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An innovative multisource teacher collaborative framework for self-knowledge distillation. <em>TNNLS</em>, <em>36</em>(9), 16420-16434. (<a href='https://doi.org/10.1109/TNNLS.2025.3552931'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-knowledge distillation, abbreviated as SKD, exhibits greater computational efficiency than traditional knowledge distillation (KD) because it learns from its own predictions rather than from a pretrained teacher. Existing SKD methods diversify knowledge through auxiliary branches, data augmentation, historical models, and label smoothing. However, previous methods primarily extract knowledge from a single-source teacher, overlooking the diversity and complementarity of various types of teacher knowledge in model learning, thereby limiting performance improvements. In response to this challenge, we propose a pioneering paradigm termed multisource teacher collaboration for self-knowledge distillation (MSTCS-KD), which integrates knowledge from diverse types of teachers to complementarily enhance the model’s learning capability. We start by adding lightweight auxiliary branches with different structures in the shallow layers to build the student network, while also incorporating a teacher-guided attention mechanism to support adaptive learning. Then, we perform collaborative distillation by combining “heterogeneous knowledge” from the primary network’s deepest layers with “homogeneous knowledge” from the student’s outputs on augmented samples. This complementary distillation approach improves the model’s ability to learn features, generalize, and enhance trainability. Extensive experiments demonstrate that our method outperforms other state-of-the-art SKD methods across various network architectures and datasets.},
  archive      = {J_TNNLS},
  author       = {Lei Zhao and Wing W. Y. Ng and Jianjun Zhang and Xiguang Wu},
  doi          = {10.1109/TNNLS.2025.3552931},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16420-16434},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {An innovative multisource teacher collaborative framework for self-knowledge distillation},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Milne–Hamming method with zeroing neural network for time-varying nonlinear optimization and redundant manipulator application. <em>TNNLS</em>, <em>36</em>(9), 16407-16419. (<a href='https://doi.org/10.1109/TNNLS.2025.3563991'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continuous zeroing neural network (ZNN) and its discrete ZNN (DZNN) are comprehensively developed in many optimization systems. In this article, a Milne–Hamming method with DZNN classified as an implicit method is proposed and discussed upon the previous researches. Specifically, the Milne–Hamming discrete ZNN (MHDZNN) model is aimed for time-varying nonlinear optimization (TV-NO) problem with functional limitations. This Milne–Hamming (MH) method is a four-step discretized formula with fixed parameters and is introduced to discretize the ZNN model. Theoretical analyses of the MHDZNN model derive that MHDZNN possesses a larger stepsize domain $\mu \in (0,1/2)$ of absolute stability. Its convergent error is of order $O(\tau ^{5})$ and the corresponding truncation error constant is $1/40$ , which shows intimate relation to the accuracy. Compared with the existing DZNN models such as four-step explicit methods with the same $O(\tau ^{5})$ pattern, the convergent error constant of MHDZNN is smaller by a factor and maximal stability domain is greater. Finally, numerical simulations and application to redundant manipulators are provided and studied to verify the effectiveness of the proposed MHDZNN model.},
  archive      = {J_TNNLS},
  author       = {Ying Kong and Xi Chen and Yunliang Jiang and Danfeng Sun},
  doi          = {10.1109/TNNLS.2025.3563991},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16407-16419},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Milne–Hamming method with zeroing neural network for time-varying nonlinear optimization and redundant manipulator application},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BihoT: A large-scale dataset and benchmark for hyperspectral camouflaged object tracking. <em>TNNLS</em>, <em>36</em>(9), 16392-16406. (<a href='https://doi.org/10.1109/TNNLS.2025.3564059'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral object tracking (HOT) has many important applications, particularly in scenes where objects are camouflaged. The existing trackers can effectively retrieve objects via band regrouping because of the bias in the existing HOT datasets, where most objects tend to have distinguishing visual appearances rather than spectral characteristics. This bias allows a tracker to directly use the visual features obtained from the false-color images generated by hyperspectral images (HSIs) without extracting spectral features. To tackle this bias, the tracker should focus on the spectral information when object appearance is unreliable. Thus, we provide a new task called hyperspectral camouflaged object tracking (HCOT) and meticulously construct a large-scale HCOT dataset, BihoT, consisting of 41912 HSIs covering 49 video sequences. The dataset covers various artificial camouflage scenes, where objects have similar appearances, diverse spectrums, and frequent occlusion (OCC), making it a challenging dataset for HCOT. Besides, a simple but effective baseline model, named spectral prompt-based distractor-aware network (SPDAN), is proposed, comprising a spectral embedding network (SEN), a spectral prompt-based backbone network (SPBN), and a distractor-aware module (DAM). Specifically, the SEN extracts spectral-spatial features via 3-D and 2-D convolutions to form a refined prompt representation. Then, the SPBN fine-tunes powerful RGB trackers with spectral prompts and alleviates the insufficiency of training samples. Moreover, the DAM utilizes a novel statistic to capture the distractor caused by occlusion from objects and background and corrects the deterioration of the tracking performance via a novel motion predictor. Extensive experiments demonstrate that our proposed SPDAN achieves the state-of-the-art performance on the proposed BihoT and other HOT datasets.},
  archive      = {J_TNNLS},
  author       = {Hanzheng Wang and Wei Li and Xiang-Gen Xia and Qian Du},
  doi          = {10.1109/TNNLS.2025.3564059},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16392-16406},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {BihoT: A large-scale dataset and benchmark for hyperspectral camouflaged object tracking},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AdvMixUp: Adversarial MixUp regularization for deep learning. <em>TNNLS</em>, <em>36</em>(9), 16379-16391. (<a href='https://doi.org/10.1109/TNNLS.2025.3562363'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) have shown significant progress in many application fields. However, overfitting remains a significant challenge in their development. While existing data-augmentation techniques such as MixUp have been successful in preventing overfitting, they often fail to generate hard mixed samples near the decision boundary, impeding model optimization. In this article, we present adversarial MixUp (AdvMixUp), a novel sample-dependent method for regularizing DNNs. AdvMixUp addresses this issue by incorporating adversarial training (AT) to create sample-dependent and feature-level interpolation masks, generating more challenging mixed samples. These virtual samples enable DNNs to learn more robust features, ultimately reducing overfitting. Empirical evaluations on CIFAR-10, CIFAR-100, Tiny-ImageNet, and ImageNet demonstrate that AdvMixUp outperforms existing MixUp variants.},
  archive      = {J_TNNLS},
  author       = {Jun Fu and Xianrui Ji and Dexiong Chen and Guosheng Hu and Shuang Li and Xiating Feng},
  doi          = {10.1109/TNNLS.2025.3562363},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16379-16391},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {AdvMixUp: Adversarial MixUp regularization for deep learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Counterfactual dual-bias VQA: A multimodality debias learning for robust visual question answering. <em>TNNLS</em>, <em>36</em>(9), 16366-16378. (<a href='https://doi.org/10.1109/TNNLS.2025.3562085'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual question answering (VQA) models often face two language bias challenges. First, they tend to rely solely on the question to predict the answer, often overlooking relevant information in the accompanying images. Second, even when considering the question, they may focus only on the wh-words, neglecting other crucial keywords that could enhance interpretability and the question sensitivity. Existing debiasing methods attempt to address this by training a bias model using question-only inputs to enhance the robustness of the target VQA model. However, this approach may not fully capture the language bias present. In this article, we propose a multimodality counterfactual dual-bias model to mitigate the linguistic bias issue in target VQA models. Our approach involves designing a shared-parameterized dual-bias model that incorporates both visual and question counterfactual samples as inputs. By doing so, we aim to fully model language biases, with visual and question counterfactual samples, respectively, emphasizing important objects and keywords to relevant the answers. To ensure that our dual-bias model behaves similarly to an ordinary model, we freeze the parameters of the target VQA model, meanwhile using the cross-entropy and Kullback-Leibler (KL) divergence as the loss function to train the dual-bias model. Subsequently, to mitigate language bias in the target VQA model, we freeze the parameters of the dual-bias model to generate pseudo-labels and then incorporate a margin loss to re-train the target VQA model. Experimental results on the VQA-CP datasets demonstrate the superior effectiveness of our proposed counterfactual dual-bias model. Additionally, we conduct an analysis of the unsatisfactory performance on the VQA v2 dataset. The origin code of the proposed model is available at https://github.com/Arrow2022jv/MCD},
  archive      = {J_TNNLS},
  author       = {Boyue Wang and Xiaoqian Ju and Junbin Gao and Xiaoyan Li and Yongli Hu and Baocai Yin},
  doi          = {10.1109/TNNLS.2025.3562085},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16366-16378},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Counterfactual dual-bias VQA: A multimodality debias learning for robust visual question answering},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient and robust feature selection approach based on zentropy measure and neighborhood-aware model. <em>TNNLS</em>, <em>36</em>(9), 16351-16365. (<a href='https://doi.org/10.1109/TNNLS.2025.3565320'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The feature selection based on the rough set (RS) theory has been an active research topic in data mining and knowledge discovery. Fuzzy RSs (FRSs), an efficient tool to process the inconsistency between features and decisions, have attracted attention to the problems of feature selection. However, most FRSs-based feature selection methods pay much attention to the approximation space while ignoring the interaction between different levels. Note that the single-level feature selection method, depending on the boundary objects, is easily influenced by the noise data and cannot integrate multiple granular levels to evaluate features accurately. Therefore, this article proposes an efficient and robust feature selection approach based on the neighborhood-aware model and zentropy measure. Specifically, we first define a neighborhood-aware FRS (NAFRS) with weighted fuzzy relation to improve the antinoise ability of FRSs. Then, we propose a fuzzy granule zentropy (FGZE) measure based on zentropy by analyzing the granular level relation in NAFRS. Moreover, a significance measure with FGZE is designed and applied to feature selection. Finally, the experimental results of our method on 22 datasets by comparing it with 12 representative feature selection methods demonstrate the antinoise and the classification ability of the proposed method.},
  archive      = {J_TNNLS},
  author       = {Kehua Yuan and Duoqian Miao and Hongyun Zhang and Witold Pedrycz},
  doi          = {10.1109/TNNLS.2025.3565320},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16351-16365},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {An efficient and robust feature selection approach based on zentropy measure and neighborhood-aware model},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning temporal features with alternated similarity and proximity attention for time-series prediction. <em>TNNLS</em>, <em>36</em>(9), 16339-16350. (<a href='https://doi.org/10.1109/TNNLS.2025.3559222'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time-series prediction is a fundamental problem in various scientific and engineering domains. Recently, attention-based models have shown great promise in long-term time-series forecasting. However, we prove that vanilla attention is equivalent to a one-step random walk on a bipartite graph between the query and the keys, in which the limited number of walks and simplified graph structure could make it less powerful in capturing complex, high-order featural and temporal dependencies. Inspired by how human brains iteratively reactivate memories through reminding, we propose “Alternated Similarity And Proximity Attention,” or ASAP-attention. ASAP-attention employs a random walk on two concurrent views (graphs) that, respectively, capture the featural similarity and the temporal proximity between time points. In particular, the random walk alternately visits the two graphs, each time remembering the previous probability configuration to build a coherent chain of distributions to retrieve useful historical data. This dynamic interplay between temporal and featural clues enhances the model’s ability to capture implicit and heterogeneous data dependencies without using positional encoding. When incorporating ASAP-attention with encoder-only Transformer architecture, we observed highly promising results against a wide collection of state-of-the-art methods on various benchmark datasets for long time-series forecasts (e.g., weather, electricity, illness, and exchange-rate data). Our source code is available at https://github.com/jychen01/ASAP-attention},
  archive      = {J_TNNLS},
  author       = {Jingyang Chen and Ping Li and Jiancheng Lv and Hongyuan Zha and Kai Zhang and Jie Zhang},
  doi          = {10.1109/TNNLS.2025.3559222},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16339-16350},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Learning temporal features with alternated similarity and proximity attention for time-series prediction},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Defending against neural network model inversion attacks via data poisoning. <em>TNNLS</em>, <em>36</em>(9), 16324-16338. (<a href='https://doi.org/10.1109/TNNLS.2025.3554656'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model inversion attacks pose a significant privacy threat to machine learning models by reconstructing sensitive data from their outputs. While various defenses have been proposed to counteract these attacks, they often come at the cost of the classifier’s utility, thus creating a challenging trade-off between privacy protection and model utility. Moreover, most existing defenses require retraining the classifier for enhanced robustness, which is impractical for large-scale, well-established models. This article introduces a novel defense mechanism to better balance privacy and utility, particularly against adversaries who employ a machine learning model (i.e., inversion model) to reconstruct private data. Drawing inspiration from data poisoning attacks, which can compromise the performance of machine learning models, we propose a strategy that leverages data poisoning to contaminate the training data of inversion models, thereby preventing model inversion attacks. Two defense methods are presented. The first, termed label-preserving poisoning attacks for all output vectors (LPA), involves subtle perturbations to all output vectors while preserving their labels. Our findings demonstrate that these minor perturbations, introduced through a data poisoning approach, significantly increase the difficulty of data reconstruction without compromising the utility of the classifier. Subsequently, we introduce a second method, label-flipping poisoning for partial output vectors (LFP), which selectively perturbs a small subset of output vectors and alters their labels during the process. Empirical results indicate that LPA is notably effective, outperforming the current state-of-the-art defenses. Our data poisoning-based defense provides a new retraining-free defense paradigm that preserves the victim classifier’s utility.},
  archive      = {J_TNNLS},
  author       = {Shuai Zhou and Dayong Ye and Tianqing Zhu and Wanlei Zhou},
  doi          = {10.1109/TNNLS.2025.3554656},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16324-16338},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Defending against neural network model inversion attacks via data poisoning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient domain knowledge-guided semantic prediction framework for pathological subtypes on the basis of radiological images with limited annotations. <em>TNNLS</em>, <em>36</em>(9), 16309-16323. (<a href='https://doi.org/10.1109/TNNLS.2025.3558596'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of pathological subtypes on radiological images is one of the most important deep learning (DL) tasks for the appropriate selection of clinical treatment. It is challenging for conventional DL models to obtain sufficient pathological labels for training because of the heavy workload, invasive surgery, and knowledge requirements in pathological analysis. However, existing methods based on limited annotations, such as active learning (AL) and semi-supervised learning (SSL), have difficulty in capturing lesion’s effective features because of the complicated semantic information of radiologic images. In this article, we introduce an efficient domain knowledge-guided semantic prediction framework that integrates domain knowledge-guided AL and SSL methods. This framework can effectively predict pathological subtypes on the basis of radiologic images with limited pathological annotations via three key modules: 1) the discriminative spatial-semantic feature extraction module captures the spatial-semantic features of lesions as semantic information that can better reflect the semantic relationship and effectively mitigate overfitting risk; 2) the explicit sign-guided anchor attention module measures the multimodal semantic distribution of samples under the guidance of clinical domain knowledge, thus selecting the most representative AL samples for pathological labeling; and 3) the implicit radiomics-guided dual-task entanglement module exploits the inherent constraint relationships between implicit radiomics features (IRFs) and pathological subtypes, facilitating the aggregation of unlabeled data. Experiments have been extensively conducted to evaluate our method in two clinical tasks: the pathological grading prediction in pancreatic neuroendocrine neoplasms (pNENs) and muscular invasiveness prediction in bladder cancer (BCa). The experimental results on both tasks demonstrate that the proposed method consistently outperforms the state-of-the-art approaches by a large margin.},
  archive      = {J_TNNLS},
  author       = {Chenglang Yuan and Jianpeng Li and Bin Huang and Mingyu Wang and Kangyang Cao and Yanji Luo and Yujian Zou and Shi-Ting Feng and Bingsheng Huang},
  doi          = {10.1109/TNNLS.2025.3558596},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16309-16323},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {An efficient domain knowledge-guided semantic prediction framework for pathological subtypes on the basis of radiological images with limited annotations},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward faithful neural network intrinsic interpretation with shapley additive self-attribution. <em>TNNLS</em>, <em>36</em>(9), 16294-16308. (<a href='https://doi.org/10.1109/TNNLS.2025.3570692'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-interpreting neural networks have attracted significant attention from the research community. Along this line, extensive works inherently share the intuitive principle of linear contribution aggregation from diversified perspectives, while often: 1) lacking a solid theoretical foundation ensuring genuine interpretability and 2) compromising model expressiveness. In response, we propose a generic additive self-attribution (ASA) framework to encapsulate the characteristics of various works in this field and underscore the absence of the Shapley value attribution. To fill in this gap, we propose a novel Shapley additive self-attributing neural network (SASANet). SASANet models meaningful outputs for arbitrary-numbered observable features, naturally leading to an unapproximated value function for Shapely value. Designing an intermediate sequential schema based on marginal contributions (MCs) and internal distillation procedure, we theoretically prove that the intermediate self-attribution value converging to the output’s Shapley values. Finally, we conduct extensive experiments on multiple public datasets. The experimental results clearly demonstrate SASANet, being highly interpretable, outperforms existing self-attributing models in performance and is comparable with commonly adopted closed-box models. In addition, compared with adopting post hoc interpretation methods, SASANet’s self-attribution provides a more accurate and efficient interpretation for its own predictions. To the best of the authors’ knowledge, this is the first self-interpreting neural network structure that achieves modelwise Shapley attribution. Our code is available at: https://anonymous.4open.science/r/SASANet-B343},
  archive      = {J_TNNLS},
  author       = {Ying Sun and Hengshu Zhu and Hui Xiong},
  doi          = {10.1109/TNNLS.2025.3570692},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16294-16308},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Toward faithful neural network intrinsic interpretation with shapley additive self-attribution},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Point-DAE: Denoising autoencoders for self-supervised point cloud learning. <em>TNNLS</em>, <em>36</em>(9), 16279-16293. (<a href='https://doi.org/10.1109/TNNLS.2025.3557055'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Masked autoencoder (MAE) has demonstrated its effectiveness in self-supervised point cloud learning. Considering that masking is a kind of corruption, in this work we explore a more general denoising autoencoder for point cloud learning (Point-DAE) by investigating more types of corruptions beyond masking. Specifically, we degrade the point cloud with certain corruptions as input, and learn an encoder-decoder model to reconstruct the original point cloud from its corrupted version. Three corruption families (i.e., density/masking, noise, and affine transformation) and a total of 14 corruption types are investigated with traditional non-Transformer encoders. Besides the popular masking corruption, we identify another effective corruption family, i.e., affine transformation. The affine transformation disturbs all points globally, which is complementary to the masking corruption where some local regions are dropped. We also validate the effectiveness of affine transformation corruption with the Transformer backbones, where we decompose the reconstruction of the complete point cloud into the reconstructions of detailed local patches and rough global shape, alleviating the position leakage problem in the reconstruction. Extensive experiments on tasks of object classification, few-shot learning, robustness testing, part segmentation, and 3-D object detection validate the effectiveness of the proposed method. The codes are available at https://github.com/YBZh/Point-DAE},
  archive      = {J_TNNLS},
  author       = {Yabin Zhang and Jiehong Lin and Ruihuang Li and Kui Jia and Lei Zhang},
  doi          = {10.1109/TNNLS.2025.3557055},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16279-16293},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Point-DAE: Denoising autoencoders for self-supervised point cloud learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analysis and design of a distributed kWTA with application in sealed-bid auctions with bidding price privacy protection. <em>TNNLS</em>, <em>36</em>(9), 16264-16278. (<a href='https://doi.org/10.1109/TNNLS.2025.3554440'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a distributed k-winner-take-all (kWTA) with application in sealed-bid auctions with bidding price privacy protection. The proposed kWTA is in essence a distributed network of n agents which are arbitrarily connected. Let $\aleph _{i}$ be the set of neighbor agents of the ith agent, $u_{i}$ , $x_{i}$ , and $z_{i}$ are, respectively, its input, state variable, and output. The dynamics of the ith agent is given by $ ((dx_{i}(t))/dt) = \tau \left \{{{ z_{i}(x_{i}(t)) - (k/n) - \beta \sum _{j\in \aleph _{i}} (x_{i}(t) - x_{j}(t)) }}\right \}, z_{i}(x_{i}(t)) = h(u_{i}-x_{i}(t)), \text {for}~i = 1, \ldots , n$ where $\beta \gt 0$ , k is the number of winners and $h(\cdot)$ is the Heaviside function. By the theory of discontinuous dynamic systems, it is shown that the state equation for $d{\mathbf {x}}(t)/dt$ could be formulated as a gradient differential inclusion which minimizes the following nonsmooth convex function. $V({\mathbf {x}}) = \sum _{i=1}^{n} \max \{0, u_{i} - x_{i}\} + (k/n) \sum _{i=1}^{n} x_{i} + (\beta /2){\mathbf {x}}^{T} {\mathbf {L}} {\mathbf {x}}$ where ${\mathbf {x}} = (x_{1}, \ldots , x_{n})^{n}$ and ${\mathbf {L}} \in R^{n\times n}$ is the graph Laplacian matrix. A sufficient condition for $\beta $ is derived for the kWTA giving correct output and the condition is then applied in showing that ${\mathbf {z}}(t)$ converges to the correct output in finite-time. If $\beta \rightarrow \infty $ and $x_{1}(0) = \cdots = x_{n}(0)$ , we further show that $x_{1}(t) = \cdots = x_{n}(t)$ for $t \geq 0$ , and both ${\mathbf {z}}(t)$ and ${\mathbf {x}}(t)$ converge in finite-time. Besides, $x_{i}$ converges to $u_{\pi _{n-k+1}}$ (resp. $u_{\pi _{n-k}}$ ) if $x_{i}(0) \gg 1$ (resp. $x_{i}(0) = 0)$ for $i = 1, \ldots , n$ . If the input $u_{i}$ is set to be the bid price of the ith bidder and $k = 1$ , the proposed kWTA is able to determine both the winners and the clearing price for a sealed-bid first (resp. second) price auction in a distributed manner. Once ${\mathbf {z}}(t)$ and ${\mathbf {x}}(t)$ converge, each bidder can reveal from: 1) $z_{i}$ if he/she is a winner and 2) $x_{i}$ the clearing price. As bidders do not have to disclose their bidding prices during the winner (resp. the clearing price) determination process, the loosing (resp. winning) bidding price privacy can be protected in a sealed-bid first (resp. second) price auction. It is insofar the first application of an kWTA beyond the winner’s determination.},
  archive      = {J_TNNLS},
  author       = {John Sum and Chi-Sing Leung and Janet C. C. Chang},
  doi          = {10.1109/TNNLS.2025.3554440},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16264-16278},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Analysis and design of a distributed kWTA with application in sealed-bid auctions with bidding price privacy protection},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Proportional-integral-observer-based fusion estimation for artificial neural networks: Implementing a one-bit encoding scheme. <em>TNNLS</em>, <em>36</em>(9), 16253-16263. (<a href='https://doi.org/10.1109/TNNLS.2025.3556370'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article is concerned with the proportional-integral-observer (PIO)-based fusion estimation problem for a class of artificial neural networks (ANNs) equipped with multiple sensors, which are constrained by bandwidth and subjected to unknown-but-bounded noises (UBBNs). For the purpose of efficient information communication, an approach known as the one-bit encoding mechanism (OBEM) is proposed that enables the encoding of scalar data using merely a single bit. Then, a local PIO-based set-membership estimator is devised for each sensor node, with the aim of achieving the desired estimation task while considering the possible data distortion due to OBEM and the existence of UBBNs. Subsequently, sufficient conditions are established to ensure the existence and effectiveness of the PIO-based set-membership estimator. Moreover, to enhance the global estimation performance, an ellipsoid-based fusion rule is introduced for all local PIO-based set-membership estimators. The performance of fusion estimation is then analyzed using set theory and the optimization method, leading to the determination of relevant parameters. Finally, the effectiveness and advantages of the proposed estimation algorithm are demonstrated through a simulation example.},
  archive      = {J_TNNLS},
  author       = {Kaiqun Zhu and Zidong Wang and Derui Ding and Jun Hu and Hongli Dong},
  doi          = {10.1109/TNNLS.2025.3556370},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16253-16263},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Proportional-integral-observer-based fusion estimation for artificial neural networks: Implementing a one-bit encoding scheme},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Can graph neural networks tackle heterophily? yes, with a label-guided graph rewiring approach!. <em>TNNLS</em>, <em>36</em>(9), 16238-16252. (<a href='https://doi.org/10.1109/TNNLS.2025.3565108'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) witness impressive performances on homophilic graphs characterized by a higher number of edges connecting nodes of similar class labels. A decline in the performance of GNNs can be experienced when applied to heterophilic graphs where most of the edges connect nodes with different class labels. This study presents a novel and versatile preprocessing framework comprising three fundamental stages. This framework can be seamlessly integrated with various GNN architectures to address heterophily within graphs effectively. In the initial stage, we predict class probabilities for nodes through a dense network. It is widely acknowledged that conventional feature-based similarity measures, such as cosine similarity, might not always accurately capture the correspondence between node pairs. Moving to the second stage, we introduce a reweighting strategy guided by class embeddings generated from autoencoders to counter this limitation. In the final stage, we utilize the reweighted similarity coefficients in a two-stage graph rewiring process. This process involves node deletion and subsequent insertion to generate a more homophily-oriented neighborhood. We reuse class embeddings by fusing them with the original node features to enrich the node features with class-level information. The updated node features and the rewired graph structure are ultimately fed into the GNN model. This facilitates effective message passing (MP) across neighborhoods. We extensively evaluate our approach on various standard graph datasets encompassing homophilic and heterophilic characteristics. Across these datasets, our framework consistently improves the performance of the established baseline methods.},
  archive      = {J_TNNLS},
  author       = {Kushal Bose and Saptarshi Banerjee and Swagatam Das},
  doi          = {10.1109/TNNLS.2025.3565108},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16238-16252},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Can graph neural networks tackle heterophily? yes, with a label-guided graph rewiring approach!},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scale-driven tensor representation-based multiview clustering. <em>TNNLS</em>, <em>36</em>(9), 16223-16237. (<a href='https://doi.org/10.1109/TNNLS.2025.3558613'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world data tends to exhibit an inherent hierarchical structure, providing a natural multiview perspective where features at different scales can be treated as distinct views. However, most existing multiview clustering algorithms primarily focus on the inter-sample relationships at a single level. These methods overlook the hierarchical structures present in the data and are specifically designed for native multiview data. This article introduces a comprehensive multiview clustering framework that transforms both typical data and images into a unified multiview feature representation. The framework allows for extracting multiscale features from the raw data and clustering different types of data with the same algorithm. A novel scale-driven pre-processing approach unifies the feature structure across various data types and explores local relationships among samples at multiple scales. Features at larger scales delineate the global cluster contours, while features at smaller scales reveal fine-grained local details. Subsequently, the proposed method learns the view-specific partitions from different scales of views and derives consensus features through tensor low-rank representation. By optimizing these consensus features, the approach effectively captures the precise cluster shapes from coarse to fine-grained levels. The final label indicator matrix is directly obtained from these consensus features. To demonstrate the effectiveness and versatility of the proposed method, we conducted experimental comparisons with state-of-the-art (SOTA) algorithms in both multiview clustering and image segmentation across diverse datasets. The source code and datasets are released at https://github.com/ChuanbinZhang/SDTR},
  archive      = {J_TNNLS},
  author       = {Chuanbin Zhang and Long Chen and Weiping Ding and Kai Zhao and Zhaoyin Shi and Yingxu Wang and C. L. Philip Chen},
  doi          = {10.1109/TNNLS.2025.3558613},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16223-16237},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Scale-driven tensor representation-based multiview clustering},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Class-specific prompt learning for Vision–Language models. <em>TNNLS</em>, <em>36</em>(9), 16213-16222. (<a href='https://doi.org/10.1109/TNNLS.2025.3566559'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of learning prompts to adapt pretrained vision–language models (VLMs) for downstream tasks has gained significant attention due to its potential to reduce training costs compared to model fine-tuning through few-shot learning. Most existing methods rely on a universal prompt for all classes, as it generally delivers consistent performance across various datasets. However, a universal prompt cannot capture class-specific discriminative information. To overcome this limitation, we propose class-specific prompt learning (CPL). CPL represents the context of a prompt using two components: a base vector shared among all classes and a class-specific vector designed for individual classes. This method combines the generalization ability of the base context with the adaptability of the class-specific context. Furthermore, we introduce contrastive CPL, which enhances the ability of the prompt to capture discriminative features unique to each class. Also, we adopt the self-consistency loss to regularize the base context, enhancing its generalization ability. As a result, CPL effectively learns tailored prompts for each class. Extensive experiments demonstrate that CPL achieves superior performance over existing methods in both base-class classification and new class generalization.},
  archive      = {J_TNNLS},
  author       = {Runhao Li and Yongming Chen and Zhenyu Weng and Zhiping Lin and Yap-Peng Tan},
  doi          = {10.1109/TNNLS.2025.3566559},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16213-16222},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Class-specific prompt learning for Vision–Language models},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Probabilistic safety regions via finite families of adjustable classifiers. <em>TNNLS</em>, <em>36</em>(9), 16198-16212. (<a href='https://doi.org/10.1109/TNNLS.2025.3568174'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The supervised classification recognizes patterns in the data to separate classes of behaviors. Canonical solutions contain misclassification errors that are intrinsic to the numerical approximating nature of machine learning (ML). The data analyst may minimize the classification error on a class at the expense of increasing the error of the other classes. The error control of such a design phase is often done in a heuristic manner. In this article, it is key to develop theoretical foundations capable of providing probabilistic certifications to the obtained classifiers. In this perspective, we introduce the concept of probabilistic safety region to describe a subset of the input space in which the number of misclassified instances is probabilistically controlled. The notion of adjustable classifiers, a special class of classifiers that share the property of being controllable by a scalar parameter, is then exploited to link the tuning of ML with error control. Several tests and examples corroborate the approach. They are provided through the synthetic data in order to highlight all the steps involved, as well as notable benchmark datasets and a smart mobility application.},
  archive      = {J_TNNLS},
  author       = {Alberto Carlevaro and Teodoro Alamo and Fabrizio Dabbene and Maurizio Mongelli},
  doi          = {10.1109/TNNLS.2025.3568174},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16198-16212},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Probabilistic safety regions via finite families of adjustable classifiers},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural honeypoint: An active defense framework against model inversion attacks. <em>TNNLS</em>, <em>36</em>(9), 16186-16197. (<a href='https://doi.org/10.1109/TNNLS.2025.3554217'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning-based systems have been proved to be vulnerable against model inversion attacks (MIAs), where attackers steal private information of training data by querying the target model using synthetic samples. To alleviate the urgent threat introduced by MIAs, existing advancements are proposed to increase the attack overhead by limiting the information available. Although these methods successfully reduced the attack success rate (ASR) for a one-time inversion attempt, they usually compromise the usability of the protected model. More importantly, existing MIA defense methods fail to capture attack attempts, which can lead to persistent threats to data privacy. To bridge this gap, we propose Neural Honeypoint, an active defense framework against MIAs. The key insight is that MIA attackers will make a series of forward steps in the feature space while benign users will not. Motivated by the observation, defenders can deploy active defense devices (honeypoints) on critical paths to capture attack behaviors. Specifically, Neural Honeypoint first models the attackers’ capabilities from the frequency domain and designs specialized honeypoints for protected classes in the training dataset. Subsequently, it deploys these honeypoints into the protected model via backdoor-like model fine-tuning. Then, defenders can distinguish model inversion examples by comparing the similarity of input features with deployed honeypoints. Experiments show that Neural Honeypoint reduces the ASRs of advanced MIAs to 0%~2%. Furthermore, it can effectively capture inversion queries, which helps defenders to detect and block attacks in time.},
  archive      = {J_TNNLS},
  author       = {Yixiao Xu and Mohan Li and Binxing Fang and Yuan Liu and Zhihong Tian},
  doi          = {10.1109/TNNLS.2025.3554217},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16186-16197},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Neural honeypoint: An active defense framework against model inversion attacks},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CKDF-v2: Effectively alleviating representation shift for continual learning with small memory. <em>TNNLS</em>, <em>36</em>(9), 16171-16185. (<a href='https://doi.org/10.1109/TNNLS.2025.3569834'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In continual learning (CL), the newly arrived data are often out-of-distribution from the previous ones, causing drastic representation shift (RS) when updating the old model on the new data, leading to catastrophic forgetting. In this work, we propose feature boosting calibration (FBC) to tackle this problem. Specifically, an expanded module is trained to learn all the classes, including the old and new classes, discovering critical features missed by the original/old model. Then, an FBC network (FBCN) is trained to exploit these missed features to calibrate the old representations. As the missed features increase the information needed for distinguishing between the old and new classes, FBCN generates the calibrated ones with more transferable features, thus alleviating the RS. Next, given the limited memory to store samples of the old/learned classes, the data are severely imbalanced between the old and new classes. To cope with this problem, we propose blockwise knowledge distillation (BWKD), which splits the softmax layer into blocks according to class frequency and then distills each block separately, resolving data imbalance effectively. Building upon the two improvements, we propose a two-stage training framework for CL, named CKDF-V2, providing an enhanced version of the cascaded knowledge distillation framework (CKDF). Furthermore, we integrate it with a task-token expansion method to develop a novel approach for CL based on the vision transformer (ViT). Extensive experiments show that both a convolutional neural network (CNN) and ViT-based CKDF-V2 obtain favorable results across multiple CL benchmarks.},
  archive      = {J_TNNLS},
  author       = {Kunchi Li and Hongyang Chen and Jun Wan and Shan Yu},
  doi          = {10.1109/TNNLS.2025.3569834},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16171-16185},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {CKDF-v2: Effectively alleviating representation shift for continual learning with small memory},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On learning label noise robust networks via regularization: A topological view. <em>TNNLS</em>, <em>36</em>(9), 16156-16170. (<a href='https://doi.org/10.1109/TNNLS.2025.3561368'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks, especially those update parameters by optimizing the difference between fit values and actual labels, often encounter challenges with real-world data containing mislabeled samples (called label noise). This label noise adversely affects the generalization performance of the network by disturbing local fit values. While existing network regularization methods such as data augmentation and label smoothing (LS) have shown usefulness in mitigating the devastation caused by label noise, they primarily focus on global constraints and overlook the local impacts of label noise. Furthermore, the detailed influence of label noise on network function remains underexplored. To fill this gap, our article presents an in-depth analysis of the local effects of label noise on neural networks from a topological perspective. A novel regularization method, network boundary topology regularization (NBTR), based on persistent homology, is introduced. This method is specifically designed for local fit values of the network, with the aim of simplifying the topology of each class boundary. By doing so, it effectively reduces the tendency of a network to memorize label noise. Extensive experiments have been conducted across a range of datasets, network structures, and noise types to validate the effectiveness of this method. Our findings demonstrate that this method not only surpasses strong baseline methods in network generalization accuracy, especially in asymmetric noise conditions (improving average generalization accuracy by 7.72%), but also enhances the anti-noise capabilities of traditional methods when integrated as a complementary method.},
  archive      = {J_TNNLS},
  author       = {Chun Zhou and Hua Meng and Ming Li and Zhengchun Zhou},
  doi          = {10.1109/TNNLS.2025.3561368},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16156-16170},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {On learning label noise robust networks via regularization: A topological view},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An interpretable neural control network with adaptable online learning for sample efficient robot locomotion learning. <em>TNNLS</em>, <em>36</em>(9), 16143-16155. (<a href='https://doi.org/10.1109/TNNLS.2025.3552793'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robot locomotion learning using reinforcement learning suffers from training sample inefficiency and exhibits the non-interpretable/closed-box nature. Thus, this work presents a novel SME-Adaptable Gradient-weighting Online Learning (AGOL) to address such problems. First, sequential motion executor (SME) is a three-layer interpretable neural network, where the first produces the sequentially propagating hidden states, the second constructs the corresponding triangular bases with minor non-neighbor interference, and the third maps the bases to the motor commands. Second, the AGOL algorithm prioritizes the update of the parameters with high relevance score, allowing the learning to focus more on the highly relevant ones. Thus, these two components lead to an analyzable framework, where each sequential hidden state/basis represents the learned key poses/robot configuration. Compared to state-of-the-art methods, the SME-AGOL requires 40% fewer samples and receives 150% higher final reward/locomotion performance on a simulated hexapod robot, while taking merely 10 min of learning time from scratch on a physical hexapod robot. Taken together, this work not only proposes the SME-AGOL for sample efficient and understandable locomotion learning but also emphasizes the potential exploitation of interpretability for improving sample efficiency and learning performance.},
  archive      = {J_TNNLS},
  author       = {Arthicha Srisuchinnawong and Poramate Manoonpong},
  doi          = {10.1109/TNNLS.2025.3552793},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16143-16155},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {An interpretable neural control network with adaptable online learning for sample efficient robot locomotion learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multithreaded asynchronous deep reinforcement learning with multisensor fusion for robot collision avoidance. <em>TNNLS</em>, <em>36</em>(9), 16128-16142. (<a href='https://doi.org/10.1109/TNNLS.2025.3556438'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To develop a safe and efficient navigation system of robotic vehicles in dynamic scenes, a new collision-avoidance method using deep reinforcement learning (DRL) is presented. First, a novel method of DRL based on multithreaded asynchronous proximal policy optimization (MAPPO) is developed. It can convert expensive online calculation into an offline training process, improving the sample efficiency during policy learning. Then, a multisensor fusion measurement (MSFM) method is presented by the combination of global reference path (GRP), laser scanner measurement (LSM), and motion energy (ME), to observe the state space of environment to maximum extent. By multireward refining at each timestep, the sparsity of rewards is avoided. On this basis, a collision-avoidance neural network (CANN) fused in multiscale and multilevel is devised to generate high-quality obstacle features, which can enable the MAPPO to master collision threat effectively. Besides, a premature collision prediction (PCP) module supervised by GRP is devised as an auxiliary task to learn high-level feature representation to further improve the safety during robot collision avoidance. Finally, a two-stage training strategy from 2-D Stage to 3-D Gazebo is presented to realize sufficient robot-environment interaction. This way, the policy model can maximize its degree of exploration in complex dynamic scenarios. Extensive navigation experiments are conducted on the complex simulation and real-world scenarios with a variety of obstacles, along with multiple comparative experiments to testify the effectiveness and robustness of our approach in robot collision avoidance. Experiment results reveal that our method can make farsighted navigation decisions in complex dynamic environments to dodge collisions successfully while moving toward the goal.},
  archive      = {J_TNNLS},
  author       = {Chao Sun and Xing Wu and Yanxu Su and Xiasheng Shi and Changyin Sun},
  doi          = {10.1109/TNNLS.2025.3556438},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16128-16142},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Multithreaded asynchronous deep reinforcement learning with multisensor fusion for robot collision avoidance},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Boosting generalization of semantic segmentation with unseen style seeking-based meta-learning. <em>TNNLS</em>, <em>36</em>(9), 16113-16127. (<a href='https://doi.org/10.1109/TNNLS.2025.3560263'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article considers a worst and most challenging scene in domain generalization (DG), where a model aims to generalize well on unseen domains while only one single domain is available for training. Existing randomization-based methods achieve this goal by enriching the style of the training data. However, they fail to guarantee the diversity of newly generated data required for generalization and thus lead to insufficient expansion of the training distribution. Thus, we propose a novel single DG (SDG) framework, unseen style seeking-based meta-learning (USSML). In USSML, multiple plausible domains with various styles are first constructed from a single source domain and the combination is performed across generated domains to emulate unseen images, extending the distribution boundaries of the source domain. The domain combination is performed at two levels, i.e., global and instance, to meet the generalization challenge in semantic segmentation. Then, the generated diverse domains are further exploited to force the model to optimize in an unbiased manner across all domains by relearning regions lacking domain-invariant representation capability, driving the model toward domain invariance. A point worth mentioning is that the proposed method is easily integrated into existing segmentation methods with little computational cost to improve their generalization. Extensive experiments are conducted on five popular segmentation datasets and the results have verified the effectiveness of USSML in improving the model’s generalization and the superiority of USSML over existing works.},
  archive      = {J_TNNLS},
  author       = {Qi Zang and Shuang Wang and Dong Zhao and Wanqing Li and Zining Wang and Dou Quan and Fei Liang and Licheng Jiao},
  doi          = {10.1109/TNNLS.2025.3560263},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16113-16127},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Boosting generalization of semantic segmentation with unseen style seeking-based meta-learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time depth completion with multimodal feature alignment. <em>TNNLS</em>, <em>36</em>(9), 16100-16112. (<a href='https://doi.org/10.1109/TNNLS.2025.3551903'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a key problem in computer vision, depth completion aims to recover dense depth maps from sparse ones [generally derived from light detection and ranging (LiDAR)]. Most methods introduce synchronous RGB images and leverage multimodal fusion to integrate multimodal features from these modalities to describe the complete scene. However, their different natural characteristics lead to inconsistency in features, potentially impacting the effectiveness of multimodal feature fusion. To address this issue, we propose a feature alignment network (FANet) that introduces an alignment scheme to enhance the consistency between multimodal features. This scheme aligns the modality-invariant semantic context, which is invariant to changes in modality and represents the correlation between a pixel and its surroundings. Specifically, we first design an asymmetric context extraction (ACE) module to extract modality-invariant semantic contexts from multimodal features within limited GPU memory, and then pull them closer to improve consistency. Crucially, our alignment scheme is only applied during the training phase, and no additional computation cost is incurred in the inference phase. Moreover, we introduce a simple yet effective refinement module to refine estimated results via residual learning based on intermediate depth maps and sparse depth maps. Extensive experiments on KITTI and VOID datasets demonstrate that our method achieves competitive performance against typical real-time methods. In addition, we embed the proposed alignment scheme and refinement module into other methods to demonstrate their effectiveness.},
  archive      = {J_TNNLS},
  author       = {Shenglun Chen and Xinzhu Ma and Hong Zhang and Haojie Li and Baoli Sun and Zhihui Wang},
  doi          = {10.1109/TNNLS.2025.3551903},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16100-16112},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Real-time depth completion with multimodal feature alignment},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring contextual knowledge-enhanced speech recognition in air traffic control communication: A comparative study. <em>TNNLS</em>, <em>36</em>(9), 16085-16099. (<a href='https://doi.org/10.1109/TNNLS.2025.3569776'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate recognition of named entities from spoken instructions remains a significant challenge for automatic speech recognition (ASR) techniques in air traffic control (ATC), which limits the reliability of ASR-based applications. A promising solution to overcome this challenge is to integrate prior contextual knowledge into ASR since it contains rich named entities used in ATC communications. Although existing studies have investigated ATC-related contextual ASR techniques, there is a lack of benchmarks to evaluate the advantages of different approaches. In this article, a comprehensive comparative study is presented to explore effective contextual ASR approaches for the ATC domain. Specifically, several typical contextual ASR approaches are introduced in ATC to conduct a comprehensive comparison. Moreover, a novel contextual ASR model, denoted CATCNet, is presented to dedicatedly address the domain-specific problems in ATC, such as limited resources, fast speech, and volatile noise. Several evaluation metrics are proposed to validate the performance of comparison approaches based on the practical requirements of ATC efforts. Extensive experiments are conducted across two real-world ATC speech corpora to build the benchmark. The experimental results demonstrated that integrating context knowledge is effective in improving the recognition performance of named entities. Crucially, the proposed CATCNet outperforms other baseline models by confirming all technical improvements, achieving 80.0% and 86.54% instruction recognition accuracy (IRA) on the ATCSpeech and C-ATCSpeech corpora, respectively. It is believed that this work not only overcomes the bottleneck of ASR performance in the ATC domain, but also provides an applicable solution for ATC-related ASR applications.},
  archive      = {J_TNNLS},
  author       = {Dongyue Guo and Shiyu Zhang and Jianwei Zhang and Bo Yang and Yi Lin},
  doi          = {10.1109/TNNLS.2025.3569776},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16085-16099},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Exploring contextual knowledge-enhanced speech recognition in air traffic control communication: A comparative study},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reinforcement learning with sparse-executing action via sparsity regularization. <em>TNNLS</em>, <em>36</em>(9), 16072-16084. (<a href='https://doi.org/10.1109/TNNLS.2025.3555314'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning (RL) has demonstrated impressive performance in decision-making tasks like embodied control, autonomous driving, and financial trading. In many decision-making tasks, the agents often encounter the problem of executing actions under limited budgets. However, classic RL methods typically overlook the challenges posed by such sparse-executing actions. They operate under the assumption that all actions can be taken for an unlimited number of times, both in the formulation of the problem and in the development of effective algorithms. To tackle the issue of limited action execution in RL, this article first formalizes the problem as a sparse action Markov decision process (SA-MDP), in which specific actions in the action space can only be executed for a limited time. Then, we propose a policy optimization algorithm, Action Sparsity REgularization (ASRE), which adaptively handles each action with a distinct preference. ASRE operates through two steps. First, ASRE evaluates action sparsity by constrained action sampling. Following this, ASRE incorporates the sparsity evaluation into policy learning by way of an action distribution regularization. We provide theoretical identification that validates the convergence of ASRE to a regularized optimal value function. Experiments on tasks with known sparse-executing actions, where classical RL algorithms struggle to train policy efficiently, show that ASRE effectively constrains the action sampling and outperforms baselines. Moreover, we present that ASRE can generally improve the performance in Atari games, demonstrating its broad applicability.},
  archive      = {J_TNNLS},
  author       = {Jing-Cheng Pang and Tian Xu and Shengyi Jiang and Yu-Ren Liu and Yang Yu},
  doi          = {10.1109/TNNLS.2025.3555314},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16072-16084},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Reinforcement learning with sparse-executing action via sparsity regularization},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Probably approximately correct bayes meta-learning with parameterized-bounded guarantees. <em>TNNLS</em>, <em>36</em>(9), 16062-16071. (<a href='https://doi.org/10.1109/TNNLS.2025.3551687'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In meta-learning, the learner extracts knowledge from the observed tasks and quickly adapts to unseen future tasks. We provide a novel and rigorous-analyzed probably approximately correct Bayes (PAC-Bayes) meta-learning method with parameterized bounds, which learns a posterior distribution from given priors and the data samples. The proposed method is designed to improve generalization stabilities with tighter bound guarantees. We prove that the proposed PAC-Bayes bound of the meta-learner is tighter than previous work under a given condition in a rigorous theoretical way. An explicit theoretical analysis of the generalization errors is also given based on the proposed meta-learning method. Using the proposed bound in our work, we deduce an optimal objective function of the meta-learner that should be minimized during the meta-training process. We validate our theoretical hypothesis by conducting synthetic and real-world environments for meta-learning. Both rigorous proofs and experimental results reveal that our method yields state-of-the-art performances under a variety of meta-learning tasks in terms of accuracy and uncertainty robustness.},
  archive      = {J_TNNLS},
  author       = {Zhewei Zhang and Yujun Cheng and Junyu Shen and Xuejing Li and Shengjin Wang},
  doi          = {10.1109/TNNLS.2025.3551687},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16062-16071},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Probably approximately correct bayes meta-learning with parameterized-bounded guarantees},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning self-growth maps for fast and accurate imbalanced streaming data clustering. <em>TNNLS</em>, <em>36</em>(9), 16049-16061. (<a href='https://doi.org/10.1109/TNNLS.2025.3563769'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Streaming data clustering is a popular research topic in data mining and machine learning. Since streaming data is usually analyzed in data chunks, it is more susceptible to encountering the dynamic cluster imbalance issue. That is, the imbalance ratio (IR) of clusters changes over time, which can easily lead to fluctuations in either the accuracy or the efficiency of streaming data clustering. Therefore, an accurate and efficient streaming data clustering approach is proposed to adapt to the drifting and imbalanced cluster distributions. We first design a self-growth map (SGM) that can automatically arrange neurons on demand according to local distribution, and thus achieve fast and incremental adaptation to the streaming distributions. Since SGM allocates an excess number of density-sensitive neurons to describe the global distribution, it can avoid missing small clusters among imbalanced distributions. We also propose a fast hierarchical merging (HM) strategy to combine the neurons that break up the relatively large clusters. It exploits the maintained SGM to quickly retrieve the intracluster distribution pairs for merging, which circumvents the most laborious global searching. It turns out that the proposed SGM can incrementally adapt to the distributions of new chunks, and the self-growth map-guided hierarchical merging for the imbalanced data clustering (SOHI) approach can quickly explore a true number of imbalanced clusters. Extensive experiments demonstrate that SOHI can efficiently and accurately explore cluster distributions for streaming data.},
  archive      = {J_TNNLS},
  author       = {Yiqun Zhang and Sen Feng and Pengkai Wang and Zexi Tan and Xiaopeng Luo and Yuzhu Ji and Rong Zou and Yiu-Ming Cheung},
  doi          = {10.1109/TNNLS.2025.3563769},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16049-16061},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Learning self-growth maps for fast and accurate imbalanced streaming data clustering},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Synchronous image-label diffusion probability model with application to stroke lesion segmentation on non-contrast CT. <em>TNNLS</em>, <em>36</em>(9), 16035-16048. (<a href='https://doi.org/10.1109/TNNLS.2025.3555188'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The stroke lesion volume is a key radiologic measurement for assessing the prognosis of acute ischemic stroke (AIS) patients, which is challenging to be automatically measured on noncontrast CT (NCCT) scans. Recent diffusion probabilistic models (DPMs) in the domain of image generation have shown potentials of being used for lesion volume segmentation on medical images. In this article, a novel synchronous image-label diffusion probability model (SDPM) is proposed for stroke lesion segmentation on NCCT using a dual-Markov diffusion process with shared noise. The proposed SDPM is fully based on a generative latent variable model (LVM), offering a probabilistic elaboration from stem to stem. To fit into our segmentation tasks using the strength from generation models, we develop the architecture of the network where an additional net-stream, parallel with a noise prediction stream, is introduced to obtain the initial label estimates with noise for efficiently inferring the final labels. By optimizing the specified variational boundaries, the trained model can infer the final label estimates given the input images at any scale of time in four different label-inference methods, which gives more flexibility to the proposed SDPM. The proposed model was assessed on three stroke lesion datasets including one public and two private datasets. Compared with several U-Net, transformer, and DPM-based segmentation methods, our proposed SDPM model is able to achieve the state-of-the-art accuracy.},
  archive      = {J_TNNLS},
  author       = {Jianhai Zhang and Tonghua Wan and M. Ethan MacDonald and Bijoy Menon and Aravind Ganesh and Wu Qiu},
  doi          = {10.1109/TNNLS.2025.3555188},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16035-16048},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Synchronous image-label diffusion probability model with application to stroke lesion segmentation on non-contrast CT},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CellMix: A general instance relationship-based method for data augmentation toward pathology image classification. <em>TNNLS</em>, <em>36</em>(9), 16020-16034. (<a href='https://doi.org/10.1109/TNNLS.2025.3554752'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the pathology image analysis, obtaining and maintaining high-quality annotated samples is an extremely labor-intensive task. To overcome this challenge, mixing-based methods have introduced new relationships to traditional preprocessing data augmentation techniques. Nonetheless, these methods fail to fully consider the unique features of pathology images, such as local specificity, global distribution, and inner/outer sample instance relationships. To better comprehend these characteristics and create valuable pseudosamples, we propose the CellMix framework, which employs a novel distribution-oriented in-place shuffle approach. The images are divided into patches based on the granularity of pathology instances, and the patches are in-place shuffled within the same batch. Thus, the locational relationships among instances can be effectively preserved while new relationships can be further introduced. Moreover, inspired by curriculum learning (CL), a loss-driven strategy is designed to control the relationship augmentation. This strategy enables the model to adaptively explore the instances at multiple scales and efficiently handle distribution-related noise under various difficulties. Our experiments in pathology image classification tasks demonstrate state-of-the-art (SOTA) performance on seven distinct datasets. This innovative instance relationship-centered method sheds light on general data augmentation for pathology image classification. The associated codes are available at: https://github.com/sagizty/CellMix.},
  archive      = {J_TNNLS},
  author       = {Tianyi Zhang and Zhiling Yan and Chunhui Li and Nan Ying and Yanli Lei and Shangqing Lyu and Yunlu Feng and Yu Zhao and Guanglei Zhang},
  doi          = {10.1109/TNNLS.2025.3554752},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16020-16034},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {CellMix: A general instance relationship-based method for data augmentation toward pathology image classification},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rapid dynamical pattern classification via deterministic learning from sampling sequences. <em>TNNLS</em>, <em>36</em>(9), 16005-16019. (<a href='https://doi.org/10.1109/TNNLS.2025.3565535'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article is concerned with the rapid classification issue for dynamical patterns consisting of sampling sequences in a relatively large-scale dynamical dataset constructed by benchmark Rossler systems. Specifically, based on a recently developed deterministic learning mechanism, a rapid dynamical pattern classification method is developed, which contains a modeling stage and a classification stage. In the modeling stage, a deterministic learning scheme is employed to accurately learn/model the inherent dynamics of the training dynamical patterns and store the acquired knowledge in a set of constant radial basis function (RBF) networks. In the classification stage, based on the trained RBF networks, a set of dynamical estimators is developed for real-time dynamic comparison. The generating recognition errors are then used to effectively represent the dynamic differences in real-time. To this end, the associated class label of the minimum recognition error is assigned to the test pattern also in real-time. To demonstrate the effectiveness of the proposed method, a relatively large-scale dynamical pattern dataset containing various dynamical behaviors is constructed by utilizing a deterministic chaos prospector (DCP) technique. The simulation results show that the new method achieves competitive classification performances compared to the state-of-the-art time-series classification method for the dynamical system classification task. In addition to performance advantages, the new method can perform real-time time-series classification with the first 10% of data achieving over 95% of accuracy based on the full-length data. Besides, the superiority of our method is demonstrated from various datasets in the UCR time-series classification (TSC) archive.},
  archive      = {J_TNNLS},
  author       = {Weiming Wu and Zhirui Li and Chen Sun and Cong Wang and Guanrong Chen},
  doi          = {10.1109/TNNLS.2025.3565535},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {16005-16019},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Rapid dynamical pattern classification via deterministic learning from sampling sequences},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DigNet: Digging clues from Local–Global interactive graph for aspect-level sentiment classification. <em>TNNLS</em>, <em>36</em>(9), 15993-16004. (<a href='https://doi.org/10.1109/TNNLS.2025.3564306'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In aspect-level sentiment classification (ASC), state-of-the-art models encode either syntax graphs or relation graphs to capture the local syntactic information or global relational information. Despite the advantages of syntax and relation graphs, they have respective shortages which are neglected, limiting the representation power in the graph modeling process. To resolve their limitations, we design a novel local–global interactive graph (LGIG), which marries their advantages by stitching the two graphs via interactive edges. To model this LGI graph, we propose a novel neural network termed DigNet, whose core module is the stacked local–global interactive (LGI) layers performing two processes: intragraph message passing (IGMP) and cross-graph message passing (CGMP). In this way, the local syntactic and global relational information can be reconciled as a whole in understanding the aspect-level sentiment. Concretely, we design two variants of LGIGs with different kinds of interactive edges and three variants of LGI layers. We conduct experiments on several public benchmark datasets and the results show that we outperform previous best scores by 3%, 2.32%, and 6.33% in terms of Macro- $F1$ on Lap14, Res14, and Res15 datasets, respectively, confirming the effectiveness and superiority of the proposed LGIG and DigNet.},
  archive      = {J_TNNLS},
  author       = {Bowen Xing and Ivor W. Tsang},
  doi          = {10.1109/TNNLS.2025.3564306},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {15993-16004},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {DigNet: Digging clues from Local–Global interactive graph for aspect-level sentiment classification},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Revisiting tropical polynomial division: Theory, algorithms, and application to neural networks. <em>TNNLS</em>, <em>36</em>(9), 15978-15992. (<a href='https://doi.org/10.1109/TNNLS.2025.3570807'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tropical geometry has recently found several applications in the analysis of neural networks with piecewise linear activation functions. This article presents a new look at the problem of tropical polynomial division and its application to the simplification of neural networks. We analyze tropical polynomials with real coefficients, extending earlier ideas and methods developed for polynomials with integer coefficients. We first prove the existence of a unique quotient-remainder pair and characterize the quotient in terms of the convex bi-conjugate of a related function. Interestingly, the quotient of tropical polynomials with integer coefficients does not necessarily have integer coefficients. Furthermore, we develop a relationship of tropical polynomial division with the computation of the convex hull of unions of convex polyhedra and use it to derive an exact algorithm for tropical polynomial division. An approximate algorithm is also presented, based on an alternation between data partition and linear programming. We also develop special techniques to divide composite polynomials, described as sums or maxima of simpler ones. Finally, we provide numerical results to demonstrate the efficiency of the proposed algorithms, using the MNIST handwritten digits, SVHN, CIFAR-10, and CIFAR-100 datasets, along with an application example in learning model predictive control (LMPC).},
  archive      = {J_TNNLS},
  author       = {Ioannis Kordonis and Petros Maragos},
  doi          = {10.1109/TNNLS.2025.3570807},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {15978-15992},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Revisiting tropical polynomial division: Theory, algorithms, and application to neural networks},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive hardness-driven augmentation and alignment strategies for multisource domain adaptations. <em>TNNLS</em>, <em>36</em>(9), 15963-15977. (<a href='https://doi.org/10.1109/TNNLS.2025.3565728'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multisource domain adaptation (MDA) aims to transfer knowledge from multiple labeled source domains to an unlabeled target domain. Nevertheless, traditional methods primarily focus on achieving interdomain alignment through sample-level constraints, such as maximum mean discrepancy (MMD), neglecting three pivotal aspects: 1) the potential of data augmentation; 2) the significance of intradomain alignment; and 3) the design of cluster-level constraints. In this article, we introduce a novel hardness-driven strategy for MDA tasks, named $\mathrm {A}^{3}\mathrm {MDA}$ , which collectively considers these three aspects through adaptive hardness quantification and utilization in both data augmentation and domain alignment. To achieve this, $\mathrm {A}^{3}\mathrm {MDA}$ progressively proposes three adaptive hardness measurements (AHMs), i.e., basic, smooth, and comparative AHMs, each incorporating distinct mechanisms for diverse scenarios. Specifically, basic AHM aims to gauge the instantaneous hardness for each source/target sample. Then, hardness values measured by smooth AHM will adaptively adjust the intensity level of strong data augmentation to maintain compatibility with the model’s generalization capacity. In contrast, comparative AHM is designed to facilitate cluster-level constraints. By leveraging hardness values as sample-specific weights, the traditional MMD is enhanced into a weighted-clustered variant, strengthening the robustness and precision of interdomain alignment. As for the often-neglected intradomain alignment, we adaptively construct a pseudo-contrastive matrix (PCM) by selecting harder samples based on the hardness rankings, enhancing the quality of pseudo-labels, and shaping a well-clustered target feature space. Experiments on multiple MDA benchmarks show that $\mathrm {A}^{3}\mathrm {MDA}$ outperforms other methods.},
  archive      = {J_TNNLS},
  author       = {Yuxiang Yang and Xinyi Zeng and Pinxian Zeng and Chen Zu and Binyu Yan and Jiliu Zhou and Yan Wang},
  doi          = {10.1109/TNNLS.2025.3565728},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {15963-15977},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Adaptive hardness-driven augmentation and alignment strategies for multisource domain adaptations},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RadDQN: A deep q learning-based architecture for finding time-efficient minimum radiation exposure pathway. <em>TNNLS</em>, <em>36</em>(9), 15951-15962. (<a href='https://doi.org/10.1109/TNNLS.2025.3562653'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in deep reinforcement learning (DRL) have expanded its use in various automation sectors, including the nuclear industry. While DRL shows promise for optimizing radiation exposure, the development of radiation-aware autonomous unmanned aerial vehicles (UAVs) is hindered by inefficient reward functions and exploration strategies. In this article, we introduce a radiation-aware deep Q-learning network (RadDQN), designed to provide time-efficient, minimum radiation-exposure pathways in radiation zones. RadDQN operates on a radiation-sensitive reward function considering surrounding radiation intensity through the inverse square law and prioritizes reaching the final destination. Departing from the traditional $\epsilon $ -greedy algorithm, RadDQN implements unique exploration strategies that guide the agent to transform random actions into model-directed ones if transitioning to a future state projects higher radiation exposure compared to its current state. This approach ensures minimal radiation exposure while efficiently progressing toward the goal. We validate RadDQN’s accuracy against a grid-based deterministic method. Our results demonstrate that the formulated reward function and exploration strategy effectively manage various radiation field distributions. In addition, RadDQN shows superior convergence rates and higher training stability compared to the baseline model, indicating its effectiveness in optimizing radiation-aware UAV navigation and potential for real-world applications.},
  archive      = {J_TNNLS},
  author       = {Biswajit Sadhu and Trijit Sadhu and S. Anand},
  doi          = {10.1109/TNNLS.2025.3562653},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {15951-15962},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {RadDQN: A deep q learning-based architecture for finding time-efficient minimum radiation exposure pathway},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Persistence of backdoor-based watermarks for neural networks: A comprehensive evaluation. <em>TNNLS</em>, <em>36</em>(9), 15939-15950. (<a href='https://doi.org/10.1109/TNNLS.2025.3565170'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) have gained considerable traction in recent years due to the unparalleled results they gathered. However, the cost behind training such sophisticated models is resource-intensive, resulting in many to consider DNNs to be intellectual property (IP) to model owners. In this era of cloud computing, high-performance DNNs are often deployed all over the Internet so that people can access them publicly. As such, DNN watermarking schemes, especially backdoor-based watermarks, have been actively developed in recent years to preserve proprietary rights. Nonetheless, there lies much uncertainty on the robustness of existing backdoor watermark schemes, toward both adversarial attacks and unintended means such as fine-tuning neural network models. One reason for this is that no complete guarantee of robustness can be assured in the context of backdoor-based watermark. In this article, we extensively evaluate the persistence of recent backdoor-based watermarks within neural networks in the scenario of fine-tuning, and we propose/develop a novel data-driven idea to restore watermark after fine-tuning without exposing the trigger set. Our empirical results show that by solely introducing training data after fine-tuning, the watermark can be restored if model parameters do not shift dramatically during fine-tuning. Depending on the types of trigger samples used, trigger accuracy can be reinstated to up to 100%. This study further explores how the restoration process works using loss landscape visualization, as well as the idea of introducing training data in the fine-tuning stage to alleviate watermark vanishing.},
  archive      = {J_TNNLS},
  author       = {Anh Tu Ngo and Chuan Song Heng and Nandish Chattopadhyay and Anupam Chattopadhyay},
  doi          = {10.1109/TNNLS.2025.3565170},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {15939-15950},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Persistence of backdoor-based watermarks for neural networks: A comprehensive evaluation},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Revising representation and target deviations for accurate human pose estimation. <em>TNNLS</em>, <em>36</em>(9), 15924-15938. (<a href='https://doi.org/10.1109/TNNLS.2025.3569464'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Owing to the normalized instance scales and robust supervision, heatmap-based human pose estimation (HPE) methods with top-down paradigm have achieved a dominant performance. However, there are two inherent deviations in the basic framework, i.e., representation and target deviations, resulting in performance bottlenecks. The representation deviation is caused by transforming various scales of instances into a unified input size, which results in performance degradation because data with different scale-related characteristics can hardly be handled via unified parameters. The target deviation is caused by exploiting a prior distribution (e.g., Gauss) to model the prediction error, which hinders sufficient network training. In this article, we propose a novel framework called DRPose to revise the abovementioned deviations. Specifically, to address the representation deviation, a scale-aware domain bridging (SDB) block is proposed to transfer feature maps from multiple scale-dependent domains into a unified intermediate domain with dynamic parameters. To address the target deviation, a differentiable coordinate decoder (DCD) is presented to adaptively adjust target distribution of heatmaps in an end-to-end manner. Extensive experiments show that the proposed method significantly improves the performance of most existing models with negligible additional cost. Beyond this, our method achieves 77.1% AP on the COCO test-dev set, outperforming prior works with similar model complexity.},
  archive      = {J_TNNLS},
  author       = {Zian Zhang and Yongqiang Zhang and Yancheng Bai and Man Zhang and Rui Tian and Yin Zhang and Mingli Ding and Wangmeng Zuo},
  doi          = {10.1109/TNNLS.2025.3569464},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {15924-15938},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Revising representation and target deviations for accurate human pose estimation},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Binary channel fuzzy self-adjusted neural network for solving time-changing QP problems. <em>TNNLS</em>, <em>36</em>(9), 15911-15923. (<a href='https://doi.org/10.1109/TNNLS.2025.3564965'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel binary channel fuzzy self-adjusted neural network (BCF-SANN) is proposed and researched for solving time-changing quadratic programming (QP) problems in this article. Unlike the fixed parameters of the typical zeroing neural network, the main parameters of the proposed BCF-SANN are time-changing, and its errors are adaptively quickly convergent. The biggest advantage of the novel neural network is that it combines a fuzzy self-adjusted controller, which takes the errors and derivatives of errors as fuzzy inputs and neural networks, further improving the convergence and robustness of the neural networks. To design the novel neural network, a time-changing QP problem is first established; then, using Lagrange’s law, the time-changing QP problem is transformed into a time-changing matrix equation; and finally, based on the time-changing parameter neural dynamics method, a novel BCF-SANN is proposed. The detailed design process is given in this article, and the convergence and robustness of the proposed BCF-SANN are proved by theoretical analysis. Through comparative experiments, it is demonstrated that the proposed BCF-SANN has a faster convergence rate and stronger robustness than the traditional zeroing neural network and 1-D fuzzy recurrent neural network (RNN).},
  archive      = {J_TNNLS},
  author       = {Yamei Luo and Qingyi Ren and Zihao Zheng and Siyuan Chen and Xin Ma and Yu Liu and Xiaoli Li and Junzhi Yu and Zhijun Zhang},
  doi          = {10.1109/TNNLS.2025.3564965},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {15911-15923},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Binary channel fuzzy self-adjusted neural network for solving time-changing QP problems},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Recognizing natural images from EEG with language-guided contrastive learning. <em>TNNLS</em>, <em>36</em>(9), 15896-15910. (<a href='https://doi.org/10.1109/TNNLS.2025.3562743'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalography (EEG), known for its convenient noninvasive acquisition but moderate signal-to-noise ratio, has recently gained much attention due to the potential to decode image information. However, previous works have not delivered sufficient evidence of this task, primarily limited by performance and biological plausibility. In this work, we first introduce a self-supervised framework to demonstrate the feasibility of recognizing images from EEG signals. Contrastive learning is leveraged to align the representations of EEG responses with image stimuli. Then, language descriptions of the stimuli generated by large language models (LLMs) help guide learning core semantic information. With the framework, we attain significantly above-chance results on the THINGS-EEG2 dataset, achieving a top-1 accuracy of 19.7% and a top-5 accuracy of 51.5% in challenging 200-way zero-shot tasks. Furthermore, we conduct thorough experiments to resolve the human visual responses with EEG from temporal, spatial, spectral, and semantic perspectives. These results provide evidence of feasibility and plausibility regarding EEG-based image recognition, substantiated by comparative studies with the THINGS-Magnetoencephalography (MEG) dataset. The findings offer valuable insights for neural decoding and real-world applications of brain-computer interfaces (BCIs), such as health care and robot control. The code is available at https://github.com/eeyhsong/NICE-LLM.},
  archive      = {J_TNNLS},
  author       = {Yonghao Song and Yijun Wang and Huiguang He and Xiaorong Gao},
  doi          = {10.1109/TNNLS.2025.3562743},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {15896-15910},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Recognizing natural images from EEG with language-guided contrastive learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Complex dual-tree pyramid scattering transformer. <em>TNNLS</em>, <em>36</em>(9), 15881-15895. (<a href='https://doi.org/10.1109/TNNLS.2025.3565582'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attention-based transformer networks have recently played an increasingly important role in computer vision tasks. However, since pixel-by-pixel attention multiplication does not involve constraint assumptions such as spatial invariance, the computational complexity grows quadratically with the increase of input pixels. Therefore, this article proposes a complex pyramid scattering Transformer in dense scale space, which introduces sparse scattering constraints with a small number of wavelet basis parameters. It enhances the Transformer’s flexibility and sparsity in multiscale space and, to a certain extent, slows down the increase in computational complexity caused by multiresolution input. In addition, compared with the general single-tree real wavelet transform, the dual-tree complex scattering method improves the aliasing of the scattering attention layer and helps obtain a more robust feature representation. At the same time, the multihead stepwise pyramid scattering coupling mechanism helps increase the abundance of directional priors. We conduct experiments in image classification and video tracking scenarios and verify the reliability and superiority of our dual-tree complex pyramid scattering Transformer for visual tasks with different scale requirements. The performance is better than that of the baseline Transformer and other advanced wavelet scattering networks at the same parameter scale. The code is available at https://github.com/Dawn5786/CPSTFormer},
  archive      = {J_TNNLS},
  author       = {Xiaotong Li and Licheng Jiao and Lingling Li and Fang Liu and Hao Zhu and Xin Zhang and Xu Liu and Shuyuan Yang},
  doi          = {10.1109/TNNLS.2025.3565582},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {15881-15895},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Complex dual-tree pyramid scattering transformer},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised domain adaptation via bidirectional transmission generator self-training. <em>TNNLS</em>, <em>36</em>(9), 15866-15880. (<a href='https://doi.org/10.1109/TNNLS.2025.3561353'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised domain adaptation (UDA) aims to transfer knowledge from the labeled source domain to the fully unlabeled target domain, thus improving the classification performance of the target domain. Recently, self-training methods have shown their effectiveness on UDA. It iteratively trains target data using the generated target pseudo-labels. However, the feature space for generating pseudo-labels contains a large amount of source information, which traps the model in the source domain, making it challenging for the generator to learn discriminative features of the target domain. In this article, we propose a self-training domain adaptation (DA) model with bidirectional transmission generators (BDTGs). Specifically, we design a bidirectional transmission structure for generators, using exponential moving average (EMA) as the bridge between two generators. The structure has two advantages: 1) by transmitting weight parameters to each other during the training process, it promotes the shift of the feature space, thereby alleviating the difficulty of the model in adapting target domain features and 2) the transmission disturbs the classification boundary and is able to expose unreliable target samples near the boundary. We design a cosine similarity-based filter to identify such samples, to reduce the influence of noisy pseudo-labels with incorrect semantic information on the model. Extensive experiments conducted on five benchmark UDA datasets show that our approach has superior classification performance.},
  archive      = {J_TNNLS},
  author       = {Xing Wei and Zhaoxin Ji and Fan Yang and Chong Zhao and Bin Wen and Yang Lu},
  doi          = {10.1109/TNNLS.2025.3561353},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {15866-15880},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Unsupervised domain adaptation via bidirectional transmission generator self-training},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unlearning attacks for regression learning. <em>TNNLS</em>, <em>36</em>(9), 15851-15865. (<a href='https://doi.org/10.1109/TNNLS.2025.3553821'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the machine unlearning has emerged as a popular method for efficiently erasing the impact of personal data in machine learning (ML) models upon the data owner’s removal request. However, few studies take into consideration the security concerns that may exist in the unlearning process. In this article, we propose the first unlearning attack dubbed unlearning attack for regression learning (UnAR) to deliberately influence the predictive behavior of the target sample against regression learning models. The central concept of UnAR revolves around misleading the regression model into erasing the information associated with the influential samples for the target sample. Observing that the influential samples for target data are generally located far away from the regression plane, we thus propose two novel methods, known as influential sample selection (ISS) and influential sample unlearning (ISU), to identify and subsequently eliminate the lineage of the influential samples. By doing so, we can substantially introduce bias into the prediction pertaining to the target sample, yielding the deliberate manipulation for the user adversely. We extensively evaluate UnAR on five public datasets, and the experimental results indicate our attacks can achieve prediction deviations over 35% by unlearning only 0.5% data as the influential samples.},
  archive      = {J_TNNLS},
  author       = {Jian Chen and Wenlong Shi and Wanyu Lin and Chen Wang and Wei Liu and Hailong Sun and Gaoyang Liu},
  doi          = {10.1109/TNNLS.2025.3553821},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {15851-15865},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Unlearning attacks for regression learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Training a dynamic growing mixture model for lifelong learning. <em>TNNLS</em>, <em>36</em>(9), 15836-15850. (<a href='https://doi.org/10.1109/TNNLS.2025.3569156'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lifelong learning (LLL) defines a training paradigm that aims to continuously acquire and capture new concepts from a sequence of tasks without forgetting. Recently, dynamic expansion models (DEMs) have been proposed to address catastrophic forgetting under the LLL paradigm. However, the efficiency of DEMs lacks a thorough explanation based on theoretical analysis. In this article, we develop a new theoretical framework that interprets the forgetting process of the DEM as increasing the statistical discrepancy distance between the distribution of the probabilistic representation of the new data and the previously learned knowledge. The theoretical analysis shows that adding new components to a mixture model represents a trade-off between model complexity and its performance. Inspired by the theoretical analysis, we introduce a new DEM, called the growing mixture model (GMM), where generative data components are added according to the novelty of the incoming task information compared to what is already known. A new component selection mechanism considering the model’s already acquired knowledge is employed for updating new DEM’s components, promoting efficient future task learning. We also train a compact student model with samples drawn through the generative mechanisms of the GMM, aiming to accumulate cross-domain representations over time. By employing the student model, we can significantly reduce the number of parameters and make quick inferences during the testing phase.},
  archive      = {J_TNNLS},
  author       = {Fei Ye and Adrian G. Bors},
  doi          = {10.1109/TNNLS.2025.3569156},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {15836-15850},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Training a dynamic growing mixture model for lifelong learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Safe physics-informed machine learning for optimal predefined-time stabilization: A lyapunov-based approach. <em>TNNLS</em>, <em>36</em>(9), 15822-15835. (<a href='https://doi.org/10.1109/TNNLS.2025.3554713'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we introduce the notion of safe predefined-time stability and address an optimal safe predefined-time stabilization problem. In particular, safe predefined-time stability characterizes parameter-dependent nonlinear dynamical systems whose trajectories starting in a given set of admissible states remain in the set of admissible states for all time and converge to an equilibrium point in a predefined time. Furthermore, we provide a Lyapunov theorem establishing sufficient conditions for safe predefined-time stability. We address the optimal safe predefined-time stabilization problem by synthesizing feedback controllers that guarantee closed-loop system safe predefined-time stability while optimizing a given performance measure. Specifically, safe predefined-time stability of the closed-loop system is guaranteed via a Lyapunov function satisfying a differential inequality while simultaneously serving as a solution to the steady-state Hamilton-Jacobi–Bellman (HJB) equation ensuring optimality. Given that the HJB equation is generally difficult to solve, we develop a physics-informed machine learning-based algorithm for learning the safely predefined-time stabilizing solution to the steady-state HJB equation. Several simulation results are provided to demonstrate the efficacy of the proposed approach.},
  archive      = {J_TNNLS},
  author       = {Nick-Marios T. Kokolakis and Zhen Zhang and Shanqing Liu and Kyriakos G. Vamvoudakis and Jérôme Darbon and George Em Karniadakis},
  doi          = {10.1109/TNNLS.2025.3554713},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {15822-15835},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Safe physics-informed machine learning for optimal predefined-time stabilization: A lyapunov-based approach},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning to coordinate with different teammates via team probing. <em>TNNLS</em>, <em>36</em>(9), 15807-15821. (<a href='https://doi.org/10.1109/TNNLS.2025.3563773'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coordinating with different teammates is essential in cooperative multiagent systems (MASs). However, most multiagent reinforcement learning (MARL) methods assume fixed team compositions, which leads to agents overfitting their training partners and failing to cooperate well with different teams during the deployment phase. A common way to mitigate the problem is to anticipate teammate behaviors and adapt policies accordingly during cooperation. However, these methods use the same policy for both collecting information for modeling teammates and maximizing cooperation performance. We argue that these two goals may conflict and reduce the effectiveness of both. In this work, we propose coordinating with different teammates via team probing (CDP), a novel approach that rapidly adapts to different teams by disentangling probing and adaptation phases. Specifically, we first generate a diverse population of teams as training partners with a novel value-based diversity objective. Then, we train a probing module to probe and reveal the coordination pattern of each team with policy-dynamics reconstruction and get a representation space of the population. Finally, we train a generalist meta-policy consisting of several expert policies with module selection based on the clustering of the learned representation space. We empirically show that CDP surpasses existing policy adaptation methods in various complex multiagent scenarios with both seen and unseen teammates.},
  archive      = {J_TNNLS},
  author       = {Hao Ding and Chengxing Jia and Zongzhang Zhang and Cong Guan and Feng Chen and Lei Yuan and Yang Yu},
  doi          = {10.1109/TNNLS.2025.3563773},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {15807-15821},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Learning to coordinate with different teammates via team probing},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge transfer and reinforcement based on biunbiased neural network: A novel solution for open-set fault transfer diagnosis. <em>TNNLS</em>, <em>36</em>(9), 15794-15806. (<a href='https://doi.org/10.1109/TNNLS.2025.3569582'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault transfer diagnosis is a key technology to ensure the reliability and safety of industrial systems, the core of which is to identify the health status of the equipment among different working conditions with multiclassification methods. However, most of them are based on a closed-set assumption that the label space among different working conditions is consistent, which is hard to satisfy in a practical industrial environment as unknown faults would inevitably occur during operation, i.e., the open-set fault transfer diagnosis (OSFTD) problem. Moreover, during the transfer process, unnecessary source-specific knowledge tends to be adapted, which brings about biased diagnostics on both domain and category. Aiming at this issue, an OSFTD framework, coined as knowledge transfer and reinforcement based on biunbiased neural network (KTR-BUNN), is proposed. First, a domain-unbiased knowledge transfer subnet is proposed, including an uncertainty-aware fault transferability evaluator (FTE) that estimates the transferability of target-domain samples unbiasedly to guide distribution alignment of known faults and a triple-tier unknown fault separator (UFS) that takes transferability as the criterion to extrapolate unknown faults. Second, a class-unbiased knowledge reinforcement subnet is designed to promote the recognition of fault semantic features at the embedding space, where fault knowledge graphs (FKGs) are constructed to describe the relationships between fault types, and they are optimized by a contrastive fault correlation loss, so that fine-grained class-level fault features can be further aligned. The knowledge transfer and knowledge reinforcement mechanisms work jointly to facilitate the performance of OSFTD. Finally, extensive experimental results conducted on diverse diagnostic tasks illustrate the superiority of the proposed KTR-BUNN.},
  archive      = {J_TNNLS},
  author       = {Lei Wang and Huaguang Zhang and Jinhai Liu and Fengyuan Zuo},
  doi          = {10.1109/TNNLS.2025.3569582},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {15794-15806},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Knowledge transfer and reinforcement based on biunbiased neural network: A novel solution for open-set fault transfer diagnosis},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MDFA: A quantitative framework for the analysis of multimodal facial esthetics. <em>TNNLS</em>, <em>36</em>(9), 15779-15793. (<a href='https://doi.org/10.1109/TNNLS.2025.3570389'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of big data, the problem of facial beauty prediction (FBP) has been addressed using a combination of deep learning and esthetics based on data and models. Most existing methods are based on 2-D unimodal information processing. Owing to the high cost of 3-D data acquisition equipment, studies on the use of multimodal features of 2-D and 3-D for esthetic evaluation are scarce. Moreover, most existing methods are based on self-built 3-D datasets, which are limited to practical application scenarios of 2-D facial images. This study proposed a label distribution-based multimodal facial esthetic analysis framework (LDMFE). The LDMFE performed facial esthetic evaluation by combining 2-D and 3-D information following the process used by the human brain to conduct the 3-D esthetic evaluation. FBP was performed by extracting facial depth structure information using a depth information extraction network, DIENet, which comprises a facial structure perception layer (FSP-Layer) and an attention decision block (AD-Block). Furthermore, to ensure a high degree of agreement between the predicted label distribution of the network and the true distribution, a simple and efficient distribution measurement loss function called ${\mathcal {L}}_{\text {WD}}$ was proposed. Compared with the label distribution-based FBP loss and the latest FBP loss, ${\mathcal {L}}_{\text {WD}}$ was more stable and effective. The performance of LDMFE was evaluated using three datasets. The experimental results demonstrate that the LDMFE exhibits state-of-the-art performance.},
  archive      = {J_TNNLS},
  author       = {Huanyu Chen and Weisheng Li and Bin Xiao and Xinbo Gao},
  doi          = {10.1109/TNNLS.2025.3570389},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {15779-15793},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {MDFA: A quantitative framework for the analysis of multimodal facial esthetics},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel dynamic neural network for heterogeneity-aware structural brain network exploration and alzheimer’s disease diagnosis. <em>TNNLS</em>, <em>36</em>(9), 15764-15778. (<a href='https://doi.org/10.1109/TNNLS.2025.3569650'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneity is a fundamental characteristic of brain diseases, distinguished by variability not only in brain atrophy but also in the complexity of neural connectivity and brain networks. However, existing data-driven methods fail to provide a comprehensive analysis of brain heterogeneity. Recently, dynamic neural networks (DNNs) have shown significant advantages in capturing sample-wise heterogeneity. Therefore, in this article, we first propose a novel dynamic heterogeneity-aware network (DHANet) to identify critical heterogeneous brain regions, explore heterogeneous connectivity between them, and construct a heterogeneous-aware structural brain network (HGA-SBN) using structural magnetic resonance imaging (sMRI). Specifically, we develop a 3-D dynamic convmixer to extract abundant heterogeneous features from sMRI first. Subsequently, the critical brain atrophy regions are identified by dynamic prototype learning with embedding the hierarchical brain semantic structure. Finally, we employ a joint dynamic edge-correlation (JDE) modeling approach to construct the heterogeneous connectivity between these regions and analyze the HGA-SBN. To evaluate the effectiveness of the DHANet, we conduct elaborate experiments on three public datasets and the method achieves state-of-the-art (SOTA) performance on two classification tasks.},
  archive      = {J_TNNLS},
  author       = {Wenju Cui and Yilin Leng and Yunsong Peng and Chen Bai and Lei Li and Xi Jiang and Gang Yuan and Jian Zheng},
  doi          = {10.1109/TNNLS.2025.3569650},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {15764-15778},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A novel dynamic neural network for heterogeneity-aware structural brain network exploration and alzheimer’s disease diagnosis},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive secure finite-time optimal control of unknown nonlinear systems with state constraints via generalized fuzzy hyperbolic models. <em>TNNLS</em>, <em>36</em>(9), 15749-15763. (<a href='https://doi.org/10.1109/TNNLS.2025.3565622'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, a novel adaptive critic learning (ACL) framework is constructed for a class of nonzero-sum (NZS) differential games problem of unknown continuous-time (CT) nonlinear systems with state constraints. First, generalized fuzzy hyperbolic model (GFHM)-based identifiers are established to reconstruct the unknown system dynamics. Then, under the ACL framework, a critic network with secure finite-time experience replay turning law is developed for each player to acquire the Nash equilibrium point solution in finite time while the finite-time stability is guaranteed via Lyapunov analysis. Meanwhile, the persistence of excitation (PE) condition is no longer needed in this work, by introducing an easy-to-check rank condition. Furthermore, by incorporating the immediate cost function associated with each player and the control barrier function (CBF), the algorithm ensures that the system states evolve in a secure environment. Finally, two numerical examples are presented to demonstrate the validity of the developed scheme.},
  archive      = {J_TNNLS},
  author       = {Hanguang Su and Yi Cui and Huaguang Zhang and Xiangpeng Xie and Xiaodong Liang and Jiawei Wang},
  doi          = {10.1109/TNNLS.2025.3565622},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {15749-15763},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Adaptive secure finite-time optimal control of unknown nonlinear systems with state constraints via generalized fuzzy hyperbolic models},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mixed-granularity implicit representation for continuous hyperspectral compressive reconstruction. <em>TNNLS</em>, <em>36</em>(9), 15735-15748. (<a href='https://doi.org/10.1109/TNNLS.2025.3551891'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral images (HSIs) are crucial across numerous fields but are hindered by the long acquisition times associated with traditional spectrometers. The coded aperture snapshot spectral imaging (CASSI) system mitigates this issue through a compression technique that accelerates the acquisition process. However, reconstructing HSIs from compressed data presents challenges due to fixed spatial and spectral resolution constraints. This study introduces a novel method using implicit neural representation (INR) for continuous HSI reconstruction. We propose the mixed-granularity implicit representation (MGIR) framework, which includes a hierarchical spectral–spatial implicit encoder (HSSIE) for efficient multiscale implicit feature extraction. This is complemented by a mixed-granularity local feature aggregator (MGLFA) that adaptively integrates local features across scales, combined with a decoder that merges coordinate information for precise reconstruction. By leveraging INRs, the MGIR framework enables reconstruction at any desired spatial–spectral resolution, significantly enhancing the flexibility and adaptability of the CASSI system. Extensive experimental evaluations confirm that our model produces reconstructed images at arbitrary resolutions and matches the state-of-the-art methods across varying spectral–spatial compression ratios (CRs). The code will be released at https://github.com/chh11/MGIR.},
  archive      = {J_TNNLS},
  author       = {Jianan Li and Huan Chen and Wangcai Zhao and Rui Chen and Tingfa Xu},
  doi          = {10.1109/TNNLS.2025.3551891},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {15735-15748},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Mixed-granularity implicit representation for continuous hyperspectral compressive reconstruction},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online adaptive optimal control algorithm based on weighted policy iteration. <em>TNNLS</em>, <em>36</em>(9), 15723-15734. (<a href='https://doi.org/10.1109/TNNLS.2025.3564329'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we propose a novel online learning algorithm based on weighted policy iteration (WPI) for addressing optimal control problems of nonlinear systems. WPI is proposed to deal with the influence of the neural network (NN) approximation error on the admissibility of the improved control policy. It is shown that the new iterative method can converge to the optimal solution uniformly. Utilizing NN approximation and experience replaying techniques, a WPI-based online learning algorithm is proposed. The new online algorithm distinguishes from previously known ones in that there can be fewer neurons in the hidden layer, giving rise to significant computational improvement. The assumption that the number of neurons needs to be sufficiently large can be dropped. Besides, instead of a standard persistently excited (PE) condition, only a relaxed PE condition is needed, which is also easier to check. Finally, numerical experiments are conducted to verify the effectiveness of our method.},
  archive      = {J_TNNLS},
  author       = {Wanlin Tan and Rui Luo and Zhinan Peng and Qiang Ling},
  doi          = {10.1109/TNNLS.2025.3564329},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {15723-15734},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Online adaptive optimal control algorithm based on weighted policy iteration},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey and evaluation of adversarial attacks in object detection. <em>TNNLS</em>, <em>36</em>(9), 15706-15722. (<a href='https://doi.org/10.1109/TNNLS.2025.3561225'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning models achieve remarkable accuracy in computer vision tasks yet remain vulnerable to adversarial examples—carefully crafted perturbations to input images that can deceive these models into making confident but incorrect predictions. This vulnerability poses significant risks in high-stakes applications such as autonomous vehicles, security surveillance, and safety-critical inspection systems. While the existing literature extensively covers adversarial attacks in image classification, comprehensive analyses of such attacks on object detection systems remain limited. This article presents a novel taxonomic framework for categorizing adversarial attacks specific to object detection architectures, synthesizes existing robustness metrics, and provides a comprehensive empirical evaluation of state-of-the-art attack methodologies on popular object detection models, including both traditional detectors and modern detectors with vision-language pretraining. Through rigorous analysis of open-source attack implementations and their effectiveness across diverse detection architectures, we derive key insights into attack characteristics. Furthermore, we delineate critical research gaps and emerging challenges to guide future investigations in securing object detection systems against adversarial threats. Our findings establish a foundation for developing more robust detection models while highlighting the urgent need for standardized evaluation protocols in this rapidly evolving domain.},
  archive      = {J_TNNLS},
  author       = {Khoi Nguyen Tiet Nguyen and Wenyu Zhang and Kangkang Lu and Yu-Huan Wu and Xingjian Zheng and Hui Li Tan and Liangli Zhen},
  doi          = {10.1109/TNNLS.2025.3561225},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {15706-15722},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A survey and evaluation of adversarial attacks in object detection},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning for low-light vision: A comprehensive survey. <em>TNNLS</em>, <em>36</em>(9), 15685-15705. (<a href='https://doi.org/10.1109/TNNLS.2025.3566647'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual recognition in low-light environments is a challenging problem since degraded images are the stacking of multiple degradations (noise, low light and blur, etc.). It has received extensive attention from academia and industry in the era of deep learning. Existing surveys focus on low-light image enhancement (LLIE) methods and normal-light visual recognition methods, while few comprehensive surveys of low-light-related vision tasks. This article provides a comprehensive survey of the latest advancements in low-light vision, including methods, datasets, and evaluation metrics, in two aspects: visual quality-driven and recognition quality-driven. On the visual quality-driven aspect, we survey a large number of very recent LLIE methods. On the recognition quality-driven aspect, we survey low-light object detection techniques in the deep learning era using more intuitive categorization method. Furthermore, a quantitative benchmarking of different methods is conducted on several widely adopted low-light vision-related datasets. Finally, we discuss the challenges that exist in low-light vision and future directions worth exploring. We provide a public website that will continue to track developments in this promising field.},
  archive      = {J_TNNLS},
  author       = {Qian Zhao and Gang Li and Bin He and Runjie Shen},
  doi          = {10.1109/TNNLS.2025.3566647},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {15685-15705},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Deep learning for low-light vision: A comprehensive survey},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey on confidence calibration of deep learning-based classification models under class imbalance data. <em>TNNLS</em>, <em>36</em>(9), 15664-15684. (<a href='https://doi.org/10.1109/TNNLS.2025.3565159'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Confidence calibration in classification models is a vital technique for accurately estimating the posterior probabilities of predicted results, which is crucial for assessing the likelihood of correct decisions in real-world applications. Class imbalance data, which biases the model’s learning and subsequently skews predicted posterior probabilities, makes confidence calibration more challenging. Especially for underrepresented classes, which are often more important and tend to have higher uncertainty, confidence calibration is more complex and essential. Unlike previous surveys that typically separately investigate confidence calibration or class imbalance, this article comprehensively investigates confidence calibration methods for deep learning-based classification models under class imbalance. First, the problem of confidence calibration under class imbalance data is outlined. Second, this article explores the impact of class imbalance data on confidence calibration in theory, providing some explanations for empirical findings in existing studies. Third, this article reviews 60 state-of-the-art confidence calibration methods under class imbalance data, divides these methods into six groups according to method differences, and systematically compares seven properties to evaluate their superiority. Then, some commonly used and emerging evaluation methodology are summarized, including public datasets and evaluation metrics. Subsequently, this article performs necessary comparative experiments to provide better guidelines and insights to the readership. Finally, we discuss several application fields and promising research directions that serve as a guideline for future studies.},
  archive      = {J_TNNLS},
  author       = {Jinzong Dong and Zhaohui Jiang and Dong Pan and Zhiwen Chen and Qingyi Guan and Hongbin Zhang and Gui Gui and Weihua Gui},
  doi          = {10.1109/TNNLS.2025.3565159},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {15664-15684},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A survey on confidence calibration of deep learning-based classification models under class imbalance data},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Threats and defenses in the federated learning life cycle: A comprehensive survey and challenges. <em>TNNLS</em>, <em>36</em>(9), 15643-15663. (<a href='https://doi.org/10.1109/TNNLS.2025.3563537'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) offers innovative solutions for privacy-preserving distributed machine learning (ML). Different from centralized data collection algorithms, FL enables participants to locally train their model and only share the model updates for aggregation. Since private data never leaves the end node, FL effectively mitigates privacy leakage during collaborative training. Despite its promising potential, FL is vulnerable to various attacks due to its distributed nature, affecting the entire life cycle of FL services. These threats can harm the model’s utility or compromise participants’ privacy, either directly or indirectly. In response, numerous defense frameworks have been proposed, demonstrating effectiveness in specific settings and scenarios. To provide a clear understanding of the current research landscape, this article reviews the most representative and state-of-the-art threats and defense frameworks throughout the FL service life cycle. We start by identifying FL threats that harm utility and privacy, including those with potential or direct impacts. Then, we dive into the defense frameworks, analyze the relationship between threats and defenses, and compare the trade-offs among different defense strategies. We subsequently revisit these studies to evaluate their practicality in real-world scenarios and conclude by summarizing existing research bottlenecks and outlining future directions. We hope this survey sheds light on trustworthy FL research and contributes to the FL community.},
  archive      = {J_TNNLS},
  author       = {Yanli Li and Zhongliang Guo and Nan Yang and Huaming Chen and Dong Yuan and Weiping Ding},
  doi          = {10.1109/TNNLS.2025.3563537},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {15643-15663},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Threats and defenses in the federated learning life cycle: A comprehensive survey and challenges},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey on self-supervised monocular depth estimation based on deep neural networks. <em>TNNLS</em>, <em>36</em>(9), 15622-15642. (<a href='https://doi.org/10.1109/TNNLS.2025.3552598'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monocular depth estimation aims to predict the corresponding scene depth map to an input image, which has wide application prospects in various fields, such as robot navigation, autonomous driving, and augmented reality. Due to the advantage that only images rather than ground truth depth maps are required for model training, self-supervised monocular depth estimation methods have received more and more attention in recent years. Although numerous self-supervised monocular depth estimation methods were proposed, there has been no a comprehensive survey on them yet. Addressing this issue, we review recent developments in the community of self-supervised monocular depth estimation in this article. First, 89 existing works in the literature are categorized and reviewed. Then, we introduce the public datasets and evaluation metrics used in monocular depth estimation. Next, the performances of some state-of-the-art methods are compared and analyzed. Finally, we summarize several open problems and possible future developments in this community.},
  archive      = {J_TNNLS},
  author       = {Qiulei Dong and Zhengming Zhou and Xiaolan Qiu and Liting Zhang},
  doi          = {10.1109/TNNLS.2025.3552598},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {15622-15642},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A survey on self-supervised monocular depth estimation based on deep neural networks},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Vision-based learning for drones: A survey. <em>TNNLS</em>, <em>36</em>(9), 15601-15621. (<a href='https://doi.org/10.1109/TNNLS.2025.3564184'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drones, as advanced cyber-physical systems (CPSs), are undergoing a transformative shift with the advent of vision-based learning, a field that is rapidly gaining prominence due to its profound impact on drone autonomy and functionality. Unlike existing task-specific surveys, this work offers a comprehensive overview of vision-based learning for drones, emphasizing its pivotal role in enhancing their operational capabilities across various scenarios. First, the fundamental principles of vision-based learning are elucidated, demonstrating how it significantly improves drones’ visual perception and decision-making processes. Vision-based control methods are then categorized into indirect, semidirect, and end-to-end approaches from the perception-control perspective. Various applications of vision-based drones with learning capabilities are further explored, ranging from single-agent systems to more complex multiagent and heterogeneous system scenarios, while highlighting the challenges and innovations characterizing each domain. Finally, open questions and potential solutions are discussed to guide future research and development in this dynamic and rapidly evolving field. With the growth of large language models (LLMs) and embodied intelligence, vision-based learning for drones provides a promising yet challenging road toward achieving artificial general intelligence (AGI) in the 3-D physical world.},
  archive      = {J_TNNLS},
  author       = {Jiaping Xiao and Rangya Zhang and Yuhang Zhang and Mir Feroskhan},
  doi          = {10.1109/TNNLS.2025.3564184},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {15601-15621},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Vision-based learning for drones: A survey},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward quantum federated learning. <em>TNNLS</em>, <em>36</em>(9), 15580-15600. (<a href='https://doi.org/10.1109/TNNLS.2025.3552643'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum federated learning (QFL) is an emerging interdisciplinary field that merges the principles of quantum computing (QC) and federated learning (FL), with the goal of leveraging quantum technologies to enhance privacy, security, and efficiency in the learning process. Currently, there is no comprehensive survey for this interdisciplinary field. This review offers a thorough, holistic examination of QFL. We aim to provide a comprehensive understanding of the principles, techniques, and emerging applications of QFL. We discuss the current state of research in this rapidly evolving field, identify challenges and opportunities associated with integrating these technologies, and outline future directions and open research questions. We propose a unique taxonomy of QFL techniques, categorized according to their characteristics and the quantum techniques employed. As the field of QFL continues to progress, we can anticipate further breakthroughs and applications across various industries, driving innovation and addressing challenges related to data privacy, security, and resource optimization. This review serves as a first-of-its-kind comprehensive guide for researchers and practitioners interested in understanding and advancing the field of QFL.},
  archive      = {J_TNNLS},
  author       = {Chao Ren and Rudai Yan and Huihui Zhu and Han Yu and Minrui Xu and Yuan Shen and Yan Xu and Ming Xiao and Zhao Yang Dong and Mikael Skoglund and Dusit Niyato and Leong Chuan Kwek},
  doi          = {10.1109/TNNLS.2025.3552643},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  number       = {9},
  pages        = {15580-15600},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Toward quantum federated learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
