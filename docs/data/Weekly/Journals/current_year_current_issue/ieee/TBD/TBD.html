<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TBD</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tbd">TBD - 52</h2>
<ul>
<li><details>
<summary>
(2025). Topology-based node-level membership inference attacks on graph neural networks. <em>TBD</em>, <em>11</em>(5), 2809-2826. (<a href='https://doi.org/10.1109/TBDATA.2025.3558855'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Graph neural networks (GNNs) have obtained considerable attention due to their ability to leverage the inherent topological and node information present in graph data. While extensive research has been conducted on privacy attacks targeting machine learning models, the exploration of privacy risks associated with node-level membership inference attacks on GNNs remains relatively limited. GNNs learn representations that encapsulate valuable information about the nodes. These learned representations can be exploited by attackers to infer whether a specific node belongs to the training dataset, leading to the disclosure of sensitive information. The insidious nature of such privacy breaches often leads to an underestimation of the associated risks. Furthermore, the inherent challenges posed by node membership inference attacks make it difficult to develop effective attack models for GNNs that can successfully infer node membership. We propose a more efficient approach that specifically targets node-level membership inference attacks on GNNs. Initially, we combine nodes and their respective neighbors to carry out node membership inference attacks. To address the challenge of variable-length features arising from the differing number of neighboring nodes, we introduce an effective feature processing strategy. Furthermore, we propose two strategies: multiple training of shadow models and random selection of non-membership data, to enhance the performance of the attack model. We empirically evaluate the efficacy of our proposed method using three benchmark datasets. Additionally, we explore two potential defense mechanisms against node-level membership inference attacks.},
  archive  = {J},
  author   = {Faqian Guan and Tianqing Zhu and Wanlei Zhou and Philip S. Yu},
  doi      = {10.1109/TBDATA.2025.3558855},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2809-2826},
  title    = {Topology-based node-level membership inference attacks on graph neural networks},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Utility-driven data analytics algorithm for transaction modifications using pre-large concept with single database scan. <em>TBD</em>, <em>11</em>(5), 2792-2808. (<a href='https://doi.org/10.1109/TBDATA.2025.3556615'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Utility-driven pattern analysis is a fundamental method for analyzing noteworthy patterns with high utility for diverse quantitative transactional databases. Recently, various approaches have emerged to handle large, dynamic database environments more efficiently by reducing the number of data scans and pattern expansion operations with the pre-large concept. However, existing pre-large-based high utility pattern mining methods either fail to handle real-time transaction modifications or require additional data scans to validate candidate patterns. In this paper, we propose a novel efficient utility-driven pattern mining algorithm using the pre-large concept for transaction modifications. Our method incorporates a single-scan-based framework through the management of actual utility values and discovers high utility patterns without candidate generation for efficient utility-driven dynamic data analysis in the modification environment. We compared the performance of the proposed method with state-of-the-art methods through extensive performance evaluation utilizing real and synthetic datasets. According to the evaluation results and a case study, the suggested method performs a minimum of 1.5 times faster than state-of-the-art methods alongside minimal compromise in memory, and it scaled well with increases in database size. Further statistical analyses indicate that the proposed method reduces the pattern search space compared to the previous method while delivering a complete set of accurate results without loss.},
  archive  = {J},
  author   = {Unil Yun and Hanju Kim and Myungha Cho and Taewoong Ryu and Seungwan Park and Doyoon Kim and Doyoung Kim and Chanhee Lee and Witold Pedrycz},
  doi      = {10.1109/TBDATA.2025.3556615},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2792-2808},
  title    = {Utility-driven data analytics algorithm for transaction modifications using pre-large concept with single database scan},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel concept-cognitive learning model oriented to three-way concept for knowledge acquisition. <em>TBD</em>, <em>11</em>(5), 2779-2791. (<a href='https://doi.org/10.1109/TBDATA.2025.3556637'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Concept-cognitive learning (CCL) is the process of enabling machines to simulate the concept learning of the human brain. Existing CCL models focus on formal context while neglecting the importance of skill context. Furthermore, CCL models, which solely focus on positive information, restrict the learning capacity by neglecting negative information, and greatly impeding the acquisition of knowledge. To overcome these issues, we proposes a novel concept-cognitive learning model oriented to three-way concept for knowledge acquisition. First, this paper explains and investigates the relationship between skills and knowledge based on the three-way concept and its properties. Then, in order to simultaneously consider positive and negative information, describe more detailed information, learn more skills, and acquire accurate knowledge, a three-way information granule is described from the perspective of cognitive learning. Then, a transformation method is proposed to transform between different three-way information granules, allowing for the transformation of arbitrary three-way information granule into necessary, sufficient, sufficient and necessary three-way information granules. Finally, algorithm corresponding to the transformation method is designed, and subsequently tested across diverse UCI datasets. The experimental outcomes affirm the effectiveness and excellence of the suggested model and algorithm.},
  archive  = {J},
  author   = {Weihua Xu and Di Jiang},
  doi      = {10.1109/TBDATA.2025.3556637},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2779-2791},
  title    = {A novel concept-cognitive learning model oriented to three-way concept for knowledge acquisition},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Revocable DSSE in healthcare systems with range query support. <em>TBD</em>, <em>11</em>(5), 2764-2778. (<a href='https://doi.org/10.1109/TBDATA.2025.3556636'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {With the rapid development of cloud computing, online health monitoring systems are becoming increasingly prevalent. To protect medical data privacy while supporting search operations, Dynamic Searchable Symmetric Encryption (DSSE) technology has been widely used in health monitoring systems. For better monitoring of patient status, keyword range query is also a necessary requirement for the DSSE scheme. Furthermore, in the multi-user setting, user revocation usually leads the owner to download and re-encrypt all indexes, resulting in significant computational overhead. In this paper, we propose a lightweight revocable DSSE scheme with range query support. First, we propose a novel and privacy-preserving range query algorithm that defends plaintext inference attacks. Second, we design a singly linked list structure based on delegatable pseudorandom functions and key-updatable pseudorandom functions, which support lightweight user revocation. Rigorous security analysis proves the security of our proposed range query scheme and demonstrates that our scheme can achieve forward and backward privacy. Experimental evaluations show that our scheme is highly efficient.},
  archive  = {J},
  author   = {Hanqi Zhang and Yandong Zheng and Chang Xu and Liehuang Zhu and Jiayin Wang},
  doi      = {10.1109/TBDATA.2025.3556636},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2764-2778},
  title    = {Revocable DSSE in healthcare systems with range query support},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Split learning on segmented healthcare data. <em>TBD</em>, <em>11</em>(5), 2749-2763. (<a href='https://doi.org/10.1109/TBDATA.2025.3556639'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Sequential data learning is vital to harnessing the encompassed rich knowledge for diverse downstream tasks, particularly in healthcare (e.g., disease prediction). Considering data sensitiveness, privacy-preserving learning methods, based on federated learning (FL) and split learning (SL), have been widely investigated. Yet, this work identifies, for the first time, existing methods overlook that sequential data are generated by different patients at different times and stored in different hospitals, failing to learn the sequential correlations between different temporal segments. To fill this void, a novel distributed learning framework STSL is proposed by training a model on the segments in order. Considering that patients have different visit sequences, STSL first implements privacy-preserving visit ordering based on a secure multi-party computation mechanism. Then batch scheduling participates patients with similar visit (sub-)sequences into the same training batch, facilitating subsequent split learning on batches. The scheduling process is formulated as an NP-hard optimization problem on balancing learning loss and efficiency and a greedy-based solution is presented. Theoretical analysis proves the privacy preservation property of STSL. Experimental results on real-world eICU data show its superior performance compared with FL and SL ($5\% \sim 28\%$ better accuracy) and effectiveness (a remarkable 75% reduction in communication costs).},
  archive  = {J},
  author   = {Ling Hu and Tongqing Zhou and Zhihuang Liu and Fang Liu and Zhiping Cai},
  doi      = {10.1109/TBDATA.2025.3556639},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2749-2763},
  title    = {Split learning on segmented healthcare data},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PViTGAtt-IP: Severity quantification of lung infections in chest X-rays and CT scans via parallel and cross-attended encoders. <em>TBD</em>, <em>11</em>(5), 2736-2748. (<a href='https://doi.org/10.1109/TBDATA.2025.3556612'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The development of a robust and adaptive deep learning technique for the diagnosis of pneumonia and the assessment of its severity was a major challenge. Indeed, both chest X-rays (CXR) and CT scans have been widely studied for the diagnosis, detection and quantification of pneumonia. In this paper, a novel approach (PViTGAtt-IP) based on a parallel array of vision transformers is presented, in which the input image is divided into regions of interest. Each region is fed into an individual model and the collective output gives the severity score. Three parallel architectures were also derived and tested. The proposed models were subjected to rigorous tests on two different datasets: RALO CXRs and Per COVID-19 CT scans. The experimental results showed that the proposed models exhibited high performance in accurately predicting scores for both datasets. In particular, the parallel transformers with multi-gate attention proved to be the best performing model. Furthermore, a comparative analysis using state-of-the-art methods showed that our proposed approach consistently achieved competitive or even better performance in terms of the Mean Absolute Error (MAE) and the Pearson Correlation Coefficient (PC). This emphasizes the effectiveness and superiority of our models in the context of diagnosing and assessing the severity of pneumonia.},
  archive  = {J},
  author   = {Bouthaina Slika and Fadi Dornaika and Fares Bougourzi and Karim Hammoudi},
  doi      = {10.1109/TBDATA.2025.3556612},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2736-2748},
  title    = {PViTGAtt-IP: Severity quantification of lung infections in chest X-rays and CT scans via parallel and cross-attended encoders},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Incorporating confused phraseological knowledge based on pinyin input method for chinese spelling correction. <em>TBD</em>, <em>11</em>(5), 2724-2735. (<a href='https://doi.org/10.1109/TBDATA.2025.3552344'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Chinese Spelling Correction (CSC) is designed to detect and correct spelling errors that occur in Chinese text. In real life, most keyboard input scenarios use the pinyin input method. Researching spelling errors in this scenario is practical and valuable. However, there is currently no research that has truly proposed a model suitable for this scenario. Considering this concern, this paper proposes a model IPCK-IME, which incorporates confused phraseological knowledge based on the pinyin input method. The model integrates its own phonetic features with external similarity knowledge to guide the model to output more correct characters. Furthermore, to mitigate the influence of spelling errors on the semantics of sentences, a Gaussian bias is introduced into the self-attention network of the model. This approach aims to reduces the focus on typos and improve attention to local context. Empirical evidence indicates that our method surpasses existing models in correcting spelling errors generated by the pinyin input method. And, it is more appropriate for correcting Chinese spelling errors in real input scenarios.},
  archive  = {J},
  author   = {Weidong Zhao and Xiaoyu Wang and Liqing Qiu},
  doi      = {10.1109/TBDATA.2025.3552344},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2724-2735},
  title    = {Incorporating confused phraseological knowledge based on pinyin input method for chinese spelling correction},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive graph structure learning neural rough differential equations for multivariate time series forecasting. <em>TBD</em>, <em>11</em>(5), 2710-2723. (<a href='https://doi.org/10.1109/TBDATA.2025.3552334'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Multivariate time series forecasting has extensive applications in urban computing, such as financial analysis, weather prediction, and traffic forecasting. Using graph structures to model the complex correlations among variables in time series, and leveraging graph neural networks and recurrent neural networks for temporal aggregation and spatial propagation stage, has shown promise. However, traditional methods’ graph structure node learning and discrete neural architecture are not sensitive to issues such as sudden changes, time variance, and irregular sampling often found in real-world data. To address these challenges, we propose a method called Adaptive Graph structure Learning neural Rough Differential Equations (AGLRDE). Specifically, we combine dynamic and static graph structure learning to adaptively generate a more robust graph representation. Then we employ a spatio-temporal encoder-decoder based on Neural Rough Differential Equations (Neural RDE) to model spatio-temporal dependencies. Additionally, we introduce a path reconstruction loss to constrain the path generation stage. We conduct experiments on six benchmark datasets, demonstrating that our proposed method outperforms existing state-of-the-art methods. The results show that AGLRDE effectively handles aforementioned challenges, significantly improving the accuracy of multivariate time series forecasting.},
  archive  = {J},
  author   = {Yuming Su and Tinghuai Ma and Huan Rong and Mohamed Magdy Abdel Wahab},
  doi      = {10.1109/TBDATA.2025.3552334},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2710-2723},
  title    = {Adaptive graph structure learning neural rough differential equations for multivariate time series forecasting},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective graph contrastive learning for recommendation. <em>TBD</em>, <em>11</em>(5), 2696-2709. (<a href='https://doi.org/10.1109/TBDATA.2025.3552341'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Recently, numerous studies have integrated self-supervised contrastive learning with Graph Convolutional Networks (GCNs) to address the data sparsity and popularity bias to enhance recommendation performance. While such studies have made breakthroughs in accuracy metric, they often neglect non-accuracy objectives such as diversity, novelty and percentage of long-tail items, which greatly reduces the user experience in real-world applications. To this end, we propose a novel graph collaborative filtering model named Multi-Objective Graph Contrastive Learning for recommendation (MOGCL), designed to provide more comprehensive recommendations by considering multiple objectives. Specifically, MOGCL comprises three modules: a multi-objective embedding generation module, an embedding fusion module and a transfer learning module. In the multi-objective embedding generation module, we employ two GCN encoders with different goal orientations to generate node embeddings targeting accuracy and non-accuracy objectives, respectively. These embeddings are then effectively fused with complementary weights in the embedding fusion module. In the transfer learning module, we suggest an auxiliary self-supervised task to promote the maximization of the mutual information of the two sets of embeddings, so that the obtained final embeddings are more stable and comprehensive. The experimental results on three real-world datasets show that MOGCL achieves optimal trade-offs between multiple objectives comparing to the state-of-the-arts.},
  archive  = {J},
  author   = {Lei Zhang and Mingren Ke and Likang Wu and Wuji Zhang and Zihao Chen and Hongke Zhao},
  doi      = {10.1109/TBDATA.2025.3552341},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2696-2709},
  title    = {Multi-objective graph contrastive learning for recommendation},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MHT-net: A matching-based hierarchical transfer network for glaucoma detection from fundus images. <em>TBD</em>, <em>11</em>(5), 2681-2695. (<a href='https://doi.org/10.1109/TBDATA.2025.3552342'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Glaucoma is a chronic and irreversible eye disease. Early detection and treatment can effectively prevent severe consequences. Deep transfer learning is widely used in fundus imaging analysis to remedy the shortage of training data of glaucoma. The model trained on the source domain may struggle to predict glaucoma in the target domain due to distribution differences. Several limitations cannot be ignored: (1) Image matching: enhancing global and local image consistency through bidirectional matching; (2) Hierarchical transfer: developing a strategy for transferring different hierarchical features. To this end, we propose a novel Matched Hierarchical Transfer Network (MHT-Net) to achieve automatic glaucoma detection. We initially create a fundus structure detector to match global and local images using intermediate layers of a pre-trained diagnostic model with source domain data. Next, a hierarchical transfer network is implemented, sharing parameters for general features and using a domain discriminator for specific features. By integrating adversarial and classification losses, the model acquires domain-invariant features, facilitating precise and seamless transfer of fundus information from source to target domains. Extensive experiments demonstrate the effectiveness of our proposed method, outperforming existing glaucoma detection methods. These advantages endow our algorithm as a promising efficient assisted tool in the glaucoma screening.},
  archive  = {J},
  author   = {Linna Zhao and Jianqiang Li and Li Li and Xi Xu},
  doi      = {10.1109/TBDATA.2025.3552342},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2681-2695},
  title    = {MHT-net: A matching-based hierarchical transfer network for glaucoma detection from fundus images},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-guided graph refinement with progressive fusion for multiplex graph contrastive representation learning. <em>TBD</em>, <em>11</em>(5), 2669-2680. (<a href='https://doi.org/10.1109/TBDATA.2025.3552331'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Multiplex Graph Contrastive Learning (MGCL) has attracted significant attention. However, existing MGCL methods often struggle with suboptimal graph structures and fail to fully capture intricate interdependencies across multiplex views. To address these issues, we propose a novel self-supervised framework, Multiplex Graph Refinement with progressive fusion (MGRefine), for multiplex graph contrastive representation learning. Specifically, MGRefine introduces a multi-view learning module to extract a structural guidance matrix by exploring the underlying relationships between nodes. Then, a progressive fusion module is employed to progressively enhance and fuse representations from different views, capturing and leveraging nuanced interdependencies and comprehensive information across the multiplex graphs. The fused representation is then used to construct a consensus guidance matrix. A self-enhanced refinement module continuously refines the multiplex graphs using these guidance matrices while providing effective supervision signals. MGRefine achieves mutual reinforcement between graph structures and representations, ensuring continuous optimization of the model throughout the learning process in a self-enhanced manner. Extensive experiments demonstrate that MGRefine outperforms state-of-the-art methods and also verify the effectiveness of MGRefine across various downstream tasks on several benchmark datasets.},
  archive  = {J},
  author   = {Qi Dai and Yu Gu and Xiaofeng Zhu and Xiaohua Li and Fangfang Li and Ge Yu},
  doi      = {10.1109/TBDATA.2025.3552331},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2669-2680},
  title    = {Self-guided graph refinement with progressive fusion for multiplex graph contrastive representation learning},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MSST: Multi-scale spatial-temporal representation learning for trajectory similarity computation. <em>TBD</em>, <em>11</em>(5), 2657-2668. (<a href='https://doi.org/10.1109/TBDATA.2025.3552340'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Computing trajectory similarity is a fundamental task in trajectory analysis. Traditional heuristic methods suffer from quadratic computational complexity, which limits their scalability to large datasets. Recently, Trajectory Representation Learning (TRL) has been extensively studied to address this limitation. However, most existing TRL algorithms face two key challenges. First, they prioritize spatial similarity while neglecting the intricate spatio-temporal dynamics of trajectories, particularly temporal regularities. Second, these methods are often constrained by predefined single spatial or temporal scales, which can significantly impact performance, since the measurement of trajectory similarity depends on spatial and temporal resolution. To address these issues, we propose MSST, a Multi-Scale Self-supervised Trajectory Representation Learning framework. MSST simultaneously processes spatial and temporal information by generating 3D spatial-temporal tokens, thereby capturing spatio-temporal characteristics of trajectories more effectively. Further, MSST explore the multi-scale characteristics of trajectories. Finally, self-supervised contrastive learning is employed to enhance the consistency between the trajectory representations from different views. Experimental results on three real-world datasets for similarity trajectory computation provide insight into the design properties of our approach and demonstrate the superiority of our approach over existing TRL methods. MSST significantly surpasses all state-of-the-art competitors in terms of effectiveness, efficiency, and robustness. We explore the multi-scale characteristics of trajectories. To the best of our knowledge, this is the first effort in the TRL literature. Compared to previous TRL research, the proposed method can balance the noise and the details of trajectories, enabling a more comprehensive analysis by accounting for the variability inherent in trajectory data across different scales.},
  archive  = {J},
  author   = {Li Li and Junjun Si and Jinna Lv and Junting Lu and Jianyu Zhang and Shuaifu Dai},
  doi      = {10.1109/TBDATA.2025.3552340},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2657-2668},
  title    = {MSST: Multi-scale spatial-temporal representation learning for trajectory similarity computation},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing weak supervision for concept prerequisite relation learning. <em>TBD</em>, <em>11</em>(5), 2643-2656. (<a href='https://doi.org/10.1109/TBDATA.2025.3552330'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Concept prerequisite relation learning is used to identify dependency relations between knowledge concepts, which helps learners choose effective learning paths. Currently, most of the mainstream methods utilise deep learning algorithms to capture the prerequisite relations between concepts through supervised or semi-supervised learning. However, these methods are highly dependent on labelled data, which is scarce and costly to annotate in reality. To address this problem, we propose a framework called Weakly Supervised Enhanced Concept Prerequisite Relation Learning (WSECPRL). Specifically, we first generate an enhanced concept pseudo-relation graph without labeled data using the pre-trained language model and the large knowledge base as auxiliary information. Second, we propose an improved variational graph auto-encoder model to correctly determine the concept prerequisite relations. We incorporate a multi-head attention mechanism to enhance the representation learning capability of weakly supervised learning. The model reconstructs a directed graph into multiple undirected graphs by splitting the adjacency matrix and determines the direction of the concept prerequisite relation based on the strength of the dependency relation between concepts. Finally, experimental results on several publicly available datasets demonstrate the effectiveness of our proposed framework, with WSECPRL outperforming existing baseline models in terms of F1 scores and AUC.},
  archive  = {J},
  author   = {Miao Zhang and Jiawei Wang and Kui Xiao and Zhifang Huang and Zhifei Li and Yan Zhang},
  doi      = {10.1109/TBDATA.2025.3552330},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2643-2656},
  title    = {Enhancing weak supervision for concept prerequisite relation learning},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NetPrompt: Neural network prompting enhances event extraction in large language models. <em>TBD</em>, <em>11</em>(5), 2628-2642. (<a href='https://doi.org/10.1109/TBDATA.2025.3552333'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Event Extraction involves extracting event-related information such as event types and event arguments from context, which has long been tackled through well-designed neural networks or fine-tuned pre-trained language models. These approaches require substantial annotated data for tuning parameters and are resource-intensive. Recently, Prompting strategies with frozen parameters, such as Chain-of-Thought and Self-Consistency, have delivered success in NLP using LLMs by generating intermediate thought steps. However, they suffer from the challenge of error propagation and lack of interaction between different thoughts. In this paper, we propose Neural Network-based Prompting (NetPrompt), a novel network-structured prompting strategy for event extraction. The core idea behind NetPrompt is to imitate the excellent information integration capabilities of neural network structures. Specifically, we first decompose the event extraction problem into diverse intermediate subtasks, and each subtask is represented as a node in different layers of the network, the output of the nodes in the preceding layer is fed into the subsequent layer. Secondly, we propose pruning strategies to adapt the reasoning overhead to different problems. Finally, we have conducted extensive experiments on two widely used event extraction benchmarks to evaluate NetPrompt. The results demonstrated that NetPrompt significantly improved the event extraction performance compared to previous methods.},
  archive  = {J},
  author   = {Lin Mu and Yide Cheng and Jun Shen and Yiwen Zhang and Hong Zhong},
  doi      = {10.1109/TBDATA.2025.3552333},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2628-2642},
  title    = {NetPrompt: Neural network prompting enhances event extraction in large language models},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Residual learning for self-knowledge distillation: Enhancing neural networks through consistency across layers. <em>TBD</em>, <em>11</em>(5), 2615-2627. (<a href='https://doi.org/10.1109/TBDATA.2025.3552326'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Knowledge distillation is widely used technique to transfer knowledge from a large pretrained teacher network to a small student network. However, training complex teacher models requires significant computational resources and storage. To address this, a growing area of research, known as self-knowledge distillation (Self-KD), aims to enhance the performance of a neural network by leveraging its own latent knowledge. Despite its potential, existing Self-KD methods often struggle to effectively extract and utilize the model's dark knowledge. In this work, we identify a consistency problem between feature layer and output layer, and propose a novel Self-KD approach called Residual Learning for Self-Knowledge Distillation (RSKD). Our method addresses this issue by enabling the last feature layer of the student model learn the residual gap between the outputs of the pseudo-teacher and the student. Additionally, we extend RSKD by allowing each intermediate feature layer of the student model to learn the residual gap between the corresponding deeper features of the pseudo-teacher and the student. Extensive experiments on various visual datasets demonstrate the effectiveness of the proposed method, which outperforms the state-of-the-art baselines.},
  archive  = {J},
  author   = {Hanpeng Liu and Shuoxi Zhang and Kun He},
  doi      = {10.1109/TBDATA.2025.3552326},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2615-2627},
  title    = {Residual learning for self-knowledge distillation: Enhancing neural networks through consistency across layers},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal subdata selection for prediction based on the distribution of the covariates. <em>TBD</em>, <em>11</em>(5), 2601-2614. (<a href='https://doi.org/10.1109/TBDATA.2025.3552343'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Huge data sets are widely available now and there is growing interest in selecting an optimal subsample from the full data set to improve inference efficiency and reduce labeling costs. We propose a new criterion called J–optimality, that builds upon a popular optimal selection criterion that minimizes the Random–X prediction error by additionally incorporating the joint distribution of the covariates. A key advantage of our approach is that we can relate the subsampling selection problem to that of finding an optimal approximate design under a convex criterion, where analytical tools for finding and studying them are already available. Consequently, the J–optimal subsampling method comes with theoretical results and theory-based algorithms for finding them. Simulation results and real data analysis show our proposed methods outperform current subsampling methods and the proposed algorithms can also adapt efficiently to select an optimal subsample from streaming data.},
  archive  = {J},
  author   = {Alvaro Cia-Mina and Jesus Lopez-Fidalgo and Weng Kee Wong},
  doi      = {10.1109/TBDATA.2025.3552343},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2601-2614},
  title    = {Optimal subdata selection for prediction based on the distribution of the covariates},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient antagonistic $k$<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>k</mml:mi></mml:math>-plex enumeration in signed graphs. <em>TBD</em>, <em>11</em>(5), 2587-2600. (<a href='https://doi.org/10.1109/TBDATA.2025.3552335'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {A signed graph is a graph where each edge receives a sign, positive or negative. The signed graph model has been used in many real applications, such as protein complex discovery and social network analysis. Finding cohesive subgraphs in signed graphs is a fundamental problem. A $k$-plex is a common model for cohesive subgraphs in which every vertex is adjacent to all but at most $k$ vertices within the subgraph. In this paper, we propose the model of size-constrained antagonistic $k$-plex in a signed graph. The proposed model guarantees that the resulting subgraph is a $k$-plex and can be divided into two sub-$k$-plexes, both of which have positive inner edges and negative outer edges. This paper aims to identify all maximal antagonistic $k$-plexes in a signed graph. Through rigorous analysis, we show that the problem is NP-Hardness. We propose a novel framework for maximal antagonistic $k$-plexes utilizing set enumeration. Efficiency is improved through pivot pruning and early termination based on the color bound. Preprocessing techniques based on degree and dichromatic graphs effectively narrow the search space before enumeration. Extensive experiments on real-world datasets demonstrate our algorithm’s efficiency, effectiveness, and scalability.},
  archive  = {J},
  author   = {Lantian Xu and Rong-Hua Li and Dong Wen and Qiangqiang Dai and Guoren Wang},
  doi      = {10.1109/TBDATA.2025.3552335},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2587-2600},
  title    = {Efficient antagonistic $k$<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>k</mml:mi></mml:math>-plex enumeration in signed graphs},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comprehensive architecture search for deep graph neural networks. <em>TBD</em>, <em>11</em>(5), 2572-2586. (<a href='https://doi.org/10.1109/TBDATA.2025.3552336'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In recent years, Neural Architecture Search (NAS) has emerged as a promising approach for automatically discovering superior model architectures for deep Graph Neural Networks (GNNs). Different methods have paid attention to different types of search spaces. However, due to the time-consuming nature of training deep GNNs, existing NAS methods often fail to explore diverse search spaces sufficiently, which constrains their effectiveness. To crack this hard nut, we propose CAS-DGNN, a novel comprehensive architecture search method for deep GNNs. It encompasses four kinds of search spaces that are the composition of aggregate and update operators, different types of aggregate operators, residual connections, and hyper-parameters. To meet the needs of such a complex situation, a phased and hybrid search strategy is proposed to accommodate the diverse characteristics of different search spaces. Specifically, we divide the search process into four phases, utilizing evolutionary algorithms and Bayesian optimization. Meanwhile, we design two distinct search methods for residual connections (All-connected search and Initial Residual search) to streamline the search space, which enhances the scalability of CAS-DGNN. The experimental results show that CAS-DGNN achieves higher accuracy with competitive search costs across ten public datasets compared to existing methods.},
  archive  = {J},
  author   = {Yukang Dong and Fanxing Pan and Yi Gui and Wenbin Jiang and Yao Wan and Ran Zheng and Hai Jin},
  doi      = {10.1109/TBDATA.2025.3552336},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2572-2586},
  title    = {Comprehensive architecture search for deep graph neural networks},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust semi-supervised deep nonnegative matrix factorization with constraint propagation for data representation. <em>TBD</em>, <em>11</em>(5), 2557-2571. (<a href='https://doi.org/10.1109/TBDATA.2025.3547174'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Deep nonnegative matrix factorization (DNMF) technique has attached much great attention in recent year, since it can effectively discover the underlying hierarchical structure of complex data. However, most existing unsupervised and semi-supervised DNMF approaches not only suffer from the noisy data seriously, but also fail to enhance the decomposition quality of DNMF obviously by using the obtained supervisory information. To overcome these drawbacks, a robust semi-supervised DNMF method, called the correntropy based semi-supervised DNMF with constraint propagation (CSDCP), is proposed in this paper for learning a compact and meaningful data representation from the original data. Particularly, instead of adopting the traditional Frobenius norm, CSDCP employs the nonlinear and local similarity measure (e.g., correntropy) as the loss function in DNMF to enhance the robustness of DNMF for the noisy data. In addition, the hypergraph based constraint propagation (HCP) algorithm is adopted in CSDCP to exploit the limited supervisory information fully for capturing good data representation. Moreover, algorithm analysis of CSDCP is presented in this paper, including convergence analysis, robustness analysis supervised information analysis, and computational complexity. Extensive experimental results have illustrated that, in comparison to the most related DNMF approaches, CSDCP usually has better clustering results on six nonnegative datasets in clustering tasks.},
  archive  = {J},
  author   = {Siyuan Peng and Jingxing Yin and Zhijing Yang and Feiping Nie and Badong Chen},
  doi      = {10.1109/TBDATA.2025.3547174},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2557-2571},
  title    = {Robust semi-supervised deep nonnegative matrix factorization with constraint propagation for data representation},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). How to decide like human? a commonsense-aware hierarchical framework for knowledge graph reasoning. <em>TBD</em>, <em>11</em>(5), 2545-2556. (<a href='https://doi.org/10.1109/TBDATA.2025.3544126'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Reasoning over knowledge graphs has attracted considerable attention from researchers and is being widely applied to contribute question answering systems, recommender systems, and other information retrieval systems. However, existing reasoning methods tend to suffer from poor interpretability which is not consistent with human commonsense. The trustworthiness and reliability of the knowledge discover outcomes thus decreased as a result. Inspired by the process of human decision-making, we propose a commonsense-aware hierarchical framework called HDLH, which incorporates commonsense knowledge into hierarchical knowledge graph reasoning process with deep reinforcement learning. HDLH implements hierarchical reasoning process through exploration and exploitation sequentially by applying multi-agent reinforcement learning. Multiple agents in HDLH simulate the multi-level decision-making ability of humans, and reason hierarchically and reasonably to maintain its efficiency and interpretability. Moreover, commonsense knowledge is incorporated by means of the reward-shaping function, ultimately guiding the agent to reason more consistently with human perceptions and reduce the huge search space. We evaluated HDLH with various tasks on five real-world datasets. The experimental results reveal that HDLH achieves better performance compared with state-of-the-art baseline models.},
  archive  = {J},
  author   = {Yi Xia and Gang Zhou and Junyong Luo and Mingjing Lan and Ningbo Huang},
  doi      = {10.1109/TBDATA.2025.3544126},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2545-2556},
  title    = {How to decide like human? a commonsense-aware hierarchical framework for knowledge graph reasoning},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Higher-order community detection by motif-based modularity optimization. <em>TBD</em>, <em>11</em>(5), 2529-2544. (<a href='https://doi.org/10.1109/TBDATA.2025.3544129'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Recently higher-order community detection based on network motifs has received increasing attention, because motif-based communities reflect not only mesoscale structures but also functional characteristics of real-life networks. In this study, we propose a Modularity Optimization method for Motif-based Community Detection (MOMCD). In order to approximate the global optimum in modularity optimization, an improved nature-inspired metaheuristic algorithm is proposed as optimization strategy. In addition, by comprehensively utilizing motif-based (higher-order) and edge-based (lower-order) structural information, a neighbor community modification operation and a local search operation are also designed to improve the quality of individuals and promote the convergence of MOMCD. Experimental results show that MOMCD is promising and competitive in identifying motif-based communities from synthetic and real-life networks, which outperforms state-of-the-art approaches in terms of quality and accuracy, and deepens our understanding of network structural and functional characteristics.},
  archive  = {J},
  author   = {Jing Xiao and Yu-Cheng Zou and Xiao-Ke Xu},
  doi      = {10.1109/TBDATA.2025.3544129},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2529-2544},
  title    = {Higher-order community detection by motif-based modularity optimization},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LightST: A simplifying spatio-temporal graph neural network for traffic flow forecasting. <em>TBD</em>, <em>11</em>(5), 2517-2528. (<a href='https://doi.org/10.1109/TBDATA.2025.3544131'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Traffic flow forecasting task plays an essential role in intelligent transportation systems. Accurately capturing the intricate spatio-temporal dependencies in traffic network signals is the core of precise prediction. Recently, a paradigm that models spatio-temporal dependencies through graph neural networks and time series models has become one of the most promising methods to solve this problem. However, existing methods still have limitations due to ineffectively modeling dynamic spatial dependencies and high time and space complexity. To address these issues, we propose a simplifying and powerful general spatio-temporal traffic flow forecasting model called LightST. Specifically, LightST first embeds temporal covariates and spatial position information to enhance the spatio-temporal modeling capabilities. Then, stacked temporal linear layers are introduced to capture temporal dependencies efficiently. Finally,we propose a concise adaptive spatio-temporal embedding graph convolution method to extract implicit spatial dependencies over time via dynamic graph convolution with adaptive spatio-temporal embedding graph generation. Extensive experiment results on four public traffic flow datasets demonstrate the superiority of our LightST concerning computational efficiency and prediction performance.},
  archive  = {J},
  author   = {Jie Hu and Taichuan Zheng and Lilan Peng and Fei Teng and Shengdong Du and Tianrui Li},
  doi      = {10.1109/TBDATA.2025.3544131},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2517-2528},
  title    = {LightST: A simplifying spatio-temporal graph neural network for traffic flow forecasting},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A theoretical analysis of efficiency constrained utility-privacy bi-objective optimization in federated learning. <em>TBD</em>, <em>11</em>(5), 2503-2516. (<a href='https://doi.org/10.1109/TBDATA.2025.3534622'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Federated learning (FL) enables multiple clients to collaboratively learn a shared model without sharing their individual data. Concerns about utility, privacy, and training efficiency in FL have garnered significant research attention. Differential privacy has emerged as a prevalent technique in FL, safeguarding the privacy of individual user data while impacting utility and training efficiency. Within Differential Privacy Federated Learning (DPFL), previous studies have primarily focused on the utility-privacy trade-off, neglecting training efficiency, which is crucial for timely completion. Moreover, differential privacy achieves privacy by introducing controlled randomness (noise) on selected clients in each communication round. Previous work has mainly examined the impact of noise level ($\sigma$) and communication rounds ($T$) on the privacy-utility dynamic, overlooking other influential factors like the sample ratio ($q$, the proportion of selected clients). This paper systematically formulates an efficiency-constrained utility-privacy bi-objective optimization problem in DPFL, focusing on $\sigma$, $T$, and $q$. We provide a comprehensive theoretical analysis, yielding analytical solutions for the Pareto front. Extensive empirical experiments verify the validity and efficacy of our analysis, offering valuable guidance for low-cost parameter design in DPFL.},
  archive  = {J},
  author   = {Hanlin Gu and Xinyuan Zhao and Gongxi Zhu and Yuxing Han and Yan Kang and Lixin Fan and Qiang Yang},
  doi      = {10.1109/TBDATA.2025.3534622},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2503-2516},
  title    = {A theoretical analysis of efficiency constrained utility-privacy bi-objective optimization in federated learning},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Risk-constrained reinforcement learning with augmented lagrangian multiplier for portfolio optimization. <em>TBD</em>, <em>11</em>(5), 2489-2502. (<a href='https://doi.org/10.1109/TBDATA.2025.3533905'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {We explored the application of Risk-averse Reinforcement Learning (Risk-averse RL) in Constrained Markov Decision Process (CMDP) in optimizing investment portfolios, incorporating constraints assessment. The investment portfolio must be always constrained with risk characteristics by investors and regulators. Therefore, the hard constraint is necessary for the practical Portfolio optimization. Moreover, traditional portfolio optimization techniques lack flexibility to model complex dynamic financial market. To address this issue, Augmented Lagrangian Multiplier (ALM) was employed to enforce constraints on the agent, mitigating the impact of risk in the decision process. Our proposal of the risk-constrained RL algorithm demonstrated no constraint violations during the testing phase, and outperformance compared to other Risk-averse RL algorithms, fulfilling our primary goal. This suggests that incorporating a risk-constrained RL technique holds promise for portfolio optimization, particularly for risk-averse investors.},
  archive  = {J},
  author   = {Bayaraa Enkhsaikhan and Ohyun Jo},
  doi      = {10.1109/TBDATA.2025.3533905},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2489-2502},
  title    = {Risk-constrained reinforcement learning with augmented lagrangian multiplier for portfolio optimization},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MultiTec: A data-driven multimodal short video detection framework for healthcare misinformation on TikTok. <em>TBD</em>, <em>11</em>(5), 2471-2488. (<a href='https://doi.org/10.1109/TBDATA.2025.3533919'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {With the prevalence of social media and short video sharing platforms (e.g., TikTok, YouTube Shorts), the proliferation of healthcare misinformation has become a widespread and concerning issue that threatens public health and undermines trust in mass media. This paper focuses on an important problem of detecting multimodal healthcare misinformation in short videos on TikTok. Our objective is to accurately identify misleading healthcare information that is jointly conveyed by the visual, audio, and textual content within the TikTok short videos. Three critical challenges exist in solving our problem: i) how to effectively extract information from distractive and manipulated visual content in short videos? ii) How to efficiently identify the interrelation of the heterogeneous visual and speech content in short videos? iii) How to accurately capture the complex dependency of the densely connected sequential content in short videos? To address the above challenges, we develop MultiTec, a multimodal detector that explicitly explores the audio and visual content in short videos to investigate both the sequential relation of video elements and their inter-modality dependencies to jointly detect misinformation in healthcare videos on TikTok. To the best of our knowledge, MultiTec is the first modality-aware dual-attentive short video detection model for multimodal healthcare misinformation on TikTok. We evaluate MultiTec on two real-world healthcare video datasets collected from TikTok. Evaluation results show that MultiTec achieves substantial performance gains compared to state-of-the-art baselines in accurately detecting misleading healthcare short videos.},
  archive  = {J},
  author   = {Lanyu Shang and Yang Zhang and Yawen Deng and Dong Wang},
  doi      = {10.1109/TBDATA.2025.3533919},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2471-2488},
  title    = {MultiTec: A data-driven multimodal short video detection framework for healthcare misinformation on TikTok},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scalable learning-based community-preserving graph generation. <em>TBD</em>, <em>11</em>(5), 2457-2470. (<a href='https://doi.org/10.1109/TBDATA.2025.3533898'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Graph generation plays an essential role in understanding the formation of complex network structures across various fields, such as biological and social networks. Recent studies have shifted towards employing deep learning methods to grasp the topology of graphs. Yet, most current graph generators fail to adequately capture the community structure, which stands out as a critical and distinctive aspect of graphs. Additionally, these generators are generally limited to smaller graphs because of their inefficiencies and scaling challenges. This paper introduces the Community-Preserving Graph Adversarial Network (CPGAN), designed to effectively simulate graphs. CPGAN leverages graph convolution networks within its encoder and maintains shared parameters during generation to encapsulate community structure data and ensure permutation invariance. We also present the Scalable Community-Preserving Graph Attention Network (SCPGAN), aimed at enhancing the scalability of our model. SCPGAN considerably cuts down on inference and training durations, as well as GPU memory usage, through the use of an ego-graph sampling approach and a short-pipeline autoencoder framework. Tests conducted on six real-world graph datasets reveal that CPGAN manages a beneficial balance between efficiency and simulation quality when compared to leading-edge baselines. Moreover, SCPGAN marks substantial strides in model efficiency and scalability, successfully increasing the size of generated graphs to the 10 million node level while maintaining competitive quality, on par with other advanced learning models.},
  archive  = {J},
  author   = {Sheng Xiang and Chenhao Xu and Dawei Cheng and Ying Zhang},
  doi      = {10.1109/TBDATA.2025.3533898},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2457-2470},
  title    = {Scalable learning-based community-preserving graph generation},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CTDI: CNN-transformer-based spatial-temporal missing air pollution data imputation. <em>TBD</em>, <em>11</em>(5), 2443-2456. (<a href='https://doi.org/10.1109/TBDATA.2025.3533882'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Accurate and comprehensive air pollution data is essential for understanding and addressing environmental challenges. Missing data can impair accurate analysis and decision-making. This study presents a novel approach, named CNN-Transformer-based Spatial-Temporal Data Imputation (CTDI), for imputing missing air pollution data. Data pre-processing incorporates observed air pollution data and related urban data to produce 24-hour period tensors as input samples. 1-by-1 CNN layers capture the interaction between different types of input data. Deep learning transformer architecture is employed in a spatial-temporal (S-T) transformer module to capture long-range dependencies and extract complex relationships in both spatial and temporal dimensions. Hong Kong air pollution data is statistically analyzed and used to evaluate CTDI in its recovery of generated and actual patterns of missing data. Experimental results show that CTDI consistently outperforms existing imputation methods across all evaluated scenarios, including cases with higher rates of missing data, thereby demonstrating its robustness and effectiveness in enhancing air quality monitoring. Additionally, ablation experiments reveal that each component significantly contributes to the model's performance, with the temporal transformer proving particularly crucial under varying rates of missing data.},
  archive  = {J},
  author   = {Yangwen Yu and Victor O. K. Li and Jacqueline C. K. Lam and Kelvin Chan and Qi Zhang},
  doi      = {10.1109/TBDATA.2025.3533882},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2443-2456},
  title    = {CTDI: CNN-transformer-based spatial-temporal missing air pollution data imputation},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data exchange for the metaverse with accountable decentralized TTPs and incentive mechanisms. <em>TBD</em>, <em>11</em>(5), 2431-2442. (<a href='https://doi.org/10.1109/TBDATA.2025.3533924'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {As a global virtual environment, the metaverse poses various challenges regarding data storage, sharing, interoperability, and privacy preservation. Typically, a trusted third party (TTP) is considered necessary in these scenarios. However, relying on a single TTP may introduce biases, compromise privacy, or lead to single-point-of-failure problem. To address these challenges and enable secure data exchange in the metaverse, we propose a system based on decentralized TTPs and the Ethereum blockchain. First, we use the threshold ElGamal cryptosystem to create the decentralized TTPs, employing verifiable secret sharing (VSS) to force owners to share data honestly. Second, we leverage the Ethereum blockchain to serve as the public communication channel, automatic verification machine, and smart contract engine. Third, we apply discrete logarithm equality (DLEQ) algorithms to generate non-interactive zero knowledge (NIZK) proofs when encrypted data is uploaded to the blockchain. Fourth, we present an incentive mechanism to benefit data owners and TTPs from data-sharing activities, as well as a penalty policy if malicious behavior is detected. Consequently, we construct a data exchange framework for the metaverse, in which all involved entities are accountable. Finally, we perform comprehensive experiments to demonstrate the feasibility and analyze the properties of the proposed system.},
  archive  = {J},
  author   = {Liang Zhang and Xingyu Wu and Yuhang Ma and Haibin Kan},
  doi      = {10.1109/TBDATA.2025.3533924},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2431-2442},
  title    = {Data exchange for the metaverse with accountable decentralized TTPs and incentive mechanisms},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing the transferability of adversarial examples with random diversity ensemble and variance reduction augmentation. <em>TBD</em>, <em>11</em>(5), 2417-2430. (<a href='https://doi.org/10.1109/TBDATA.2025.3533892'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Currently, deep neural networks (DNNs) are susceptible to adversarial attacks, particularly when the network's structure and parameters are known, while most of the existing attacks do not perform satisfactorily in the presence of black-box settings. In this context, model augmentation is considered to be effective to improve the success rates of black-box attacks on adversarial examples. However, the existing model augmentation methods tend to rely on a single transformation, which limits the diversity of augmented model collections and thus affects the transferability of adversarial examples. In this paper, we first propose the random diversity ensemble method (RDE-MI-FGSM) to effectively enhance the diversity of the augmented model collection, thereby improving the transferability of the generated adversarial examples. Afterwards, we put forward the random diversity variance ensemble method (RDE-VRA-MI-FGSM), which adopts variance reduction augmentation (VRA) to improve the gradient variance of the enhanced model set and avoid falling into a poor local optimum, so as to further improve the transferability of adversarial examples. Furthermore, experimental results demonstrate that our approaches are compatible with many existing transfer-based attacks and can effectively improve the transferability of gradient-based adversarial attacks on the ImageNet dataset. Also, our proposals have achieved higher attack success rates even if the target model adopts advanced defenses. Specifically, we have achieved an average attack success rate of 91.4% on the defense model, which is higher than other baseline approaches.},
  archive  = {J},
  author   = {Sensen Zhang and Haibo Hong and Mande Xie},
  doi      = {10.1109/TBDATA.2025.3533892},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2417-2430},
  title    = {Enhancing the transferability of adversarial examples with random diversity ensemble and variance reduction augmentation},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multiplex hypergraph attribute-based graph collaborative filtering for cold-start POI recommendation. <em>TBD</em>, <em>11</em>(5), 2401-2416. (<a href='https://doi.org/10.1109/TBDATA.2025.3533908'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Within the scope of location-based services and personalized recommendations, the challenges of recommending new and unvisited points of interest (POIs) to mobile users are compounded by the sparsity of check-in data. Traditional recommendation models often overlook user and POI attributes, which exacerbates data sparsity and cold-start problems. To address this issue, a novel multiplex hypergraph attribute-based graph collaborative filtering is proposed for POI recommendation to create a robust recommendation system capable of handling sparse data and cold-start scenarios. Specifically, a multiplex network hypergraph is first constructed to capture complex relationships between users, POIs, and attributes based on the similarities of attributes, visit frequencies, and preferences. Then, an adaptive variational graph auto-encoder adversarial network is developed to accurately infer the users’/POIs’ preference embeddings from their attribute distributions, which reflect complex attribute dependencies and latent structures within the data. Moreover, a dual graph neural network variant based on both Graphsage K-nearest neighbor networks and gated recurrent units are created to effectively capture various attributes of different modalities in a neighborhood, including temporal dependencies in user preferences and spatial attributes of POIs. Finally, experiments conducted on Foursquare and Yelp datasets reveal the superiority and robustness of the developed model compared to some typical state-of-the-art approaches and adequately illustrate the effectiveness of the issues with cold-start users and POIs.},
  archive  = {J},
  author   = {Simon Nandwa Anjiri and Derui Ding and Yan Song and Ying Sun},
  doi      = {10.1109/TBDATA.2025.3533908},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2401-2416},
  title    = {A multiplex hypergraph attribute-based graph collaborative filtering for cold-start POI recommendation},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SRGTNet: Subregion-guided transformer hash network for fine-grained image retrieval. <em>TBD</em>, <em>11</em>(5), 2388-2400. (<a href='https://doi.org/10.1109/TBDATA.2025.3533916'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Fine-grained image retrieval (FGIR) is a crucial task in computer vision, with broad applications in areas such as biodiversity monitoring, e-commerce, and medical diagnostics. However, capturing discriminative feature information to generate binary codes is difficult because of high intraclass variance and low interclass variance. To address this challenge, we (i) build a novel and highly reliable fine-grained deep hash learning framework for more accurate retrieval of fine-grained images. (ii) We propose a part significant region erasure method that forces the network to generate compact binary codes. (iii) We introduce a CNN-guided Transformer structure for use in fine-grained retrieval tasks to capture fine-grained images effectively in contextual feature relationships to mine more discriminative regional features. (iv) A multistage mixture loss is designed to optimize network training and enhance feature representation. Experiments were conducted on three publicly available fine-grained datasets. The results show that our method effectively improves the performance of fine-grained image retrieval.},
  archive  = {J},
  author   = {Hongchun Lu and Songlin He and Xue Li and Min Han and Chase Wu},
  doi      = {10.1109/TBDATA.2025.3533916},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2388-2400},
  title    = {SRGTNet: Subregion-guided transformer hash network for fine-grained image retrieval},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Anomaly detection in multi-level model space. <em>TBD</em>, <em>11</em>(5), 2376-2387. (<a href='https://doi.org/10.1109/TBDATA.2025.3534625'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Anomaly detection (AD) is gaining prominence, especially in situations with limited labeled data or unknown anomalies, demanding an efficient approach with minimal reliance on labeled data or prior knowledge. Building upon the framework of Learning in the Model Space (LMS), this paper proposes conducting AD through Learning in the Multi-Level Model Spaces (MLMS). LMS transforms the data from the data space to the model space by representing each data instance with a fitted model. In MLMS, to fully capture the dynamic characteristics within the data, multi-level details of the original data instance are decomposed. These details are individually fitted, resulting in a set of fitted models that capture the multi-level dynamic characteristics of the original instance. Representing each data instance with a set of fitted models, rather than a single one, transforms it from the data space into the multi-level model spaces. The pairwise difference measurement between model sets is introduced, fully considering the distance between fitted models and the intra-class aggregation of similar models at each level of detail. Subsequently, effective AD can be implemented in the multi-level model spaces, with or without sufficient multi-class labeled data. Experiments on multiple AD datasets demonstrate the effectiveness of the proposed method.},
  archive  = {J},
  author   = {Ao Chen and Xiren Zhou and Yizhan Fan and Huanhuan Chen},
  doi      = {10.1109/TBDATA.2025.3534625},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2376-2387},
  title    = {Anomaly detection in multi-level model space},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GCLNet: Generalized contrastive learning for weakly supervised temporal action localization. <em>TBD</em>, <em>11</em>(5), 2365-2375. (<a href='https://doi.org/10.1109/TBDATA.2025.3528727'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Weakly supervised temporal action localization (WTAL) aims to precisely locate action instances in given videos by video-level classification supervision, which is partly related to action classification. Most existing localization works directly utilize feature encoders pre-trained for video classification tasks to extract video features, resulting in non-targeted features that lead to incomplete or over-complete action localization. Therefore, we propose Generalized Contrast Learning Network (GCLNet), in which two novel strategies are proposed to improve the pre-trained features. First, to address the issue of over-completeness, GCLNet introduces text information with good context independence and category separability to enrich the expression of video features, as well as proposes a novel generalized contrastive learning approach for similarity metrics, which facilitates pulling closer the features belonging to the same category while pushing farther apart those from different categories. Consequently, it enables more compact intra-class feature learning and ensures accurate action localization. Second, to tackle the problem of incomplete, we exploit the respective advantages of RGB and Flow features in scene appearance and temporal motion expression, designing a hybrid attention strategy in GCLNet to enhance each channel features mutually. This process greatly improves the features through establishing cross-channel consensus. Finally, we conduct extensive experiments on THUMOS14 and ActivityNet1.2, respectively, and the results show that our proposed GCLNet can produce more representative action localization features.},
  archive  = {J},
  author   = {Jing Wang and Dehui Kong and Baocai Yin},
  doi      = {10.1109/TBDATA.2025.3528727},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2365-2375},
  title    = {GCLNet: Generalized contrastive learning for weakly supervised temporal action localization},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Emulating reader behaviors for fake news detection. <em>TBD</em>, <em>11</em>(5), 2353-2364. (<a href='https://doi.org/10.1109/TBDATA.2025.3527230'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The wide dissemination of fake news has affected our lives in many aspects, making fake news detection important and attracting increasing attention. Existing approaches make substantial contributions in this field by modeling news from a single-modal or multi-modal perspective. However, these modal-based methods can result in sub-optimal outcomes as they ignore reader behaviors in news consumption and authenticity verification. For instance, they haven't taken into consideration the component-by-component reading process: from the headline, images, comments, to the body, which is essential for modeling news with more granularity. To this end, we propose an approach of Emulating the behaviors of readers (Ember) for fake news detection on social media, incorporating readers’ reading and verificating process to model news from the component perspective thoroughly. Specifically, we first construct intra-component feature extractors to emulate the behaviors of semantic analyzing on each component. Then, we design a module that comprises inter-component feature extractors and a sequence-based aggregator. This module mimics the process of verifying the correlation between components and the overall reading and verification sequence. Thus, Ember can handle the news with various components by emulating corresponding sequences. We conduct extensive experiments on nine real-world datasets, and the results demonstrate the superiority of Ember.},
  archive  = {J},
  author   = {Junwei Yin and Min Gao and Kai Shu and Zehua Zhao and Yinqiu Huang and Jia Wang},
  doi      = {10.1109/TBDATA.2025.3527230},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2353-2364},
  title    = {Emulating reader behaviors for fake news detection},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generalized time series classification via component decomposition and alignment. <em>TBD</em>, <em>11</em>(5), 2338-2352. (<a href='https://doi.org/10.1109/TBDATA.2025.3527215'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The objective of domain generalization is to develop a model that can handle the domain shift problem without access to the target domain. In this paper, we propose a new domain generalization approach called Decomposition Framework with Dynamic Component Alignment (DFDCA), which employs signal decomposition on input data and conducts domain alignment on each component, providing another perspective on domain generalization for time series classification. Specifically, we first utilize a neural decomposition module to decompose the original time series data into several components, and design loss functions to guide the network to effectively perform signal decomposition for class-wise domain alignment on the decomposed components. The denoising attention mechanism is then introduced to enhance informative components while suppressing task-irrelevant components. Our proposed approach is evaluated on four publicly available datasets based on the cross-domain setting where the training and test samples are drawn from different distributions. The results demonstrate that it outperforms other baseline methods, achieving state-of-the-art performance.},
  archive  = {J},
  author   = {Yichuan Cheng and Darrick Lee and Harald Oberhauser and Haoliang Li},
  doi      = {10.1109/TBDATA.2025.3527215},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2338-2352},
  title    = {Generalized time series classification via component decomposition and alignment},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view heterogeneous HyperGNN for heterophilic knowledge combination prediction. <em>TBD</em>, <em>11</em>(5), 2321-2337. (<a href='https://doi.org/10.1109/TBDATA.2025.3527216'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Knowledge combination prediction involves analyzing current knowledge elements and their relationships, then forecasting how these elements, drawn from various fields, can be creatively combined to form new, innovative solutions. This process is critical for countries and businesses to understand future technology trends and promote innovation in an era of rapid scientific and technological advancement. Existing methods often overlook the integration of knowledge combinations from multiple views, along with their inherent heterophily and the dual “many-to-one” property, where a single knowledge combination can include multiple elements, and a single element may belong to various combinations. To this end, we propose a novel framework named Multi-view Heterogeneous HyperGNN for Heterophilic Knowledge Combination Prediction (H3KCP). Specifically, H3KCP first constructs a hypergraph reflecting the dual “many-to-one” property of knowledge combinations, where each hyperedge may contain several nodes and each node can also belong to multiple hyperedges. Next, the framework employs a multi-view fusion approach to model knowledge combinations, considering heterophily and integrating insights from co-occurrence, co-citation, and hierarchical structure-based views. Furthermore, our analysis of H3KCP from a spectral graph perspective offers insights into its rationality. Finally, extensive experiments on real-world patent datasets and the Open Academic Graph dataset validate the effectiveness and efficiency of our approach, yielding significant insights into knowledge combinations.},
  archive  = {J},
  author   = {Huijie Liu and Shulan Ruan and Han Wu and Zhenya Huang and Defu Lian and Qi Liu and Enhong Chen},
  doi      = {10.1109/TBDATA.2025.3527216},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2321-2337},
  title    = {Multi-view heterogeneous HyperGNN for heterophilic knowledge combination prediction},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Relational clustering-based parallel spaces construction and embedding for dynamic knowledge graph. <em>TBD</em>, <em>11</em>(5), 2308-2320. (<a href='https://doi.org/10.1109/TBDATA.2025.3527238'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {With the increasing amount of data in various domains, knowledge graphs (KGs) have become powerful tools for representing complex and heterogeneous information in a structured way, and for extracting valuable information from knowledge graphs through embedding techniques to support downstream tasks such as recommendation and Q&A systems. Knowledge graphs consist of triples that are continuously added as knowledge is updated. However, most existing embedding models are designed for static graphs, requiring the entire model to be retrained for each update, which is time-consuming. Existing global dynamic embedding models focus on exploiting the structural and relational information of the whole graph to achieve embedding quality, resulting in reduced dynamic efficiency. To address this problem, we propose a relational clustering-based parallel space model in which knowledge from different domains is embedded in different subspaces, allowing each subspace to focus on the data characteristics of a specific domain, thereby improving the quality of knowledge. Second, the new data only affects some subspaces but not the performance of other spaces, improving the model's adaptability to dynamics. Furthermore, we employ two incremental approaches based on the type of added data to improve the efficiency of dynamic embedding while ensuring that the added data preserves the characteristics of the parallel space. The experimental results show that the dynamic embedding efficiency of our model is improved by an average of 50.3% compared to the SOTA dynamic embedding model for the link prediction task. Particularly on FB15K, our model not only improves the efficiency by 41% but also increases the accuracy by 7.5%, demonstrating the accuracy and efficiency of our model.},
  archive  = {J},
  author   = {Yao Liu and Yongfei Zhang},
  doi      = {10.1109/TBDATA.2025.3527238},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2308-2320},
  title    = {Relational clustering-based parallel spaces construction and embedding for dynamic knowledge graph},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Portraying fine-grained tenant portrait for churn prediction using semi-supervised graph convolution and attention network. <em>TBD</em>, <em>11</em>(5), 2296-2307. (<a href='https://doi.org/10.1109/TBDATA.2025.3527200'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {With the widespread application of Big Data and intelligent information systems, the tenant has become the main form of most scenarios. As a data mining technique, the portrait has been widely used to provide targeted services. Therefore, we transfer the traditional user-driven portrait into tenant driven for churn prediction. To achieve it, this paper first proposes a three-layer architecture and defines the fine-grained features for creating portraits from the perspective of tenants. In a large-scale telecommunication industry dataset of 100,000 tenants, we construct the tenant portrait through the proposed framework, and analyze the influences of the defined features on churn possibility. Then, considering the information missing caused by privacy concerns, we come up with the CrossMatch, a portrait completion model based on semi-supervised and graph convolution, which combines the relation characteristics among tenants for recovering missing information. On this basis, we design the tenant churn prediction method based on a directed attention network. Moreover, we recover missing information on three public node datasets with CrossMatch, achieving around 1-2$\%$ improvement. We then apply the directed attention network for churn prediction and achieve an Accuracy of 75.06$\%$, Precision of 77.78$\%$, and F1-score of 71.43$\%$, which outperforms all the baselines.},
  archive  = {J},
  author   = {Zuodong Jin and Peng Qi and Muyan Yao and Dan Tao},
  doi      = {10.1109/TBDATA.2025.3527200},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2296-2307},
  title    = {Portraying fine-grained tenant portrait for churn prediction using semi-supervised graph convolution and attention network},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A data-centric $\ell$-diversity model for securely publishing personal data with enhanced utility. <em>TBD</em>, <em>11</em>(5), 2278-2295. (<a href='https://doi.org/10.1109/TBDATA.2024.3524832'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In this paper, we propose and implement a novel anonymization model, called data-centric $\ell$-diversity, to effectively safeguard the privacy of individuals with considerably enhanced utility in data publishing scenarios. Through experimental analysis of real-life datasets, we found that when the data quality is poor (e.g., distributions are uneven), most of the existing methods only anonymize some parts of the data (where distributions are balanced) and leave other parts unprocessed, which can lead to explicit privacy disclosures. Furthermore, they do not identify and repair problematic parts of the data before anonymization, and therefore, they are not secure from the threat of privacy breaches. To address these technical problems, in this paper, we implement an automated method that identifies vulnerabilities in the underlying data to be anonymized w.r.t. distribution, and that repairs them by injecting virtual samples of good quality. Later, we implement a data partitioning strategy that creates compact and diverse classes of size $k$, where $k$ is the privacy parameter. Finally, only shallow generalization (or no generalization) is applied to each class to minimally generalize the data, whereas existing methods overly distort data by not improving the quality beforehand, which can lead to poor utility in data-driven services. We conducted detailed experiments on four datasets to justify the performance of our model in realistic scenarios, and achieved promising results from the perspectives of boosted accuracy, privacy preservation, data utility enrichment, and reduced computing overheads. Compared with baseline methods, our model enhanced privacy preservation by 36.56% on three different metrics, and data utility was augmented with 18.65% less information loss and 14.37% greater accuracy. Lastly, our model, on average, has shown a 26.13% reduction in time overheads compared to the SOTA baseline methods.},
  archive  = {J},
  author   = {Abdul Majeed and Seong Oun Hwang},
  doi      = {10.1109/TBDATA.2024.3524832},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2278-2295},
  title    = {A data-centric $\ell$-diversity model for securely publishing personal data with enhanced utility},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FinLLMs: A framework for financial reasoning dataset generation with large language models. <em>TBD</em>, <em>11</em>(5), 2264-2277. (<a href='https://doi.org/10.1109/TBDATA.2024.3524083'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Large Language models (LLMs) usually rely on extensive training datasets. In the financial domain, creating numerical reasoning datasets that include a mix of tables and long text often involves substantial manual annotation expenses. To address the limited data resources and reduce the annotation cost, we introduce FinLLMs, a method for generating financial question-answering (QA) data based on common financial formulas using LLMs. First, we compile a list of common financial formulas and construct a graph based on the variables these formulas employ. We then augment the formula set by combining those that share identical variables as new elements. Specifically, we explore formulas obtained by manual annotation and merge those formulas with shared variables by traversing the constructed graph. Finally, utilizing LLMs, we generate financial QA data that encompasses both tabular information and long textual content, building on the collected formula set. Our experiments demonstrate that the synthetic data generated by FinLLMs effectively enhances the performance of various numerical reasoning models in the financial domain, including both pre-trained language models (PLMs) and fine-tuned LLMs. This performance surpasses that of two established benchmark financial QA datasets.},
  archive  = {J},
  author   = {Ziqiang Yuan and Kaiyuan Wang and Shoutai Zhu and Ye Yuan and Jingya Zhou and Yanlin Zhu and Wenqi Wei},
  doi      = {10.1109/TBDATA.2024.3524083},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2264-2277},
  title    = {FinLLMs: A framework for financial reasoning dataset generation with large language models},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Blockchain-empowered federated learning: Benefits, challenges, and solutions. <em>TBD</em>, <em>11</em>(5), 2244-2263. (<a href='https://doi.org/10.1109/TBDATA.2025.3541560'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Federated learning (FL) is a distributed machine learning approach that protects user data privacy by training models locally on clients and aggregating them on a parameter server. While effective at preserving privacy, FL systems face limitations such as single points of failure, lack of incentives, and inadequate security. To address these challenges, blockchain technology is integrated into FL systems to provide stronger security, fairness, and scalability. However, blockchain-empowered FL (BC-FL) systems introduce additional demands on network, computing, and storage resources. This survey provides a comprehensive review of recent research on BC-FL systems, analyzing the benefits and challenges associated with blockchain integration. We explore why blockchain is applicable to FL, how it can be implemented, and the challenges and existing solutions for its integration. Additionally, we offer insights on future research directions for the BC-FL system.},
  archive  = {J},
  author   = {Zeju Cai and Jianguo Chen and Yuting Fan and Zibin Zheng and Keqin Li},
  doi      = {10.1109/TBDATA.2025.3541560},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2244-2263},
  title    = {Blockchain-empowered federated learning: Benefits, challenges, and solutions},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Digital twin data management: A comprehensive review. <em>TBD</em>, <em>11</em>(5), 2224-2243. (<a href='https://doi.org/10.1109/TBDATA.2025.3533891'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Digital Twins are virtual representations of physical assets and systems that rely on effective Data Management to integrate, process, and analyze diverse data sources. This article comprehensively examines Data Management challenges, architectures, techniques, and applications in the context of Digital Twins. It explores key issues such as data heterogeneity, quality assurance, scalability, security, and interoperability. The paper outlines architectural approaches like centralized, distributed, cloud-based, and blockchain solutions and Data Management techniques for modeling, integration, fusion, quality management, and visualization. Domain-specific considerations across manufacturing, smart cities, healthcare, and other sectors are discussed. Finally, open research challenges related to standards, real-time data processing, intelligent Data Management, and ethical aspects are highlighted. By synthesizing the state-of-the-art, this review serves as a valuable reference for developing robust Data Management strategies that enable Digital Twin deployments.},
  archive  = {J},
  author   = {Ezekiel B. Ouedraogo and Ammar Hawbani and Xingfu Wang and Zhi Liu and Liang Zhao and Mohammed A. A. Al-qaness and Saeed Hamood Alsamhi},
  doi      = {10.1109/TBDATA.2025.3533891},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2224-2243},
  title    = {Digital twin data management: A comprehensive review},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid self-supervised learning framework for vertical federated learning. <em>TBD</em>, <em>11</em>(5), 2210-2223. (<a href='https://doi.org/10.1109/TBDATA.2024.3403386'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Vertical federated learning (VFL), a variant of Federated Learning (FL), has recently drawn increasing attention as the VFL matches the enterprises’ demands of leveraging more valuable features to achieve better model performance. However, conventional VFL methods may run into data deficiency as they exploit only aligned and labeled samples (belonging to different parties), leaving often the majority of unaligned and unlabeled samples unused. The data deficiency hampers the effort of the federation. In this work, we propose a Federated Hybrid Self-Supervised Learning framework, named FedHSSL, that utilizes cross-party views (i.e., dispersed features) of samples aligned among parties and local views (i.e., data augmentation) of unaligned samples within each party to improve the representation learning capability of the VFL joint model. FedHSSL further exploits invariant features across parties to boost the performance of the joint model through partial model aggregation. FedHSSL, as a framework, can work with various representative SSL methods. We empirically demonstrate that FedHSSL methods outperform baselines by large margins. We provide an in-depth analysis of FedHSSL regarding label leakage, which is rarely investigated in existing self-supervised VFL works. The experimental results show that, with proper protection, FedHSSL achieves the best privacy-utility trade-off against the state-of-the-art label inference attack compared with baselines.},
  archive  = {J},
  author   = {Yuanqin He and Yan Kang and Xinyuan Zhao and Jiahuan Luo and Lixin Fan and Yuxing Han and Qiang Yang},
  doi      = {10.1109/TBDATA.2024.3403386},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2210-2223},
  title    = {A hybrid self-supervised learning framework for vertical federated learning},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards fair and scalable trial assignment in federated bandits: A shapley value approach. <em>TBD</em>, <em>11</em>(5), 2195-2209. (<a href='https://doi.org/10.1109/TBDATA.2024.3403369'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Federated multi-armed bandits extend the multi-armed bandits framework to the federated learning setting where multiple clients in the same exploration space collaboratively identify the optimal arm. While previous studies demonstrated its efficiency like classical federated learning, in this paper, we present the first work that reveals the serious fairness problem in federated multi-armed bandits when clients have heterogeneous and overlapping armsets. The fairness problem happens because clients with different trial requirements should conduct different numbers of trials summing up to a global requirement, but they wish to minimize their exploration effort. To address the novel fairness concern, we formally formulate the fairness-aware trial assignment as a coalitional game. Based on the theoretically derived trial requirements, we devise a Shapley value-based trial assignment mechanism to guarantee fairness. Regardless of the #P-hard complexity when deriving the general Shapley value, we achieve an accurate computation of trial assignment with polynomial complexity by exploiting its unique characteristic. We further carefully control the numbers of trials in each iteration to resolve the communication bottleneck and minimize the wasted trials. Experiment results show that, compared to the naïve federated scheme, our design outperforms with both high fairness metrics and high efficiency in total trials and communication.},
  archive  = {J},
  author   = {Zibo Wang and Yifei Zhu and Dan Wang and Zhu Han},
  doi      = {10.1109/TBDATA.2024.3403369},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2195-2209},
  title    = {Towards fair and scalable trial assignment in federated bandits: A shapley value approach},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Personalized federated learning with contrastive momentum. <em>TBD</em>, <em>11</em>(5), 2184-2194. (<a href='https://doi.org/10.1109/TBDATA.2024.3403387'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In this paper, we propose pFedMo, a personalized federated learning algorithm with contrastive momentum. In pFedMo, we design a score function to personalize worker models by distilling knowledge from the aggregator's representation model so as to address the non-i.i.d. issue. To accelerate the convergence, we leverage the momentum acceleration on both the worker side and the aggregator side. However, the typical momentum without personalization does not suit well for the worker models with personalization, influencing convergence performance. To address this, we develop a personalized/contrastive momentum method for efficient momentum acceleration. We provide mathematical proof for the convergence of pFedMo on non-i.i.d. data. Extensive experiments based on real-world datasets and IoT system are conducted, verifying that pFedMo outperforms existing mainstream benchmarks, and achieves up to 35.90% accuracy increase and 3.64x training time speedup under a wide range of settings.},
  archive  = {J},
  author   = {Sen Fu and Zhengjie Yang and Chuang Hu and Wei Bao},
  doi      = {10.1109/TBDATA.2024.3403387},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2184-2194},
  title    = {Personalized federated learning with contrastive momentum},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heterogeneous device collaboration based federated learning for big data applications. <em>TBD</em>, <em>11</em>(5), 2174-2183. (<a href='https://doi.org/10.1109/TBDATA.2024.3404104'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In the era of Big Data, artificial intelligence and information science are the key technologies to extract the value of data and enhance the competitiveness of enterprises. The characteristics of distributed, small-scale, and sparse lead to the isolated data island problem. To solve these problems, Federated Learning is proposed. However, a large number of terminal models need to be uploaded to the server in Federated Learning, especially for the actual scenario of Internet of Things. Therefore, huge communication costs are required which dramatically increases the pressure on the backbone network. Furthermore, the low quality of the local model will lead to decreased accuracy and convergence rates of the model. To overcome the above limitations, we propose heterogeneous device collaboration based federated learning (HDCFL), which constructs a three-layer structure for Federated Learning by leveraging edge computing and designs a heterogeneous device collaboration method that groups the terminals based on their computing power, communication time, and data volume to train the model. Then, we conduct a theoretical analysis of the proposed algorithm which verifies its advantage. At last, the experimental result demonstrates that the proposed algorithm consistently achieves superior performance in terms of both convergence speed and accuracy compared with state-of-the-art baselines.},
  archive  = {J},
  author   = {Wenhua Wang and Quan Yang and Yuzhu Liang and Yang Xu and Qin Liu and Tian Wang},
  doi      = {10.1109/TBDATA.2024.3404104},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2174-2183},
  title    = {Heterogeneous device collaboration based federated learning for big data applications},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Harnessing the power of local supervision in federated learning. <em>TBD</em>, <em>11</em>(5), 2162-2173. (<a href='https://doi.org/10.1109/TBDATA.2024.3403383'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Federated learning is widely accepted as a privacy-preserving paradigm for training a shared global model across multiple client devices in a collaborative fashion. However, in practice, the significantly limited computational power on client devices has been a major barrier when we wish to train large models with potentially hundreds of millions of parameters. In this paper, we propose a new architecture, referred to as Infocomm, that incorporates locally supervised learning in federated learning. With locally supervised learning, the disadvantages of split learning can be avoided by using a more flexible way to offload training from resource constrained clients to a more capable server. Infocomm enables parallel training of different modules of the neural network in both the server and clients in a gradient-isolated fashion. The efficacy in reducing both training time and communication time is supported by our theoretical analysis and empirical results. In the scenario involving larger models and fewer available local data, Infocomm has been observed to reduce the elapsed time per round by over 37% without sacrificing accuracy compared to both conventional federated learning or directly combining federated learning and split learning, which showcases the advantages of Infocomm under power-constrained IoT scenarios.},
  archive  = {J},
  author   = {Fei Wang and Baochun Li},
  doi      = {10.1109/TBDATA.2024.3403383},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2162-2173},
  title    = {Harnessing the power of local supervision in federated learning},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Accelerating blockchain-enabled federated learning with clustered clients. <em>TBD</em>, <em>11</em>(5), 2148-2161. (<a href='https://doi.org/10.1109/TBDATA.2024.3403390'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {With the rapid development of Big Data, Federated learning (FL) has found numerous applications, enabling machine learning (ML) on edge devices while preserving privacy. However, FL still faces crucial challenges, such as single point of failure and poisoning attacks, which motivate the integration of blockchain-enabled FL (BeFL). Beyond that, the efficiency issue still limits the further application of BeFL. To address these issues, we propose a novel decentralized framework: Accelerating Blockchain-Enabled Federated Learning with Clustered Clients (ABFLCC), who utilize actual training time for clustering clients to achieve hierarchical FL and solve the single point of failure problem through blockchain. Additionally, the framework clusters edge devices considering their actual training times, which allows for synchronous FL within clusters and asynchronous FL across clusters simultaneously. This approach guarantees that devices with a similar training time have a consistent global model version, improving the stability of the converging process, while the asynchronous learning between clusters enhances the efficiency of convergence. The proposed framework is evaluated through simulations on three real-world public datasets, demonstrating a training efficiency improvement of 30% to 70% in terms of convergence time compared to existing BeFL systems.},
  archive  = {J},
  author   = {Laizhong Cui and Yinghao Li and Yipeng Zhou and Youyang Qu and Jiangchuan Liu},
  doi      = {10.1109/TBDATA.2024.3403390},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2148-2161},
  title    = {Accelerating blockchain-enabled federated learning with clustered clients},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MemDefense: Defending against membership inference attacks in IoT-based federated learning via pruning perturbations. <em>TBD</em>, <em>11</em>(5), 2135-2147. (<a href='https://doi.org/10.1109/TBDATA.2024.3403388'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Depending on large-scale devices, the Internet of Things (IoT) provides massive data support for resource sharing and intelligent decision, but privacy risks also increase. As a popular distributed learning framework, Federated Learning (FL) is widely used because it does not need to share raw data while only parameters to collaboratively train models. However, Federated Learning is not spared by some emerging attacks, e.g., membership inference attack. Therefore, for IoT devices with limited resources, it is challenging to design a defense scheme against the membership inference attack ensuring high model utility, strong membership privacy and acceptable time efficiency. In this article, we propose MemDefense, a lightweight defense mechanism to prevent membership inference attack from local models and global models in IoT-based FL, while maintaining high model utility. MemDefense adds crafted pruning perturbations to local models at each round of FL by deploying two key components, i.e., parameter filter and noise generator. Specifically, the parameter filter selects the apposite model parameters which have little impact on the model test accuracy and contribute more to member inference attacks. Then, the noise generator is used to find the pruning noise that can reduce the attack accuracy while keeping high model accuracy, protecting each participant's membership privacy. We comprehensively evaluate MemDefense with different deep learning models and multiple benchmark datasets. The experimental results show that low-cost MemDefense drastically reduces the attack accuracy within limited drop of classification accuracy, meeting the requirements for model utility, membership privacy and time efficiency.},
  archive  = {J},
  author   = {Meng Shen and Jin Meng and Ke Xu and Shui Yu and Liehuang Zhu},
  doi      = {10.1109/TBDATA.2024.3403388},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2135-2147},
  title    = {MemDefense: Defending against membership inference attacks in IoT-based federated learning via pruning perturbations},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cepe-FL: Communication-efficient and privacy-enhanced federated learning via adaptive compressive sensing. <em>TBD</em>, <em>11</em>(5), 2119-2134. (<a href='https://doi.org/10.1109/TBDATA.2024.3403393'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Model updates are exchanged between server(s) and participants in Federated Learning (FL), which can result in excessive delay, especially for large models. Existing communication-efficient FL approaches such as quantization and top-k sampling apply compression to gradients assuming that gradients are sparse and can tolerate small deviations. This can hardly be applied to down-link transmission. In this work, we employ compressive sensing on model parameters instead of gradients and propose a two-way adaptive compression scheme, Cepe-FL, which exploits dictionary learning to project non-sparse model parameters into sparse representations to ensure reconstruction accuracy. Cepe-FL supports joint model reconstruction with drastic reduction in computational complexity from $O(n)$ to $O(1)$. Cepe-FL adjusts the compression ratio adaptively according to the training loss, achieving the best trade-off between communication and model precision. Furthermore, it demonstrates efficacy in defending against membership inference attacks since only compressed models are exchanged. We conduct extensive experiments on three image classification tasks and compare with three communication-efficient approaches including FedPAQ, FedAvg and T-FedAvg. Cepe-FL presents the best performance in all tasks under IID and non-IID scenarios. We also implement white-box membership inference attacks, and the results show Cepe-FL can significantly suppress success ratio of inference in comparison with other approaches.},
  archive  = {J},
  author   = {Ye Liu and Shan Chang and Yiqi Liu},
  doi      = {10.1109/TBDATA.2024.3403393},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2119-2134},
  title    = {Cepe-FL: Communication-efficient and privacy-enhanced federated learning via adaptive compressive sensing},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FRACTAL: Data-aware clustering and communication optimization for decentralized federated learning. <em>TBD</em>, <em>11</em>(5), 2102-2118. (<a href='https://doi.org/10.1109/TBDATA.2024.3403381'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Decentralized federated learning (DFL) is a promising technique to enable distributed machine learning over edge nodes without relying on a centralized parameter server. However, existing DFL network topologies, such as fully connected, partially connected, or lower-tier hierarchical topology often struggle to effectively address the unique challenges presented by edge networks, including edge heterogeneity, communication resource constraint, and data Non-IID. In order to tackle these challenges, we propose a data-aware clustering algorithm, called FRACTAL, to construct a multi-tier hierarchical topology in a bottom-up manner taking into consideration both data distribution and communication efficiency for DFL. We theoretically explore the quantitative relationship between the convergence bound of multi-tier FL and the data distribution among each-tier servers. To further improve communication efficiency and address edge heterogeneity, we deploy a time-sharing communication scheduling algorithm within each fractal unit (the basic structure in FRACTAL consisting of multiple nodes and an aggregator), called magic mirror method (MMM), to determine the optimal order of model distributing and uploading for nodes. We conduct extensive experiments on the classical models and datasets to evaluate the performance of FRACTAL, and the results show that FRACTAL can significantly accelerate the DFL model training by 48.6%–72.3% compared with the state-of-the-art solutions.},
  archive  = {J},
  author   = {Qianpiao Ma and Jianchun Liu and Hongli Xu and Qingmin Jia and Renchao Xie},
  doi      = {10.1109/TBDATA.2024.3403381},
  journal  = {IEEE Transactions on Big Data},
  month    = {10},
  number   = {5},
  pages    = {2102-2118},
  title    = {FRACTAL: Data-aware clustering and communication optimization for decentralized federated learning},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Guest editorial special issue on federated learning for big data applications. <em>TBD</em>, <em>11</em>(5), 2099-2101. (<a href='https://doi.org/10.1109/TBDATA.2024.3417057'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Xiaowen Chu and Wei Wang and Cong Wang and Yang Liu and Rongfei Zeng and Christopher G. Brinton},
  doi     = {10.1109/TBDATA.2024.3417057},
  journal = {IEEE Transactions on Big Data},
  month   = {10},
  number  = {5},
  pages   = {2099-2101},
  title   = {Guest editorial special issue on federated learning for big data applications},
  volume  = {11},
  year    = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
