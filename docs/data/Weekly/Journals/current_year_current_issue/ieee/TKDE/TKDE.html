<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TKDE</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tkde">TKDE - 33</h2>
<ul>
<li><details>
<summary>
(2025). Toward effective and transferable detection for multi-modal fake news in the social media stream. <em>TKDE</em>, <em>37</em>(11), 6723-6737. (<a href='https://doi.org/10.1109/TKDE.2025.3609045'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid proliferation of multimedia fake news on social media has raised significant concerns in recent years. Existing studies on fake news detection predominantly adopt an instance-based paradigm, where the detector evaluates a single post to determine its veracity. Despite notable advancements achieved in this domain, we argue that the instance-based approach is misaligned with real-world deployment scenarios. In practice, detectors typically operate on servers that process incoming posts in temporal order, striving to assess their authenticity promptly. Instance-based detectors lack awareness of temporal information and contextual relationships between surrounding posts, therefore fail to capture long-range dependencies from the timeline. To bridge this gap, we introduce a more practical stream-based multi-modal fake news detection paradigm, which assumes that social media posts arrive continuously over time and allows the utilization of previously seen posts to aid in the classification of incoming ones. To enable effective and transferable fake news detection under this novel paradigm, we propose maintaining historical knowledge as a collection of incremental high-level forgery patterns. Based on this principle, we design a novel framework called Incremental Forgery Pattern Learning and Clues Refinement (IPLCR). IPLCR incrementally learns high-level forgery patterns as the stream evolves, leveraging this knowledge to improve the detection of newly arrived posts. At the core of IPLCR is the Incremental Forgery Pattern Bank (IPB), which dynamically summarizes historical posts into a set of latent forgery patterns. IPB is designed to continuously incorporate timely knowledge and actively discard obsolete information, even during inference. When a new post arrives, IPLCR retrieves the most relevant forgery pattern knowledge from IPB and refines the clues for fake news detection. The refined clues are subsequently incorporated into IPB to enrich its knowledge base. Extensive experiments validate IPLCRâ€™s effectiveness as a robust stream-based detector. Moreover, IPLCR addresses several critical issues relevant to industrial applications, including seamless context transfer and efficient model upgrading, making it a practical solution for real-world deployment.},
  archive      = {J_TKDE},
  author       = {Jingyi Xie and Jiawei Liu and Zheng-jun Zha},
  doi          = {10.1109/TKDE.2025.3609045},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {11},
  number       = {11},
  pages        = {6723-6737},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Toward effective and transferable detection for multi-modal fake news in the social media stream},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TensorMon: A breakthrough in sparse data gathering leveraging tensor-enhanced techniques for system and network monitoring. <em>TKDE</em>, <em>37</em>(11), 6708-6722. (<a href='https://doi.org/10.1109/TKDE.2025.3601198'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse data gathering has become a promising solution for reducing measurement costs by leveraging the inherent sparsity of data. However, most existing approaches rely on low-dimensional models such as compressive sensing or matrix completion, which are limited in capturing complex high-dimensional structures. To overcome these limitations, we propose TensorMon, a novel tensor-based sparse data gathering framework that introduces a cuboid sampling strategy to more effectively exploit multidimensional correlations. Unlike traditional entry-based or tube-based sampling, TensorMon introduces the innovative concept of cuboid sampling. We further develop a lightweight sampling scheduling algorithm and a non-iterative inference algorithm to ensure efficient measurement planning and accurate reconstruction of unmeasured data. Theoretical analysis establishes a new performance bound for our sampling strategy, which is significantly lower than those in existing literature. To validate our theoretical findings, we conduct extensive experiments on four real-world datasets: two network monitoring datasets, a city-scale crowd flow dataset, and a road traffic speed dataset. Experimental results demonstrate that TensorMon achieves substantial reductions in measurement cost, delivers high inference accuracy, and ensures rapid data recovery, highlighting its effectiveness and practicality across diverse application scenarios.},
  archive      = {J_TKDE},
  author       = {Jiazheng Tian and Kun Xie and Xin Wang and Jigang Wen and Gaogang Xie and Wei Liang and Dafang Zhang and Kenli Li},
  doi          = {10.1109/TKDE.2025.3601198},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {11},
  number       = {11},
  pages        = {6708-6722},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {TensorMon: A breakthrough in sparse data gathering leveraging tensor-enhanced techniques for system and network monitoring},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Similarity and dissimilarity guided co-association matrix construction for ensemble clustering. <em>TKDE</em>, <em>37</em>(11), 6694-6707. (<a href='https://doi.org/10.1109/TKDE.2025.3608721'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensemble clustering aggregates multiple weak clusterings to achieve a more accurate and robust consensus result. The Co-Association matrix (CA matrix) based method is the mainstream ensemble clustering approach that constructs the similarity relationships between sample pairs according the weak clustering partitions to generate the final clustering result. However, the existing methods neglect that the quality of cluster is related to its size, i.e., a cluster with smaller size tends to higher accuracy. Moreover, they also do not consider the valuable dissimilarity information in the base clusterings which can reflect the varying importance of sample pairs that are completely disconnected. To this end, we propose the Similarity and Dissimilarity Guided Co-association matrix (SDGCA) to achieve ensemble clustering. First, we introduce normalized ensemble entropy to estimate the quality of each cluster, and construct a similarity matrix based on this estimation. Then, we employ the random walk to explore high-order proximity of base clusterings to construct a dissimilarity matrix. Finally, the adversarial relationship between the similarity matrix and the dissimilarity matrix is utilized to construct a promoted CA matrix for ensemble clustering. We compared our method with 13 state-of-the-art methods across 12 datasets, and the results demonstrated the superior clustering ability and robustness of the proposed approach.},
  archive      = {J_TKDE},
  author       = {Xu Zhang and Yuheng Jia and Mofei Song and Ran Wang},
  doi          = {10.1109/TKDE.2025.3608721},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {11},
  number       = {11},
  pages        = {6694-6707},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Similarity and dissimilarity guided co-association matrix construction for ensemble clustering},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semi-supervised short text stream classification based on drift-aware incremental deep learning. <em>TKDE</em>, <em>37</em>(11), 6680-6693. (<a href='https://doi.org/10.1109/TKDE.2025.3605389'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world applications have produced massive short text streams. Contrary to the traditional normal texts, they present the characteristics such as short length, only having few labeled data, high-velocity, high-volume and dynamic data distributions, which deteriorate the issues of data sparseness, label missing and concept drift. Obviously, it is a huge challenge for existing short text (stream) classification algorithms due to the poor effectiveness, where they always assume all short texts are completely labeled and little attention is paid on the concept drift issue hidden in short text streams. Therefore, we propose a novel semi-supervised short text steam classification method based on the drift-aware incremental deep learning ensemble model. Specifically, with the sliding window mechanism, we first fuse three types of statistical, semantic and structure information to solve the data sparseness issue. Second, a semi-supervised incremental deep learning ensemble model based on GCN and the refined LSTM is developed to adapt to the high-volume, high-velocity and label missing short text streams. Third, a label-probability distribution based concept drift detector is introduced to distinguish concept drifts. Finally, as compared with eleven well-known classification methods, extensive experiments demonstrate the effectiveness of the proposed method in the handling of short text streams with limited labeled data.},
  archive      = {J_TKDE},
  author       = {Peipei Li and Shiying Yu and Jiajun Li and Xuegang Hu},
  doi          = {10.1109/TKDE.2025.3605389},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {11},
  number       = {11},
  pages        = {6680-6693},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Semi-supervised short text stream classification based on drift-aware incremental deep learning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Score-based generative diffusion models for social recommendations. <em>TKDE</em>, <em>37</em>(11), 6666-6679. (<a href='https://doi.org/10.1109/TKDE.2025.3600103'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the prevalence of social networks on online platforms, social recommendation has become a vital technique for enhancing personalized recommendations. The effectiveness of social recommendations largely relies on the social homophily assumption, which presumes that individuals with social connections often share similar preferences. However, this foundational premise has been recently challenged due to the inherent complexity and noise present in real-world social networks. In this paper, we tackle the low social homophily challenge from an innovative generative perspective, directly generating optimal user social representations that maximize consistency with collaborative signals. Specifically, we propose the Score-based Generative Model for Social Recommendation (SGSR), which effectively adapts the Stochastic Differential Equation (SDE)-based diffusion models for social recommendations. To better fit the recommendation context, SGSR employs a joint curriculum training strategy to mitigate challenges related to missing supervision signals and leverages self-supervised learning techniques to align knowledge across social and collaborative domains. Extensive experiments on real-world datasets demonstrate the effectiveness of our approach in filtering redundant social information and improving recommendation performance.},
  archive      = {J_TKDE},
  author       = {Chengyi Liu and Jiahao Zhang and Shijie Wang and Wenqi Fan and Qing Li},
  doi          = {10.1109/TKDE.2025.3600103},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {11},
  number       = {11},
  pages        = {6666-6679},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Score-based generative diffusion models for social recommendations},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SAQE: Complex logical query answering via semantic-aware representation learning. <em>TKDE</em>, <em>37</em>(11), 6651-6665. (<a href='https://doi.org/10.1109/TKDE.2025.3603877'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Performing complex First-Order Logic (FOL) queries on knowledge graphs is crucial for advancing knowledge reasoning. Knowledge graphs encapsulate rich semantic interactions among entities, encompassing both explicit structural knowledge represented by triples $(e_{1}, r, e_{2})$ and implicit relational knowledge through multi-hop paths $(e_{1} \stackrel{r_{1}}{\rightarrow } \cdots e_{3} \cdots \stackrel{r_{2}}{\rightarrow } e_{2})$. Traditional models often focus solely on either triple-level or path-level knowledge, overlooking the benefits of integrating both to enhance logic query answering. This oversight leads to suboptimal representation learning and inefficient query reasoning. To overcome these challenges, we introduce a new Semantic-Aware representation learning model for Query-answering Embeddings (SAQE). Specifically, SAQE employs a joint learning approach that integrates triple-level and path-level knowledge semantics and captures both explicit and implicit contextual nuances within the knowledge graph, yielding more accurate and contextually relevant representations. To efficiently handle the large combinatorial search spaces in FOL reasoning, we propose a novel hierarchical reasoning optimization strategy by a multi-hop tree thus optimizing subqueries rooted at variable nodes in a divide-and-conquer manner. Theoretical analysis confirms that SAQE effectively supports various types of FOL reasoning and enhances generalizations for query answering. Extensive experiments demonstrate that our model achieves state-of-the-art performance across several established datasets.},
  archive      = {J_TKDE},
  author       = {Zongsheng Cao and Qianqian Xu and Zhiyong Yang and Yuan He and Xiaochun Cao and Qingming Huang},
  doi          = {10.1109/TKDE.2025.3603877},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {11},
  number       = {11},
  pages        = {6651-6665},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {SAQE: Complex logical query answering via semantic-aware representation learning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SandwichSketch: A more accurate sketch for frequent object mining in data streams. <em>TKDE</em>, <em>37</em>(11), 6636-6650. (<a href='https://doi.org/10.1109/TKDE.2025.3607691'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Frequent object mining has gained considerable interest in the research community and can be split into frequent item mining and frequent set mining depending on the type of object. While existing sketch-based algorithms have made significant progress in addressing these two tasks concurrently, they also possess notable limitations. They either support only software platforms with low throughput or compromise accuracy for faster processing speed and better hardware compatibility. In this paper, we make a substantial stride towards supporting frequent object mining by designing SandwichSketch, which draws inspiration from sandwich making and proposes two techniques including the double fidelity enhancement and hierarchical hot locking to guarantee high fidelity on both two tasks. We implement SandwichSketch on three platforms (CPU, Redis, and FPGA) and show that it enhances accuracy by $38.4\times$ and $5\times$ for two tasks on three real-world datasets, respectively. Additionally, it supports a distributed measurement scenario with less than a 0.01% decrease in Average Relative Error (ARE) when the number of nodes increases from 1 to 16.},
  archive      = {J_TKDE},
  author       = {Zhuochen Fan and Ruixin Wang and Zihan Jiang and Ruwen Zhang and Tong Yang and Sha Wang and Yuhan Wu and Ruijie Miao and Kaicheng Yang and Bui Cui},
  doi          = {10.1109/TKDE.2025.3607691},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {11},
  number       = {11},
  pages        = {6636-6650},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {SandwichSketch: A more accurate sketch for frequent object mining in data streams},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RexUniNLU: Recursive method with explicit schema instructor for universal natural language understanding. <em>TKDE</em>, <em>37</em>(11), 6624-6635. (<a href='https://doi.org/10.1109/TKDE.2025.3595143'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information Extraction (IE) and Text Classification (CLS) serve as the fundamental pillars of NLU, with both disciplines relying on analyzing input sequences to categorize outputs into pre-established schemas. However, there is no existing encoder-based model that can unify IE and CLS tasks from this perspective. To fully explore the foundation shared within NLU tasks, we have proposed a recursive method with explicit schema instructor for universal NLU. Specifically, we first redefine the true universal information extraction (UIE) with a formal formulation that covers almost all extraction schemas, including quadruples and quintuples which remain unsolved for previous UIE models. Then, we expands the formulation to all CLS and multi-modal NLU tasks. Based on that, we introduce RexUniNLU, an universal NLU solution that employs explicit schema constraints for IE and CLS, which encompasses all IE and CLS tasks and prevent incorrect connections between schema and input sequence. To avoid interference between different schemas, we reset the position ids and attention mask matrices. Extensive experiments are conducted on IE, CLS in both English and Chinese, and multi-modality, revealing the effectiveness and superiority.},
  archive      = {J_TKDE},
  author       = {Chengyuan Liu and Shihang Wang and Yangyang Kang and Fubang Zhao and Kun Kuang and Weiming Lu and Changlong Sun and Fei Wu},
  doi          = {10.1109/TKDE.2025.3595143},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {11},
  number       = {11},
  pages        = {6624-6635},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {RexUniNLU: Recursive method with explicit schema instructor for universal natural language understanding},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rethinking oversampling with class alliance constraints from data complexity perspective. <em>TKDE</em>, <em>37</em>(11), 6610-6623. (<a href='https://doi.org/10.1109/TKDE.2025.3606036'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class overlap is a major factor of data complexity that hampers classifier performance, particularly in imbalanced learning scenarios. Most existing oversampling methods rely on conservative seed sample selection and decoupled synthesis strategies, which limit sample diversity and fail to effectively control overlap risk. This paper proposes a novel oversampling framework called TMACO (Class Alliance-Constrained Oversampling), which integrates data complexity considerations into both seed selection and sample generation. First, TMACO selects seed sample units using a class alliance constraint that jointly considers spatial geometry and class distribution to enhance diversity and representativeness. Second, it generates synthetic samples based on three-point units to ensure regional stability. Third, a region-level filtering mechanism is applied to prevent synthetic samples from intruding into majority class areas. Extensive experiments on benchmark and real-world datasets demonstrate that TMACO consistently improves minority class performance and overall classification accuracy compared to state-of-the-art oversampling techniques. The proposed method also offers interpretable parameter control and adapts well to varying task objectives.},
  archive      = {J_TKDE},
  author       = {Mingming Han and Husheng Guo and Gaoxia Jiang and Wenjian Wang},
  doi          = {10.1109/TKDE.2025.3606036},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {11},
  number       = {11},
  pages        = {6610-6623},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Rethinking oversampling with class alliance constraints from data complexity perspective},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PRIME: A phishing detection framework with quantitative and fuzzy-based dual validation. <em>TKDE</em>, <em>37</em>(11), 6597-6609. (<a href='https://doi.org/10.1109/TKDE.2025.3609320'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Phishing attacks continue to pose a significant cybersecurity threat, especially as social engineering (SE) tactics become more contextually embedded and difficult to detect. To address the limitations of traditional rule-based framework and AI-driven classifiers, we propose PRIME, a phishing email evaluation framework that leverages large language models (LLMs) to assess manipulative intent across six interpretable criteria. Three risk scoring strategies, namely equal weighting, semantically weighted scoring, and fuzzy logic-based classification, are applied to aggregate the criterion scores into multi-level risk assessments. Qualitative comparisons with established frameworks demonstrate PRIMEâ€™s broad coverage and conceptual soundness. Quantitative experiments validate its effectiveness, with the fuzzy-based method achieving perfect recall on a phishing-only dataset and consistent performance across multiple years. An ablation study, where each criterion is removed in turn, highlights the critical role of the Context and Content dimension in detecting both explicit and subtle SE cues. By separating LLMs interpretation from final decision-making, PRIME enhances transparency, robustness, and adaptability in phishing detection systems.},
  archive      = {J_TKDE},
  author       = {Yicun Tian and Youyang Qu and Ming Ding and Shigang Liu and Pei-Wei Tsai and Jun Zhang},
  doi          = {10.1109/TKDE.2025.3609320},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {11},
  number       = {11},
  pages        = {6597-6609},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {PRIME: A phishing detection framework with quantitative and fuzzy-based dual validation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Personalized review summarization by using graph-based retrieval augmemted generation. <em>TKDE</em>, <em>37</em>(11), 6582-6596. (<a href='https://doi.org/10.1109/TKDE.2025.3605824'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Review summarization aims to provide a summary that covers the main aspect of the product review and reflects personal preference. Existing methods employ the historical reviews of customer and product to provide useful clues for the target summary generation. However, most of the existing methods indiscriminately model the historical reviews of customer and product. Since the historical customer reviews provide the personal information while the historical product reviews provide the commonly focused aspect of the product, these two types of heterogeneous information should be separately modeled. Moreover, the review rating of the historical reviews can be seen as a high-level abstraction of the customer preference and product which have been ignored by most of the existing methods. In this paper, we propose the Heterogeneous Historical Review aware Review Summarization (HHRRS) which separately models the two types of historical reviews with the rating information by a graph reasoning module with a contrastive loss. We employ a multi-task paradigm that conducts the review sentiment classification and summarization jointly. And we also propose a novel Graph Retrieval Augmemted Review Summarization (GRARS) to model the two types of heterogeneous information in a fine-grained manner. We conduct extensive experiments on four benchmark datasets, and demonstrate the superiority of HHRRS on both tasks.},
  archive      = {J_TKDE},
  author       = {Shuo Shang and Xin Cheng and Yiren Xiong and Feng Guo and Shen Gao and Xiuying Chen and Feng Wang and Yongbo Wang and Dongyan Zhao and Rui Yan},
  doi          = {10.1109/TKDE.2025.3605824},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {11},
  number       = {11},
  pages        = {6582-6596},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Personalized review summarization by using graph-based retrieval augmemted generation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Personalized recommendation models in federated settings: A survey. <em>TKDE</em>, <em>37</em>(11), 6562-6581. (<a href='https://doi.org/10.1109/TKDE.2025.3606643'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated recommender systems (FedRecSys) have emerged as a pivotal solution for privacy-aware recommendations, balancing growing demands for data security and personalized experiences. Current research efforts predominantly concentrate on adapting traditional recommendation architectures to federated environments, optimizing communication efficiency, and mitigating security vulnerabilities. However, user personalization modeling, which is essential for capturing heterogeneous preferences in this decentralized and non-IID data setting, remains underexplored. This survey addresses this gap by systematically exploring personalization in FedRecSys, charting its evolution from centralized paradigms to federated-specific innovations. We establish a foundational definition of personalization in a federated setting, emphasizing personalized models as a critical solution for capturing fine-grained user preferences. The work critically examines the technical hurdles of building personalized FedRecSys and synthesizes promising methodologies to meet these challenges. As the first consolidated study in this domain, this survey serves as both a technical reference and a catalyst for advancing personalized FedRecSys research.},
  archive      = {J_TKDE},
  author       = {Chunxu Zhang and Guodong Long and Zijian Zhang and Zhiwei Li and Honglei Zhang and Qiang Yang and Bo Yang},
  doi          = {10.1109/TKDE.2025.3606643},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {11},
  number       = {11},
  pages        = {6562-6581},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Personalized recommendation models in federated settings: A survey},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Orthogonal keys high precision and recall for mining database keys from inconsistent and incomplete relations. <em>TKDE</em>, <em>37</em>(11), 6550-6561. (<a href='https://doi.org/10.1109/TKDE.2025.3608680'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce the notion of orthogonality between column sets as a means to eliminate accidental keys during data driven key discovery. This becomes particularly important for inconsistent relations, where keys that almost hold need to be considered as well. Here we employ the classic $g_{3}$ metric for dirtiness, which can be applied to a variety of key semantics for incomplete relations, although the difficulty in computing the metric under different semantics varies greatly. Efficient algorithms for orthogonal mining and measuring dirtiness are proposed and evaluated on a real-world database. Additionally, we propose the notion of partial key, which turns out to be particularly useful for dealing with incomplete data in a key discovery context.},
  archive      = {J_TKDE},
  author       = {Henning Koehler and Sebastian Link},
  doi          = {10.1109/TKDE.2025.3608680},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {11},
  number       = {11},
  pages        = {6550-6561},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Orthogonal keys high precision and recall for mining database keys from inconsistent and incomplete relations},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Noise-tolerant feature selections based on two-type weight-fuzzy granulations and three-view uncertainty measures. <em>TKDE</em>, <em>37</em>(11), 6535-6549. (<a href='https://doi.org/10.1109/TKDE.2025.3604005'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Noise-tolerant feature selections are valuable for data learning; they can resort to efficient fuzzy granulations and uncertainty measures, and a fundamental model concerns weighted kernel fuzzy rough sets (WKFRSs) which consider data distributions and uncertainty. In terms of current WKFRSs, fuzzy granulations adopt $k$-nearest neighbors for weighted optimization, while uncertainty measures consider single algebraic and informational views; corresponding feature selection algorithms have made achievements of noisy processing, but still exist advancement space from granulation deepening and measurement reinforcement. In this paper embracing WKFRSs, two-type weight-fuzzy granulations are defined by using self-adapting radius neighborhoods, three-view uncertainty measures are comprehensively constructed from uncertainty mechanisms, so $2\times (1+1+2)=8$ heuristic algorithms of feature selections are systematically established for better noise-aware learning. At first, two improved factors of local density and boundary influence are proposed by general neighborhood characterization and statistical radius determination, and thus two sample weights emerge to adjust Gaussian-kernel fuzzy relations to induce two weight-fuzzy granulations. Then, the fuzzy precision and fuzzy-complementary mutual information are respectively proposed from algebraic and informational views, and the two are combined into two fused measures via arithmetic and geometric means. Furthermore, the above two-type granulations and three-view measures two-dimensionally generate $2\times (1+1+2)=8$ new heuristic selection algorithms via feature significances. Finally by data experiments, constructional fuzzy granulations, uncertainty measures, feature selections are validated to have anti-noise characteristics and corresponding robustness, while new selection algorithms acquire better performances of classification learning than multiple contrast algorithms.},
  archive      = {J_TKDE},
  author       = {Xin Xie and Xianyong Zhang and Xiaoling Yang and Jilin Yang},
  doi          = {10.1109/TKDE.2025.3604005},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {11},
  number       = {11},
  pages        = {6535-6549},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Noise-tolerant feature selections based on two-type weight-fuzzy granulations and three-view uncertainty measures},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view clustering via high-order bipartite graph learning and tensor low-rank representation. <em>TKDE</em>, <em>37</em>(11), 6521-6534. (<a href='https://doi.org/10.1109/TKDE.2025.3603594'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph-based multi-view clustering methods have demonstrated satisfying performance by effectively capturing relationships among data samples. However, most existing methods primarily emphasize direct pairwise relationships, neglecting the exploration of high-order correlations present within each view. To this end, a novel approach, called multiview clustering via high-order bipartite graph learning and tensor low-rank representation (HBGTLRR), is proposed. Specifically, we first construct high-order bipartite graphs to capture latent relationships and concatenate them into a tensor. By applying tensor nuclear norm (TNN) minimization, we obtain a low-rank representation that reduces noise and preserves high-order consistency. Subsequently, a consensus graph is constructed by adaptively fusing the high-order bipartite graphs with corresponding weights, and then a Laplacian low-rank constraint is imposed on it to effectively capture the intrinsic data structure. Finally, extensive experimental results show that HBGTLRR significantly outperforms existing methods, thereby validating the effectiveness of our proposed method.},
  archive      = {J_TKDE},
  author       = {Chuan Tang and Miaomiao Li and Jun Wang and Chang Tang and Jiahe Jiang and Tianyi Wang and En Zhu and Xinwang Liu},
  doi          = {10.1109/TKDE.2025.3603594},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {11},
  number       = {11},
  pages        = {6521-6534},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Multi-view clustering via high-order bipartite graph learning and tensor low-rank representation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large-scale storage location assignment via hierarchical reinforcement learning: A rank and assign approach. <em>TKDE</em>, <em>37</em>(11), 6506-6520. (<a href='https://doi.org/10.1109/TKDE.2025.3609173'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The storage location assignment problem for export containers (EC-SLAP) is crucial to the efficiency of cargo turnover in ports. Existing methods fall short in real-world applications due to the challenges of the unpredictability of container arrival sequences and the large-scale problem. We propose a new buffer-wise framework based on hierarchical reinforcement learning for EC-SLAP, aimed at optimizing container turnover efficiency. The framework comprises two processes: 1) Ranking Agent ranks containers in the buffer, reducing the uncertainty of random arrival sequences compared to the immediate assignment. 2) Assigning Agents assign storage locations in a two-step process by block and slot, diminishing the dimensionality of the large-scale discrete action space. We iteratively optimize agents by asynchronously obtaining rewards from the environment. In addition, to address the challenge of sparse rewards in long-sequence decision-making, we have developed a novel immediate reward function to enhance learning efficiency and accelerate convergence. We propose a new large-scale dataset, NZP-SLAD, collected from real-world historical data from the terminal operating system of Ningbo-Zhoushan Port and develop a realistic container terminal simulator. We conducted numerous offline simulations and tests with this dataset. The experimental results demonstrate that our proposed method achieves rapid convergence and significantly surpasses expert methods used in real-world production.},
  archive      = {J_TKDE},
  author       = {Weihang Pan and Minghao Chen and Binbin Lin and Yafei Wang and Xinkui Zhao and Xiaofei He and Jieping Ye},
  doi          = {10.1109/TKDE.2025.3609173},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {11},
  number       = {11},
  pages        = {6506-6520},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Large-scale storage location assignment via hierarchical reinforcement learning: A rank and assign approach},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large language models meet causal inference: Semantic-rich dual propensity score for sequential recommendation. <em>TKDE</em>, <em>37</em>(11), 6494-6505. (<a href='https://doi.org/10.1109/TKDE.2025.3606149'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential recommender systems (SRSs) are designed to suggest relevant items to users by analyzing their interaction sequences. However, SRSs often suffer from exposure bias in these sequences due to imbalanced item exposure and varied user activity levels, creating a self-reinforcing loop favoring popular items regardless of their true relevance. Most SRSs only focus on item dependencies to address exposure bias, while overlooking user-side exposure bias and the rich semantics behind interactions. These oversights result in a limited understanding of less active usersâ€™ preferences and inaccurate preference capture for less exposed items, exacerbating exposure biases. Towards this end, we propose a novel method LLM-enhanced Dual Propensity Score Estimation (LDPE), which synergistically integrates Large Language Models (LLMs) and causal inference. First, LDPE leverages LLMsâ€™ superior ability in capturing rich semantics from textual data and then integrates collaborative information to generate debiased semantic-rich LLM-based user/item embeddings. With these debiased item/user embeddings, LDPE estimates time-aware debiased propensity scores from both the item and user sides. These dual propensity scores can fully mitigate exposure bias by considering item popularity, user activity levels, and temporal dynamics. Lastly, LDPE employs the transformer as the backbone of our method, incorporating estimated dual propensity scores for accurately predicting usersâ€™ true preferences. Extensive experiments show that our LDPE outperforms state-of-the-art baselines in terms of recommendation performance.},
  archive      = {J_TKDE},
  author       = {Dianer Yu and Qian Li and Sirui Huang and Jie Cao and Guandong Xu},
  doi          = {10.1109/TKDE.2025.3606149},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {11},
  number       = {11},
  pages        = {6494-6505},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Large language models meet causal inference: Semantic-rich dual propensity score for sequential recommendation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Label propagation-based membership degree computation towards a computationally efficient fuzzy community detection approach. <em>TKDE</em>, <em>37</em>(11), 6478-6493. (<a href='https://doi.org/10.1109/TKDE.2025.3593203'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel fuzzy community detection (FCD) approach, which we term as â€˜Label Propagation-Based Fuzzy Community (LaProFC)â€™, and shows that it has the ability to outperform the existing FCD approaches. While designing the proposed FCD approach, we introduce a new compound type similarity metric termed â€˜proportion of common neighbors and edges-based similarity (CCS)â€™ to compute similarity between two neighboring nodes. By executing local exploration on graphs with modified local random walk (mLRW), most similar neighbors of each node are identified; and based on the directions of most similar neighbors some tentative communities are generated. Afterward, these tentative communities are corrected and stabilized by iteratively computing membership degrees of each node using a novel label propagation-based membership computation function. We also propose a novel edge-density-based technique called â€˜community-weight based tie-breaking (CTB)â€™, which is incorporated with the membership degree computation function. We conduct extensive experiments with both real-life and synthetic datasets and show the working of the proposed approach. Our Proposed LaProFC approach outperforms baseline approaches in terms of popular quality and accuracy metrices including modularity and normalized mutual information. Further, popular multi-criteria decision making (MCDM) tools are used to show supremacy of the proposed approach by computing the ranks of different approaches through two sets of accuracy and quality metrices. Our proposed LaProFC approach supersedes other approaches in terms of faster computations and asymptotic time complexity.},
  archive      = {J_TKDE},
  author       = {Uttam K. Roy and Pranab K. Muhuri},
  doi          = {10.1109/TKDE.2025.3593203},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {11},
  number       = {11},
  pages        = {6478-6493},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Label propagation-based membership degree computation towards a computationally efficient fuzzy community detection approach},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Is precise recovery necessary? a task-oriented imputation approach for time series forecasting on variable subset. <em>TKDE</em>, <em>37</em>(11), 6464-6477. (<a href='https://doi.org/10.1109/TKDE.2025.3594032'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Variable Subset Forecasting (VSF) refers to a unique scenario in multivariate time series forecasting, where available variables in the inference phase are only a subset of the variables in the training phase. VSF presents significant challenges as the entire time series may be missing, and neither inter- nor intra-variable correlations persist. Such conditions impede the effectiveness of traditional imputation methods, primarily focusing on filling in individual missing data points. Inspired by the principle of feature engineering that not all variables contribute positively to forecasting, we propose Task-Oriented Imputation for VSF (TOI-VSF), a novel framework shifts the focus from accurate data recovery to directly support the downstream forecasting task. TOI-VSF incorporates a self-supervised imputation module, agnostic to the forecasting model, designed to fill in missing variables while preserving the vital characteristics and temporal patterns of time series data. Additionally, we implement a joint learning strategy for imputation and forecasting, ensuring that the imputation process is directly aligned with and beneficial to the forecasting objective. Extensive experiments across four datasets demonstrate the superiority of TOI-VSF, outperforming baseline methods by 15% on average. The code is available at https://github.com/Asteriaqq/TOI-VSF.},
  archive      = {J_TKDE},
  author       = {Qi Hao and Runchang Liang and Yue Gao and Hao Dong and Wei Fan and Lu Jiang and Pengyang Wang},
  doi          = {10.1109/TKDE.2025.3594032},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {11},
  number       = {11},
  pages        = {6464-6477},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Is precise recovery necessary? a task-oriented imputation approach for time series forecasting on variable subset},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GOIO: Generative oversampling approach to class imbalance and overlap of tabular data. <em>TKDE</em>, <em>37</em>(11), 6450-6463. (<a href='https://doi.org/10.1109/TKDE.2025.3608246'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class imbalance, which is common in real-world classification tasks, often leads to biased models favoring majority classes. Data oversampling is a widely used strategy to address this issue. However, traditional oversampling methods often generate incorrect or redundant instances when class overlap occurs, increasing decision boundary complexity. To this end, we propose a novel Generative Oversampling approach to addressing Class Imbalance and Overlap (GOIO) in the classification of tabular data. GOIO combines a Metric-Learning-based Variational Autoencoder (MLVAE) and a Conditional Latent Diffusion Model (CLDM) to handle class imbalance and overlap effectively. The MLVAE employs a triplet-center loss to the adverse effects of class overlap by transforming the data distribution into a more separable latent feature space. Following this, the CLDM is trained with class-center feature prompting and classifier-free guidance strategy to capture class-specific latent distributions accurately. Minority class samples are synthesized in the latent space using the CLDM and then reconstructed into the data space via the MLVAE decoder. Comprehensive experiments on 18 real-world and five synthetic datasets demonstrate that GOIO outperforms the state-of-the-art oversampling methods in F1-score, MCC, and Accuracy. Ablation studies further validate the effectiveness of the proposed contributions in addressing class imbalance and overlap.},
  archive      = {J_TKDE},
  author       = {Shiqi Ren and Jinliang Ding and Cuie Yang and Yiu-ming Cheung},
  doi          = {10.1109/TKDE.2025.3608246},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {11},
  number       = {11},
  pages        = {6450-6463},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {GOIO: Generative oversampling approach to class imbalance and overlap of tabular data},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Financial time series prediction with multi-granularity graph augmented learning. <em>TKDE</em>, <em>37</em>(11), 6436-6449. (<a href='https://doi.org/10.1109/TKDE.2025.3607005'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Financial time series prediction is an important and challenging data mining task for quantitative investment. The inherent non-linearity, high noise, and susceptibility to various factors, such as macroeconomic conditions and market sentiment in the stock market, increase the difficulty of prediction. Existing financial industries mainly employ time series models or fundamental analysis methods for prediction. However, these methods fail to effectively capture the complex interrelationships between equity. In recent years, graph neural networks (GNNs), due to their powerful relational modeling capabilities, have been applied to stock prediction. However, with the advances of recent digital power, such as widely-used high-frequency trading techniques, existing graph-based methods still have shortcomings in effectively learning multi-granularity temporal relations as they cannot effectively learn the patterns in different frequencies, e.g., minute-level, daily, weekly, etc. Therefore, in this paper, we propose a multi-granularity graph augmented learning framework for interrelated financial time series forecasting. We first construct a temporal return relationship graph with multi-granularity financial time series, including weekly, daily, and minute-level, to comprehensively capture the dynamic relations of equities, including both medium-term trends and short-term fluctuations. Then, to further augment the node relations, we devise an attentional graph augment module to improve the graph learning with fundamental data, which are jointly optimized in the prediction layer. We conduct extensive empirical studies on multiple datasets from both the Chinese and U.S. stock markets. The results demonstrate that our proposed model consistently outperforms existing baseline methods across four key financial metrics, including ARR, ASR, CR, and IR, thereby validating its effectiveness and superiority. The model has been applied and empirically tested in commercial-grade trading platforms, further demonstrating its efficiency and robustness in real-world trading environments.},
  archive      = {J_TKDE},
  author       = {Peng Zhu and Yuante Li and Qinyuan Liu and Dawei Cheng and Changjun Jiang},
  doi          = {10.1109/TKDE.2025.3607005},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {11},
  number       = {11},
  pages        = {6436-6449},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Financial time series prediction with multi-granularity graph augmented learning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated graph neural networks with equivalent hypergraph construction for traffic flow prediction. <em>TKDE</em>, <em>37</em>(11), 6420-6435. (<a href='https://doi.org/10.1109/TKDE.2025.3607895'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic flow prediction is essential for intelligent transportation systems, yet privacy concerns and limited cross-regional data sharing hinder accurate modeling of global traffic patterns. This paper proposes a Federated Graph Neural Network with Equivalent Hypergraph (FGNNEH) framework to address these challenges by preserving privacy and enhancing cross-client collaboration. FGNNEH consists of two key stages. First, local traffic networks are transformed into high-dimensional hypernodes through an integrated process of backbone network extraction, kernel matrix analysis, and multilayer perceptrons. The backbone network extraction simplifies graph structures by isolating critical nodes and edges based on topological centrality, ensuring computational efficiency while retaining key spatial dependencies. Kernel matrix analysis captures complex nonlinear correlations among traffic flow features, including spatial-temporal dependencies and region-specific dynamics, enabling more effective feature representation. The multilayer perceptrons further fuse these features into robust hypernode embeddings that encapsulate both structural and traffic flow characteristics. Second, a global hypergraph construction mechanism is introduced to optimize inter-client collaboration. This mechanism employs an iterative performance feedback loop to dynamically add or remove edges between hypernodes, addressing the issue of lost inter-client connections and enabling effective cross-regional information exchange. Together, these components reconstruct a global traffic model that balances local privacy with holistic accuracy. Experiments on real-world traffic datasets, including PeMSD4, METR-LA and Guangzhou, demonstrate that FGNNEH outperforms existing methods in prediction accuracy, computational efficiency, and scalability.},
  archive      = {J_TKDE},
  author       = {Feng Wang and Yuhang Cao and Li Liu and Qi Kang and Jun Chen},
  doi          = {10.1109/TKDE.2025.3607895},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {11},
  number       = {11},
  pages        = {6420-6435},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Federated graph neural networks with equivalent hypergraph construction for traffic flow prediction},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing robustness and generalization capability for multimodal recommender systems via sharpness-aware minimization. <em>TKDE</em>, <em>37</em>(11), 6406-6419. (<a href='https://doi.org/10.1109/TKDE.2025.3604242'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal recommender systems utilize a variety of information types to model user preferences and item properties, aiding in the discovery of items that align with user interests. Rich multimodal information alleviates inherent challenges in recommendation systems, such as data sparsity and cold start problems. However, multimodal information further introduces challenges in terms of robustness and generalization capability. Regarding robustness, multimodal information magnifies the risks associated with information adjustment and inherent noise, posing severe challenges to the stability of recommendation models. For generalization capability, multimodal recommender systems are more complex and difficult to train, making it harder for models to handle data beyond the training set, posing significant challenges to model generalization capability. In this paper, we analyze the shortcomings of existing robustness and generalization capability enhancement strategies in the multimodal recommendation field. We propose a sharpness-aware minimization strategy focused on batch data (BSAM), which effectively enhances the robustness and generalization capability of multimodal recommender systems without requiring extensive hyper-parameter tuning. Furthermore, we introduce a mixed loss variant strategy (BSAM+), which accelerates convergence and achieves remarkable performance improvement. We provide rigorous theoretical proofs and conduct experiments with nine advanced models on five widely used datasets to validate the superiority of our strategies. Moreover, our strategies can be integrated with existing robust training and data augmentation strategies to achieve further improvement, providing a superior training paradigm for multimodal recommendations.},
  archive      = {J_TKDE},
  author       = {Jinfeng Xu and Zheyu Chen and Jinze Li and Shuo Yang and Wei Wang and Xiping Hu and Raymond Chi-Wing Wong and Edith C. H. Ngai},
  doi          = {10.1109/TKDE.2025.3604242},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {11},
  number       = {11},
  pages        = {6406-6419},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Enhancing robustness and generalization capability for multimodal recommender systems via sharpness-aware minimization},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient algorithms for influence maximization in hypergraphs by stratified sampling. <em>TKDE</em>, <em>37</em>(11), 6392-6405. (<a href='https://doi.org/10.1109/TKDE.2025.3599790'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Influence maximization (IM) aims to identify $k$ vertices that maximize influence spread across a network. While well-studied in regular graphs, IM in hypergraphs presents unique challenges: conventional graph-based IM methods fail to capture hypergraph-specific structural properties, and existing hypergraph IM algorithms lack theoretical guarantees for time complexity and approximation quality. We address these gaps with HyperIM, a novel algorithm leveraging stratified sampling to generate random reversible reachable sets for efficient seed selection. Our key innovation lies in dual-perspective stratified sampling: assigning sampling probabilities based on vertex structural properties while applying size-adaptive sampling strategies. This approach optimizes seed selection, reduces computational costs, and provides rigorous theoretical guarantees. We further propose HyperIM_BRR, which optimizes the required number of reversible reachable sets, achieving substantial cost reduction without sacrificing accuracy. Extensive experiments on real-world hypergraphs demonstrate that our algorithms significantly outperform state-of-the-art methods, delivering faster execution times and superior influence spread.},
  archive      = {J_TKDE},
  author       = {Lingling Zhang and Tiancheng Lu and Zhiping Shi and Zhiwei Zhang and Ye Yuan and Guoren Wang},
  doi          = {10.1109/TKDE.2025.3599790},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {11},
  number       = {11},
  pages        = {6392-6405},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Efficient algorithms for influence maximization in hypergraphs by stratified sampling},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Document-level relation extraction with low entity redundancy feature map. <em>TKDE</em>, <em>37</em>(11), 6379-6391. (<a href='https://doi.org/10.1109/TKDE.2025.3607566'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Document-level relation extraction (RE) aims to determine the relations between entities scattered across different sentences through reading and reasoning. Existing methods use semantic segmentation to obtain global information among triples by analyzing entity-level matrices. However, complete document input may introduce certain interference, making it challenging to express the underlying relationships. To address this, we propose a novel approach introducing a low-entity redundancy feature map, achieved by removing certain entities. The proposed optimal path filtering (OPF) selects entity-related sentences using heuristic rules and formulates sentence selection as a set cover problem, solved via backtracking pruning. U-Net is then applied to obtain global features. Our experiment achieves state-of-the-art results on two common document-level RE datasets, Re-DocRED and CDR, outperforming previous methods.},
  archive      = {J_TKDE},
  author       = {Rongen Yan and Depeng Dang and Keqin Peng and Yakun Li and Ye Tao and Lei Hou and Juanzi Li and Jie Tang},
  doi          = {10.1109/TKDE.2025.3607566},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {11},
  number       = {11},
  pages        = {6379-6391},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Document-level relation extraction with low entity redundancy feature map},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributional shortest-path graph kernels. <em>TKDE</em>, <em>37</em>(11), 6367-6378. (<a href='https://doi.org/10.1109/TKDE.2025.3606566'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional shortest-path graph kernels generate for each graph a histogram-like feature map, whose elements represent the number of occurrences of non-isomorphic shortest paths in this graph. The histogram-like feature map does not contain the distributions of the shortest paths within and across graphs, causing inaccurate graph similarities. To this end, we propose a novel graph kernel called the Distributional Shortest-Path (DSP) graph kernel to embrace both types of distribution information. Since the distribution of substructures (e.g., the shortest paths) follows a power law like that of words in natural language, we utilize neural language models to learn each nodeâ€™s distributional shortest-path feature map, encompassing the distributions and dependencies of the shortest paths in each graph. Moreover, we design the Partition Kernel (PK) to capture the dataset-wide distribution information of the shortest paths. PK projects similar (i.e., belonging to the same partition) distributional shortest-path node feature maps to the same point in the Reproducing Kernel Hilbert Space. Finally, Kernel Mean Embedding (KME) is applied to compute graph feature maps and efficiently construct the DSP graph kernel. Empirical experiments demonstrate that DSP outperforms state-of-the-art graph kernels on most benchmark datasets.},
  archive      = {J_TKDE},
  author       = {Wei Ye and Wengang Guo and Shuhao Tang and Hao Tian and Xin Sun and Xiaofeng Cao and Heng Tao Shen},
  doi          = {10.1109/TKDE.2025.3606566},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {11},
  number       = {11},
  pages        = {6367-6378},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Distributional shortest-path graph kernels},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DiST: Efficient distributed spatio-temporal clustering with automatic parameter optimization. <em>TKDE</em>, <em>37</em>(11), 6352-6366. (<a href='https://doi.org/10.1109/TKDE.2025.3607744'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid advancements in positioning technologies, the volume of spatio-temporal data has grown significantly. Analyzing the spatial and temporal characteristics of these data is imperative for uncovering underlying associations and deriving insights into natural and societal mechanisms. Clustering is a widely utilized technique for data analysis, which groups data with similar characteristics for further investigation. However, current clustering methodologies usually inadequately address temporal properties that are vital in numerous scenarios. Additionally, traditional spatio-temporal clustering approaches are constrained to standalone environments, which struggle to handle large-scale spatio-temporal datasets. To this end, we introduce DiST, the first distributed spatio-temporal clustering method, which simultaneously considers both temporal and spatial proximity. DiST comprises data partition, local clustering, and global merging stages, along with an auto-tuning framework for parameter optimization. DiST addresses key challenges, including the integration of temporal and spatial attributes, managing data duplication across distributed nodes, and selecting appropriate parameters for diverse data characteristics. Comparative experiments on two real-world datasets validate the performance and scalability of DiST, demonstrating its effectiveness in spatio-temporal data analysis.},
  archive      = {J_TKDE},
  author       = {Jiajun Li and Shuxiang Gou and Ruiyuan Li and Huajun He and Wenhui Li and Yu Zheng},
  doi          = {10.1109/TKDE.2025.3607744},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {11},
  number       = {11},
  pages        = {6352-6366},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {DiST: Efficient distributed spatio-temporal clustering with automatic parameter optimization},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Differential privacy configurations in the real world: A comparative analysis. <em>TKDE</em>, <em>37</em>(11), 6334-6351. (<a href='https://doi.org/10.1109/TKDE.2025.3603731'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An increasing number of technologies depend on the large-scale collection of individual-level data, whether for gathering statistical insights from billions of users or for training AI models. However, reliance on personal data raises privacy concerns that, in turn, limit the collection and analysis essential to these technologies. Differential Privacy (DP) has gained traction in both academia and industry, ensuring privacy by adding carefully crafted noise to data or its outputs based on a pre-defined privacy loss budget $\varepsilon$. As real-world implementations emerge, we can examine how DP is practically used beyond academic settings, supporting industry adoption and expanding knowledge on DP applications. Using a systematic process, we comprehensively surveyed the deployed parameters of DP configurations in both commercial and governmental implementations ($n=140$) and compared them to those employed in academic research. We also propose a high-level taxonomy for DP configuration that captures practical implementations of differentially-private Machine Learning (ML) and Federated Learning (FL) applications, and highlights key factors such as the privacy unit and the privacy loss budget $\varepsilon$. Our results show that, on average, $\varepsilon$ values utilized in industry span a wider range than those used in academic research, with distinct configuration policies for governmental and commercial organizations. Moreover, we identified contrasting reasoning behind $\varepsilon$ selection across deployment environments, as well as insufficient transparency in how commercial organizations report implemented DP parameters and limited support for user-oriented configuration. Finally, we discuss how the collected knowledge can be used to create methodological guidelines for the configuration of DP in real-world environments, supporting the vision of an Epsilon Registry.},
  archive      = {J_TKDE},
  author       = {Michael Khavkin and Eran Toch},
  doi          = {10.1109/TKDE.2025.3603731},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {11},
  number       = {11},
  pages        = {6334-6351},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Differential privacy configurations in the real world: A comparative analysis},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). COIN-GNN: Inductive spatial-temporal prediction for continuous distribution shifts via graph neural networks. <em>TKDE</em>, <em>37</em>(11), 6320-6333. (<a href='https://doi.org/10.1109/TKDE.2025.3606629'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distribution shifts from external events and new entities can significantly compromise spatial-temporal prediction accuracy, potentially leading to severe outcomes like traffic accidents. Existing methods often fail under these conditions due to two main limitations: they focus on invariant patterns, missing the diversity required to capture the evolving dynamics of distribution shifts; they rely on often inaccessible future knowledge, such as spatial information of new entities, limiting their generalizability. To address these limitations, we formally define the problem of inductive spatial-temporal prediction under continuous distribution shifts and introduce the Contrastive Learning Based Inductive Graph Neural Network (COIN-GNN) as a solution. We develop a novel metric, Relation Importance (RI), to effectively select stable entities and distinct spatial relationships, forming an informative subgraph. Additionally, we construct an informative temporal memory buffer to store and review influential timestamps identified using influence functions. COIN-GNN then generates pseudo-observations for unstable and uninformative entities during these influential timestamps, simulating potential distribution shifts. By applying contrastive learning, the network learns stable and informative representations that can effectively counter distribution shifts without relying on future knowledge. Our extensive experiments on several real-world datasetsâ€”from traffic to weatherâ€”demonstrate COIN-GNNâ€™s superior performance across different domains without requiring future knowledge.},
  archive      = {J_TKDE},
  author       = {Jialun Zheng and Divya Saxena and Jiannong Cao},
  doi          = {10.1109/TKDE.2025.3606629},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {11},
  number       = {11},
  pages        = {6320-6333},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {COIN-GNN: Inductive spatial-temporal prediction for continuous distribution shifts via graph neural networks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Balancing act: MDGAN for imbalanced tabular data synthesis. <em>TKDE</em>, <em>37</em>(11), 6304-6319. (<a href='https://doi.org/10.1109/TKDE.2025.3607862'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Addressing the persistent challenge of learning from imbalanced datasets is crucial in advancing machine learning applications. Standard machine learning algorithms typically assume that the input data is balanced, and they often struggle to effectively learn the distribution of minority class data when dealing with imbalanced data. To address this, our study designed an improved Generative Adversarial Networks (GANs) model, named MDGAN, for tabular sample synthesis to augment samples and balance the data distribution. MDGAN employs a multi-generator and multi-discriminator structure to capture non-connected subspace manifolds, thereby better fitting the complete data distribution. To enhance the diversity among the multiple generators, an exclusive loss among generators was designed, ensuring that each generator produces data of different modalities. Additionally, a contrastive loss was introduced to ensure that the generated samples better fit the minority class distribution and are separated from the majority class distribution, preventing blurred classification boundaries. Qualitative and quantitative tests were conducted on 25 real datasets, and the experimental results indicate that MDGAN outperforms traditional classical models and current advanced oversampling models.},
  archive      = {J_TKDE},
  author       = {Hongwei Ding and Nana Huang and Qi Tao and Jiaqi Liang and Xiaohui Cui},
  doi          = {10.1109/TKDE.2025.3607862},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {11},
  number       = {11},
  pages        = {6304-6319},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Balancing act: MDGAN for imbalanced tabular data synthesis},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Authenticated subgraph matching on large-scale graphs in hybrid-storage blockchains. <em>TKDE</em>, <em>37</em>(11), 6286-6303. (<a href='https://doi.org/10.1109/TKDE.2025.3598850'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graphs serve as an essential data structure to model complex relationships in a variety of applications, such as social networks, web graphs, and chemical informatics. Due to the high cost of maintaining large-scale graph data and executing graph queries, data owners often outsource their graph data to a third-party service provider for graph processing. In this scenario, it is crucial to ensure the integrity of query results, as the provider may have the incentive to return only partial or tampered results to save computing resources or serve their own interests. Blockchain, as a promising solution for secure data storage and retrieval, opens up new opportunities for data management in such scenarios. To scale the blockchain, existing studies have concentrated on using off-chain storage while ensuring the integrity of query results for key-value data in hybrid-storage blockchain architectures. To the best of our knowledge, there is no work to enable the blockchain to support subgraph matching queries. In this paper, we first study the problem of authenticated subgraph matching queries. Traditional subgraph matching algorithms follow the filtering-searching paradigm. The main challenge is to design an Authenticated Data Structure (ADS) and aggregation algorithm that efficiently aggregates non-results for verification during the filtering-searching process. We first propose a vertex-based scheme - the novel ADS MELTree can generate candidate vertices and aggregate non-resulting vertices in the filtering phase, while the aggregation algorithm AMatching can aggregate invalid partial results in the search phase. Furthermore, we propose the bidirectional search aggregation algorithm AMatching* and ADS MVPTree to reduce the computational cost in the search phase and to reduce the on-chain storage cost. In addition, we propose a novel path-based scheme to enhance the aggregation of non-results and accelerate the processing. We design the path-based ADS MPETree for generating candidate paths and aggregating non-resulting paths, and the aggregation algorithm PMatching for efficiently aggregating invalid partial results one path at a time. The results of extensive experiments on five real-world graphs demonstrate the efficiency of our proposed ADSs and aggregation algorithms.},
  archive      = {J_TKDE},
  author       = {Siyu Li and Zhiwei Zhang and Kai Zhong and Kangfei Zhao and Meihui Zhang and Ye Yuan and Guoren Wang},
  doi          = {10.1109/TKDE.2025.3598850},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {11},
  number       = {11},
  pages        = {6286-6303},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Authenticated subgraph matching on large-scale graphs in hybrid-storage blockchains},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A region-aware dual latent state mining framework for service recommendation in large-scale service networks. <em>TKDE</em>, <em>37</em>(11), 6272-6285. (<a href='https://doi.org/10.1109/TKDE.2025.3609553'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In large-scale service networks, Quality of Service (QoS) data is vital for tasks such as resource provisioning, real-time service recommendation, and user experience optimization; yet effectively predicting QoS often faces two key obstacles: data sparsity and highly imbalanced distributions (where most response times cluster near small values while a minority grow disproportionately large). Existing approaches typically rely on individual object (user/service) features, overlooking the phenomenon that users or services within the same region (physical or virtual) exhibit similar network states. This paper presents a Region-Aware Dual-Latent State Learning (R2SL) framework that tackles these challenges by explicitly modeling regional network latent states. Specifically, we propose to learn physical-region (city-level) and virtual-region (AS-level) latent states from historical QoS records through a joint EMâ€“gradient descent strategy, thereby alleviating data sparsity. Furthermore, to mitigate label imbalance in QoS data, we introduce a Smooth Huber (S-Huber) loss function that appropriately reweights extreme errors, preventing the training process from being dominated by outliers. We also develop a sparsely activated mixture-of-experts module, dynamically routing regional latent features based on each prediction taskâ€™s context. Experiments on real-world QoS datasets show that R2SL substantially outperforms state-of-the-art baselines, including the newly introduced FRLN. On throughput tasks, R2SL reduces MAE by an average of 18.8% and RMSE by 12.9%, while on response time tasks, it achieves 26.4% lower MAE and 24.2% lower RMSE. These findings indicate that dual-latent state modeling, combined with a distribution-aware loss, effectively captures complex regional patterns and mitigates long-tail label effects, making R2SL a powerful and scalable framework for large-scale QoS data mining in service networks.},
  archive      = {J_TKDE},
  author       = {Ziliang Wang and Xiaohong Zhang and Ze Shi Li and Meng Yan},
  doi          = {10.1109/TKDE.2025.3609553},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {11},
  number       = {11},
  pages        = {6272-6285},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A region-aware dual latent state mining framework for service recommendation in large-scale service networks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A knowledge-guided pre-training temporal data analysis foundation model for urban computing. <em>TKDE</em>, <em>37</em>(11), 6259-6271. (<a href='https://doi.org/10.1109/TKDE.2025.3607026'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal data analysis plays a pivotal role in applications such as weather forecasting, traffic flow management, energy consumption monitoring, and other areas of urban computing. In recent years, temporal data modeling has transitioned from traditional deep learning methods to pre-trained models. However, existing approaches often exhibit significant task-specific limitations, requiring bespoke model designs and extensive domain data for training. To address these challenges, this study introduces KPT, a novel foundation model for temporal data analysis in urban computing. By leveraging temporal competitive attention and feature interaction attention mechanisms, KPT can effectively capture global context, integrate cross-variable features precisely, and achieve universal feature learning across diverse time series tasks. Additionally, the knowledge prompt network facilitates the deep fusion of cross-layer features via an intricate interaction mechanism, enabling the model to identify and align shared temporal patterns across different time series data. These patterns then transformed into knowledge prompts, thereby enhancing the universal feature learning capabilities of the pre-trained model. Experimental results demonstrate that KPT excels in four core temporal analysis tasks within urban computing, outperforming task-specific models. This highlights KPTâ€™s ability to generalize across tasks and underscores its potential as a foundation model for multi-task scenarios in urban computing.},
  archive      = {J_TKDE},
  author       = {Haochen Shi and Shengdong Du and Yan Yang and Junbo Zhang and Tianrui Li and Yu Zheng},
  doi          = {10.1109/TKDE.2025.3607026},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {11},
  number       = {11},
  pages        = {6259-6271},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A knowledge-guided pre-training temporal data analysis foundation model for urban computing},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
