<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>sage</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="adbe">ADBE - 3</h2>
<ul>
<li><details>
<summary>
(2025). Creativity: An individual or collective phenomenon? a historical-psychological perspective. <em>ADBE</em>, <em>33</em>(4), 249-269. (<a href='https://doi.org/10.1177/10597123251343849'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper examines the concept of creativity from a historical-psychological perspective, exploring its evolution over time and its manifestation as both an individual and collective phenomenon. Through a narrative-theoretical review of the literature on creativity’s conceptualization, nature, and valuation, we examine how social, cultural, and psychological factors have influenced the understanding of creativity throughout history. The discussion contrasts key aspects at the individual level, such as motivation, personality, intuition, exceptionality, and intelligence, with group dimensions like domain, field, collaboration, background, and the societal consequences of creative acts. The paper presents diverse psychological frameworks, including behaviorism, psychoanalysis, Gestalt psychology, humanistic psychology, and cognitive psychology, each offering unique insights into the mechanisms behind creativity. By tracing the historical phases of creativity—from its early association with divine creation to its modern applications in art, science, and technology, as well as its relationship with artificial intelligence—this paper highlights how creativity has been judged and valued across different eras. One of the conclusions drawn is that while the concept of artistic genius and originality cannot be disentangled from its broader social and cultural context, creativity is also an intensely personal psychological process, with the internalized sociocultural context acting as a proxy for external fields and domains.},
  archive      = {J_ADBE},
  author       = {Leonardo Barón-Birchenall and Andrea Sánchez-Vallejo and Carlos Toro-Silva and Andrea Folleco-Eraso},
  doi          = {10.1177/10597123251343849},
  journal      = {Adaptive Behavior},
  month        = {8},
  number       = {4},
  pages        = {249-269},
  shortjournal = {Adaptive Behavior},
  title        = {Creativity: An individual or collective phenomenon? a historical-psychological perspective},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The imaginal space: A theory of scaffolded minds in a cultural niche. <em>ADBE</em>, <em>33</em>(4), 221-247. (<a href='https://doi.org/10.1177/10597123251355904'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We humans have scaffolded minds into an ecological niche. Considering this, the main thesis I will defend in this article is that we humans live surrounded by images, and we spatially organise these images into a particular cultural niche which I call imaginal space, a material or virtual space that we interactively navigate. We use such images in the imaginal space as fundamental props in the imaginative dynamics of our scaffolded minds. The images we find in our imaginal space are public depictive representations. They are twofold objects: on the one hand, they are material objects in that they can be manipulated into the ecological niche; on the other hand, they also are normative objects in that their representational function can be redesigned through a practice of use. As a first consequence of this main thesis, I will contend that public representations emergent into the imaginal space of a certain community may play a crucial regulative role for imagination: emergent systems of public representations can get a canonical status in their community, so that they can exert a normative power on the members of that community regulating their imagistic mental representations. As a second consequence, I will defend that the canonical images emergent in the imaginal space constitute the collective imagery of a human community: they support and influence the development of public narratives in the considered community.},
  archive      = {J_ADBE},
  author       = {Francesco Consiglio},
  doi          = {10.1177/10597123251355904},
  journal      = {Adaptive Behavior},
  month        = {8},
  number       = {4},
  pages        = {221-247},
  shortjournal = {Adaptive Behavior},
  title        = {The imaginal space: A theory of scaffolded minds in a cultural niche},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Investigating dominant situation of resting behavior as a potential labor pool in robotic swarm for group foraging. <em>ADBE</em>, <em>33</em>(4), 197-220. (<a href='https://doi.org/10.1177/10597123241309184'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The foraging task is a commonly studied scenario for distributed swarm robotic systems. The robots switch searching and resting behavior in a distributed manner to perform foraging quickly and energy efficiently. It is known that robots that are resting can act as a potential labor pool in addition to saving energy. Because they function as a potential labor pool, resting robots can help with foraging if needed. In this study, we consider the group foraging task, which requires two or more robots to transport a food item. In a group foraging task, resting robots can help with the transportation of a heavy food item in response to the recruitment of other robots. Until now, the efficacy of the resting behavior as a potential labor pool has been suggested, but the environments in which this function is dominant is still unknown. In this study, we propose a state-transition model for robots that includes the resting behavior and investigate the performance through multi-agent simulation. By comparing models with and without the resting behavior, we found that the function of the resting behavior as a potential labor pool is dominant in cases when the food items are heavy or the population is small.},
  archive      = {J_ADBE},
  author       = {Tomohiro Hayakawa and Toshiyuki Yasuda and Fumitoshi Matsuno},
  doi          = {10.1177/10597123241309184},
  journal      = {Adaptive Behavior},
  month        = {8},
  number       = {4},
  pages        = {197-220},
  shortjournal = {Adaptive Behavior},
  title        = {Investigating dominant situation of resting behavior as a potential labor pool in robotic swarm for group foraging},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="becb">BECB - 15</h2>
<ul>
<li><details>
<summary>
(2025). PEDI: Towards efficient pathway enrichment and data integration in bioinformatics for healthcare using deep learning optimisation. <em>BECB</em>, <em>16</em>. (<a href='https://doi.org/10.1177/11795972251321684'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents an enhanced identification procedure utilising bioinformatics data, employing optimisation techniques to tackle crucial difficulties in healthcare operations. A system model is designed to tackle essential difficulties by analysing major contributions, including risk factors, data integration and interpretation, error rates and data wastage and gain. Furthermore, all essential aspects are integrated with deep learning optimisation, encompassing data normalisation and hybrid learning methodologies to efficiently manage large-scale data, resulting in personalised healthcare solutions. The implementation of the suggested technology in real time addresses the significant disparity between data-driven and healthcare applications, hence facilitating the seamless integration of genetic insights. The contributions are illustrated in real time, and the results are presented through simulation experiments encompassing 4 scenarios and 2 case studies. Consequently, the comparison research reveals that the efficacy of bioinformatics for enhancing routes stands at 7%, while complexity diminish to 1%, thereby indicating that healthcare operations can be transformed by computational biology.},
  archive      = {J_BECB},
  author       = {Hariprasath Manoharan and Shitharth Selvarajan},
  doi          = {10.1177/11795972251321684},
  journal      = {Biomedical Engineering and Computational Biology},
  month        = {1-12},
  shortjournal = {Biomed. Eng. Comput. Biol.},
  title        = {PEDI: Towards efficient pathway enrichment and data integration in bioinformatics for healthcare using deep learning optimisation},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Biomechanical evaluation of cervical interbody fusion cages for anterior cervical discectomy and fusion with variations in morphology: A finite element analysis. <em>BECB</em>, <em>16</em>. (<a href='https://doi.org/10.1177_11795972251321307'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The spinal diseases commonly faced by people in the 19th century included intervertebral disc degeneration, tuberculosis and congenital defects that resulted in neurological impairment and global disability. To address these issues, cervical spine surgery was performed. Modern techniques currently used in spine surgery include interbody devices, pedicle screws, artificial discs and bone grafts. The postoperative complications clinically reported during follow-up include nonunion and implant subsidence, which remain significant drawbacks. The objective of this study is to develop a 3-dimensional finite element model of the C2-C7 cervical spine and validate it against existing experimental studies. The loading conditions considered for this study include a compressive preload of 50 N and a 1 Nm moment applied to the C2 vertebra, with the C7 vertebra fixed at the bottom. In this study, the biomechanical alterations of 4 different cage morphologies were analysed using finite element analysis. Valeo cages with 4 distinct designs were implanted at the C5-C6 level, and physiological motion at the surgical site was studied. Cage subsidence and migration, which can lead to adjacent segment disc degeneration, were also examined. Subsidence was primarily attributed to higher stress encountered in the cage, so stress distribution within the cages was evaluated. Additionally, stress distribution in the anterior plate and screws was analysed. The study concludes that introducing anterior plate and screw fixation helps prevent cage subsidence. Physiological motion at the surgical level was reduced compared to the intact model. Adjacent disc stress was also evaluated and found to be lower than in the intact model.},
  archive      = {J_BECB},
  author       = {Pechimuthu Susai Manickam and Raja Dhason and Ryan Bock and Sonny Bal and Sandipan Roy and Shubhabrata Datta},
  doi          = {10.1177_11795972251321307},
  journal      = {Biomedical Engineering and Computational Biology},
  month        = {1-12},
  shortjournal = {Biomed. Eng. Comput. Biol.},
  title        = {Biomechanical evaluation of cervical interbody fusion cages for anterior cervical discectomy and fusion with variations in morphology: A finite element analysis},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prediction of potential drugs targeting acute pancreatitis based on the HLA-DR-related gene-monocyte infiltration regulatory network. <em>BECB</em>, <em>16</em>. (<a href='https://doi.org/10.1177_11795972251328458'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BECB},
  author       = {Wei Xu and Lan Hu and Shengyi Shi and Jie Gao and Jing Ye and Yiming Lu},
  doi          = {10.1177_11795972251328458},
  journal      = {Biomedical Engineering and Computational Biology},
  month        = {1-12},
  shortjournal = {Biomed. Eng. Comput. Biol.},
  title        = {Prediction of potential drugs targeting acute pancreatitis based on the HLA-DR-related gene-monocyte infiltration regulatory network},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Can smart alloy material improve the biomechanical behavior of prostheses used in the human trachea? a fluid-structure interaction approach. <em>BECB</em>, <em>16</em>. (<a href='https://doi.org/10.1177_11795972251330678'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BECB},
  author       = {Hamidreza Mortazavy Beni},
  doi          = {10.1177_11795972251330678},
  journal      = {Biomedical Engineering and Computational Biology},
  month        = {1-12},
  shortjournal = {Biomed. Eng. Comput. Biol.},
  title        = {Can smart alloy material improve the biomechanical behavior of prostheses used in the human trachea? a fluid-structure interaction approach},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Is it curbing-spread of SARS-CoV-2 variants by considering non-linear predictive control?. <em>BECB</em>, <em>16</em>. (<a href='https://doi.org/10.1177_11795972251321306'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although SARS-COV-2 started in 2019, its losses are still significant, and it takes victims. In the present study, the epidemic patterns of SARS-COV-2 disease have been investigated from the point of view of mathematical modeling. Also, the effect of quarantine has been considered. This mathematical model is designed in the form of fractional calculations along with a model predictive control (MPC) to monitor this model. The fractional-order model has the memory and hereditary properties of the system, which can provide more adjustable parameters to the designer. Because the MPC can predict future outputs, it can overcome the conditions and events that occur in the future. The results of the simulations show that the proposed nonlinear model predictive controller (NMPC) of fractional-order has a lower mean squared error in susceptible people compared to the optimal control of fractional-order (~3.6e-04 vs. 47.4). This proposed NMPC of fractional-order can be used for other models of epidemics.},
  archive      = {J_BECB},
  author       = {Mohadeseh Najafi and Hamidreza Mortazavy Beni and Ashkan Heydarian and Samaneh Sadat Sajjadi and Ahmad Hajipour},
  doi          = {10.1177_11795972251321306},
  journal      = {Biomedical Engineering and Computational Biology},
  month        = {1-12},
  shortjournal = {Biomed. Eng. Comput. Biol.},
  title        = {Is it curbing-spread of SARS-CoV-2 variants by considering non-linear predictive control?},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Screening biomarkers and risk factors for COVID-19 progression in a border population between brazil-bolivia. <em>BECB</em>, <em>16</em>. (<a href='https://doi.org/10.1177_11795972241298786'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BECB},
  author       = {Ana Maísa Passos-Silva and Adrhyan Araújo and Tárcio Peixoto Roca and Jackson Alves da Silva Queiroz and Gabriella Sgorlon and Rita de Cássia Pontello Rampazzo and Juan Miguel Villalobos Salcedo and Juliana Pavan Zuliani and Deusilene Vieira},
  doi          = {10.1177_11795972241298786},
  journal      = {Biomedical Engineering and Computational Biology},
  month        = {1-12},
  shortjournal = {Biomed. Eng. Comput. Biol.},
  title        = {Screening biomarkers and risk factors for COVID-19 progression in a border population between brazil-bolivia},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An enhanced hybrid model combining CNN, BiLSTM, and attention mechanism for ECG segment classification. <em>BECB</em>, <em>16</em>. (<a href='https://doi.org/10.1177_11795972251341051'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning models are necessary in the field of healthcare for the diagnosis of cardiac rhythm diseases since the conventional ECG classification is based on hand-crafted feature engineering and traditional machine learning. Nevertheless, CNN and BiLSTM architectures provide automatic feature learning, enhancing ECG classification accuracy. The current research work puts forward a framework integrating CNN with CBAM and BiLSTM layers for the purpose of extracting valuable features and classifying ECG signals. The model classifies heartbeats according to the AAMI EC57 standard into 5 categories: normal beats (N), supraventricular ectopic beats (S), ventricular ectopic beats (V), fusion beats (F), and unknown beats (Q). To tackle uneven class distributions, SMOTE synthesizes new samples, making the model more robust. Evaluation on MIT-BIH arrhythmia database yields remarkable results with 99.20% accuracy, 97.50% sensitivity, 99.81% specificity, and 98.29% mean F 1 score. Deep learning methods have great potential to alleviate clinicians’ workload and improve diagnostic accuracy of cardiac diseases.},
  archive      = {J_BECB},
  author       = {Mechichi Najia and Benzarti Faouzi},
  doi          = {10.1177_11795972251341051},
  journal      = {Biomedical Engineering and Computational Biology},
  month        = {1-12},
  shortjournal = {Biomed. Eng. Comput. Biol.},
  title        = {An enhanced hybrid model combining CNN, BiLSTM, and attention mechanism for ECG segment classification},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rib and sternum fractures from falls: Global burden of disease and predictions. <em>BECB</em>, <em>16</em>. (<a href='https://doi.org/10.1177_11795972251350223'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BECB},
  author       = {Zhanghao Huang and Jun Zhu},
  doi          = {10.1177_11795972251350223},
  journal      = {Biomedical Engineering and Computational Biology},
  month        = {1-12},
  shortjournal = {Biomed. Eng. Comput. Biol.},
  title        = {Rib and sternum fractures from falls: Global burden of disease and predictions},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analysis of muscle forces and their impact on femoral bone stresses using response surface methodology (RSM). <em>BECB</em>, <em>16</em>. (<a href='https://doi.org/10.1177_11795972251351766'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, reliability methods were demonstrated as a promising approach in medical engineering by identifying the most significant muscle forces affecting femoral stress. First, the finite element method (FEM) in Abaqus software was used to model the effects of 10 muscle and joint forces across various regions of the femur. Then, using the response surface methodology (RSM), and examining the effect coefficients of each joint and muscle force, the hip joint reaction force with an impact coefficient of 210.97 was identified as the most effective force on bone stress. After that, the gluteus minimus and gluteus medius muscle forces were ranked second and third in terms of stress effect with coefficients of 66.6 and 34.47. This study showed that the anterior femoral muscles have a significant effect on stress compared to the posterior femoral muscles. RSM enables faster and more precise identification of joint and muscle forces influencing femoral stresses compared to conventional methods. This innovative approach not only increased the understanding of biomechanical phenomena, but also provided a more efficient tool for investigating and optimizing such processes in biomedical engineering applications.},
  archive      = {J_BECB},
  author       = {Saeed Habibi and Mohammad Nazari Shalkouhi and Mohammad Javad Keyhani Dehnavi and Mahkame Sharbatdar and Aisa Rassoli},
  doi          = {10.1177_11795972251351766},
  journal      = {Biomedical Engineering and Computational Biology},
  month        = {1-12},
  shortjournal = {Biomed. Eng. Comput. Biol.},
  title        = {Analysis of muscle forces and their impact on femoral bone stresses using response surface methodology (RSM)},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning based model reveals the metabolites involved in coronary artery disease. <em>BECB</em>, <em>16</em>. (<a href='https://doi.org/10.1177_11795972251352014'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BECB},
  author       = {Fathima Lamya and Muhammad Arif and Mahbuba Rahman and Abdul Rehman Zar Gul and Tanvir Alam},
  doi          = {10.1177_11795972251352014},
  journal      = {Biomedical Engineering and Computational Biology},
  month        = {1-12},
  shortjournal = {Biomed. Eng. Comput. Biol.},
  title        = {Machine learning based model reveals the metabolites involved in coronary artery disease},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A numerical systematic review and meta-analysis of diagnosing the vibration modes of the cylindrical shell in the MRI machine. <em>BECB</em>, <em>16</em>. (<a href='https://doi.org/10.1177_11795972251353069'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetic Resonance Imaging (MRI) is a non-invasive imaging method that utilizes radio waves and magnetic fields. This study focuses on reducing the acoustic noise produced inside the cylindrical shell of the scanner, where the patient is located. Vibration modes are generated by eddy currents in the cylindrical shell induced by gradient magnetic fields. Additionally, the scanner wall is typically joined to the gradient spiral cylinder, causing vibrations to be transmitted to the wall and thereby producing extra sound waves. The present study investigates methods for mitigating noise from the scanner wall and reducing the transmission noise from the spiral gradient cylinder. Numerical methods and practical solutions for lowering acoustic noise in MRI gradient coils are explored. A 20 mm uniform absorber is demonstrated as an effective design for significantly reducing acoustic noise in the frequency range 0 to 3 kHz. Finally, numerical analysis of gradient cycles yields solutions that lower both vibration and noise levels.},
  archive      = {J_BECB},
  author       = {Hamidreza Mortazavy Beni and Fatemeh Aghaei and Ashkan Heydarian and Fatemeh Yekta Asaei and Hosein Samaram},
  doi          = {10.1177_11795972251353069},
  journal      = {Biomedical Engineering and Computational Biology},
  month        = {1-12},
  shortjournal = {Biomed. Eng. Comput. Biol.},
  title        = {A numerical systematic review and meta-analysis of diagnosing the vibration modes of the cylindrical shell in the MRI machine},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RunicNet: Leveraging CNNs with attention mechanisms for cervical cancer cell classification. <em>BECB</em>, <em>16</em>. (<a href='https://doi.org/10.1177_11795972251351815'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BECB},
  author       = {Erin Beate Bjørkeli and Morteza Esmaeili},
  doi          = {10.1177_11795972251351815},
  journal      = {Biomedical Engineering and Computational Biology},
  month        = {1-12},
  shortjournal = {Biomed. Eng. Comput. Biol.},
  title        = {RunicNet: Leveraging CNNs with attention mechanisms for cervical cancer cell classification},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring the landscape of operating room scheduling: A bibliometric analysis of recent advancements and future prospects. <em>BECB</em>, <em>16</em>. (<a href='https://doi.org/10.1177_11795972241271549'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BECB},
  author       = {Md Al Amin and Majed Hadid and Adel Elomri and Rabah Ismaen and Ismail Dergaa and Hind Alashi and Amal Jobran Al-Hajaji and Moustafa Alkhalil and Omar M Aboumarzouk and Abdelfatteh EL Omri},
  doi          = {10.1177_11795972241271549},
  journal      = {Biomedical Engineering and Computational Biology},
  month        = {1-12},
  shortjournal = {Biomed. Eng. Comput. Biol.},
  title        = {Exploring the landscape of operating room scheduling: A bibliometric analysis of recent advancements and future prospects},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sustainable E-health: Energy-efficient tiny AI for epileptic seizure detection via EEG. <em>BECB</em>, <em>16</em>. (<a href='https://doi.org/10.1177/11795972241283101'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tiny Artificial Intelligence (Tiny AI) is transforming resource-constrained embedded systems, particularly in e-health applications, by introducing a shift in Tiny Machine Learning (TinyML) and its integration with the Internet of Things (IoT). Unlike conventional machine learning (ML), which demands substantial processing power, TinyML strategically delegates processing requirements to the cloud infrastructure, allowing lightweight models to run on embedded devices. This study aimed to (i) Develop a TinyML workflow that details the steps for model creation and deployment in resource-constrained environments and (ii) apply the workflow to e-health applications for the real-time detection of epileptic seizures using electroencephalography (EEG) data. The methodology employs a dataset of 4097 EEG recordings per patient, each 23.5 seconds long, from 500 patients, to develop a robust and resilient model. The model was deployed using TinyML on microcontrollers tailored to hardware with limited resources. TensorFlow Lite (TFLite) efficiently runs ML models on small devices, such wearables. Simulation outcomes demonstrated significant performance, particularly in predicting epileptic seizures, with the ExtraTrees Classifier achieving a notable 99.6% Area Under the Curve (AUC) on the validation set. Because of its superior performance, the ExtraTrees Classifier was selected as the preferred model. For the optimized TinyML model, the accuracy remained practically unchanged, whereas inference time was significantly reduced. Additionally, the converted model had a smaller size of 256 KB, approximately ten times smaller, making it suitable for microcontrollers with a capacity of no more than 1 MB. These findings highlight the potential of TinyML to significantly enhance healthcare applications by enabling real-time, energy-efficient decision-making directly on local devices. This is especially valuable in scenarios with limited computing resources or during emergencies, as it reduces latency, ensures privacy, and operates without reliance on cloud infrastructure. Moreover, by reducing the size of training datasets needed, TinyML helps lower overall costs and minimizes the risk of overfitting, making it an even more cost-effective and reliable solution for healthcare innovations.},
  archive      = {J_BECB},
  author       = {Moez Hizem and Mohamed Ould-Elhassen Aoueileyine and Samir Brahim Belhaouari and Abdelfatteh EL Omri and Ridha Bouallegue},
  doi          = {10.1177/11795972241283101},
  journal      = {Biomedical Engineering and Computational Biology},
  month        = {1-12},
  shortjournal = {Biomed. Eng. Comput. Biol.},
  title        = {Sustainable E-health: Energy-efficient tiny AI for epileptic seizure detection via EEG},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Computed tomography-derived radiomics models for distinguishing difficult-to-diagnose inflammatory and malignant pulmonary nodules. <em>BECB</em>, <em>16</em>. (<a href='https://doi.org/10.1177_11795972251371467'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_BECB},
  author       = {Shaohong Wu and Xiaoyan Wang and Wenli Shan and Jiao Ren and Lili Guo},
  doi          = {10.1177_11795972251371467},
  journal      = {Biomedical Engineering and Computational Biology},
  month        = {1-12},
  shortjournal = {Biomed. Eng. Comput. Biol.},
  title        = {Computed tomography-derived radiomics models for distinguishing difficult-to-diagnose inflammatory and malignant pulmonary nodules},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="dsc">DSC - 1</h2>
<ul>
<li><details>
<summary>
(2025). Enhanced stratified sampling-density-based spatial clustering of applications with noise (SS-DBSCAN) for high-dimensional data. <em>DSC</em>, <em>8</em>(2). (<a href='https://doi.org/10.1177_24518492251349080'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research introduces an enhanced stratified sampling-density-based spatial clustering of applications with noise (SS-DBSCAN), a scalable and robust density-based clustering algorithm designed to tackle challenges in high-dimensional and complex data analysis. The algorithm integrates advanced parameter optimization techniques to improve clustering accuracy and interpretability. Key innovations include a fast grid search method for optimizing the search of optimal minimum points (MinPts) by keeping the ϵ parameter obtained constant. Notably, this study emphasizes the often-overlooked MinPts parameter, introducing a dynamic approach that initiates by calculating density metrics within a specified ϵ distance and adjusting the MinPts range based on the standard deviation of these metrics. This approach identifies optimal MinPts values based on the maximum allowed range. Comprehensive experiments on five real-world datasets demonstrate SS-DBSCAN’s superior performance compared to density-based spatial clustering of applications with noise (DBSCAN), hierarchical DBSCAN, and ordering points to identify the clustering structure (OPTICS), evidenced by higher silhouette and Davies–Bouldin index scores. The results highlight SS-DBSCAN’s ability to capture intrinsic clustering structures accurately, providing deeper insights across various research domains. SS-DBSCAN’s scalability and adaptability to diverse data densities make it a valuable tool for analyzing large, complex datasets.},
  archive      = {J_DSC},
  author       = {Gloriana Monko and Masaomi Kimura},
  doi          = {10.1177_24518492251349080},
  journal      = {Data Science},
  month        = {7-12},
  number       = {2},
  shortjournal = {Data Sci.},
  title        = {Enhanced stratified sampling-density-based spatial clustering of applications with noise (SS-DBSCAN) for high-dimensional data},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="eai">EAI - 15</h2>
<ul>
<li><details>
<summary>
(2025). Federated learning strategies for integrating composite meta-consistency loss with multi-head attention. <em>EAI</em>, <em>38</em>(4), 725-742. (<a href='https://doi.org/10.1177/30504554251340238'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to solve the problem of accuracy decline caused by feature redundancy, this paper designs a federated learning strategy that combines composite meta-consistency loss and multi-head attention. Firstly, this paper decorrelates the features based on the dual theory of constraints to eliminate redundant information, and improves the stability of the model through gradient-based regularization. Composite meta-consistency loss is constructed based on these two optimization methods. Experiments show that compared with the latest algorithms, the maximum accuracy of CIFAR-10 and Oxford-Pets in this paper is improved by 0.82% and 2.19%, respectively. After that, this paper introduces multi-head attention into the framework of federated learning. After capturing richer context information in the process of feature extraction, the combination of inner-layer update and outer-layer update of the meta-learning method enables the federated learning framework to effectively cope with the data distribution of different clients and finally accelerate the convergence speed. Compared with other algorithms, the average accuracy of the first 40 rounds in the MINIST, CIFAR-10 and CIFAR-100 data sets is higher. In CIFAR-10, SVHN, Oxford-Pets, taking Robust-HDP as the benchmark, the speedup ratio reaches 1.5, 1.42, and 1.34, respectively, which is faster than other algorithms.},
  archive      = {J_EAI},
  author       = {Afei Li and Xiaolei Yang and Li Ma and Lu Yu and Liyu Hao and Yongshan Liu},
  doi          = {10.1177/30504554251340238},
  journal      = {The European Journal on Artificial Intelligence},
  month        = {11},
  number       = {4},
  pages        = {725-742},
  shortjournal = {Eur. Artif. Intell.},
  title        = {Federated learning strategies for integrating composite meta-consistency loss with multi-head attention},
  volume       = {38},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MASNet: Multi-attention sparse network for light detection and ranging (LIDAR)-based three-dimensional (3D) object detection. <em>EAI</em>, <em>38</em>(4), 707-724. (<a href='https://doi.org/10.1177/30504554251340241'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies have shown that pillar-based detectors perform better in terms of both accuracy and speed, but these detectors perform poorly for detecting small objects such as pedestrians and cyclists. To solve this problem, we propose a highly efficient pillar-based model named MASNet, which mainly consists of a pillar mix attention (PMA) module, an attention-pooling operation, and a focal sparse network (FSN) module. The PMA module encodes the pillar features by fusion of the point-wise attention module and the channel-wise attention module. The attention-pooling operation aggregates the attention-encoded pillar features in a more comprehensive way to obtain the most expressive pillar features. In addition, the FSN module exploits the intrinsic sparsity of the data by introducing focal sparse convolution, which enriches the learned pillar features in the foreground without adding redundant pillars in other regions. On the KITTI three-dimensional (3D) Object Detection Benchmark, it achieves a 3D average precision of (77.81%, 60.30%, and 53.92%) in easy, moderate, and hard levels, which outperforms other pillar-based methods for the detection of cyclists. Additionally, our method is only 0.52% lower than the top-ranked method (pillar feature network (PIFENet)) on the KITTI Bird's Eye View pedestrian leaderboard, but our inference speed reaches 41 frames per second ahead of PIFENet by 57.69%.},
  archive      = {J_EAI},
  author       = {Fuqiang You and H Ziheng Zhang and Hao Chen},
  doi          = {10.1177/30504554251340241},
  journal      = {The European Journal on Artificial Intelligence},
  month        = {11},
  number       = {4},
  pages        = {707-724},
  shortjournal = {Eur. Artif. Intell.},
  title        = {MASNet: Multi-attention sparse network for light detection and ranging (LIDAR)-based three-dimensional (3D) object detection},
  volume       = {38},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal coupling prompt learning for image classification tasks. <em>EAI</em>, <em>38</em>(4), 684-706. (<a href='https://doi.org/10.1177/30504554251335569'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, vision-language pretraining (VLP) models have become a crucial driving force in the advancement of artificial intelligence. Besides, studies such as contrastive language-image pretraining (CLIP) have demonstrated that incorporating prompt learning within VLP models can significantly enhance the performance of downstream tasks. However, we believe that CLIP’s visual encoder suffers from feature extraction bias in image classification tasks, which is because of the uneven quantity and distribution of image features CLIP learned between the pretraining and fine-tuning stages. This can be further summarized as an inherent bias in feature extraction for differently distributed samples during the pretraining phase. To address the above problem this paper proposes (i) text-semantic hierarchical injection prompt learning method, which constructs self-attention layers and prompt mapping structures and injects text semantic features into the visual encoder layer by layer to generate visual prompt features and (ii) visual-semantic attention interactive prompt learning method, which further integrates text embeddings with the output features of the visual encoder through cross-attention and constructs instance-level text prompt features for each image. Based on the two above methods, this paper further proposes the multimodal coupling prompt learning CLIP (MCPL-CLIP) to enhance CLIP’s performance in image classification tasks. Experiments conducted on 15 image classification datasets demonstrate that MCPL-CLIP outperforms baseline models such as MaPLe, CoCoOp, and CoOp in cross-dataset transfer, domain generalization, and base-to-novel class generalization tasks, showcasing its superior text semantic representation and visual feature extraction capabilities.},
  archive      = {J_EAI},
  author       = {Yufei Liu and Hua Cheng and Yiquan Fang and Yiming Pan and Zehong Qian and Xiaoning Chen},
  doi          = {10.1177/30504554251335569},
  journal      = {The European Journal on Artificial Intelligence},
  month        = {11},
  number       = {4},
  pages        = {684-706},
  shortjournal = {Eur. Artif. Intell.},
  title        = {Multimodal coupling prompt learning for image classification tasks},
  volume       = {38},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). KANDiff: Low-light image enhancement based on diffusion models. <em>EAI</em>, <em>38</em>(4), 666-683. (<a href='https://doi.org/10.1177/30504554251342571'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-light image enhancement technique aims to improve the contrast and brightness of low-light images. Diffusion models, attributed to adeptness at capturing intricate details, have achieved good results in image enhancement, but there are problems such as inadequate estimation of noise characteristics and the emergence of color bias in the enhanced images. To address the aforementioned problems, this paper proposes a diffusion models-based method for low-light image enhancement, termed KANDiff. In the diffusion model architecture, this paper adds the nonlinear learnable activation function Kolmogorov–Arnold network to the noise estimation network U-Net to generate higher quality enhanced images. Additionally, KANDiff mitigates color bias in the enhanced images through a joint loss function and employs a patch-based image restoration strategy to significantly enhance the model generalization capability. The experimental results show that the KANDiff algorithm proposed in this paper can achieve high-quality image enhancement and achieve better enhancement effects compared to other algorithms.},
  archive      = {J_EAI},
  author       = {Yuanxin Ren and Minghui Yue and Yuxuan He and Liye Zhang},
  doi          = {10.1177/30504554251342571},
  journal      = {The European Journal on Artificial Intelligence},
  month        = {11},
  number       = {4},
  pages        = {666-683},
  shortjournal = {Eur. Artif. Intell.},
  title        = {KANDiff: Low-light image enhancement based on diffusion models},
  volume       = {38},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid biogeography-based optimization algorithm for distributed assembly permutation flowshop scheduling problem. <em>EAI</em>, <em>38</em>(4), 649-665. (<a href='https://doi.org/10.1177/30504554251347434'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The distributed assembly permutation flowshop scheduling problem (DAPFSP) has become a significant research topic in recent years. However, most existing studies rely on approximation search algorithms, such as metaheuristic algorithms, to address the high complexity of DAPFSP. To overcome the limitations of instability and poor search capability in these algorithms, this study proposes a hybrid biogeography-based optimization (HBBO) algorithm to solve DAPFSP with the objective of minimizing makespan. Two factory allocation methods are employed to generate initial solutions, reducing the possibility of redundant solutions. A crossover operator is utilized to improve the quality of partial solutions during the global search phase of HBBO. Additionally, four migration rate models are comprehensively tested as alternatives to commonly used models. Two neighborhood search methods are incorporated as the local search strategy for HBBO. The Metropolis acceptance criterion is employed to retain some inferior solutions, thereby enhancing solution diversity and preventing the algorithm from getting trapped in local optima. A series of experiments are conducted, and the computational results demonstrate that HBBO delivers promising results for DAPFSP.},
  archive      = {J_EAI},
  author       = {Long Cheng and Lei Wang and JingCao Cai and Kongfu Hu and Yuan Xiong and Qiangqiang Xia},
  doi          = {10.1177/30504554251347434},
  journal      = {The European Journal on Artificial Intelligence},
  month        = {11},
  number       = {4},
  pages        = {649-665},
  shortjournal = {Eur. Artif. Intell.},
  title        = {A hybrid biogeography-based optimization algorithm for distributed assembly permutation flowshop scheduling problem},
  volume       = {38},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-aspect graph representation feature integration for recommender dialogue system. <em>EAI</em>, <em>38</em>(4), 630-648. (<a href='https://doi.org/10.1177/30504554251347451'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation-based dialogue systems aim to capture user preferences via interactive conversations for personalized recommendations. While existing studies focus on modeling user preferences, real-time dialog scenarios face challenges in balancing historical conversation contexts and immediate interests. This study proposes MGIRD, a multi-aspect graph representation approach integrating ordinary graphs and hypergraphs. We use graph structures to model users’ current interests and hypergraphs for historical conversation features, while incorporating historical behaviors in the recommendation module to balance context relevance. A novel item selection mechanism is introduced during dialog generation to naturally integrate recommended items. Experiments on Chinese TG-Redial and English Redial datasets show MGIRD outperforms most state-of-the-art methods in recommendation accuracy and dialog diversity, validating its effectiveness in enhancing recommendation quality and conversational fluency.},
  archive      = {J_EAI},
  author       = {Shi Li and Qing Yang Bai},
  doi          = {10.1177/30504554251347451},
  journal      = {The European Journal on Artificial Intelligence},
  month        = {11},
  number       = {4},
  pages        = {630-648},
  shortjournal = {Eur. Artif. Intell.},
  title        = {Multi-aspect graph representation feature integration for recommender dialogue system},
  volume       = {38},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic graph anomaly detection model combining dual behavior contrast. <em>EAI</em>, <em>38</em>(4), 617-629. (<a href='https://doi.org/10.1177/30504554251347752'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current dynamic graph anomaly detection models learn multibehavior patterns for abnormal edges poorly and rely too much on the differences in long-term snapshots. Aiming at the above problems, combine dual behavior contrast dynamic graph anomaly detection model is proposed. Firstly, a dual behavior learning module is designed, where the role-based behavior learning submodule constructs graphlet degree vector by identifying four self-isomorphic orbits to capture deep structural features, while the attribute-based behavior learning submodule obtains attribute vectors through graph convolutional network. Then, the results are combined in the dynamic edge representation module to form the dynamic representations of edges to capture dual behavior patterns. Lastly, the anomaly detection module is designed to detect newly generated edges by combining contrastive learning with gated recurrent unit. We conduct experiments from four perspectives: anomaly detection accuracy, parameter sensitivity, robustness of module variants, and model runtime efficiency. The results demonstrate that the model achieves a peak accuracy of 92.05% in the task of dynamic edge anomaly detection.},
  archive      = {J_EAI},
  author       = {Jian Feng and Xiaotian Zhao},
  doi          = {10.1177/30504554251347752},
  journal      = {The European Journal on Artificial Intelligence},
  month        = {11},
  number       = {4},
  pages        = {617-629},
  shortjournal = {Eur. Artif. Intell.},
  title        = {Dynamic graph anomaly detection model combining dual behavior contrast},
  volume       = {38},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Action recognition based virtual panorama live broadcasting system. <em>EAI</em>, <em>38</em>(4), 601-616. (<a href='https://doi.org/10.1177/30504554251347439'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the significant success of transformers in natural language processing, an increasing number of researchers are introducing them into the field of computer vision, particularly for action recognition. As a crucial task in video understanding, action recognition has significant applications in live broadcasting, autonomous driving, and medical diagnostics. The attention mechanisms in transformers mimicking human visual attention allocation, thereby enhancing the processing capabilities and comprehension of long video sequences. However, they often overlook the aggregation of multiscale detail features and the hierarchical representations of early visual information. Additionally, attention networks are computationally intensive and parameter-heavy, complicating model training and extending inference times, rendering them unsuitable for real-time applications. To crack these nuts, we propose a lightweight multiscale action recognition model based on convolutional enhancement block (ConvEB) and multiscale average pooling encoder. The ConvEB aims to establish long-range dependencies among multiscale local features in the early stages of the network, providing effective inductive biases for the attention network to compensate for the loss of detailed information. Moreover, we introduce a parallel pooling mixer to replace the original attention mixer, ensuring model lightweight while maintaining recognition accuracy. Finally, we deploy this model in the construction of a virtual panorama live broadcasting system. Experimental results demonstrate that our action recognition algorithm achieves competitive performance, and the constructed panoramic system basically meets the needs of daily live broadcasting.},
  archive      = {J_EAI},
  author       = {Lichuan Geng and Zihao Zhao and Qiaohong Hou},
  doi          = {10.1177/30504554251347439},
  journal      = {The European Journal on Artificial Intelligence},
  month        = {11},
  number       = {4},
  pages        = {601-616},
  shortjournal = {Eur. Artif. Intell.},
  title        = {Action recognition based virtual panorama live broadcasting system},
  volume       = {38},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BSNet: Boundary-location network based on deep multi-scale modulation for camouflaged object detection. <em>EAI</em>, <em>38</em>(4), 581-600. (<a href='https://doi.org/10.1177/30504554251328322'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Camouflaged object detection (COD) aims to identify objects seamlessly embedded in the surrounding environment. Due to the high inherent similarity between the texture of the camouflaged object and its complex background, making COD far more challenging than traditional target detection. To solve these problems, we propose a method that uses holistic boundary information to optimize COD through a two-stage strategy. Specifically, the feature enhancement module is initially implemented to refine features at different scales and emphasize boundary details of camouflaged entities. Then, our network employs a boundary localization module to guide low-level local edge features through high-level global semantic. Furthermore, the boundary-embedded feature aggregation module is introduced to achieve cross-level fusion of multi-scale features, by embedding and effectively activating boundary information, which reduces the interference from cluttered backgrounds. Extensive experiments on four benchmark datasets demonstrate that our proposed model outperforms the other 17 state-of-the-art COD methods. The source code and results of our method are available at https://github.com/WObaibai/BSNet .},
  archive      = {J_EAI},
  author       = {Yuhong Chen and Meng Dai and Qing Zhang and Jiayun Wu},
  doi          = {10.1177/30504554251328322},
  journal      = {The European Journal on Artificial Intelligence},
  month        = {11},
  number       = {4},
  pages        = {581-600},
  shortjournal = {Eur. Artif. Intell.},
  title        = {BSNet: Boundary-location network based on deep multi-scale modulation for camouflaged object detection},
  volume       = {38},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design and implementation of a lightweight online human behavior recognition method for nighttime surveillance videos. <em>EAI</em>, <em>38</em>(4), 562-580. (<a href='https://doi.org/10.1177/30504554251347452'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to study human behavior recognition techniques in nighttime near-infrared surveillance videos and address the lack of lightweight behavior recognition networks in the field of nighttime near-infrared public monitoring. The goal is to develop a method suitable for lightweight edge processing devices. Due to the absence of a nighttime infrared video behavior recognition dataset, we have constructed a custom dataset for human behavior in near-infrared monitoring. This dataset involved 1630 video samples categorized into 10 classes. To overcome the challenge posed by large models and high device requirements, we propose a behavior recognition algorithm based on lightweight two-dimensional convolutional neural networks. This algorithm can adapt to low-quality near-infrared surveillance videos. Besides, it's able to focus on different temporal features and avoid interference from static background frames in long videos. The proposed method achieves an accuracy of 92.3% by using the self-built dataset captured by an active infrared camera and exhibits a processing speed of 35ms per video on the AGX Xavier device. Compared to popular lightweight algorithms like MoViNet-A0 and X3D-XS, this algorithm achieves higher accuracy and shorter processing time under similar model computational complexity.},
  archive      = {J_EAI},
  author       = {Mingrui Liu and Xiaogang Wang and Jiayi Zhou and Keyu Chen and Rui Song},
  doi          = {10.1177/30504554251347452},
  journal      = {The European Journal on Artificial Intelligence},
  month        = {11},
  number       = {4},
  pages        = {562-580},
  shortjournal = {Eur. Artif. Intell.},
  title        = {Design and implementation of a lightweight online human behavior recognition method for nighttime surveillance videos},
  volume       = {38},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-branch hybrid visual networks and hierarchical adaptive fusion strategy: An effective multimodal fake news detection model. <em>EAI</em>, <em>38</em>(4), 543-561. (<a href='https://doi.org/10.1177/30504554251351227'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current fake news detection models do not adequately extract fine-grained image features and also ignore the important impact of shallow text features on the results. In addition, the fusion methods are too simple and do not take into account the different importance of various information sources on the final detection results. To address these limitations, we propose a named Dual-branch Hybrid Visual Networks and Hierarchical Adaptive Fusion Strategy Model (DVHAM). Specifically, we design a dual-branch hybrid network based on transformer and convolutional neural network architecture. This network not only considers the global features of the image but also fully incorporates the local details of the image. In addition, we incorporate the hierarchical information of text to construct a hierarchical adaptive dynamic fusion module. The module employs a paired multihead attention mechanism and an adaptive adjustment strategy based on a gating mechanism. This design enables the model to capture and utilize the complementarity and correlation between the semantic and visual information at different levels in the text model. Simultaneously, it adaptively fuses the modal interaction features containing different information for the final detection task. DVHAM achieves an accuracy of 91.5%, 92.4%, and 90.6% on the Weibo, TWITTER, and PHEME datasets, respectively. This proves the effectiveness of DVHAM in the field of fake news detection.},
  archive      = {J_EAI},
  author       = {Xian Fu and Zhuzhu Zhang and Yu Sun and Tianrun Wu and Hui Zhang and Yaqiang Cao and Qi Cheng and Ningning Zhang},
  doi          = {10.1177/30504554251351227},
  journal      = {The European Journal on Artificial Intelligence},
  month        = {11},
  number       = {4},
  pages        = {543-561},
  shortjournal = {Eur. Artif. Intell.},
  title        = {Dual-branch hybrid visual networks and hierarchical adaptive fusion strategy: An effective multimodal fake news detection model},
  volume       = {38},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ME2FNet: Muti-level edge-enhanced fusion network for camouflaged object detection. <em>EAI</em>, <em>38</em>(4), 530-542. (<a href='https://doi.org/10.1177/30504554251351219'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Camouflaged object detection (COD) is an emerging research direction in computer vision in recent years, aiming to segment objects that are visually integrated with the background, which is a valuable task and has attracted increasing interest from researchers. Since camouflaged objects are integrated with their surroundings, their boundaries are also very blurred, and it becomes an important issue in COD to segment the edges of the objects accurately and completely. To address the above issues, in this article, we propose a novel multi-level edge-enhanced fusion for camouflaged object detection network (ME 2 FNet). Specifically, we design a residual texture enhanced module to obtain more refined features from the noise-filled backbone features. Then, we design an edge extraction module (EEM), which aims to extract effective edge semantic information from low-level features and high-level features by a simple local channel attention mechanism. Finally, we design a boundary-guided fusion module, which aims to fuse the previously obtained prior information. It can fuse the edge information extracted by EEM with the features at different levels of the backbone network, and guide the learning under the supervision of ground truth. At the same time, it fuses the high-level global information with the features at different levels, so that the final predicted edge is clearer and the overall structure is more complete. Extensive experiments on three challenging benchmark datasets have shown that ME 2 FNet outperforms multiple leading-edge models in recent years and achieves advanced results under four widely used evaluation metrics.},
  archive      = {J_EAI},
  author       = {Xuwei Tong and Guangjian Zhang and Yuhao Yang},
  doi          = {10.1177/30504554251351219},
  journal      = {The European Journal on Artificial Intelligence},
  month        = {11},
  number       = {4},
  pages        = {530-542},
  shortjournal = {Eur. Artif. Intell.},
  title        = {ME2FNet: Muti-level edge-enhanced fusion network for camouflaged object detection},
  volume       = {38},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging context-sensitivity for user-centered explainability. <em>EAI</em>, <em>38</em>(4), 496-529. (<a href='https://doi.org/10.1177/30504554251331568'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread integration of artificial intelligence (AI) into our daily lives has spurred an escalating demand for explainable AI (XAI). This demand is particularly pronounced in critical domains such as healthcare and finance, where understanding the decision-making processes of AI models is paramount. Despite noteworthy strides in XAI, prevailing approaches often neglect the crucial dimension of context, resulting in explanations that are challenging to comprehend and act upon for different stakeholders. This paper advocates for a paradigm shift towards context-sensitive explainability, tailoring explanations to users’ specific needs and understanding promoting inclusivity and accessibility. We propose a novel context taxonomy and a versatile framework, “ConEX” for developing context-sensitive explanations using any state-of-the-art post hoc explainer. Our empirical user study highlights diverse preferences for contextualization levels, emphasizing the importance of catering to these preferences to build trust and satisfaction in AI systems. Our contributions extend beyond the theoretical realm, offering practical guidance for developing context-sensitive explanations that are tailored to the specific needs of diverse stakeholders. By embracing context-sensitive explainability, we can unlock the true potential of AI, fostering trust, transparency, and informed decision-making across various domains.},
  archive      = {J_EAI},
  author       = {Yasmeen Khaled and Nourhan Ehab},
  doi          = {10.1177/30504554251331568},
  journal      = {The European Journal on Artificial Intelligence},
  month        = {11},
  number       = {4},
  pages        = {496-529},
  shortjournal = {Eur. Artif. Intell.},
  title        = {Leveraging context-sensitivity for user-centered explainability},
  volume       = {38},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A methodology and a platform for high-quality rich personal data collection#. <em>EAI</em>, <em>38</em>(4), 474-495. (<a href='https://doi.org/10.1177/30504554251333615'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, pervasive use of sensors in smart devices, e.g., phones, watches, medical devices, has increased dramatically the availability of personal data. However, existing research on data collection primarily focuses on the objective view of reality, as provided, for instance, by sensors, often neglecting the integration of subjective human input, as provided, for instance, by user answers to questionnaires. This limits substantially the exploitability of the collected data. In this paper, we present a methodology and a platform designed for the collection of a combination of large-scale sensor data and qualitative human feedback. The methodology has been designed to be deployed on top, and enrich functionalities of an existing data collection APP, called iLog, which has been used in large scale, worldwide data collection experiments. The main goal is to put the key actors involved in an experiment, i.e., the researcher in charge, the participant, and iLog in better control of the experiment itself, thus improving the quality and richness of the data collected. The novel functionalities of the resulting platform are: (i) a time-wise representation of the situational context within which the data collection is performed, (ii) an explicit representation of the temporal context within which the data collection is performed, (iii) a calendar-based dashboard for the real-time monitoring of the data collection context(s), and, (iv) a mechanism for the run-time revision of the data collection plan. The practicality and utility of the proposed functionalities are demonstrated in a case study involving 350 University students.},
  archive      = {J_EAI},
  author       = {Ivan Kayongo and Leonardo Malcotti and Haonan Zhao and Fausto Giunchiglia},
  doi          = {10.1177/30504554251333615},
  journal      = {The European Journal on Artificial Intelligence},
  month        = {11},
  number       = {4},
  pages        = {474-495},
  shortjournal = {Eur. Artif. Intell.},
  title        = {A methodology and a platform for high-quality rich personal data collection#},
  volume       = {38},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A conversational agent that learns to be aligned with the moral value of respect. <em>EAI</em>, <em>38</em>(4), 457-473. (<a href='https://doi.org/10.1177/30504554241311168'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Videogame developers typically conduct user experience surveys to gather feedback from users once they have played. Nevertheless, as users may not recall all the details once finished, we propose an ethical conversational agent that respectfully conducts the survey during gameplay. To achieve this without hindering user’s engagement, we resort to reinforcement learning and an ethical embedding algorithm. Specifically, we transform the learning environment so that it guarantees that the agent learns to be respectful (i.e. aligned with the moral value of respect) while pursuing its individual objective of eliciting as much feedback information as possible. When applying this approach to a simple videogame, our comparative tests between the two agents (ethical and unethical) empirically demonstrate that endowing a survey-oriented conversational agent with this moral value of respect avoids disturbing user’s engagement while still pursuing its individual objective, which is to gather as much information as possible.},
  archive      = {J_EAI},
  author       = {Eric Roselló-Marín and Inmaculada Rodríguez and Maite Lopez-Sanchez and Manel Rodríguez-Soto and Juan Antonio Rodríguez-Aguilar},
  doi          = {10.1177/30504554241311168},
  journal      = {The European Journal on Artificial Intelligence},
  month        = {11},
  number       = {4},
  pages        = {457-473},
  shortjournal = {Eur. Artif. Intell.},
  title        = {A conversational agent that learns to be aligned with the moral value of respect},
  volume       = {38},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="icae">ICAE - 7</h2>
<ul>
<li><details>
<summary>
(2025). Models and tools for supporting sustainability assessment in systems engineering. <em>ICAE</em>, <em>32</em>(3), 326-342. (<a href='https://doi.org/10.1177/10692509251352461'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since several years, sustainability has become a very important challenge for our societies. Our lifestyles are in the process of making our planet uninhabitable because of the various impacts that we, as human beings, are inflicting on it. As part of these impacts, we focus on Complex Systems designed by humans. It is of uttermost importance to be able to analyze and design complex systems so that the sustainability features are taken into account. More specifically, the contribution of this article is to propose models and tools for the assessment of systems sustainability during the analysis and design phases. The analysis and design of systems may be difficult tasks. It is even more so for complex systems. Since decades, the System Engineering (SE) field has given birth to a family of systemic and multidisciplinary approaches for the design of systems. Among SE approaches, Model-Based System Engineering (MBSE) is a special kind of SE that relies on formalized models as first-class citizens deliverables for all analysis and design activities from requirements elicitation to final design and validation. SysML (Systems Modelling Language) is one of these MBSE approaches. SysML is a well-known, general purpose graphical systems modelling language that supports SE approaches. In addition, SysML allows its own language extension by the creation of new concepts and diagrams. This extension mechanism is known as Domain Specific Modelling Language (DSML). The contributions presented in this paper consist in the definition of an extension of SysML that provides models and tools in order to assess the sustainability of systems during analysis and design. This extension of SysML is based upon a technique, named profile, and proposes new modelling concepts for taking into consideration sustainability issues during systems engineering. Moreover, these new model elements are supported by software tools issued from the MBSE domain and allow the development of ad-hoc software tooling support.},
  archive      = {J_ICAE},
  author       = {Vincent Hilaire and Alexis Lalevée},
  doi          = {10.1177/10692509251352461},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {8},
  number       = {3},
  pages        = {326-342},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Models and tools for supporting sustainability assessment in systems engineering},
  volume       = {32},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design and implementation of an internet of things automatic solar shading system. <em>ICAE</em>, <em>32</em>(3), 309-325. (<a href='https://doi.org/10.1177/10692509251318454'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The implementation of energy-saving solutions becomes increasingly crucial as global energy reserves decline. The integration of automated solar shading systems not only improves living conditions, but also reduces energy costs. This work presents the design and implementation of an Internet of Things (IoT) automatic solar shading system. The developed solar shading includes custom-made louvers that are able to reflect the external light, while being transparent. Moreover, the system is equipped with a microcontroller and appropriate sensors that enable its automated operation based on measurements of the internal and external environmental conditions. A Raspberry Pi acts as a server, enabling the communication between the shading devices and the users, through an open-source home automation operating system (Home Assistant OS). The user-friendly interface, accessible via a web browser or a mobile application, provides essential data such as temperature, humidity, and device status. Alert notifications are sent when specific conditions are met. The overall system is enclosed in two 3D-printed units, ensuring its durability and easy integration into existing or new installations. In summary, this system combines the advantages of automatic solar shadings, including energy efficiency and improved occupant comfort, with smart features for remote control and monitoring through a user-friendly interface. The proposed system has been installed in a window of our laboratory, performing successfully in real-life conditions.},
  archive      = {J_ICAE},
  author       = {Georgia Stamou and Spyridon Angelopoulos and Nikolaos Stefanakis and Evangelos Hristoforou},
  doi          = {10.1177/10692509251318454},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {8},
  number       = {3},
  pages        = {309-325},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Design and implementation of an internet of things automatic solar shading system},
  volume       = {32},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Digital shielding for cross-domain wi-fi signal adaptation using relativistic average generative adversarial network. <em>ICAE</em>, <em>32</em>(3), 292-308. (<a href='https://doi.org/10.1177/10692509251339913'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wi-Fi sensing exploits radio-frequency signals emitted by Wi-Fi devices to analyze environments, enabling tasks such as people tracking, intruder detection, and gesture recognition. Its growing diffusion is driven by the IEEE 802.11bf standard, which facilitates environmental monitoring, and the increasing demand for tools capable of penetrating obstacles while preserving privacy. However, the performance of Wi-Fi-based sensing solutions is influenced by the environment in which signals are acquired. This is critical when extracting spatial and temporal information from the surrounding scene, as such data reflect both environmental structure and interference sources. A main challenge is achieving generalization across domains, that is, ensuring consistent performance under varying conditions, such as different rooms or buildings, without significant accuracy loss. This paper presents a deep model for domain adaptation of Wi-Fi signals by simulating a digital shielding mechanism. The model is based on a Relativistic average Generative Adversarial Network (RaGAN), which mimics physical shielding to suppress domain-specific features while preserving signal integrity. Both the generator and discriminator use Bidirectional Long Short-Term Memory (Bi-LSTM) architectures, enabling modeling of waveform and time-dimension signal characteristics. To support training, an acrylic box lined with electromagnetic shielding fabric, replicating a Faraday cage, was constructed. Spectra from same-sized objects made of different materials were acquired both inside (domain-free) and outside (domain-dependent) the box. A multi-class Support Vector Machine (SVM), trained on shielded spectra and tested on RaGAN-denoised data, achieved 96 percent accuracy. The SVM also distinguished materials, suggesting a promising approach for security systems aimed at identifying the nature and composition of potentially dangerous objects.},
  archive      = {J_ICAE},
  author       = {Danilo Avola and Federica Bruni and Gian Luca Foresti and Daniele Pannone and Amedeo Ranaldi},
  doi          = {10.1177/10692509251339913},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {8},
  number       = {3},
  pages        = {292-308},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Digital shielding for cross-domain wi-fi signal adaptation using relativistic average generative adversarial network},
  volume       = {32},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An automated workflow based on UAV imagery and deep learning methods for monitoring excavation area work. <em>ICAE</em>, <em>32</em>(3), 272-291. (<a href='https://doi.org/10.1177/10692509251340464'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid advancement of Artificial Intelligence (AI) is transforming the construction sector, particularly in site monitoring and safety management. Real-time monitoring enables the automatic detection of work progress issues, anomalies, and hazardous situations. However, no existing Deep Learning (DL)-based system is specifically designed to utilize Unmanned Aerial Vehicles (UAVs) for excavation area monitoring. This study presents an automated workflow that integrates UAV imagery with DL architectures, featuring a 1D Convolutional Neural Network (1D-CNN) for classifying excavation work phases and a VGG16 network for detecting safety fences. These technologies are incorporated into a Decision Support System (DSS), which automates report generation and enhances decision-making by providing structured, data-driven insights. The system was validated in a real-world case study involving an oil and gas construction company, demonstrating its ability to streamline site management tasks and improve safety oversight. Compared to traditional monitoring methods, our approach leverages UAV technology and DL methodologies to provide higher accuracy, efficiency, and scalability in excavation site monitoring. This contribution supports the digital transformation of construction management, offering a practical and innovative solution for real-time progress tracking and compliance verification.},
  archive      = {J_ICAE},
  author       = {Riccardo Rosati and Matteo Fabiani and Roberto Pierdicca and Adriano Mancini},
  doi          = {10.1177/10692509251340464},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {8},
  number       = {3},
  pages        = {272-291},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {An automated workflow based on UAV imagery and deep learning methods for monitoring excavation area work},
  volume       = {32},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A cost-effective autonomous underwater system for small size object detection. <em>ICAE</em>, <em>32</em>(3), 258-271. (<a href='https://doi.org/10.1177/10692509251336668'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {According to US National Oceanic and Atmospheric Administration (NOAA), we have only explored five percent of our world ocean. Among the ocean exploration tasks, underwater object detection is a multidisciplinary challenge that extends beyond engineering into fields such as oceanography, marine biology, and environmental science. Scientifically, it involves understanding the complex interactions between sound waves, light, and water, as well as the navigation dynamics within marine environments. The underwater environment presents unique physical challenges for object detection due to factors like light attenuation, turbidity, and the variability of acoustic propagation. This paper introduces a cost-effective autonomous underwater prototype for real-time detection, and localization of small underwater objects (e.g., archaeological artifacts, parts of infrastructures, wreckage debris, but also life forms like fishes, corals etc.) in shallow waters. The system combines object identification with autonomous navigation capabilities. It consists of an autonomous underwater vehicle equipped with sensors, cameras, and localization tools, as well as a ground control station for monitoring and intervention. In particular, we focus on a case study about detecting and reporting the locations of unexploded ordnance materials, contributing to the monitoring of underwater hazards in conflict-affected regions. Key contributions include the integration of a cost-effective autonomous remotely operated vehicle with sensors and software for real-time detection and localization of small underwater objects, as well as an annotated dataset of UXO images, usable as a benchmark.},
  archive      = {J_ICAE},
  author       = {Denis Tavaris and Leonardo Scandino and Gian Luca Foresti and Ivan Scagnetto},
  doi          = {10.1177/10692509251336668},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {8},
  number       = {3},
  pages        = {258-271},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {A cost-effective autonomous underwater system for small size object detection},
  volume       = {32},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Segmentation networks for detecting overlapping screws in 3D and color images for industrial quality control. <em>ICAE</em>, <em>32</em>(3), 244-257. (<a href='https://doi.org/10.1177/10692509251328780'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores cost-effective, real-time strategies for bin picking in industrial quality control. An anomaly detection solution was developed for a screw production plant, utilizing machine vision and AI to identify overlapping screws as anomalies. Two improvements are proposed to a basic solution initially relying on a laser profiler for depth images. The first improvement applies a Convolutional Neural Network (CNN) to the laser profiler's output, and the second replaces the laser profiler with a camera that captures color images, applying a CNN to its output. The first improvement was tested with real laser profiler data using YOLOv8 and Mask R-CNN segmentation models. After achieving comparable results on the real dataset, the second improvement was tested on multiple synthetic datasets, simulating different scenarios, including setups with mixed screws. Results demonstrated that model performance on color images, represented in the RGB color space (red, green, and blue), was comparable to depth images, validating color cameras as an appropriate alternative. Since color cameras are cheaper and capture images faster, they are well-suited for high-speed quality control systems, offering significant cost and performance advantages. Code is available at: https://github.com/enmarchi/overlapping_screws_geneneration_code .},
  archive      = {J_ICAE},
  author       = {Enrico Marchi and Daniele Fornasier and Alberto Miorin and Gian Luca Foresti},
  doi          = {10.1177/10692509251328780},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {8},
  number       = {3},
  pages        = {244-257},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Segmentation networks for detecting overlapping screws in 3D and color images for industrial quality control},
  volume       = {32},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gravity-constrained simultaneous localization and mapping for suppressing map warping in complex large-scale environments. <em>ICAE</em>, <em>32</em>(3), 229-243. (<a href='https://doi.org/10.1177/10692509251331372'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simultaneous Localization and Mapping (SLAM) serves as a foundational technology for autonomous systems operating within large-scale, complex environments. Traditional SLAM methodologies, however, are prone to altitude-axis distortions resulting from cumulative errors. To mitigate these issues, Gravity-Constrained SLAM (GC-SLAM) is introduced as a novel computational method that integrates gravity constraints and incremental optimisation to enhance mapping accuracy and computational efficiency. GC-SLAM incorporates a gravity constraint handling actor within the global optimisation algorithm, effectively reducing vertical-axis errors caused by accumulated drift during mapping. Furthermore, an incremental optimisation strategy is employed to manage the computational complexity associated with increasing map size. Performance evaluations of GC-SLAM are conducted on the KITTI dataset and large-scale environments, comparing its effectiveness against state-of-the-art SLAM-based algorithms, including FAST-LIO2, LIO-SAM (Lidar Inertial Odometry and SLAM), Lego-LOAM (Lightweight and Ground-optimised Lidar Odometry and Mapping), and A-LOAM (Advanced Lidar Odometry and Mapping). Experimental results demonstrate that GC-SLAM effectively suppresses vertical-axis distortions, significantly enhances localisation accuracy, and outperforms competing methods.},
  archive      = {J_ICAE},
  author       = {Kaiyi Xian and Duo Liu and Gexiang Zhang and Ferrante Neri and Song Chen},
  doi          = {10.1177/10692509251331372},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {8},
  number       = {3},
  pages        = {229-243},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Gravity-constrained simultaneous localization and mapping for suppressing map warping in complex large-scale environments},
  volume       = {32},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="ida">IDA - 14</h2>
<ul>
<li><details>
<summary>
(2025). Multi-strategy improved african vulture optimization algorithm for global optimization and engineering design problems. <em>IDA</em>, <em>29</em>(5), 1313-1344. (<a href='https://doi.org/10.1177_1088467X241301637'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a multi-strategy improved African Vulture Optimization Algorithm (MIAVOA) is proposed address the drawback of premature convergence of the African Vulture Optimization Algorithm (AVOA). Firstly, the gaussian quasi reflection-based learning strategy is introduced, which improves the vulture initial population’s randomness and diversity. Then, the adaptive control strategy is used to enhance the search ability of the algorithm and avoid premature convergence. Furthermore, the elite candidate pooling strategy is designed in the exploitation phase, which expands the discovery fields for the optimal solution and reinforces the ability to escape from local optima. Finally, the formula of starvation factor is modified to balance the exploitative and explorative abilities of algorithm. MIAVOA is compared with seven state-of-the-art meta-heuristics on CEC 2022 and 23 classical test functions. It is observed that the proposed algorithm significant outperforms the other compared algorithms in terms of convergence and accuracy on the majority of benchmark functions. In addition, four engineering design problems and mobile robot path planning problem are utilized to evaluate the performance of MIAVOA. The experimental results demonstrate MIAVOA is effective and can achieve better applicability in real-world scenarios.},
  archive      = {J_IDA},
  author       = {Xinzhe Li and Qingyang Zhang and Shengxiang Yang and Yongquan Dong},
  doi          = {10.1177_1088467X241301637},
  journal      = {Intelligent Data Analysis},
  month        = {9},
  number       = {5},
  pages        = {1313-1344},
  shortjournal = {Intell. Data Anal.},
  title        = {Multi-strategy improved african vulture optimization algorithm for global optimization and engineering design problems},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Livernet based segmentation of lesions from computed tomography scan for liver tumor detection. <em>IDA</em>, <em>29</em>(5), 1289-1312. (<a href='https://doi.org/10.1177/1088467X241301660'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Millions of lives could be saved annually if liver tumours could be detected early with computed tomography. But it's a huge strain for radiologists to read hundreds or even tens of these CT scans. Therefore, developing an autonomous, rapid, and reliable method of reading, detecting, and assessing CT scans is important. However, extracting the liver region from CT scans is a bottleneck for any approach. This paper introduces a three-part automatic process. Initial processing includes noise suppression and image enhancement. Optimized Bi-lateral Filtering is used to carry it out; in this case, the process's control parameters are optimized using the Monarch butterfly optimization method. After that, automatic liver segmentation and lesion identification are performed. Mask-Region-based Convolutional Neural Network segment liver from the pre-processed images. Then a new generator network named LiverNet is used to detect tumors within the liver. Finally, an Enhanced Swin Transformer Network employing Adversarial Propagation distinguishes between malignant and benign liver lesions. Positive developments were discovered as a result of the inquiry. Expert results are associated with the consequences of segmentation and analysis. The classifier makes a relatively accurate tumour differentiation and gives the radiologist a second opinion.},
  archive      = {J_IDA},
  author       = {Priyan Malarvizhi Kumar and Hardik Gohel and Jeeva Selvaraj and Balasubramanian Prabhu Kavin},
  doi          = {10.1177/1088467X241301660},
  journal      = {Intelligent Data Analysis},
  month        = {9},
  number       = {5},
  pages        = {1289-1312},
  shortjournal = {Intell. Data Anal.},
  title        = {Livernet based segmentation of lesions from computed tomography scan for liver tumor detection},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). YONET: A unified model for simultaneous identification and segmentation of structures in medical images. <em>IDA</em>, <em>29</em>(5), 1275-1288. (<a href='https://doi.org/10.1177/1088467X241301679'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proposed novel model, YONET, performs the identification and segmentation of medical images collaboratively. Many types of image-processing software are being developed to extract meaningful information from medical photos to enhance patient diagnosis. Simultaneous segmentation and object detection is a computer vision task that combines object detection and image segmentation, two related functions usually done separately. It involves detecting objects in an image and generating a segmentation mask for each object. This assortment of tasks can enhance the precision and velocity of object detection by providing more accurate object boundaries and, in some cases, eliminating the need for post-processing steps. The image segmentation module in YONET handles intermediate abstract representations and utilizes them as input for object detection. YONET will be trained on bounding boxes that delineate the detected objects and pixel-wise segmentation information. The resultant system is optimized for segmenting an optionally distinct class of structures and detecting a class of objects.},
  archive      = {J_IDA},
  author       = {M Bhavani and Prithi Samuel},
  doi          = {10.1177/1088467X241301679},
  journal      = {Intelligent Data Analysis},
  month        = {9},
  number       = {5},
  pages        = {1275-1288},
  shortjournal = {Intell. Data Anal.},
  title        = {YONET: A unified model for simultaneous identification and segmentation of structures in medical images},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-prompt complementary fusion network for RGBT tracking. <em>IDA</em>, <em>29</em>(5), 1261-1274. (<a href='https://doi.org/10.1177/1088467X241308764'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGBT target tracking is a significant downstream task in the field of object tracking. However, compared to visible light target tracking, RGBT target tracking faces the challenge of smaller datasets, making it difficult to achieve performance levels comparable to those achieved in visible light target tracking. To address how to effectively combine the complementary characteristics of visible and thermal modalities, as well as how to fully leverage the superior performance of models trained on visible light target tracking tasks, while also aiming for lower computational costs and higher tracking effectiveness, a dual-prompt complementary fusion strategy for an RGBT tracking network is proposed. Drawing on the concept of prompt learning, this network aims to extend the efficient performance of visible light target tracking to the RGBT target tracking domain. In its implementation, the prompt module inputs both visible and thermal modality information as dual prompts into the backbone network, where the network utilizes these prompts to generate new, enriched prompt information at each layer. Subsequently, an information enhancement fusion module enhances the acquired prompt information and refeeds it into the backbone network, aiming to improve the tracking accuracy and robustness. Experimental results on GTOT, RGBT234 and LasHeR datasets show that the tracking accuracy (PR) and success rate (SR) of the network reach 93.1%/76.8%, 84.4%/62.4% and 66.8%/53.8%, respectively, which is improved compared with the current mainstream RGBT target tracking network, which verifies the effectiveness of the network.},
  archive      = {J_IDA},
  author       = {Xihui Wu and Hongwei Ge and Ting Li and Shuzhi Su},
  doi          = {10.1177/1088467X241308764},
  journal      = {Intelligent Data Analysis},
  month        = {9},
  number       = {5},
  pages        = {1261-1274},
  shortjournal = {Intell. Data Anal.},
  title        = {Dual-prompt complementary fusion network for RGBT tracking},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bilingual generated text detection through semantic and statistical analysis. <em>IDA</em>, <em>29</em>(5), 1248-1260. (<a href='https://doi.org/10.1177_1088467X241307192'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The release of Large Language Models (LLMs) has achieved human-level text generation, leading to malicious uses such as disinformation propagation and academic dishonesty. Existing research has faced substantial challenges in low detection rates and poor generalization on multilingual generated text and short text. To fill these gaps, in this paper, we propose a generic bilingual generated text detection model to integrate semantic and statistical features, which exhibits proficiency in English and Chinese. To obtain fine-grained features, we employ the multilingual pre-trained language model xlm-RoBERTa to extract the CLS vector as overall semantic features, integrating with statistical features log rank, probability, and cumulative probability for detection. Moreover, Shapley additive explanations (SHAP) serves to interpret the decision-making process. The experimental results demonstrate significant advancements over baselines, notably with the F1 score improvements exceeding 10% and 5% on the English and Chinese HC3 sentence-level datasets, respectively. Our proposed method exhibits higher generalization for advanced LLMs and out-of-domain datasets with a 91.13% F1 score, thereby providing a more robust solution for detecting generated text.},
  archive      = {J_IDA},
  author       = {Chenxi Min and Ru Zhang and Jianyi Liu},
  doi          = {10.1177_1088467X241307192},
  journal      = {Intelligent Data Analysis},
  month        = {9},
  number       = {5},
  pages        = {1248-1260},
  shortjournal = {Intell. Data Anal.},
  title        = {Bilingual generated text detection through semantic and statistical analysis},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring data augmentation techniques for advancing emotion recognition in text - An ANOVA-RFE fusion approach with emotion fusion ensemble. <em>IDA</em>, <em>29</em>(5), 1219-1247. (<a href='https://doi.org/10.1177/1088467X251325354'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion recognition in text is a complex challenge essential for enhancing human-computer interaction. This study introduces an advanced system utilizing the EmoBank dataset, which contains text annotated with six basic emotions from diverse sources like social media, narratives, news articles, and movie scripts, ensuring accurate labeling through automated algorithms and manual annotation. Extensive preprocessing techniques, including tokenization, lowercasing, stop words removal, stemming, lemmatization, punctuation removal, handling special characters and numbers, text normalization, and encoding, prepare the text for analysis. Data augmentation methods such as random insertion, deletion, swapping, synonym replacement, and leveraging Large Language Models (LLMs) like GPT-3, BERT, and RoBERTa enrich the dataset. Feature extraction combines word embeddings with self-attention mechanisms to capture contextual and semantic information. The ANOVA-RFE Fusion technique is applied for feature selection, while the Emotion Fusion Ensemble (EFE) method enhances classification by combining Random Forest, Gradient Boosting, AdaBoost, XGBoost, Extra Trees, SVM, and K-NN. Systematic experimentation and hyperparameter tuning using grid search validate the system's performance. Notably, the combination of GPT-3+WE+ANOVA-RFE+EFE achieved 89% accuracy before tuning and 94% after tuning. This research underscores the critical role of integrated processing, augmentation, and ensemble learning in advancing emotion recognition, suggesting future exploration of emerging language models, novel augmentation techniques, and domain specific adaptations for developing more accurate and robust systems.},
  archive      = {J_IDA},
  author       = {Nirmal Varghese Babu and E. Grace Mary Kanaga},
  doi          = {10.1177/1088467X251325354},
  journal      = {Intelligent Data Analysis},
  month        = {9},
  number       = {5},
  pages        = {1219-1247},
  shortjournal = {Intell. Data Anal.},
  title        = {Exploring data augmentation techniques for advancing emotion recognition in text - An ANOVA-RFE fusion approach with emotion fusion ensemble},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel HVAC fuzzy controller based on improved snake optimizer algorithm. <em>IDA</em>, <em>29</em>(5), 1199-1218. (<a href='https://doi.org/10.1177_1088467X241303347'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heating, ventilation, and air conditioning (HVAC) systems are characterized by time-varying, nonlinear, and parametric coupling, making it challenging to design their controllers. As a major source of energy consumption in buildings, the control schemes for HVAC systems need to be optimized to improve energy efficiency. To address the above issues, a fuzzy controller was designed to regulate the HVAC system, and an improved snake optimizer (ISO) was proposed to optimize the membership function of the fuzzy controller in this study. In the ISO algorithm, the parameter Threshold of the snake optimizer (SO) was dynamically adjusted, and the snake egg-hatching formula was improved. Benchmark function tests show that the convergence speed and optimization accuracy of ISO are superior to those of the established comparison algorithms. Furthermore, simulation experiments indicate that the ISO-optimized HVAC system has a temperature error of 0 and a humidity ratio error of less than 1.5% compared to competing methods. In addition, the ISO-optimized HVAC system achieves a 40.8% reduction in annual energy consumption.},
  archive      = {J_IDA},
  author       = {Zuqiang Long and Jiaying Gu and Zhiyong Hu and Ke Sun},
  doi          = {10.1177_1088467X241303347},
  journal      = {Intelligent Data Analysis},
  month        = {9},
  number       = {5},
  pages        = {1199-1218},
  shortjournal = {Intell. Data Anal.},
  title        = {A novel HVAC fuzzy controller based on improved snake optimizer algorithm},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Performance comparison: Cloud-based vs. open-source NER for english and polish. <em>IDA</em>, <em>29</em>(5), 1187-1198. (<a href='https://doi.org/10.1177_1088467X241305521'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Named Entity Recognition (NER) plays a vital role in Natural Language Processing (NLP) tasks, extracting valuable information from textual data. This study addresses a gap in NER research by comparing the effectiveness of cloud-based NER tools (Azure NER and Google Cloud NER) and a popular open-source tool (SpaCy) for recognizing named entities in both English and Polish text. Text data is imported into a PostgreSQL database and processed by each NER tool. The extracted entities and their labels are stored in a dedicated SQL Entity table, enabling performance evaluation across different languages and entity types. This research contributes to the field of NLP by investigating the suitability of cloud-based NER tools for multilingual tasks, particularly those involving Polish text, which presents unique linguistic challenges. By analyzing the performance of these NER approaches, the study provides valuable insights for selecting the most effective NER technique for specific NLP applications, especially when dealing with multilingual content.},
  archive      = {J_IDA},
  author       = {Lukasz Pawlik},
  doi          = {10.1177_1088467X241305521},
  journal      = {Intelligent Data Analysis},
  month        = {9},
  number       = {5},
  pages        = {1187-1198},
  shortjournal = {Intell. Data Anal.},
  title        = {Performance comparison: Cloud-based vs. open-source NER for english and polish},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Some novel probabilistic dual hesitant fuzzy information measures and their applications to multi-attribute decision-making. <em>IDA</em>, <em>29</em>(5), 1153-1186. (<a href='https://doi.org/10.1177/1088467X241308761'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probabilistic dual hesitant fuzzy set (PDHFS), as an extension of dual hesitant fuzzy set (DHFS) and probabilistic hesitant fuzzy set (PHS), can better describe the uncertainty and fuzziness in the real world through membership degree (MD) and non-membership degree (NMD) and their respective probability information. Therefore, it can collect more comprehensive fuzzy information in decision-making issues, which makes PDHFS has a wide range of applications in practice. The distance, similarity and entropy measures (EMs) of PDHFSs were studied. Due to the particularity of PDHFS, the length of MD and NMD of two probabilistic dual hesitation fuzzy elements (PDHFEs) are often different. To define the distance measure more expediently, many current studies need to add fresh elements to ensure that the length of corresponding elements in MD and NMD are the same, which will destroy the original information of the elements. In order to overcome this disadvantage, this paper defined some novel PDHF distance measures without adding elements. Some novel PDHF similarity measures were defined through the complementary relationship between distance and similarity measures based on the newly proposed PDHF distance measures. The fuzziness of a given PDHFS can be measured by the similarity measure between it and its complement. Based on the property, some novel PDHF EMs were proposed. Finally, three numerical examples are given to illustrate the effectiveness and rationality of these novel information measures.},
  archive      = {J_IDA},
  author       = {Baoquan Ning and Cun Wei and Guiwu Wei},
  doi          = {10.1177/1088467X241308761},
  journal      = {Intelligent Data Analysis},
  month        = {9},
  number       = {5},
  pages        = {1153-1186},
  shortjournal = {Intell. Data Anal.},
  title        = {Some novel probabilistic dual hesitant fuzzy information measures and their applications to multi-attribute decision-making},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). VLinear: Enhanced linear complexity time series forecasting model. <em>IDA</em>, <em>29</em>(5), 1142-1152. (<a href='https://doi.org/10.1177_1088467X241303376'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a novel time series prediction model(VLinear), designed with linear computational complexity, demonstrating superior predictive performance compared to DLiner without increasing parameter count or computational demands. Our model introduces two key innovations: first, a Feature Pyramid Network (FPN) is employed to effectively capture time series data characteristics, bypassing the traditional decomposition into trend and seasonal components. Second, a multi-layer fusion structure is developed to integrate deep and shallow features seamlessly. Empirically, VLinear outperforms DLiner in 31 out of 32 test cases on eight open-source datasets, with an average reduction of 16.8% in mean squared error (MSE) and 11.8% in mean absolute error (MAE). Additionally, compared to the transformer-based PatchTST, VLinear achieves 10 best MSE and 15 best MAE results, using only 8% of PatchTST’s total computational load in the 32 test projects.},
  archive      = {J_IDA},
  author       = {Chu Li and Bingjia Xiao and Qiping Yuan},
  doi          = {10.1177_1088467X241303376},
  journal      = {Intelligent Data Analysis},
  month        = {9},
  number       = {5},
  pages        = {1142-1152},
  shortjournal = {Intell. Data Anal.},
  title        = {VLinear: Enhanced linear complexity time series forecasting model},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-task intent recommendation based on dynamic and static intent integration and disentanglement. <em>IDA</em>, <em>29</em>(5), 1122-1141. (<a href='https://doi.org/10.1177/1088467X241301915'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems that mine users’ intentions to explore their potential interaction preferences have received increasing attention. However, the existing research on intent recommendation has some limitations. On one hand, the extant studies only consider users’ historical interaction information and the sparse interactions cannot reflect users’ potential interaction intention; on the other hand, they do not consider the changes in users’ kinematic and static intentions over time and the importance of users’ intention disentanglement representation, which makes it impossible for the general intention recommendation model to obtain a better representation of the intention. We propose a multitask recommendation model with dynamic and static intent integration and de-entanglement. The model mines users’ dynamic and static intents and then combines them with regularization to model the independence of the intents, encouraging the differences between the intents. Meanwhile, to further alleviate the data sparsity problem, this study additionally constructs user–user and item–item graphs using four different similarity measures, such as cosine similarity and mutual information, applies graph convolutional networks to learn about the three graphs, and then captures the complementarity between different graphs using a graph-level cross-attention mechanism. Extensive comparative experiments and ablation studies on three public datasets demonstrate that DSI-ID consistently outperforms all baseline methods, achieving a 3.5%–7.4% improvement in recommendation performance over the best baseline.},
  archive      = {J_IDA},
  author       = {Xiao Huang and Xianyi Zhang and Tao Huang and Lin Liu and Junhao Wen},
  doi          = {10.1177/1088467X241301915},
  journal      = {Intelligent Data Analysis},
  month        = {9},
  number       = {5},
  pages        = {1122-1141},
  shortjournal = {Intell. Data Anal.},
  title        = {Multi-task intent recommendation based on dynamic and static intent integration and disentanglement},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Imbalanced data prediction model based on self-attention mechanism and generative adversarial network. <em>IDA</em>, <em>29</em>(5), 1106-1121. (<a href='https://doi.org/10.1177_1088467X241301698'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imbalanced data distribution causes the traditional machine learning classification algorithms to be affected by the characteristics of the majority class, resulting in poor classification performance for the minority-class data. To improve the classification accuracy of minority classes in imbalanced data, this study has proposed a novel model—a generative adversarial network with self-attention mechanism oversampling based on a convolutional neural network (GAN-SAMO-CNN). The self-attention mechanism (SAM) of this model focused on the correlations among data elements of the minority class. The degree of correlation was first obtained by calculating the attention scores, which enabled the effective extraction of the distribution characteristics of the data. Subsequently, a generative adversarial network (GAN) was used to generate samples with high similarity to reduce data imbalances. Finally, a CNN classification model was constructed to train and predict the samples. The experimental results showed that the F1-score , G-mean , and area under PRC curve ( AUPRC ) of the model were considerably better than those of the other imbalanced data classification methods. The proposed method was then validated using multiple independent test datasets to demonstrate the model's generalizability and robustness.},
  archive      = {J_IDA},
  author       = {Hui Li and Fengxin Zhang and Dechang Pi and Dongyan Ding},
  doi          = {10.1177_1088467X241301698},
  journal      = {Intelligent Data Analysis},
  month        = {9},
  number       = {5},
  pages        = {1106-1121},
  shortjournal = {Intell. Data Anal.},
  title        = {Imbalanced data prediction model based on self-attention mechanism and generative adversarial network},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Weighted bonferroni mean-based classifiers with factorization machines for binary classification. <em>IDA</em>, <em>29</em>(5), 1085-1105. (<a href='https://doi.org/10.1177_1088467X241301694'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature interaction plays a very significant role in binary classification. In this paper, we study binary classification with weighted feature interactions by means of weighted Bonferroni mean (WBM) operators. After analyzing the characteristics of interactions in the (dependently weighted) Bonferroni mean (BM) operators, the quadratic-polynomial (POLY2)-based classifier, and the factorization-machine (FM)-based classifier, we introduce the WBM operators to capture the independent importance of weighted feature interactions among input arguments. These operators are a general generalization of the existing BM operators and the crossover parts of the POLY2-based and FM-based classifiers. Then, the WBM-based classifiers and their special cases, namely the WBM-based classifiers based on the factorization machines (abbreiated as FM _ WBM-based classifiers), are constructed to handle the (in)dependent importance of weighted feature interactions. Extensive experimental results on the synthetic datasets and four UCI machine-learning datasets verify the effectiveness of these proposed classifiers.},
  archive      = {J_IDA},
  author       = {Yong Qiao Zhou and Wei Yang and Zhen Ming Ma and Zeshui Xu},
  doi          = {10.1177_1088467X241301694},
  journal      = {Intelligent Data Analysis},
  month        = {9},
  number       = {5},
  pages        = {1085-1105},
  shortjournal = {Intell. Data Anal.},
  title        = {Weighted bonferroni mean-based classifiers with factorization machines for binary classification},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Editorial. <em>IDA</em>, <em>29</em>(5), 1083-1084. (<a href='https://doi.org/10.1177/1088467X251355035'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IDA},
  author       = {J.M. Peña},
  doi          = {10.1177/1088467X251355035},
  journal      = {Intelligent Data Analysis},
  month        = {9},
  number       = {5},
  pages        = {1083-1084},
  shortjournal = {Intell. Data Anal.},
  title        = {Editorial},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="ijars">IJARS - 2</h2>
<ul>
<li><details>
<summary>
(2025). Composite adaptive-based trajectory tracking for unmanned surface vessels under unknown dynamics parameters. <em>IJARS</em>, <em>22</em>(5). (<a href='https://doi.org/10.1177/17298806251359453'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the trajectory tracking problem of unmanned surface vessels (USVs) when all dynamics parameters are unknown. This study designs a trajectory tracking controller for USVs based on Lyapunov theory and composite adaptive control technology. And based on dual feedback signals from tracking error and forecast error, an adaptive update law for dynamics parameters is designed using the Bounded Gain Forgetting Least Squares method. The adaptive update law enables the online identification of all dynamics parameters of USVs. Next, a concise nonlinear disturbance observer is designed based on error feedback signals to compensate for unknown time-varying environmental disturbances. A control law incorporating dynamics parameters adaptive update law and disturbance estimation is developed using composite adaptive control techniques. Subsequently, the convergence of trajectory tracking errors and dynamics parameters estimation errors is proven based on Lyapunov theory. Finally, numerical simulation experiments are conducted. The results of simulation experiments demonstrate that the proposed controller achieves precise trajectory tracking for the USV even when all dynamics parameters are completely unknown. Additionally, the controller exhibits robust disturbance rejection capabilities.},
  archive      = {J_IJARS},
  author       = {Ziming Wang and Shunhuai Chen and Zaopeng Dong and Haijun Jiang},
  doi          = {10.1177/17298806251359453},
  journal      = {International Journal of Advanced Robotic Systems},
  month        = {9-10},
  number       = {5},
  shortjournal = {Int. J. Adv. Robot. Syst.},
  title        = {Composite adaptive-based trajectory tracking for unmanned surface vessels under unknown dynamics parameters},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advances in industrial bin picking through sim-to-real transfer and cycle optimization. <em>IJARS</em>, <em>22</em>(5). (<a href='https://doi.org/10.1177/17298806251374367'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents a novel method for addressing the bin picking problem with two significant contributions. First, we propose a specialized generator for synthetic labelled data tailored for bin picking applications. This synthetic data facilitates the training of deep learning models for detecting objects. Second, a parallel workflow to optimize cycle time is presented; this workflow leverages the robot’s motion to perform all cognitive computations. Experimental results demonstrate that models trained exclusively on virtual data achieve comparable performance when applied to real-world scenarios. Additionally, the proposed workflow effectively optimizes cycle time by ensuring uninterrupted robot movement throughout the process.},
  archive      = {J_IJARS},
  author       = {Marco Ojer and Hugo Alvarez and Xiao Lin and Elena Lazkano},
  doi          = {10.1177/17298806251374367},
  journal      = {International Journal of Advanced Robotic Systems},
  month        = {9-10},
  number       = {5},
  shortjournal = {Int. J. Adv. Robot. Syst.},
  title        = {Advances in industrial bin picking through sim-to-real transfer and cycle optimization},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="ijrr">IJRR - 15</h2>
<ul>
<li><details>
<summary>
(2025). MultiSCOPE: Disambiguating in-hand object poses with proprioception and sequential interactions. <em>IJRR</em>, <em>44</em>(10-11), 1920-1938. (<a href='https://doi.org/10.1177/02783649251315757'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Joint estimation of grasped object pose and extrinsic contacts is central to robust and dexterous manipulation. In this paper, we introduce MultiSCOPE, a state-estimation algorithm that leverages sequential frictional contacts (e.g., pokes) to jointly estimate contact locations and grasped object poses using exclusively proprioception and tactile feedback. Our method addresses the problem of reducing object pose uncertainty by using two complementary particle filters over a series of actions: one to estimate contact location (CPFGrasp) and another to estimate object poses (SCOPE). Our method addresses uncertainty in both robot proprioception and force-torque measurements, which is important for estimating in-hand object pose in the real world. We implement and evaluate our approach on simulated and real-world single-arm and dual-arm robotic systems. We demonstrate that by bringing two objects into contact several times, the robots can infer contact location and object poses simultaneously.},
  archive      = {J_IJRR},
  author       = {Andrea Sipos and Nima Fazeli},
  doi          = {10.1177/02783649251315757},
  journal      = {The International Journal of Robotics Research},
  month        = {9},
  number       = {10-11},
  pages        = {1920-1938},
  shortjournal = {Int. J. Robot. Res.},
  title        = {MultiSCOPE: Disambiguating in-hand object poses with proprioception and sequential interactions},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DABA: Decentralized and accelerated large-scale bundle adjustment. <em>IJRR</em>, <em>44</em>(10-11), 1892-1919. (<a href='https://doi.org/10.1177/02783649241309968'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scaling to arbitrarily large bundle adjustment problems requires data and compute to be distributed across multiple devices. Centralized methods in prior works are only able to solve small or medium size problems due to overhead in computation and communication. In this paper, we present a fully decentralized method that alleviates computation and communication bottlenecks to solve arbitrarily large bundle adjustment problems. We achieve this by reformulating the reprojection error and deriving a novel surrogate function that decouples optimization variables from different devices. This function makes it possible to use majorization minimization techniques and reduces bundle adjustment to independent optimization subproblems that can be solved in parallel. Moreover, an efficient closed-form warm start strategy has been presented that always improves bundle adjustment estimates. We further apply Nesterov’s acceleration and adaptive restart to improve convergence while maintaining its theoretical guarantees. Despite limited peer-to-peer communication, our method has provable convergence to first-order critical points under mild conditions. On extensive benchmarks with public datasets, our method converges much faster than decentralized baselines with similar memory usage and communication load. Compared to centralized baselines using a single device, our method, while being decentralized, yields more accurate solutions with significant speedups of up to 953.7x over C e r e s and 174.6x over D e e p L M . Code: https://github.com/facebookresearch/ DABA .},
  archive      = {J_IJRR},
  author       = {Taosha Fan and Joseph Ortiz and Ming Hsiao and Maurizio Monge and Jing Dong and Todd D Murphey and Mustafa Mukadam},
  doi          = {10.1177/02783649241309968},
  journal      = {The International Journal of Robotics Research},
  month        = {9},
  number       = {10-11},
  pages        = {1892-1919},
  shortjournal = {Int. J. Robot. Res.},
  title        = {DABA: Decentralized and accelerated large-scale bundle adjustment},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FurnitureBench: Reproducible real-world benchmark for long-horizon complex manipulation. <em>IJRR</em>, <em>44</em>(10-11), 1863-1891. (<a href='https://doi.org/10.1177/02783649241304789'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning (RL), imitation learning (IL), and task and motion planning (TAMP) have demonstrated impressive performance across various robotic manipulation tasks. However, these approaches have been limited to learning simple behaviors in current real-world manipulation benchmarks, such as pushing or pick-and-place. To enable more complex, long-horizon behaviors of an autonomous robot, we propose to focus on real-world furniture assembly, a complex, long-horizon robotic manipulation task that requires addressing many current robotic manipulation challenges. We present FurnitureBench, a reproducible real-world furniture assembly benchmark aimed at providing a low barrier for entry and being easily reproducible, so that researchers across the world can reliably test their algorithms and compare them against prior work. For ease of use, we provide 200+ hours of pre-collected data (5000+ demonstrations), 3D printable furniture models, a robotic environment setup guide, and systematic task initialization. Furthermore, we provide FurnitureSim, a fast and realistic simulator of FurnitureBench. We benchmark the performance of offline RL, IL, and offline-to-online RL algorithms on our assembly tasks and demonstrate the need to improve such algorithms to be able to solve our tasks in the real world, providing ample opportunities for future research.},
  archive      = {J_IJRR},
  author       = {Minho Heo and Youngwoon Lee and Doohyun Lee and Joseph J Lim},
  doi          = {10.1177/02783649241304789},
  journal      = {The International Journal of Robotics Research},
  month        = {9},
  number       = {10-11},
  pages        = {1863-1891},
  shortjournal = {Int. J. Robot. Res.},
  title        = {FurnitureBench: Reproducible real-world benchmark for long-horizon complex manipulation},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Non-euclidean motion planning with graphs of geodesically convex sets. <em>IJRR</em>, <em>44</em>(10-11), 1840-1862. (<a href='https://doi.org/10.1177/02783649241302419'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computing optimal, collision-free trajectories for high-dimensional systems is a challenging and important problem. Sampling-based planners struggle with the dimensionality, whereas trajectory optimizers may get stuck in local minima due to inherent nonconvexities in the optimization landscape. The use of mixed-integer programming to encapsulate these nonconvexities and find globally optimal trajectories has recently shown great promise, thanks in part to tight convex relaxations and efficient approximation strategies that greatly reduce runtimes. These approaches were previously limited to Euclidean configuration spaces, precluding their use with mobile bases or continuous revolute joints. In this paper, we handle such scenarios by modeling configuration spaces as Riemannian manifolds, and we describe a reduction procedure for the zero-curvature case to a mixed-integer convex optimization problem. We further present a method for obtaining approximate solutions via piecewise-linear approximations that is applicable to manifolds of arbitrary curvature. We demonstrate our results on various robot platforms, including producing efficient collision-free trajectories for a PR2 bimanual mobile manipulator.},
  archive      = {J_IJRR},
  author       = {Thomas Cohn and Mark Petersen and Max Simchowitz and Russ Tedrake},
  doi          = {10.1177/02783649241302419},
  journal      = {The International Journal of Robotics Research},
  month        = {9},
  number       = {10-11},
  pages        = {1840-1862},
  shortjournal = {Int. J. Robot. Res.},
  title        = {Non-euclidean motion planning with graphs of geodesically convex sets},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Investigating strategies enabling novice users to teach plannable hierarchical tasks to robots. <em>IJRR</em>, <em>44</em>(10-11), 1814-1839. (<a href='https://doi.org/10.1177/02783649241301075'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning from demonstration (LfD) seeks to democratize robotics by enabling non-experts to intuitively program robots to perform novel skills through human task demonstration. Yet, LfD is challenging under a task and motion planning (TAMP) setting, as solving long-horizon manipulation tasks requires the use of hierarchical abstractions. Prior work has studied mechanisms for eliciting demonstrations that include hierarchical specifications for robotics applications but has not examined whether non-roboticist end-users are capable of providing such hierarchical demonstrations without explicit training from a roboticist for each task. We characterize whether, how, and which users can do so. Finding that the result is negative, we develop a series of training domains that successfully enable users to provide demonstrations that exhibit hierarchical abstractions. Our first experiment shows that fewer than half (35.71%) of our subjects provide demonstrations with hierarchical abstractions when not primed. Our second experiment demonstrates that users fail to teach the robot with adequately detailed TAMP abstractions, when not shown a video demonstration of an expert’s teaching strategy. Our experiments reveal the need for fundamentally different approaches in LfD to enable end-users to teach robots generalizable long-horizon tasks without being coached by experts at every step. Toward this goal, we developed and evaluated a set of TAMP domains for LfD in a third study. Positively, we find that experience obtained in different, training domains enables users to provide demonstrations with useful, plannable abstractions on new, test domains just as well as providing a video prescribing an expert’s teaching strategy in the new domain.},
  archive      = {J_IJRR},
  author       = {Nina Moorman and Aman Singh and Manisha Natarajan and Erin Hedlund-Botti and Mariah Schrum and Chuxuan Yang and Lakshmi Seelam and Matthew C. Gombolay and Nakul Gopalan},
  doi          = {10.1177/02783649241301075},
  journal      = {The International Journal of Robotics Research},
  month        = {9},
  number       = {10-11},
  pages        = {1814-1839},
  shortjournal = {Int. J. Robot. Res.},
  title        = {Investigating strategies enabling novice users to teach plannable hierarchical tasks to robots},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convex geometric motion planning of multi-body systems on lie groups via variational integrators and sparse moment relaxation. <em>IJRR</em>, <em>44</em>(10-11), 1784-1813. (<a href='https://doi.org/10.1177/02783649241296160'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper reports a novel result: with proper robot models based on geometric mechanics, one can formulate the kinodynamic motion planning problems for rigid body systems as exact polynomial optimization problems. Due to the nonlinear rigid body dynamics, the motion planning problem for rigid body systems is nonconvex. Existing global optimization-based methods do not parameterize 3D rigid body motion efficiently; thus, they do not scale well to long-horizon planning problems. We use Lie groups as the configuration space and apply the variational integrator to formulate the forced rigid body dynamics as quadratic polynomials. Then, we leverage Lasserre’s hierarchy of moment relaxation to obtain the globally optimal solution via semidefinite programming. By leveraging the sparsity of the motion planning problem, the proposed algorithm has linear complexity with respect to the planning horizon. This paper demonstrates that the proposed method can provide globally optimal solutions or certificates of infeasibility at the second-order relaxation for 3D drone landing using full dynamics and inverse kinematics for serial manipulators. Moreover, we extend the algorithms to multi-body systems via the constrained variational integrators. The testing cases on cart-pole and drone with cable-suspended load suggest that the proposed algorithms can provide rank-one optimal solutions or nontrivial initial guesses. Finally, we propose strategies to speed up the computation, including an alternative formulation using quaternion, which provides empirically tight relaxations for the drone landing problem at the first-order relaxation.},
  archive      = {J_IJRR},
  author       = {Sangli Teng and Ashkan Jasour and Ram Vasudevan and Maani Ghaffari},
  doi          = {10.1177/02783649241296160},
  journal      = {The International Journal of Robotics Research},
  month        = {9},
  number       = {10-11},
  pages        = {1784-1813},
  shortjournal = {Int. J. Robot. Res.},
  title        = {Convex geometric motion planning of multi-body systems on lie groups via variational integrators and sparse moment relaxation},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SAM-RL: Sensing-aware model-based reinforcement learning via differentiable physics-based simulation and rendering. <em>IJRR</em>, <em>44</em>(10-11), 1767-1783. (<a href='https://doi.org/10.1177/02783649241284653'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model-based reinforcement learning is recognized with the potential to be significantly more sample efficient than model-free reinforcement learning. How an accurate model can be developed automatically and efficiently from raw sensory inputs (such as images), especially for complex environments and tasks, is a challenging problem that hinders the broad application of model-based reinforcement learning in the real world. In this work, we propose a sensing-aware model-based reinforcement learning system called SAM-RL. Leveraging the differentiable physics-based simulation and rendering, SAM-RL automatically updates the model by comparing rendered images with real raw images and produces the policy efficiently. With the sensing-aware learning pipeline, SAM-RL allows a robot to select an informative viewpoint to monitor the task process. We apply our framework to real world experiments for accomplishing three manipulation tasks: robotic assembly, tool manipulation, and deformable object manipulation. We demonstrate the effectiveness of SAM-RL via extensive experiments. Videos are available on our project webpage.},
  archive      = {J_IJRR},
  author       = {Jun Lv and Yunhai Feng and Cheng Zhang and Shuang Zhao and Lin Shao and Cewu Lu},
  doi          = {10.1177/02783649241284653},
  journal      = {The International Journal of Robotics Research},
  month        = {9},
  number       = {10-11},
  pages        = {1767-1783},
  shortjournal = {Int. J. Robot. Res.},
  title        = {SAM-RL: Sensing-aware model-based reinforcement learning via differentiable physics-based simulation and rendering},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Morphological symmetries in robotics. <em>IJRR</em>, <em>44</em>(10-11), 1743-1766. (<a href='https://doi.org/10.1177/02783649241282422'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a comprehensive framework for studying and leveraging morphological symmetries in robotic systems. These are intrinsic properties of the robot’s morphology, frequently observed in animal biology and robotics, which stem from the replication of kinematic structures and the symmetrical distribution of mass. We illustrate how these symmetries extend to the robot’s state space and both proprioceptive and exteroceptive sensor measurements, resulting in the equivariance of the robot’s equations of motion and optimal control policies. Thus, we recognize morphological symmetries as a relevant and previously unexplored physics-informed geometric prior, with significant implications for both data-driven and analytical methods used in modeling, control, estimation and design in robotics. For data-driven methods, we demonstrate that morphological symmetries can enhance the sample efficiency and generalization of machine learning models through data augmentation, or by applying equivariant/invariant constraints on the model’s architecture. In the context of analytical methods, we employ abstract harmonic analysis to decompose the robot’s dynamics into a superposition of lower-dimensional, independent dynamics. We substantiate our claims with both synthetic and real-world experiments conducted on bipedal and quadrupedal robots. Lastly, we introduce the repository MorphoSymm to facilitate the practical use of the theory and applications outlined in this work.},
  archive      = {J_IJRR},
  author       = {Daniel Ordoñez Apraez and Giulio Turrisi and Vladimir Kostic and Mario Martin and Antonio Agudo and Francesc Moreno-Noguer and Massimiliano Pontil and Claudio Semini and Carlos Mastalli},
  doi          = {10.1177/02783649241282422},
  journal      = {The International Journal of Robotics Research},
  month        = {9},
  number       = {10-11},
  pages        = {1743-1766},
  shortjournal = {Int. J. Robot. Res.},
  title        = {Morphological symmetries in robotics},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robot learning on the job: Human-in-the-loop autonomy and learning during deployment. <em>IJRR</em>, <em>44</em>(10-11), 1727-1742. (<a href='https://doi.org/10.1177/02783649241273901'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid growth of computing powers and recent advances in deep learning, we have witnessed impressive demonstrations of novel robot capabilities in research settings. Nonetheless, these learning systems exhibit brittle generalization and require excessive training data for practical tasks. To harness the capabilities of state-of-the-art robot learning models while embracing their imperfections, we present Sirius, a principled framework for humans and robots to collaborate through a division of work. In this framework, partially autonomous robots are tasked with handling a major portion of decision-making where they work reliably; meanwhile, human operators monitor the process and intervene in challenging situations. Such a human–robot team ensures safe deployments in complex tasks. Further, we introduce a new learning algorithm to improve the policy’s performance on the data collected from the task executions. The core idea is re-weighing training samples with approximated human trust and optimizing the policies with weighted behavioral cloning. We evaluate Sirius in simulation and on real hardware, showing that Sirius consistently outperforms baselines over a collection of contact-rich manipulation tasks, achieving an 8% boost in simulation and 27% on real hardware than the state-of-the-art methods in policy success rate, with twice faster convergence and 85% memory size reduction. Videos and more details are available at https://ut-austin-rpl.github.io/sirius/ .},
  archive      = {J_IJRR},
  author       = {Huihan Liu and Soroush Nasiriany and Lance Zhang and Zhiyao Bao and Yuke Zhu},
  doi          = {10.1177/02783649241273901},
  journal      = {The International Journal of Robotics Research},
  month        = {9},
  number       = {10-11},
  pages        = {1727-1742},
  shortjournal = {Int. J. Robot. Res.},
  title        = {Robot learning on the job: Human-in-the-loop autonomy and learning during deployment},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semantically controllable augmentations for generalizable robot learning. <em>IJRR</em>, <em>44</em>(10-11), 1705-1726. (<a href='https://doi.org/10.1177/02783649241273686'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generalization to unseen real-world scenarios for robot manipulation requires exposure to diverse datasets during training. However, collecting large real-world datasets is intractable due to high operational costs. For robot learning to generalize despite these challenges, it is essential to leverage sources of data or priors beyond the robot’s direct experience. In this work, we posit that image-text generative models, which are pre-trained on large corpora of web-scraped data, can serve as such a data source. These generative models encompass a broad range of real-world scenarios beyond a robot’s direct experience and can synthesize novel synthetic experiences that expose robotic agents to additional world priors aiding real-world generalization at no extra cost. In particular, our approach leverages pre-trained generative models as an effective tool for data augmentation. We propose a generative augmentation framework for semantically controllable augmentations and rapidly multiplying robot datasets while inducing rich variations that enable real-world generalization. Based on diverse augmentations of robot data, we show how scalable robot manipulation policies can be trained and deployed both in simulation and in unseen real-world environments such as kitchens and table-tops. By demonstrating the effectiveness of image-text generative models in diverse real-world robotic applications, our generative augmentation framework provides a scalable and efficient path for boosting generalization in robot learning at no extra human cost.},
  archive      = {J_IJRR},
  author       = {Zoey Chen and Zhao Mandi and Homanga Bharadhwaj and Mohit Sharma and Shuran Song and Abhishek Gupta and Vikash Kumar},
  doi          = {10.1177/02783649241273686},
  journal      = {The International Journal of Robotics Research},
  month        = {9},
  number       = {10-11},
  pages        = {1705-1726},
  shortjournal = {Int. J. Robot. Res.},
  title        = {Semantically controllable augmentations for generalizable robot learning},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diffusion policy: Visuomotor policy learning via action diffusion. <em>IJRR</em>, <em>44</em>(10-11), 1684-1704. (<a href='https://doi.org/10.1177/02783649241273668'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces Diffusion Policy, a new way of generating robot behavior by representing a robot’s visuomotor policy as a conditional denoising diffusion process. We benchmark Diffusion Policy across 15 different tasks from 4 different robot manipulation benchmarks and find that it consistently outperforms existing state-of-the-art robot learning methods with an average improvement of 46.9%. Diffusion Policy learns the gradient of the action-distribution score function and iteratively optimizes with respect to this gradient field during inference via a series of stochastic Langevin dynamics steps. We find that the diffusion formulation yields powerful advantages when used for robot policies, including gracefully handling multimodal action distributions, being suitable for high-dimensional action spaces, and exhibiting impressive training stability. To fully unlock the potential of diffusion models for visuomotor policy learning on physical robots, this paper presents a set of key technical contributions including the incorporation of receding horizon control, visual conditioning, and the time-series diffusion transformer. We hope this work will help motivate a new generation of policy learning techniques that are able to leverage the powerful generative modeling capabilities of diffusion models. Code, data, and training details are available (diffusion-policy.cs.columbia.edu).},
  archive      = {J_IJRR},
  author       = {Cheng Chi and Zhenjia Xu and Siyuan Feng and Eric Cousineau and Yilun Du and Benjamin Burchfiel and Russ Tedrake and Shuran Song},
  doi          = {10.1177/02783649241273668},
  journal      = {The International Journal of Robotics Research},
  month        = {9},
  number       = {10-11},
  pages        = {1684-1704},
  shortjournal = {Int. J. Robot. Res.},
  title        = {Diffusion policy: Visuomotor policy learning via action diffusion},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Time-optimal ergodic search: Multiscale coverage in minimum time. <em>IJRR</em>, <em>44</em>(10-11), 1664-1683. (<a href='https://doi.org/10.1177/02783649241273597'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Search and exploration capabilities are essential for robots to inspect hazardous areas, support scientific expeditions in extreme environments, and potentially save human lives in natural disasters. The variability of scale in these problems requires robots to reason about time alongside their dynamics and sensor capabilities to effectively assess and explore for information. Recent advances in ergodic search methods have shown promise in supporting trajectory planning for exploration in continuous, multiscale environments with dynamics consideration. However, these methods are still limited by their inability to effectively reason about and adapt the time to explore in response to their environment. This ability is crucial for adapting exploration to variable-resolution information-gathering tasks. To address this limitation, this paper poses the time-optimal ergodic search problem and investigates solutions for fast, multiscale, and adaptive robotic exploration trajectories. The problem is formulated as a minimum-time problem with an ergodic inequality constraint whose upper bound specifies the amount of coverage needed. We show the existence of optimal solutions using Pontryagin’s conditions of optimality, and we demonstrate effective, minimum-time coverage numerically through a direct transcription optimization approach. The efficacy of the approach in generating time-optimal search trajectories is demonstrated in simulation under several nonlinear dynamic constraints, and in a physical experiment using a drone in a cluttered environment. We find that constraints such as obstacle avoidance are readily integrated into our formulation, and we show through an ablation study the flexibility of search capabilities at various scales. Last, we contribute a receding-horizon formulation of time-optimal ergodic search for sensor-driven information-gathering and demonstrate improved adaptive sampling capabilities in localization tasks.},
  archive      = {J_IJRR},
  author       = {Dayi Ethan Dong and Henry Berger and Ian Abraham},
  doi          = {10.1177/02783649241273597},
  journal      = {The International Journal of Robotics Research},
  month        = {9},
  number       = {10-11},
  pages        = {1664-1683},
  shortjournal = {Int. J. Robot. Res.},
  title        = {Time-optimal ergodic search: Multiscale coverage in minimum time},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Soft yet secure: Exploring membrane buckling for achieving a versatile grasp with a rotation-driven squeezing gripper. <em>IJRR</em>, <em>44</em>(10-11), 1648-1663. (<a href='https://doi.org/10.1177/02783649241272120'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, there is a growing demand for versatile robotic grippers that facilitate adaptive grasping across a range of objects, characterized by diverse attributes such as shapes, sizes, and mechanical properties. This research introduces a new soft gripper, denoted as ROSE ( RO tation-based S queezing Gripp E r), dedicated to the torsional buckling phenomenon to achieve its grasping capability. The inherent gripping pattern, formed through a single rotational actuation, enables ROSE to dynamically accommodate various objects (relatively smaller than the diameter of ROSE), even in challenging environments like an oil container, without a complicated controller. Experimental tests demonstrate that ROSE exhibits substantial gripping force, reaching up to more than 300 N in the specific setup, and a remarkable payload-to-weight ratio. Especially, ROSE can maintain mechanical integrity through long-term open-close operation cycles in a specific condition. In this paper, we also introduce non-linear simulations for the elaboration of behaviors of ROSE concerning different morphologies, encompassing geometry configurations and material properties. The findings highlight a significant correlation between morphological features and grasping performance, leading to the refinement of a dependable version of ROSE. This refined version was subsequently assessed through experimental trials in crop harvesting tasks, where ROSE demonstrated high success rates in picking both individual and clustered crops, regardless of their soft or stiff characteristics. Project’s website with videos: https://sites.google.com/view/rosesoftgripper .},
  archive      = {J_IJRR},
  author       = {Khoi Thanh Nguyen and Nhan Huu Nguyen and Van Anh Ho},
  doi          = {10.1177/02783649241272120},
  journal      = {The International Journal of Robotics Research},
  month        = {9},
  number       = {10-11},
  pages        = {1648-1663},
  shortjournal = {Int. J. Robot. Res.},
  title        = {Soft yet secure: Exploring membrane buckling for achieving a versatile grasp with a rotation-driven squeezing gripper},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast and robust learned single-view depth-aided monocular visual-inertial initialization. <em>IJRR</em>, <em>44</em>(10-11), 1619-1647. (<a href='https://doi.org/10.1177/02783649241262452'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In monocular visual-inertial navigation, it is desirable to initialize the system as quickly and robustly as possible. A state-of-the-art initialization method typically constructs a linear system to find a closed-form solution using the image features and inertial measurements and then refines the states with a nonlinear optimization. These methods generally require a few seconds of data, which however can be expedited (less than a second) by adding constraints from a robust but only up-to-scale monocular depth network in the nonlinear optimization. To further accelerate this process, in this work, we leverage the scale-less depth measurements instead in the linear initialization step that is performed prior to the nonlinear one, which only requires a single depth image for the first frame. Importantly, we show that the typical estimation of all feature states independently in the closed-form solution can be modeled as estimating only the scale and bias parameters of the learned depth map. As such, our formulation enables building a smaller minimal problem than the state of the art, which can be seamlessly integrated into RANSAC for robust estimation. Experiments show that our method has state-of-the-art initialization performance in simulation as well as on popular real-world datasets (TUM-VI, and EuRoC MAV). For the TUM-VI dataset in simulation as well as real-world, we demonstrate the superior initialization performance with only a 0.3 s window of data, which is the smallest ever reported, and validate that our method can initialize more often, robustly, and accurately in different challenging scenarios.},
  archive      = {J_IJRR},
  author       = {Nathaniel Merrill and Patrick Geneva and Saimouli Katragadda and Chuchu Chen and Guoquan Huang},
  doi          = {10.1177/02783649241262452},
  journal      = {The International Journal of Robotics Research},
  month        = {9},
  number       = {10-11},
  pages        = {1619-1647},
  shortjournal = {Int. J. Robot. Res.},
  title        = {Fast and robust learned single-view depth-aided monocular visual-inertial initialization},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Editorial. <em>IJRR</em>, <em>44</em>(10-11), 1617-1618. (<a href='https://doi.org/10.1177/02783649251367502'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJRR},
  author       = {Kostas Bekris and Kris Hauser and Sylvia Herbert and Jingjin Yu},
  doi          = {10.1177/02783649251367502},
  journal      = {The International Journal of Robotics Research},
  month        = {9},
  number       = {10-11},
  pages        = {1617-1618},
  shortjournal = {Int. J. Robot. Res.},
  title        = {Editorial},
  volume       = {44},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="jact">JACT - 10</h2>
<ul>
<li><details>
<summary>
(2025). Enhancing deep convolutional neural network models for orange quality classification using MobileNetV2 and data augmentation techniques. <em>JACT</em>, <em>19</em>. (<a href='https://doi.org/10.1177/17483026241309070'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces significant improvements in the construction of deep convolutional neural network models for classifying agricultural products, specifically oranges, based on their shape, size, and color. Utilizing the MobileNetV2 architecture, this research leverages its efficiency and lightweight nature, making it suitable for mobile and embedded applications. Key techniques such as depthwise separable convolutions, linear bottlenecks, and inverted residuals help reduce the number of parameters and computational load while maintaining high performance in feature extraction. Additionally, the study employs comprehensive data augmentation methods, including horizontal and vertical flips, grayscale transformations, hue adjustments, brightness adjustments, and noise addition to enhance the model's robustness and generalization capabilities. The proposed model demonstrates superior performance, achieving an overall accuracy of 99.53%∼100% with nearly perfect precision, recall of 95.7%, and F1-score of 94.6% for both “orange_good” and “orange_bad” classes, significantly outperforming previous models which typically achieved accuracies between 70% and 90%. While the classification performance was near-perfect in some aspects, there were minor errors in specific detection tasks. The confusion matrix shows that the model has high sensitivity and specificity, with very few misclassifications. Finally, this study highlights the practical applicability of the proposed model, particularly its easy deployment on resource-constrained devices and its effectiveness in agricultural product quality control processes. These findings affirm the model in this research as a reliable and highly efficient tool for agricultural product classification, surpassing the capabilities of traditional models in this field.},
  archive      = {J_JACT},
  author       = {Phan Thi Huong and Lam Thanh Hien and Nguyen Minh Son and Huynh Cao Tuan and Thanh Q. Nguyen},
  doi          = {10.1177/17483026241309070},
  journal      = {Journal of Algorithms & Computational Technology},
  month        = {1-12},
  shortjournal = {J. Algo. Comput. Technol.},
  title        = {Enhancing deep convolutional neural network models for orange quality classification using MobileNetV2 and data augmentation techniques},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tighter bounds on the gaussian Q-function based on wild horse optimization algorithm. <em>JACT</em>, <em>19</em>. (<a href='https://doi.org/10.1177/17483026251315392'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Gaussian Q-function (GQF) is widely used in various scientific and engineering fields, especially in telecommunications and wireless communication. However, the lack of a closed-form expression for this function has led to considerable research efforts to achieve more accurate approximations. This study introduces a new approximate method that provides high accuracy for the boundaries of the GQF. The proposed approach utilizes parametric functions for both the lower and upper bounds of the GQF. The parameters of these functions are estimated using the Wild Horse Optimization (WHO), a meta-heuristic optimization algorithm, with the aim of minimizing the distance between the proposed functions and the actual GQF. The optimization process targets the minimization of the maximum absolute error and the mean absolute error, ensuring that the proposed bounds provide a tight and accurate approximation of the GQF. Numerical experiments and comparisons with existing bounds demonstrate the superior accuracy of the proposed method. The new lower and upper bounds achieve significantly lower maximum absolute error and mean absolute error values compared to previous approaches. Furthermore, the study evaluates the effectiveness of the proposed bounds in estimating the symbol error probability (SEP) for various digital modulation schemes, showing that the new bounds provide more accurate estimates of the SEP compared to the existing bounds. The results highlight the practical significance of the proposed method in enhancing the reliability of error probability estimation in communication systems.},
  archive      = {J_JACT},
  author       = {Reza Etesami and Mohsen Madadi},
  doi          = {10.1177/17483026251315392},
  journal      = {Journal of Algorithms & Computational Technology},
  month        = {1-12},
  shortjournal = {J. Algo. Comput. Technol.},
  title        = {Tighter bounds on the gaussian Q-function based on wild horse optimization algorithm},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid discrete artificial bee colony optimization algorithm for the no-wait job shop problem with tardiness criterion. <em>JACT</em>, <em>19</em>. (<a href='https://doi.org/10.1177/17483026251322104'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The no-wait job shop scheduling problem (NWJSP) plays a crucial role in industrial production and is an NP-hard problem. We propose a hybrid discrete artificial bee colony (HDABC) algorithm for solving the NWJSP with the total tardiness criterion. In the proposed algorithm, we first design multiple discrete operations which combine with the basic framework of the artificial bee colony algorithm. Furthermore, we propose a new selection method that allows onlooker bee to select better food sources. To determine the start times of the jobs, we introduce and adapt the left timetabling method for the tardiness objective under consideration. Experimental results show that the HDABC algorithm has better search capability than two well-performing ABC algorithms as well as an iterated greedy algorithm in solving the NWJSP with the total tardiness criterion.},
  archive      = {J_JACT},
  author       = {Xuemei Huang and Jie Yin and Guanlong Deng},
  doi          = {10.1177/17483026251322104},
  journal      = {Journal of Algorithms & Computational Technology},
  month        = {1-12},
  shortjournal = {J. Algo. Comput. Technol.},
  title        = {A hybrid discrete artificial bee colony optimization algorithm for the no-wait job shop problem with tardiness criterion},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Approximations for standard normal distribution function and its invertible. <em>JACT</em>, <em>19</em>. (<a href='https://doi.org/10.1177/17483026251322100'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce a new approximation of the cumulative distribution function of the standard normal distribution based on Tocher's approximation. Also, we assess the quality of the new approximation using two criteria namely the maximum absolute error and the mean absolute error. The approximation is expressed in closed form and it produces a maximum absolute error of 4.43 × 10 − 10 , while the mean absolute error is 9.62 × 10 − 11 . In addition, we propose an approximation of the inverse cumulative function of the standard normal distribution based on Polya approximation and compare the accuracy of our findings with some of the existing approximations. The results show that our approximations surpass other the existing ones based on the aforementioned accuracy measures.},
  archive      = {J_JACT},
  author       = {Omar M. Eidous and Mohammad Y. Al-Rawwash},
  doi          = {10.1177/17483026251322100},
  journal      = {Journal of Algorithms & Computational Technology},
  month        = {1-12},
  shortjournal = {J. Algo. Comput. Technol.},
  title        = {Approximations for standard normal distribution function and its invertible},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimization and sensitivity analysis of heat transfer rate of tri-hybrid nanofluid of stagnation point flow. <em>JACT</em>, <em>19</em>. (<a href='https://doi.org/10.1177_17483026251331492'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In manufacturing, especially in oil flow filtration, combustion systems, cooling turbines, and other areas, heat transfer performance through hybrid nanofluids (HNFs) is a key factor in achieving dominance of the final product. The present study deals with the movement of the fluid containing tri-hybrid nanoparticles on an excessively large stagnation point area on a smooth plate in a permeable medium. Additionally, the leading partial differential equations of the proposed model are converted to ordinary differential equations (ODEs) by incorporating similarity variables, and the fourth-order Runge–Kutta method is then used to solve these. To find the missing initial conditions of first-order ODEs, a shooting technique is also used. Furthermore, the consequences of heat transmission rate in the form of graphs and tables are explored. It is noticed that by enhancing the strength of the solid volume fraction the skin friction along the x-axis ( f ″ ( 0 ) or C F X ) increases as γ ∈ ( − 2 , 10 ] and decreases for the values of γ ∈ [ − 10 , 2 ) . But the converse of this behavior is true for g ″ ( 0 ) = C F Y . Moreover, the ternary fluid has taken the most significant effect on the Nusselt number, that is, 17.12978%, 8.43809%, and 19.20192% increment for Go, Ag and Cu type mono-nanofluid and 12.67309%, 18.13489%, and 13.65317% enhancement for HNF (Go-Ag, Go-Cu, Ag-Cu, respectively).},
  archive      = {J_JACT},
  author       = {Wejdan Deebani and Jawad Raza and Liaquat Ali Lund and Zahir Shah and Meshal Shutaywi},
  doi          = {10.1177_17483026251331492},
  journal      = {Journal of Algorithms & Computational Technology},
  month        = {1-12},
  shortjournal = {J. Algo. Comput. Technol.},
  title        = {Optimization and sensitivity analysis of heat transfer rate of tri-hybrid nanofluid of stagnation point flow},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved DBO algorithm tunes fuzzy-PD controller for robot manipulator trajectory tracking. <em>JACT</em>, <em>19</em>. (<a href='https://doi.org/10.1177_17483026251331506'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a novel approach for trajectory tracking of a six degrees-of-freedom (6-DOF) collaborative robot manipulator using an adaptive fuzzy proportional derivative (PD) controller. Based on the dynamic modeling of the robot manipulator, the PD control law is designed, and the improved dung beetle optimization (DBO) algorithm is introduced using the good point set (GPS) method for population initialization and the sine strategy for convergence factor adjustment. Furthermore, a fuzzy adaptive strategy is developed to adjust the PD controller gain based on real-time errors. This article uses discrete Lyapunov iterative stability to analyze the global asymptotic stability of the robot closed-loop system. The experimental results verify that the DBO-fuzzy-PD controller is superior to the original PD controller. The ISE value is reduced from 3.4140 to 0.0384, and the IAE value is reduced from 1.9876 to 0.1843. The DBO-fuzzy-PD controller has better tracking accuracy and response speed than traditional PD. Experimental results show that the proposed DBO-fuzzy-PD controller significantly enhances the trajectory tracking performance of the 6-DOF collaborative robot manipulator.},
  archive      = {J_JACT},
  author       = {Ma Haohao and Azizan As’arry and Li Chaoqun and Mohd Idris Shah Ismail and Hafiz Rashidi Ramli and Aidin Delgoshaei and M.Y.M. Zuhri},
  doi          = {10.1177_17483026251331506},
  journal      = {Journal of Algorithms & Computational Technology},
  month        = {1-12},
  shortjournal = {J. Algo. Comput. Technol.},
  title        = {Improved DBO algorithm tunes fuzzy-PD controller for robot manipulator trajectory tracking},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient persistence landscape generation. <em>JACT</em>, <em>19</em>. (<a href='https://doi.org/10.1177_17483026251347091'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using topological summary tools such as persistence landscapes have greatly enhanced the practical usage of topological data analysis to analyze large-scale, noisy, and complex datasets. A central element of persistence landscape usage involves computing the top- k landscapes. This article presents a novel output-sensitive plane sweep algorithm for computing the top- k persistence landscapes in optimal time and space: significantly outperforming previous algorithms. Our algorithm can determine in optimal O ( n * log ( n ) ) if a given birth-death pair appears in the top- k landscapes. The runtime performance of the approach on a botnet dataset and several synthetically generated point cloud topologies, showing that the algorithm can achieve significant speedups for these datasets due to its better algorithmic design. The speedups seen range from slightly worse (in some extreme examples) to equal compared to previous works while returning exactly the same output and is significantly faster when filtering is used (15x for birth-death pairs when removing 75% of birth-death pairs). Filtering is shown to maintain machine learning performance on both synthetically generated and real world datasets while providing orders of magnitude speedup depending on how intensive of filtering is done. Due to the introduced algorithm’s algorithmic design, the speedup seen is greater when filtering using the introduced birth-death filtering algorithm. The software is freely provided in Rust with Python bindings online.},
  archive      = {J_JACT},
  author       = {Taylor Henderson and Robert Simon},
  doi          = {10.1177_17483026251347091},
  journal      = {Journal of Algorithms & Computational Technology},
  month        = {1-12},
  shortjournal = {J. Algo. Comput. Technol.},
  title        = {Efficient persistence landscape generation},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid deep learning framework for robust time-series classification: Integrating inception modules with residual networks. <em>JACT</em>, <em>19</em>. (<a href='https://doi.org/10.1177_17483026251348851'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate time-series classification (TSC) remains a fundamental challenge in deep learning due to the complexity and variability of temporal patterns. While recurrent neural networks (RNNs) such as LSTM and GRU have shown promise in modeling sequential dependencies, they often suffer from limitations like vanishing gradients and high computational cost when handling long sequences. To overcome these issues, convolutional neural networks (CNNs), particularly the Inception architecture, have emerged as powerful alternatives due to their ability to capture multiscale local patterns efficiently. In this study, we propose InceptionResNet, a hybrid deep learning framework that integrates the residual learning mechanism of ResNet into the InceptionTime architecture. By replacing the fully convolutional network (FCN) shortcut module in InceptionFCN with ResNet-50, the model gains deeper representational capacity and improved gradient flow during training. We conduct extensive experiments on the UCR-85 benchmark dataset, comparing our model against state-of-the-art approaches, including InceptionTime, InceptionFCN, ResNet, FCN, and MLP. The results show that InceptionResNet achieves superior accuracy on 49 of 85 datasets, demonstrating its robustness and effectiveness in handling diverse and complex time series data. This work highlights the potential of integrating multiscale feature extraction and deep residual learning to advance the performance of TSC models in practical applications.},
  archive      = {J_JACT},
  author       = {Duong Thi Kim Chi and Nguyen Thi Mai Trang and Tran Ba Minh Son and Nguyen Ngoc Thao and Thanh Q. Nguyen},
  doi          = {10.1177_17483026251348851},
  journal      = {Journal of Algorithms & Computational Technology},
  month        = {1-12},
  shortjournal = {J. Algo. Comput. Technol.},
  title        = {Hybrid deep learning framework for robust time-series classification: Integrating inception modules with residual networks},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A competitive-collaborative nonnegative representation method and its application for face recognition in smart campus. <em>JACT</em>, <em>19</em>. (<a href='https://doi.org/10.1177_17483026251360208'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The nonnegative representation-based classification (NRC) method has attracted increasing attention in the field of face recognition. Building upon collaborative representation (CR), NRC incorporates a nonnegative constraint on the representation coefficients, thereby reducing the contribution of irrelevant training samples and enhancing overall classification performance. Despite these improvements, NRC inherits the same decision-making mechanism as the CR method, resulting in a decoupling of the representation and classification stages. This separation limits the method’s classification effectiveness. Furthermore, the presence of multicollinearity in the nonnegative representation may introduce inaccuracies in classification estimates, further undermining performance. To address these limitations, this paper proposes the competitive-collaborative nonnegative representation (CCNR) model. CCNR integrates two regularization terms: A competitive constraint and a collaborative constraint. The competitive constraint adopts a residual-based strategy during the classification stage, thereby strengthening the connection between representation and classification. This approach enables training samples from different classes to compete in representing the query sample, significantly improving classification performance. In parallel, the collaborative constraint applies an ℓ 2 -norm regularization to the representation coefficients, enhancing the stability of the model’s solution. Moreover, the CCNR model has been effectively deployed in smart campus environments. Extensive comparative experiments conducted on publicly available face datasets validate the effectiveness of the proposed model, consistently demonstrating its competitive performance. Habitually, the source code will be made available on the author’s profile page at https://github.com/li-zi-qi/CCNR .},
  archive      = {J_JACT},
  author       = {Tingting Guo and Ziqi Li and Jun Sun and Yonghong Zhang and Qingfeng Xia and Ke Ren},
  doi          = {10.1177_17483026251360208},
  journal      = {Journal of Algorithms & Computational Technology},
  month        = {1-12},
  shortjournal = {J. Algo. Comput. Technol.},
  title        = {A competitive-collaborative nonnegative representation method and its application for face recognition in smart campus},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comparative analysis of evolutionary algorithms for optimising proportional–integral–derivative control in direct current motor speed regulation: A statistical evaluation. <em>JACT</em>, <em>19</em>. (<a href='https://doi.org/10.1177/17483026251376985'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective proportional–integral–derivative controller tuning is critical for attaining high-performance operation in direct current motor systems, especially when traditional approaches fail under nonlinear or uncertain dynamics. This study conducted a statistically robust comparative analysis of seven evolutionary algorithms for proportional–integral–derivative gain tuning: genetic algorithm, particle swarm optimisation, shuffled frog leaping algorithm, firefly algorithm, artificial bee colony, simulated annealing and invasive weed optimisation algorithm. Simulations were performed in MATLAB/Simulink using two different tuning scenarios: Case 1 (conservative bounds) and Case 2 (aggressive bounds), with the integral time absolute error serving as the primary performance metric. Analysis of variance, Tukey's honestly significant difference and Cohen's d were employed to ensure statistical validity. The results revealed distinct trade-offs among the algorithms. Particle swarm optimisation achieved the best overall performance, with a minimal integral time absolute error mean of 190.54 in Case 2, low volatility and a moderate execution time of 1200.19 s. The invasive weed optimisation algorithm was the fastest algorithm, with execution times of 285.76 and 371.43 s in Cases 1 and 2, respectively, but it exhibited higher integral time absolute error variability. Simulated annealing and the firefly algorithm yielded the lowest integral time absolute error means (158.74 and 160.22, respectively) in Case 1, but they required the highest computational time (up to 20,567.84 s for simulated annealing). In contrast, the artificial bee colony performed the worst, with a Case 2 integral time absolute error mean of 422.38 and significant gain inconsistency. Statistical analysis with analysis of variance, Tukey's honestly significant difference and Cohen's d revealed the significance of the differences. This work provides evidence-based guidance for selecting evolutionary algorithms in proportional–integral–derivative tuning based on system priorities. A hybrid invasive weed optimisation algorithm–particle swarm optimisation framework is proposed as a promising future direction, combining the rapid global search of invasive weed optimisation algorithm with the reliable convergence of particle swarm optimisation for real-time, high-precision control. DC motors power many everyday systems, from robots to electric vehicles. To control them effectively, engineers use PID controllers, but tuning these controllers can be difficult. This study compared seven computer algorithms inspired by natural processes to find the best way to tune PID settings. Results showed that Particle Swarm Optimisation (PSO) gave the most reliable overall performance, while Invasive Weed Optimisation (IWOA) was fastest but less consistent. The study provides practical guidance on choosing the right method based on priorities.},
  archive      = {J_JACT},
  author       = {Oluwaseun O. Martins and Christiaan C. Oosthuizen and Dawood A. Desai},
  doi          = {10.1177/17483026251376985},
  journal      = {Journal of Algorithms & Computational Technology},
  month        = {1-12},
  shortjournal = {J. Algo. Comput. Technol.},
  title        = {Comparative analysis of evolutionary algorithms for optimising proportional–integral–derivative control in direct current motor speed regulation: A statistical evaluation},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="jaise">JAISE - 7</h2>
<ul>
<li><details>
<summary>
(2025). Enhancing thermal comfort and sustainability in building energy management through edge machine learning-enabled smart controllers. <em>JAISE</em>, <em>17</em>(3), 376-391. (<a href='https://doi.org/10.1177/18761364251343316'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concept of smart cities is becoming increasingly popular, driven by the goal of improving residents’ overall quality of life. Effective thermal management is a crucial component of smart cities, especially in light of significant changes in global weather patterns. These changes pose challenges for individuals seeking indoor comfort, particularly in workplaces and schools. Occupants often struggle with extreme temperatures, leading to increased energy consumption due to excessive use of air conditioners and heaters. In this work, we propose a novel edge machine learning-based smart controller for air conditioners to maintain user-preferred thermal comfort levels while minimizing energy consumption. The trained long short-term memory model is embedded in a mobile application designed to predict the predicted mean vote (PMV) based on temperature setpoints and the PMV index. Through this mobile application, personalized parameters such as clothing insulation, metabolic rate, and other environmental factors are communicated to the controller. The performance of the smart controller in maintaining PMV-based temperature setpoints for cooling is compared with fixed setpoints. The results reveal that by utilizing PMV-based setpoints for male occupants, the smart controller reduces energy consumption by 38.14% compared to a fixed setpoint of 26°C and by 60.68% compared to 25°C, while maintaining the user-preferred thermal comfort level.},
  archive      = {J_JAISE},
  author       = {Muhammad Tamoor Khan and Hassaan Saleem and Malka Rania Iqbal and Muhammad Shahzaib Shahid and Abbas Javed and Muhammad Nadeem and Saleem Akhtar},
  doi          = {10.1177/18761364251343316},
  journal      = {Journal of Ambient Intelligence and Smart Environments},
  month        = {8},
  number       = {3},
  pages        = {376-391},
  shortjournal = {J. Ambient Intell. Smart Env.},
  title        = {Enhancing thermal comfort and sustainability in building energy management through edge machine learning-enabled smart controllers},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid deep learning model for human activity recognition using smartphone and smart home data. <em>JAISE</em>, <em>17</em>(3), 349-375. (<a href='https://doi.org/10.1177/18761364251339587'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing development of applications in smart homes, healthcare, and personal fitness, a broad scientific community has identified human activity recognition (HAR) as a critical study issue. This paper introduces a unique hybrid deep learning architecture for efficient human activity identification that combines multi-layer perceptrons (MLPs) with convolutional neural networks (CNNs). The suggested CNN–MLP model provides a robust solution for HAR problems by leveraging the feature extraction capabilities of CNNs and the classification prowess of MLPs. Four different datasets were employed to comprehensively assess the model’s performance: WISDM, PAMAP2, and UCI HAR datasets for smartphone-based HAR, and the CASAS Aruba dataset that provided a novel perspective on activity detection in a home context, based on smart homes, while the smartphone-based UCI HAR, WISDM, and PAMAP2 datasets offered a variety of activity data. Across all datasets, our hybrid design outperformed all previous benchmarks, achieving high accuracy rates. These results underscore the model’s adaptability and efficiency in handling diverse sensor data types and activity scenarios. Furthermore, the model’s robustness and generalizability, demonstrated by its consistent performance across multiple datasets, establish it as a significant contribution to the field of HAR.},
  archive      = {J_JAISE},
  author       = {Nadia Agti and Lyazid Sabri and Okba Kazar},
  doi          = {10.1177/18761364251339587},
  journal      = {Journal of Ambient Intelligence and Smart Environments},
  month        = {8},
  number       = {3},
  pages        = {349-375},
  shortjournal = {J. Ambient Intell. Smart Env.},
  title        = {Hybrid deep learning model for human activity recognition using smartphone and smart home data},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MMSAD—A multi-modal student attentiveness detection in smart education using facial features and landmarks. <em>JAISE</em>, <em>17</em>(3), 326-348. (<a href='https://doi.org/10.1177/18761364251315239'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Virtual education (online education or e-learning) is a form of education where the primary mode of instruction is through digital platforms and the Internet. This approach offers flexibility and accessibility, making it attractive to many students. Many institutes also offer virtual professional courses for business and working professionals. However, ensuring the reachability of courses and evaluating students’ attentiveness presents significant challenges for educators teaching virtually. Various research works have been proposed to evaluate students’ attentiveness using facial landmarks, facial expressions, eye movements, gestures, postures, etc. However, no method has been proposed for real-time analysis and evaluation. This paper introduces a multi-modal student attentiveness detection (MMSAD) model designed to analyze and evaluate real-time class videos using two modalities: facial expressions and landmarks. Using a lightweight deep learning model, the model analyzes students’ emotions from facial expressions and identifies when a person is speaking during an online class by examining lip movements from facial landmarks. The model evaluates students’ emotions using five benchmark datasets, achieving accuracy rates of 99.05% on extended Cohn-Kanade (CK+), 87.5% on RAF-DB, 78.12% on Facial Emotion Recognition-2013 (FER-2013), 98.50% on JAFFE, and 88.01% on KDEF. The model identifies individuals speaking during the class using real-time class videos. The results from these modalities are used to predict attentiveness, categorizing students as either attentive or inattentive.},
  archive      = {J_JAISE},
  author       = {Ruchi Singh and Ramanujam E and Naresh Babu M},
  doi          = {10.1177/18761364251315239},
  journal      = {Journal of Ambient Intelligence and Smart Environments},
  month        = {8},
  number       = {3},
  pages        = {326-348},
  shortjournal = {J. Ambient Intell. Smart Env.},
  title        = {MMSAD—A multi-modal student attentiveness detection in smart education using facial features and landmarks},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Global path planning on uneven terrain at construction sites for robots based on an improved a* algorithm. <em>JAISE</em>, <em>17</em>(3), 302-325. (<a href='https://doi.org/10.1177/18761364241296814'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing application of construction robots on construction sites, autonomous path planning in unstructured and uneven construction sites has become an urgent challenge. Current path planning approaches face several issues, including prolonged computation times, low efficiency, and redundant nodes, often resulting in impractical paths for robots. Addressing these concerns, this study introduces a global path planning method based on an enhanced A* algorithm to ensure safe and robust navigation of construction robots in such challenging environments. The Improved A* algorithm initially incorporates a bidirectional alternating search strategy to expedite computational speed. Subsequently, it employs path node filtering to mitigate issues associated with bidirectional search and reduce the number of critical nodes, thereby enhancing search efficiency. Furthermore, the introduction of slope constraints decreases the robot's climbing and tilting angles, augmenting the safety of the planned paths. Finally, the paths are smoothed using Bézier curve fitting, facilitating better motion control for the robots. The efficacy of the improved algorithm was validated through experiments on elevation maps with varying terrain and obstacle densities. Simulation results indicate that, compared to the traditional A* algorithm, the Improved A* algorithm reduced computation time by 71.05% to 82.90% and the number of critical nodes by 51.94% to 70.53%, while only increasing the path length by 14.6% to 37.84%. Additionally, there was a significant reduction in climbing and tilting angles, and the paths have become smoother. Therefore, this method not only improves efficiency while generating safe and reliable paths in unstructured and uneven construction sites, but also enables robots to adapt to complex environments, and promotes automation and intelligent construction processes.},
  archive      = {J_JAISE},
  author       = {Jvgang Guo and Junqi Yu and Chunyong Feng and Kai Wang and Yisheng Chen and Zhenping Dong and Jingdan Li},
  doi          = {10.1177/18761364241296814},
  journal      = {Journal of Ambient Intelligence and Smart Environments},
  month        = {8},
  number       = {3},
  pages        = {302-325},
  shortjournal = {J. Ambient Intell. Smart Env.},
  title        = {Global path planning on uneven terrain at construction sites for robots based on an improved a* algorithm},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Research on facial expression recognition based on wide attention and multi-scale fusion mechanism. <em>JAISE</em>, <em>17</em>(3), 286-301. (<a href='https://doi.org/10.1177/18761364241296439'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To solve the problem of limitations of current attention mechanisms in extracting key facial expression features and the problem of low accuracy of facial expression recognition due to insufficient consideration of feature information fusion in the receptive field by convolutional neural networks. In this paper, we propose a facial expression recognition network based on wide attention (WA) and a multi-scale fusion (MF) mechanism (wide attention and multi-scale fusion [WAMF]). WA by extracting the background information of facial expression images while focusing on texture information, thus achieving better feature extraction. The MF mechanism is added at the connection points of layers in ResNet, where features extracted from each upper layer are fused using different-sized convolutional kernels and input into the lower layer. Finally, a viewpoint-invariant Capsule Net is used as the classification network after receiving the feature maps. The proposed WAMF model was applied to two publicly available datasets, CK+ and Jaffe, achieving excellent recognition rates of 98.98% and 98.46%, respectively.},
  archive      = {J_JAISE},
  author       = {Daipeng Guo and Jing Mu and Fei Xu and Min Li},
  doi          = {10.1177/18761364241296439},
  journal      = {Journal of Ambient Intelligence and Smart Environments},
  month        = {8},
  number       = {3},
  pages        = {286-301},
  shortjournal = {J. Ambient Intell. Smart Env.},
  title        = {Research on facial expression recognition based on wide attention and multi-scale fusion mechanism},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Profile segmentation: Clustering approach based on behavioral patterns extracted from mobile phone data. <em>JAISE</em>, <em>17</em>(3), 265-285. (<a href='https://doi.org/10.1177/18761364251343210'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ubiquitous use of mobile devices in recent years has enabled learning more about human behavior. This study uses mobile phone data, point-of-interest data, and publicly available socioeconomic indicators to present an integrated analysis of individual socioeconomic and behavioral profiles in Lisbon. To effectively segment users and identify mobility patterns, we employ multiple clustering techniques tailored to different data types: varied density-based spatial clustering of applications with noise (VDBSCAN) detects meaningful places by identifying clusters of varying densities in mobile phone data, while K-Means and K-Modes cluster numerical and categorical data, respectively, to determine socioeconomic status (SES) and categorize work environments. Our analysis identifies four primary groups of individuals, each distinguished by different SES and behavioral tendencies, ranging from practical and family-oriented to lifestyle-driven patterns. The results show that SES strongly influences mobility behaviors and interactions with urban spaces, revealing disparities in housing access, services, and work environments between different population segments. These findings highlight the interaction between mobility, social habits, and economic conditions, offering key insights for urban planning and strategies to mitigate the impacts of gentrification. The proposed methodology can be applied to other cities to support inclusive policymaking, transportation planning, and spatial equity strategies, fostering more accessible and equitable urban environments.},
  archive      = {J_JAISE},
  author       = {Cláudia Rodrigues and Ana Alves and Marco Veloso and Carlos L Bento},
  doi          = {10.1177/18761364251343210},
  journal      = {Journal of Ambient Intelligence and Smart Environments},
  month        = {8},
  number       = {3},
  pages        = {265-285},
  shortjournal = {J. Ambient Intell. Smart Env.},
  title        = {Profile segmentation: Clustering approach based on behavioral patterns extracted from mobile phone data},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Preface to JAISE 17(3). <em>JAISE</em>, <em>17</em>(3), 263-264. (<a href='https://doi.org/10.1177/18761364251358517'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JAISE},
  author       = {Hamid Aghajan and Juan Carlos Augusto},
  doi          = {10.1177/18761364251358517},
  journal      = {Journal of Ambient Intelligence and Smart Environments},
  month        = {8},
  number       = {3},
  pages        = {263-264},
  shortjournal = {J. Ambient Intell. Smart Env.},
  title        = {Preface to JAISE 17(3)},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="jifs">JIFS - 13</h2>
<ul>
<li><details>
<summary>
(2025). Precision and efficiency meet: Computing the similarity of interval type-2 trapezoidal fuzzy sets. <em>JIFS</em>, <em>49</em>(4), 1107-1121. (<a href='https://doi.org/10.1177/10641246251328418'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of interval type-2 fuzzy sets in domains characterized by substantial uncertainty, particularly natural language processing and intelligent decision-making systems, has highlighted the critical need for efficient and accurate similarity assessment methodologies. However, evaluating similarity between interval type-2 fuzzy sets presents considerable challenges, primarily due to the computational inefficiencies associated with traditional similarity measurement techniques. This paper addresses these challenges by proposing a computational approach aimed at enhancing the efficiency of similarity assessments between interval type-2 trapezoidal fuzzy sets. The core of proposed approach lies in leveraging the geometric properties of trapezoids to determine the closed polygon that results from the intersection of two non-normal type-1 trapezoidal fuzzy sets. The proposed method eliminates the need for complex sequential condition evaluations and intricate flowcharts traversal common in existing methods. A key contribution of this work is the novel handling of infeasible intersection points, ensuring computational efficiency without sacrificing precision. The implementation incorporates the Shoelace algorithm for polygon area computation, further enhancing computational efficiency. Numerical analysis demonstrates that the proposed approach provides a streamlined and computationally efficient solution for similarity assessment between interval type-2 trapezoidal fuzzy sets, optimizing both precision and algorithmic performance.},
  archive      = {J_JIFS},
  author       = {Babak Rezaee},
  doi          = {10.1177/10641246251328418},
  journal      = {Journal of Intelligent & Fuzzy Systems},
  month        = {10},
  number       = {4},
  pages        = {1107-1121},
  shortjournal = {J. Intell. Fuzzy Syst.},
  title        = {Precision and efficiency meet: Computing the similarity of interval type-2 trapezoidal fuzzy sets},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent dustbin temperature control system based on evaporative cooling: Enhanced prediction and control of temperature systems using fuzzy PID strategies. <em>JIFS</em>, <em>49</em>(4), 1088-1106. (<a href='https://doi.org/10.1177/10641246251328398'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Food waste, characterized by its high perishability, odor emission, and environmental impact under high temperatures, necessitates storage at low or normal temperatures. Traditional cooling methods, such as air conditioning, consume substantial energy. To address this, we designed an evaporative cooling dustbin. Given the strong influence of external environmental factors on cooling efficiency, we collected experimental data and trained three neural network models to improve the accuracy of bin temperature prediction and regulation. We enhanced the conventional proportional-integral-derivative (PID) control algorithm with neural networks, developing three distinct control strategies. Model performance was evaluated based on prediction accuracy and control efficacy. Results indicated that augmented with feature encoding, the long short-term memory (LSTM) model achieved the highest prediction accuracy with a mean error of ±0.3°C. The fan speed prediction model also demonstrated a strong correlation, with an R² value of 0.9804. Optimal fan speed control was achieved using a fuzzy PID model informed by the LSTM algorithm. Validation tests during operational hours showed temperature errors of 0.45°C and 0.54°C for two different periods. These results highlight the ability of the enhanced LSTM model to accurately predict bin temperature, while the optimized PID strategy effectively stabilizes temperature fluctuations. Additionally, two working modes—performance and economic—were established, both of which can maintain the average temperature of the garbage box at 25 ± 0.3°C. In the performance mode, the overshoot time of the system cooling is at least 46 s, and the response is rapid and has high stability. This work advances precise prediction and control methods for nonlinear temperature systems in energy-efficient cooling applications.},
  archive      = {J_JIFS},
  author       = {Xueru Zhu and Tianwei Gu and Jufei Wang and Chao Li and Xuebin Feng and Hua Li},
  doi          = {10.1177/10641246251328398},
  journal      = {Journal of Intelligent & Fuzzy Systems},
  month        = {10},
  number       = {4},
  pages        = {1088-1106},
  shortjournal = {J. Intell. Fuzzy Syst.},
  title        = {Intelligent dustbin temperature control system based on evaporative cooling: Enhanced prediction and control of temperature systems using fuzzy PID strategies},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective threshold optimized image de-noising algorithm for high density mixed impulse noise. <em>JIFS</em>, <em>49</em>(4), 1071-1087. (<a href='https://doi.org/10.1177/18758967251353036'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel Multi-Objective Optimization based Fuzzy Switching Median Filter (MOOFASMF) to remove high density Random Valued Impulse Noise (RVIN), “Salt & Pepper” Impulse Noise (SPIN) and Mixed Impulse Noise (MIN). In this work, multi-objective optimization technique is used to find out the fuzzy switching median filter threshold values for accurate detection of corrupted pixels. The proposed multi-objective framework uses Decomposition based Multi Objective Evolutionary Algorithm (MOEA/D) to obtain optimized fuzzy switching median filter drives the threshold values with the objectives Mean Square Error (MSE) and inverse of Structural Similarity Index Metrics (SSIM) as optimization objectives. Even though the MSE and SSIM are not closely related parameters, the optimized threshold value gives better results in terms of both PSNR and SSIM. The advantages of the proposed framework are that it works effectively on RVIN, SPIN, and MIN-affected images. The effectiveness of the proposed framework is outstanding for high-density RVIN, SPIN, and MIN, which makes it more advantageous over other existing methods. Experimental results in terms of visual and quantitative metrics such as Peak Signal to Noise Ratio (PSNR), Mean Square Error (MSE), Structural Similarity Index Metrics (SSIM), and Edge Preservation Index (EPI) clearly demonstrates the better performance of the proposed algorithm over the state of art techniques. The proposed framework performed 6.02% and 32.11% better than the best existing methods in terms of PSNR and SSIM for the mixture of 40% SPIN & 50% RVIN affected image.},
  archive      = {J_JIFS},
  author       = {Suresh Babu V and Vijaykumar V R and Mohaideen Abdul Kadhar K and Sudhakar R},
  doi          = {10.1177/18758967251353036},
  journal      = {Journal of Intelligent & Fuzzy Systems},
  month        = {10},
  number       = {4},
  pages        = {1071-1087},
  shortjournal = {J. Intell. Fuzzy Syst.},
  title        = {Multi-objective threshold optimized image de-noising algorithm for high density mixed impulse noise},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sem-rouge: Graph-based embedding for automated text summarization with using large language models. <em>JIFS</em>, <em>49</em>(4), 1057-1070. (<a href='https://doi.org/10.1177/18758967251353031'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information accessibility has been transformed in the field of Artificial Intelligence (AI), particularly in natural language processing (NLP), owing to the widespread use of technologies such as ChatGPT. This paper explores the field of human-directed AI solutions with particular emphasis on newspaper summarization, a useful tool in today's busy world. Utilizing comprehensive models (LLMs), we explore extractive and abstractive summarization methods. To maximize the LLM performance, our strategy entails creating a customized news dataset enhanced with human-centric summaries and using cutting-edge data preparation techniques. To improve the accuracy assessment, we present a modified evaluation metric called Sem-rouge, which augments established units of measurement. In a comparative analysis, it was noticed that the proposed metric can highlight both syntactic and semantic similarities; hence, the metric is suitable for both extractive and abstractive summarization methods. We highlight the significance of dataset selection, data processing methods, and assessment criteria in fine-tuning auto-generated summaries using rigorous comparison analysis. Further studies will focus on improving semantic similarity techniques, integrating advanced models such as The BERT algorithm or Generative Pre-trained Transformer algorithm, and overcoming challenges such as overfitting. Finally, our study emphasizes the importance of meticulously training models and modifying them frequently to enhance automated summarization skills.},
  archive      = {J_JIFS},
  author       = {Sini Raj Pulari and Maramreddy Umadevi and Shriram K Vasudevan},
  doi          = {10.1177/18758967251353031},
  journal      = {Journal of Intelligent & Fuzzy Systems},
  month        = {10},
  number       = {4},
  pages        = {1057-1070},
  shortjournal = {J. Intell. Fuzzy Syst.},
  title        = {Sem-rouge: Graph-based embedding for automated text summarization with using large language models},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimized tree construction and clustering-based data aggregation for heterogeneous wireless sensor networks using ford-fulkerson algorithm. <em>JIFS</em>, <em>49</em>(4), 1039-1056. (<a href='https://doi.org/10.1177/18758967251353023'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of wireless sensor networks (WSNs) as a key technology for controlling and monitoring a range of applications has been accepted. Heterogeneous WSNs involve nodes with different functions, for instance, nodes with sensing, fusion, and routing duties. To maximize the performance of a heterogeneous WSN, an optimized tree construction and clustering-based data aggregation approach is proposed in this paper. The Ford-Fulkerson algorithm is used to construct an optimized spanning tree with minimum energy consumption. Clusters are then formed in a distributed manner, and data aggregation is performed among the clusters. The suggested strategy is effective, as shown by the simulation results, and adding a reliable optimization method greatly lowers energy usage and enhances network performance. The research provides a clustering-based data aggregation strategy meant to maximize data delivery from heterogeneous WSNs with low-power nodes. The employed technique combines two clustering algorithms, k-means, and fuzzy c-means, to ensure fast and reliable data forwarding among WSNs. The proposed FFA obtained 95.86% energy efficiency, 87.21% QoS, 95.25% transmission rate, 90.13% PDR, 8.86% delay, 96.21% network lifetime, 91.22% throughput, 89.42% scalability and 96.58% Fault Tolerance. The proposed method can significantly reduce energy consumption and communication overhead, improving network efficiency and utilization. This work has the potential to significantly impact the design and operation of wireless sensor networks in various applications.},
  archive      = {J_JIFS},
  author       = {T Kiruthiga and N Shanmugasundaram},
  doi          = {10.1177/18758967251353023},
  journal      = {Journal of Intelligent & Fuzzy Systems},
  month        = {10},
  number       = {4},
  pages        = {1039-1056},
  shortjournal = {J. Intell. Fuzzy Syst.},
  title        = {Optimized tree construction and clustering-based data aggregation for heterogeneous wireless sensor networks using ford-fulkerson algorithm},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new bee colony-WNN structure for identification and modelling of a yeast fermentation bioreactor. <em>JIFS</em>, <em>49</em>(4), 1023-1038. (<a href='https://doi.org/10.1177/18758967251353381'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developing an accurate model for severe nonlinear chemical processes presents a significant challenge, as it directly impacts profitability and optimal control strategies. The main aim of this work is to find an optimal model architecture capable of presenting all system modes and subsequently reducing control effort. Improving model accuracy while considering computational burden is identified as the most effective approach for achieving this goal. In this paper, the reactor is treated as a black-box model, and a new optimized model for bioreactors is proposed based on the combination of the Bee Colony Algorithm and Wavelet Neural Network (WNN). Input-output data for training and validation of the identified model are generated by applying a persistently exciting signal. A salient feature of the suggested hybrid Bee-WNN algorithm is the application of a global searching technique for optimizing the initial weights of the neural network, instead of stochastic selection through the Bee Colony approach. Additionally, the wavelet neural network algorithm is utilized to update the optimal weighting via the Levenberg Marquardt training method, thereby enhancing exploitation search abilities. To assess the usefulness of the demonstrated procedure in identification and modeling, a practical fermentation bioreactor is selected as a source of data. Furthermore, two methods, BP-ANN and ABC-WNN, which have already been presented in the research, are applied to equivalent datasets, and the obtained results are compared with those produced by the proposed methodology of the paper. Based on the results, the new extracted model improves the accuracy of the identified model more than 10 times compared to the previous training algorithm. Moreover, from a statistical perspective, the goodness of model fitting is enhanced by 0.03.},
  archive      = {J_JIFS},
  author       = {Reza Nasimi and Sassan Azadi and Mostafa Jazaeri and Mehdi Farzinfar},
  doi          = {10.1177/18758967251353381},
  journal      = {Journal of Intelligent & Fuzzy Systems},
  month        = {10},
  number       = {4},
  pages        = {1023-1038},
  shortjournal = {J. Intell. Fuzzy Syst.},
  title        = {A new bee colony-WNN structure for identification and modelling of a yeast fermentation bioreactor},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). N-hypersoft topology: A unified approach for multi-criteria group decision-making. <em>JIFS</em>, <em>49</em>(4), 1006-1022. (<a href='https://doi.org/10.1177/18758967251355735'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This manuscript introduces N -hypersoft topology ( N -HST), an innovative extension of the established hypersoft topology (HST). Unlike its predecessor, the N -hypersoft ( N -HS) set, N -HST adopts a multi-opinion approach to decision-making, enhancing robustness and adaptability across various domains. In addressing limitations observed in N -soft topology ( N -ST), particularly in handling multi-argument approximate functions, N -HST offers a comprehensive framework. The study delves into various operators within the N -HST framework, including closure, interior, exterior, and boundary operators, elucidating their interrelationships and providing a deeper understanding of the structural components. Furthermore, this manuscript explores the practical implications of N -HST in multi-criteria group decision-making (MCGDM), showcasing its applicability in real-world decision scenarios. In addition to its specific applications in MCGDM, N -HST offers generic aspects that contribute to its versatility and efficacy in decision-making processes. By accommodating multiple opinions and handling complex evaluation factors, N -HST emerges as a superior framework for addressing diverse decision-making challenges. Through a numerical example, this manuscript demonstrates the practical utility and potential impact of N -HST in various domains.},
  archive      = {J_JIFS},
  author       = {Sagvan Y Musa and Baravan A Asaad},
  doi          = {10.1177/18758967251355735},
  journal      = {Journal of Intelligent & Fuzzy Systems},
  month        = {10},
  number       = {4},
  pages        = {1006-1022},
  shortjournal = {J. Intell. Fuzzy Syst.},
  title        = {N-hypersoft topology: A unified approach for multi-criteria group decision-making},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). New forms of fuzzy filters in sheffer stroke hilbert algebras. <em>JIFS</em>, <em>49</em>(4), 991-1005. (<a href='https://doi.org/10.1177/18758967251355726'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the purpose of studying the fuzzy version of the filter in Sheffer stroke Hilbert algebra using the concept of fuzzy point, the concept of ( ∈ , ∈ ∨ q ) -fuzzy filters in the Sheffer stroke Hilbert algebra is introduced and several properties are investigated. The relationship between fuzzy filters and ( ∈ , ∈ ∨ q ) -fuzzy filters is considered, and characterizations of ( ∈ , ∈ ∨ q ) -fuzzy filters are discussed. The conditions under which ( ∈ , ∈ ∨ q ) -fuzzy filters can become fuzzy filters are explored, and ( ∈ , ∈ ∨ q ) -fuzzy filters associated with homomorphisms are studied.},
  archive      = {J_JIFS},
  author       = {Young Joo Seo and Sun Shin Ahn and Young Bae Jun},
  doi          = {10.1177/18758967251355726},
  journal      = {Journal of Intelligent & Fuzzy Systems},
  month        = {10},
  number       = {4},
  pages        = {991-1005},
  shortjournal = {J. Intell. Fuzzy Syst.},
  title        = {New forms of fuzzy filters in sheffer stroke hilbert algebras},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Educational chatbots: A systematic mapping study. <em>JIFS</em>, <em>49</em>(4), 960-990. (<a href='https://doi.org/10.1177/18758967251356870'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chatbots, text or voice software entities, are consolidating their position in the education sector, as they have gone from being rustic tools to systems that can take an active role in the teaching and learning process. That is why we decide to elaborate a Systematic Mapping Study of works that have been published on educational chatbots in the last years. Our analysis has four objectives: 1) to know the purpose of chatbots; 2) to identify the educational levels in which the chatbots are employed; 3) to examine which interaction mechanisms are implemented by chatbots; and 4) to explore which technologies and software architectures predominate in the development of educational chatbots. Following solid methodologies for systematic reviews, we compiled 104 papers. Through the analysis of these works, we obtained an overview that can be useful for both specialists and newcomers to the domain, as it helps them understand the existing trends in these applications. Additionally, the discussion extends into the disruptive impact of generative AI and outlines critical open research questions that guide future investigations in educational chatbot development.},
  archive      = {J_JIFS},
  author       = {José Fidel Urquiza-Yllescas and Sonia Mendoza and Luis Martín Sánchez-Adame and José Rodríguez and Dominique Decouchant},
  doi          = {10.1177/18758967251356870},
  journal      = {Journal of Intelligent & Fuzzy Systems},
  month        = {10},
  number       = {4},
  pages        = {960-990},
  shortjournal = {J. Intell. Fuzzy Syst.},
  title        = {Educational chatbots: A systematic mapping study},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The least squares estimation of uncertain fractional differential equations with application to the financial markets. <em>JIFS</em>, <em>49</em>(4), 948-959. (<a href='https://doi.org/10.1177/18758967251356869'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In uncertain dynamical systems, there is a class of parameter estimation problems for fractional differential equations (UFDEs) that are important and related research is scarce. Given this, the parameter estimation problem for Caputo type of UFDEs under the initial conditions is proposed. The least squares estimation method is a method that minimizes the sum of squared errors between the obtained data and the actual data. The estimation of unknown parameters in the UFDEs are obtained by the least squares estimation method based on limited observed values, and the rationality of the parameters is tested following uncertain hypothesis testing. A specific algorithm for parameter estimation is provided, and the effectiveness of the proposed model is demonstrated by two examples in the financial markets: Alibaba's stock price and the exchange rate between the RMB and Euro.},
  archive      = {J_JIFS},
  author       = {Chun Wei and Haiyan Shi and Zhiqiang Zhang and Rong Gao},
  doi          = {10.1177/18758967251356869},
  journal      = {Journal of Intelligent & Fuzzy Systems},
  month        = {10},
  number       = {4},
  pages        = {948-959},
  shortjournal = {J. Intell. Fuzzy Syst.},
  title        = {The least squares estimation of uncertain fractional differential equations with application to the financial markets},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). 3D object detection algorithm for autonomous driving based on multi-scale feature weighted point-by-point fusion. <em>JIFS</em>, <em>49</em>(4), 933-947. (<a href='https://doi.org/10.1177/18758967251356865'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate detection of 3D obstacles is crucial in autonomous vehicles and intelligent traffic systems. The multi-modal fusion of cameras and LiDAR in 3D object detection can fully leverage the advantages of both sensors, to improve the accuracy and robustness of target detection and make it become a core component of the perception system in autonomous vehicles. However, due to the inherent differences in sensor data, the difficulty of data fusion in 3D object detection still faces numerous challenges. To effectively address this issue, a 3D object detection algorithm based on multi-scale feature-weighted point-by-point fusion is proposed. By establishing correspondences between camera images and lidar point clouds on a point-wise basis, we employ the ResNet50 network model to obtain multi-scale semantic features from images. The importance of different channels in image features is reasonably assigned weights, enhancing point features with image semantic information. This approach proves beneficial in tackling the challenge of matching image and point cloud fusion, which is hindered by disparate data structures. It fully leverages the complementary nature of multi-modal information. Experimental results on the KITTI object detection benchmark dataset show that the proposed 3D object detection algorithm achieves an average detection accuracy of 80.95%, a 1.34% improvement compared to previous multi-modal algorithms, demonstrating superior 3D object detection performance.},
  archive      = {J_JIFS},
  author       = {Chunfang Yin and Haichen Qu and Yicheng Li},
  doi          = {10.1177/18758967251356865},
  journal      = {Journal of Intelligent & Fuzzy Systems},
  month        = {10},
  number       = {4},
  pages        = {933-947},
  shortjournal = {J. Intell. Fuzzy Syst.},
  title        = {3D object detection algorithm for autonomous driving based on multi-scale feature weighted point-by-point fusion},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new adaptive conformable fractional order grey prediction model with a time power term and its application. <em>JIFS</em>, <em>49</em>(4), 921-932. (<a href='https://doi.org/10.1177/18758967251356853'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, a new adaptive conformable fractional order grey prediction model with a time power term is constructed to further advance the field of grey prediction. In the modeling process, the discretization operation and ridge regression are considered to optimize the unbiasedness and adaptive performance of the model, respectively. Then, the particle swarm optimization is used to search for suitable hyperparameters. The research findings reveal that the proposed model possesses both uniformity and unbiasedness, highlighting its theoretical superiority. To verify the effectiveness of the proposed method, the real case is used. Experimental results show that the proposed method is superior to all benchmark algorithms, which verifies its effectiveness.},
  archive      = {J_JIFS},
  author       = {Zhiming Hu and Liang Zeng and Huan Xi},
  doi          = {10.1177/18758967251356853},
  journal      = {Journal of Intelligent & Fuzzy Systems},
  month        = {10},
  number       = {4},
  pages        = {921-932},
  shortjournal = {J. Intell. Fuzzy Syst.},
  title        = {A new adaptive conformable fractional order grey prediction model with a time power term and its application},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A scheduling optimization method for green flexible job shop with switching on/off strategy and time-of-use pricing under dynamic events. <em>JIFS</em>, <em>49</em>(4), 901-920. (<a href='https://doi.org/10.1177/18758967251356821'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To achieve energy conservation and emission reduction, the scope of the flexible job-shop scheduling problem (FJSP) has been broadened to address the green flexible job-shop scheduling problem (GFJSP). However, solely focusing on scheduling doesn't adequately achieve green production. Furthermore, dynamic events in the job-shop necessitate rescheduling to resume production. Considering these, this paper proposes a scheduling optimization method for a GFJSP under dynamic events (DGFJSP). Firstly, the method introduces an optimization model that considers the switching on/off strategy of machines in idle and the electric power cost under time-of-use pricing. Secondly, the method employs a multi-objective genetic algorithm based on variable neighborhood search (MOGV), which introduces an adaptive elite retention strategy based on external archive and adaptive operators. The efficiency and competitiveness of the MOGV are verified by the benchmark instance, and the MOGV is applied to rescheduling. Ultimately, the method introduces the green flexible job-shop rescheduling metrics: productivity, energy conservation, robustness, and stability as the decision-making basis of the combined rescheduling method. Total rescheduling based on MOGV reduces the value of the comprehensive indicators by 5.931% when machine breakdown and by 6.033% when order insertion or defective return compared to right-shift rescheduling.},
  archive      = {J_JIFS},
  author       = {Zhongyi Liu and Yun Jiang and Ruihang Ma},
  doi          = {10.1177/18758967251356821},
  journal      = {Journal of Intelligent & Fuzzy Systems},
  month        = {10},
  number       = {4},
  pages        = {901-920},
  shortjournal = {J. Intell. Fuzzy Syst.},
  title        = {A scheduling optimization method for green flexible job shop with switching on/off strategy and time-of-use pricing under dynamic events},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="pom">POM - 20</h2>
<ul>
<li><details>
<summary>
(2025). Information sharing and financing services on online retailing platforms. <em>POM</em>, <em>34</em>(10), 3309-3329. (<a href='https://doi.org/10.1177/10591478251333724'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online marketplaces such as Amazon and Tmall have been expanding services to boost the growth of their ecosystems. One is information service on sharing privately gathered massive consumer data that is unavailable to their sellers, and the other is financing service, e.g., Amazon Lending and Ant Financial, aiming to provide accessible and affordable financial support for small and medium-sized sellers. This paper develops a game-theoretical model to examine the interplay between information sharing and financing services on a retail platform, particularly when sellers are financially constrained. The results show that while the information-sharing service always makes the platform less likely to provide an attractive financing service, the financing service also makes the information-sharing service less likely to be provided under certain conditions. These conditions depend on the structure of capital market and the seller’s initial working capital. We find that such misalignment between these two services can be resolved by charging a fixed payment for the information service, leading to improved operational efficiency and social welfare. We finally extend our analytical results and managerial insights to general settings, demonstrating the robustness of our findings. Our findings could provide useful guidance for platform practitioners in designing integrated information-sharing and financing services.},
  archive      = {J_POM},
  author       = {Xinru Hu and Jianbin Li and Lijian Lu},
  doi          = {10.1177/10591478251333724},
  journal      = {Production and Operations Management},
  month        = {10},
  number       = {10},
  pages        = {3309-3329},
  shortjournal = {Product. Oper. Manag.},
  title        = {Information sharing and financing services on online retailing platforms},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Strategizing value-added services for platform firms. <em>POM</em>, <em>34</em>(10), 3289-3308. (<a href='https://doi.org/10.1177/10591478251332713'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Platform firms are increasingly investing in value-added services (VAS), believing these investments in VAS universally contribute to their success. Although many studies have examined platform firms’ core services (e.g., intermediation), systematic analyses of VAS provision strategies remain limited. In this article, we develop a game-theoretic model to analyze (1) the conditions under which platform firms benefit from providing VAS and (2) to which side(s) platform firms should provide VAS. We offer several insights. First, variable service costs are a critical yet previously neglected factor in governing platform firms’ VAS provision. Second, a comparison of equilibrium outcomes across three VAS provision strategies—one-sided unidirectional, two separate unidirectional, and bidirectional—reveals that the optimal strategy is jointly determined by variable service costs, cross-network externalities, and the asymmetry in the benefits of bidirectional VAS to the two platform sides. Specifically, when asymmetry is low, bidirectional VAS is optimal. When asymmetry is high, platform firms should provide unidirectional VAS to one side, considering the second side only when variable service costs are low or cross-network externalities are significant. Third, we explore the implications of VAS provision strategies for platform firms’ investment and pricing decisions. For example, when platform firms provide two separate unidirectional VAS, these investments are complementary. VAS could incentivize platform firms to offer price subsidies to one side of the platform. Finally, optimal VAS provision strategies do not always increase consumer surplus.},
  archive      = {J_POM},
  author       = {Liwen Hou and Xinxue (Shawn) Qu and Yixing Chen and Ling Xue},
  doi          = {10.1177/10591478251332713},
  journal      = {Production and Operations Management},
  month        = {10},
  number       = {10},
  pages        = {3289-3308},
  shortjournal = {Product. Oper. Manag.},
  title        = {Strategizing value-added services for platform firms},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identifying influential users by topic in unstructured user-generated content. <em>POM</em>, <em>34</em>(10), 3267-3288. (<a href='https://doi.org/10.1177/10591478251332335'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social media users generate a variety of content that can potentially influence their followers’ behaviors and preferences. However, most user-generated content, such as text and images, is unstructured, making it difficult to analyze how individuals impact the creation of such data as existing models primarily focus on the numerical aspects of behavioral data. In this article, we propose a method to identify influential users who significantly affect others’ interest in content topics, with a specific focus on text and images. Our study introduces a new variant of the topic model, incorporating a hierarchical structure and a vector auto-regressive approach. This method accounts for both the evolution of topic distribution and the social influence among users on their interest in content topics. The empirical application of our model to image-sharing social media data demonstrates that our model outperforms conventional topic models in terms of predictive accuracy and topic interpretability. Moreover, we illustrate how visualizing the estimated social influence within the network can provide valuable insights for seeded marketing campaigns and data-driven product development by identifying influential users in various content areas. This approach also offers a deeper understanding of evolving trends in content, preferences, and demand.},
  archive      = {J_POM},
  author       = {Mirai Igarashi and Kunpeng Zhang and PK Kannan and Nobuhiko Terui},
  doi          = {10.1177/10591478251332335},
  journal      = {Production and Operations Management},
  month        = {10},
  number       = {10},
  pages        = {3267-3288},
  shortjournal = {Product. Oper. Manag.},
  title        = {Identifying influential users by topic in unstructured user-generated content},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Protecting workers from rude customers to enhance organizational identification in emotional labor environments: A study with call center agents. <em>POM</em>, <em>34</em>(10), 3250-3266. (<a href='https://doi.org/10.1177/10591478251332333'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Challenges faced by call centers in managing capacity, efficiency, service speed and quality, training, emotional labor, and turnover are intrinsically intertwined. Call center agents are considered frontline workers, and as such, they often deal with hostile behavior from rude customers. However, they are expected to suppress their feelings and maintain a courteous demeanor despite rude customer behavior, which results in emotional dissonance. Such working environments, where the frontline workers experience emotional dissonance, are termed emotional labor environments. Emotional dissonance, if sustained over a long period of time, can lead to an erosion of organizational identification (OID) among agents, unless they perceive adequate protection and support from the management. A low OID can lead to high employee turnover, which in turn results in high recruitment and training costs as well as loss of experience and compromised service quality. In this study, we examine how employee protection policies and leadership style manifest in mitigating the erosion of OID. We develop a research framework to understand the mediating role of agents’ perception of the efficacy of the firm's policies to protect them from rude customers and the relevant aspects of the servant leadership style of supervisors in mitigating the erosion of agents’ OID caused by the cumulative emotional dissonance over their tenure duration. For this study, we partner with a major multinational firm in Korea in the insurance industry. We find that the perceived organizational support for protection from rude customers and supervisors’ servant leadership style are positively related to agents’ OID. The agent's OID decreases with their tenure duration, unless mediated by the agent's perception of the efficacy of protection from rude customers. We provide insights for the retention of agents with implications for capacity and service quality for the call centers. These insights may be extended to frontline workers in other emotional labor environments.},
  archive      = {J_POM},
  author       = {Hyojeong Kim and Nagesh N Murthy and Anurag Agarwal and Kwangtae Park},
  doi          = {10.1177/10591478251332333},
  journal      = {Production and Operations Management},
  month        = {10},
  number       = {10},
  pages        = {3250-3266},
  shortjournal = {Product. Oper. Manag.},
  title        = {Protecting workers from rude customers to enhance organizational identification in emotional labor environments: A study with call center agents},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The manufacturer’s role in nanostore-supermarket supply chain competition. <em>POM</em>, <em>34</em>(10), 3230-3249. (<a href='https://doi.org/10.1177/10591478251332021'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We explore retail supply chains in emerging markets in which a manufacturer can reach consumers by selling its product through very small independent stores (nanostores) and/or through a supermarket. Nanostores offer consumers the advantage of proximity, but supermarkets offer the advantage of bulk buying. We explore the competition between the supermarket and nanostores and examine the manufacturer’s role in shaping the retail market structure for its product through wholesale price contracts. We model and analyze a multi-party supply-chain game in which a manufacturer can sell its product to spatially distributed, utility-maximizing, price-sensitive consumers through nanostores and a supermarket. Consumers can buy in bulk at the supermarket, optimizing their purchase quantity, and hence visit frequency, in an economic order quantity type approach, or they can purchase from a nanostore (frequently due to store storage-space limitations). We fully solve for the equilibrium market structure and the associated retail and wholesale prices, establishing that the manufacturer’s desired channel strategy is governed by three factors: the manufacturer-nanostore supply chain cost, the manufacturer-supermarket supply chain cost, and the supermarket bargaining power. If the supply chain efficiencies are somewhat similar, then the manufacturer should (typically, but not always) use both retail formats to avail of the nanostore advantage in serving proximate consumers and the supermarket advantage in serving distant customers. The specifics of how the manufacturer should use the retail formats will depend on the supermarket power. Among other results, we establish that aggregate nanostore demand and profit can decrease in nanostore density and that the presence of a high-power supermarket can increase consumer surplus because the manufacturer induces strong price competition.},
  archive      = {J_POM},
  author       = {Jiwen Ge and Brian Tomlin},
  doi          = {10.1177/10591478251332021},
  journal      = {Production and Operations Management},
  month        = {10},
  number       = {10},
  pages        = {3230-3249},
  shortjournal = {Product. Oper. Manag.},
  title        = {The manufacturer’s role in nanostore-supermarket supply chain competition},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Competitive industry’s response to environmental taxation. <em>POM</em>, <em>34</em>(10), 3214-3229. (<a href='https://doi.org/10.1177/10591478251331345'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyze how N firms producing a commodity good with a polluting by-product respond to environmental taxes. These firms vary in operational and environmental efficiency. Under Cournot competition, we examine two demand functions: iso-elastic and linear. We establish the existence and uniqueness of the equilibrium and examine how it changes with tax levels and environmental efficiency. Our findings suggest that taxes may not always benefit firms with green, low-cost technologies, as they erode the advantages of operational efficiency. Additionally, total and per-unit emissions may increase with higher taxes or improved environmental efficiency. Finally, the observed effects can qualitatively differ based on the form of market demand.},
  archive      = {J_POM},
  author       = {Dmitry Krass and Anton Ovchinnikov},
  doi          = {10.1177/10591478251331345},
  journal      = {Production and Operations Management},
  month        = {10},
  number       = {10},
  pages        = {3214-3229},
  shortjournal = {Product. Oper. Manag.},
  title        = {Competitive industry’s response to environmental taxation},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Political uncertainty and the timing of mass layoffs. <em>POM</em>, <em>34</em>(10), 3193-3213. (<a href='https://doi.org/10.1177/10591478251331149'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study examines the relation between political uncertainty arising from state-level election cycles and the timing of employee dismissal and plant closure notices filed by US firms under the Worker Adjustment and Retraining Notification (WARN) Act of 1988 (hereafter, WARN notices). We appeal to a real options framework to predict that firms delay layoff decisions and the issuance of WARN notices until the resolution of political uncertainty. Using establishment-level data on layoffs disclosed in WARN notices and state elections occurring between 1994 and 2022, we document that the likelihood of issuing WARN notices declines during the election quarter but increases in the subsequent quarter. Cross-sectional findings show that political uncertainty plays a significant role in the timing of WARN notices during election periods while other factors, including partisanship, economic conditions, union strength, and firm visibility, may also play a role. Further, firms that delay WARN notices do not experience a significant deterioration in their medium-term financial performance. Overall, our findings provide evidence that firms delay labor adjustment decisions and the announcements of such decisions in response to political uncertainty.},
  archive      = {J_POM},
  author       = {Varouj Aivazian and Tzu-Ting Chiu and Miguel Minutti-Meza and Dushyantkumar Vyas},
  doi          = {10.1177/10591478251331149},
  journal      = {Production and Operations Management},
  month        = {10},
  number       = {10},
  pages        = {3193-3213},
  shortjournal = {Product. Oper. Manag.},
  title        = {Political uncertainty and the timing of mass layoffs},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic distributed ambulatory care scheduling. <em>POM</em>, <em>34</em>(10), 3173-3192. (<a href='https://doi.org/10.1177/10591478251331143'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate an ambulatory care scheduling problem derived from a real case in Ontario, Canada that offers multi-appointment, multi-class, multi-priority treatments in geographically distributed campuses with multiple resources. We consider a dynamic setting with uncertain patient arrival and use of the emergency department. This problem is formulated as an infinite-horizon Markov decision process model. Since we cannot solve large-sized instances via conventional approaches, we hybridize this model with a neural network to simplify feasibility constraints while respecting all assumptions. Given the curse of dimensionality, we use an affine approximation architecture to estimate the value function. An equivalent linear programing model is solved through column generation in order to compute approximate optimal policies and derive two easy-to-implement scheduling policies. Simulation results demonstrate that the approximate optimal policy and heuristics outperform alternative scheduling policies. Finally, we demonstrate that the application of our methodology can enhance performance metrics in a large ambulatory care center in Canada. We show that a template-based scheduling rule can result in high resource utilization but poor scheduling decisions. However, an efficient scheduling policy equips a booking clerk with intelligent scheduling rules that are difficult for her to predict in real-time and work well in comparison to scheduling templates.},
  archive      = {J_POM},
  author       = {Amirhossein Moosavi and Onur Ozturk and Jonathan Patrick},
  doi          = {10.1177/10591478251331143},
  journal      = {Production and Operations Management},
  month        = {10},
  number       = {10},
  pages        = {3173-3192},
  shortjournal = {Product. Oper. Manag.},
  title        = {Dynamic distributed ambulatory care scheduling},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing user experience: Unveiling the role of the quality score metrics. <em>POM</em>, <em>34</em>(10), 3157-3172. (<a href='https://doi.org/10.1177/10591478251331129'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social advertising platforms and search engines employ the so-called quality score to favor certain advertisers in ad auctions. These scores typically consider several factors including ad relevance, click-through rate (CTR), and landing page quality. While quality scores are often justified as a mechanism to enhance ad rank and reduce cost per click for high-quality ads, this study examines their broader role in incentivizing advertisers with varying investment costs to improve landing page quality and explores the implications for advertisers’ profits and the platform’s revenue in a setting where landing page quality is an endogenous decision made by advertisers. The results suggest that a quality score function in excess of the CTR incentivizes advertisers to invest in page quality in a non-monotonic way. These incentives have dual effects on auction dynamics: While advertisers can lower their cost per click by improving quality, such incentives also increase advertisers’ competitive pressure to maintain their quality advantage and secure the discount per click, particularly for those in higher positions. Our findings reveal that the former effect dominates, leading to increased advertiser profits with higher rewards. However, the intensified competition slows the profit growth for the top-position advertiser when the bottom-position advertiser invests. For platform revenue, which comprises both auction revenue and benefits derived from user experience, a quality score in excess of CTR is recommended when the user experience benefits are substantial enough to compensate for auction revenue losses. In a scenario where page quality is capped, our results show that a quality score in excess of CTR can generate higher platform revenue, even in the absence of user experience benefits.},
  archive      = {J_POM},
  author       = {Zsolt Katona and Yi Zhu and Lei Zhuang},
  doi          = {10.1177/10591478251331129},
  journal      = {Production and Operations Management},
  month        = {10},
  number       = {10},
  pages        = {3157-3172},
  shortjournal = {Product. Oper. Manag.},
  title        = {Enhancing user experience: Unveiling the role of the quality score metrics},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal processing and trading for a commodity in the presence of inventory conversion flexibility and random supply. <em>POM</em>, <em>34</em>(10), 3138-3156. (<a href='https://doi.org/10.1177/10591478251331127'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a decision support system used by an agricultural cooperative in the Indian states of Andhra Pradesh and Telangana to optimize the purchase, blending, sale, and storage of groundnuts for maximum profit. The cooperative buys raw groundnuts (input commodity) from member farmers and processes them into multiple grades of groundnut seeds (output commodity). These may then be blended to create intermediate grades to exploit arbitrage opportunities. The cooperative sells part of the output on the spot market while storing the rest for future periods. A key challenge is the random supply of input commodity—driven by the cooperative’s obligation to accept all member produce—and the option to blend the output. Unlike prior work, this study examines blending across a multiperiod planning horizon, a novel aspect in operations management literature. The problem is modeled as a dynamic program over a harvest season. We analyze the structure of the optimal value function and decisions and find that the function is not separable in input and output inventories, which complicates the identification of optimal solution. However, in special cases such as when blending is disallowed, the function simplifies. An efficient computational procedure is developed for the general case. Using real cooperative data, we demonstrate that multiperiod blending significantly boosts profits—by 100–900%, or Indian National Rupees 1.94–17.46 million annually—highlighting the value of this approach.},
  archive      = {J_POM},
  author       = {Ashish S Bhandari and Amar Sapra and Sridhar Seshadri and Trilochan Sastry},
  doi          = {10.1177/10591478251331127},
  journal      = {Production and Operations Management},
  month        = {10},
  number       = {10},
  pages        = {3138-3156},
  shortjournal = {Product. Oper. Manag.},
  title        = {Optimal processing and trading for a commodity in the presence of inventory conversion flexibility and random supply},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mitigating churn after online financial fraud: The value of blame attribution. <em>POM</em>, <em>34</em>(10), 3119-3137. (<a href='https://doi.org/10.1177/10591478251331125'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The financial industry is plagued with account-based fraudulent transactions in which perpetrators surreptitiously siphon away money from customer accounts. To address this recurrent problem, service operations teams at financial institutions (e.g., the fraud detection and mitigation teams) spend millions yearly identifying perpetrators, attributing blame, and averting customer churn. However, in the vast majority of cases, the service operations teams cannot trace fraudulent transactions back to the perpetrators, and hence, it remains unclear whether they should continue to expend significant resources into investigating account-based fraud and attributing blame. Employing a wide range of econometric and machine learning techniques on a rich dataset from a US bank and an experiment, we attempt to offer the first empirical assessment of the association between blame attribution, or lack of it, in response to customer-identified account-based fraud and customer churn. The results indicate that relative to the customers that did not experience fraud, those that did and received a resolution lacking blame attribution have 40.69 %Lift (95% confidence interval (CI) = [24.41 %Lift , 56.97 %Lift ]) in churn rate. However, customers that experienced fraud and received a resolution involving blame attribution have −62.45 %Lift (95% CI = [−31.22 %Lift , −93.68 %Lift ]) in churn rate, making them less likely to churn than those that did not experience fraud. The latter result offers one of the first field evidence of the well-known service recovery paradox. Additionally, we observe significant heterogeneity in the findings based on customer tenure and the number of customer-firm interactions and document the long-term effects of attributing and not attributing blame. These insights can assist service operations teams in their postservice failure efforts to mend customer-firm relationships. Overall, the results underscore the importance of blame attribution during service recovery for service operations teams and inform a topical debate on a banking reform proposed by the US Department of Treasury.},
  archive      = {J_POM},
  author       = {Sriram Somanchi and Vamsi K Kanuri and Rahul Telang},
  doi          = {10.1177/10591478251331125},
  journal      = {Production and Operations Management},
  month        = {10},
  number       = {10},
  pages        = {3119-3137},
  shortjournal = {Product. Oper. Manag.},
  title        = {Mitigating churn after online financial fraud: The value of blame attribution},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Algorithmic supervisor and employee performance. <em>POM</em>, <em>34</em>(10), 3101-3118. (<a href='https://doi.org/10.1177/10591478251331095'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we explore the impact of implementing an algorithmic supervisor, a data analytics tool that offers real-time feedback to employees, on their overall performance. We collaborate with a leading service company that initiated the transition from human supervisors to an algorithmic supervisor for managing call agents in their outbound call center on September 18, 2019. We collect data for 220,085 calls over a span of 6 months—that is, 3 months before and 3 months after the introduction of the algorithmic supervisor. We find that the introduction of the algorithmic supervisor improved the agents’ service quality in terms of customer satisfaction; however, this came at the expense of quantity as fewer customers were served. In particular, the adoption of the algorithmic supervisor resulted in a 15.80% reduction in the number of served customers, accompanied by a 14.91% increase in the number of satisfied customers. Moreover, our study uncovers a gender-related dimension to the impact of the algorithmic supervisor. Before its adoption, male agents outperformed their female counterparts. However, after its adoption, female agents exhibited an 11.52% increase in the number of served customers, and a remarkable 14.00% increase in the number of satisfied customers as compared to their male counterparts. Our results suggest that the adoption of the algorithmic supervisor strikes a new economic balance between service quality and service quantity and generates a social impact in differently affecting service performance of female and male employees.},
  archive      = {J_POM},
  author       = {Wei Gu and Meng Li and Shichen Zhang},
  doi          = {10.1177/10591478251331095},
  journal      = {Production and Operations Management},
  month        = {10},
  number       = {10},
  pages        = {3101-3118},
  shortjournal = {Product. Oper. Manag.},
  title        = {Algorithmic supervisor and employee performance},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Customer concentration and suppliers’ blockchain technology adoption: Evidence from china. <em>POM</em>, <em>34</em>(10), 3082-3100. (<a href='https://doi.org/10.1177/10591478251330062'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study examines the relationship between major customer concentration and supplier firms’ adoption of blockchain. Using a sample of 9,745 Chinese firm-year observations spanning 2018–2021, we find that the likelihood of suppliers’ blockchain technology adoption in supply chain management is negatively associated with major customer concentration. The negative relation is reduced when supplier firms possess greater bargaining power and demonstrate governance mechanisms against information leakage, and when major customers have less incentive to engage in opportunistic behaviors, and have fewer concerns regarding information leakage by suppliers. Our findings suggest that major customers tend to discourage supplier firms from adopting blockchain due to the concerns regarding competitive advantages and information leakage risk.},
  archive      = {J_POM},
  author       = {Chaofan Li and Qiliang Liu and Wenming Wang and Cheng (Colin) Zeng and Pin Zhou},
  doi          = {10.1177/10591478251330062},
  journal      = {Production and Operations Management},
  month        = {10},
  number       = {10},
  pages        = {3082-3100},
  shortjournal = {Product. Oper. Manag.},
  title        = {Customer concentration and suppliers’ blockchain technology adoption: Evidence from china},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pricing in the presence of strategic consumers and social learning under contingent pricing and price guarantee. <em>POM</em>, <em>34</em>(10), 3063-3081. (<a href='https://doi.org/10.1177/10591478251329858'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Purchasing new experience products or services often involves significant quality uncertainty for both consumers and firms. Social learning through online reviews helps reduce this uncertainty but exacerbates strategic waiting, as consumers delay purchases to gain more information. This paper examines the impact of social learning on firms’ pricing policies in the presence of strategic consumers under two widely adopted schemes: Contingent pricing and price guarantee. We find that while social learning always benefits the firm, it enables the price guarantee scheme to outperform contingent pricing in terms of profitability for highly patient consumers, which would not be possible without social learning. Notably, social learning drives a range of pricing patterns, even making price skimming optimal under price guarantee for highly patient consumers, as high initial prices combined with markdowns effectively alleviate strategic waiting, enhancing review outcomes and the firm’s profitability. Additionally, social learning always enables the firm to extract greater consumer surplus for impatient consumers under price guarantee. In contrast, social learning under contingent pricing consistently benefits consumers and can achieve win-win outcomes when consumers are moderately patient. Our extensions validate the robustness of these findings under different assumptions, including fully rational consumers and partially forward-looking firms. In particular, a partially forward-looking firm can achieve win-win outcomes with social learning under price guarantee, expanding its practical applicability. This study provides novel insights into the role of social learning in shaping pricing strategies, highlighting its implications for firm profitability and consumer welfare in markets influenced by review dynamics and strategic consumers.},
  archive      = {J_POM},
  author       = {Zhong-Zhong Jiang and Jinlong Zhao and Zelong Yi and Ying-Ju Chen and Guang Li},
  doi          = {10.1177/10591478251329858},
  journal      = {Production and Operations Management},
  month        = {10},
  number       = {10},
  pages        = {3063-3081},
  shortjournal = {Product. Oper. Manag.},
  title        = {Pricing in the presence of strategic consumers and social learning under contingent pricing and price guarantee},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Social heart and business sense: Translating corporate social responsibility into gross margin premium per mandatory corporate social responsibility law in india. <em>POM</em>, <em>34</em>(10), 3042-3062. (<a href='https://doi.org/10.1177/10591478251329011'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research assesses the impact of Indian government-mandated firms’ corporate social responsibility (CSR) related investments on gross margins. Using a multimethod approach, we show (a) a positive relationship between CSR investments and gross margin and (b) the moderating role of advertising investment. The contribution of our research is three-fold. First, our results suggest that mandating firms to spend on CSR can be a win-win situation for firms and governments, as opposed to the view of considering mandatory CSR as an additional burden. Second, our inquiry is one of the first to analytically and empirically show CSR contribution positively affects gross margin premium, which is based on price, important revenue-generating marketing, and operations construct. Third, we show the moderating role of advertising in achieving CSR-related gross margin premium. We discuss our study's implications for marketing and operations managers and policymakers.},
  archive      = {J_POM},
  author       = {S Arunachalam and Hariom Manchiraju and Rahul Suhag and Praveen K Kopalle},
  doi          = {10.1177/10591478251329011},
  journal      = {Production and Operations Management},
  month        = {10},
  number       = {10},
  pages        = {3042-3062},
  shortjournal = {Product. Oper. Manag.},
  title        = {Social heart and business sense: Translating corporate social responsibility into gross margin premium per mandatory corporate social responsibility law in india},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Team design and its implications for competition and disclosure. <em>POM</em>, <em>34</em>(10), 3026-3041. (<a href='https://doi.org/10.1177/10591478251328879'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article examines how the composition of managerial teams influences the information and competitive landscapes in which firms operate. Specifically, the impact of teams depends on the task environment under which they operate and the extent of competition the firm faces in the product markets. Under a substitute task environment, team heterogeneity better facilitates firm learning, whereas, under a complementary task environment, team homogeneity enhances learning. However, more learning is not always optimal, as this accentuates adverse selection concerns, which leads the firm's rival to counter by becoming more aggressive in competition. This, in turn, forces the firm to cede some of its information advantage through disclosures. In effect, when designing teams to manage information, the firm must balance its learning needs with its rival's competitive threats. Consequently, in a substitute task environment, team heterogeneity is only optimal for the firm when competition is not fierce, and homogeneity is desirable otherwise. In a complementary task environment, the preference for teams as a function of competition is reversed. Additionally, any inherent heterogeneity in the level of competition in the product markets in which the firm operates diminishes the demand for team heterogeneity. The article also derives the firm's optimal team composition when the markets are characterized by Bertrand or Cournot competition, when the available managerial pool for the firm is constrained or unconstrained, when tasks are market-specific or firm-specific, and when the task environment is generalized.},
  archive      = {J_POM},
  author       = {Anil Arya and Ram NV Ramanan},
  doi          = {10.1177/10591478251328879},
  journal      = {Production and Operations Management},
  month        = {10},
  number       = {10},
  pages        = {3026-3041},
  shortjournal = {Product. Oper. Manag.},
  title        = {Team design and its implications for competition and disclosure},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lead time prediction for inventory optimization with machine learning. <em>POM</em>, <em>34</em>(10), 3010-3025. (<a href='https://doi.org/10.1177/10591478251328630'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern decision-support applications build on planning parameters such as lead time, price, yield, etc., which are maintained as master data. The accuracy of master data significantly influences the viability of such applications. However, the maintenance of master data is considered a tedious and error-prone task. In this study, we explore the effectiveness of machine learning techniques to improve the accuracy of plan lead times. We apply both unsupervised and supervised learning methods for creating lead time prediction models. We test our approach using historical data of a global equipment manufacturer. In a numerical analysis the calculated plan lead times are over 30% more accurate than current plan lead times in terms of mean-squared-error (MSE). This increased accuracy of plan lead times reduces inventory investment by approximately 7%.},
  archive      = {J_POM},
  author       = {Robin Reiners and Christiane B Haubitz and Ulrich W Thonemann},
  doi          = {10.1177/10591478251328630},
  journal      = {Production and Operations Management},
  month        = {10},
  number       = {10},
  pages        = {3010-3025},
  shortjournal = {Product. Oper. Manag.},
  title        = {Lead time prediction for inventory optimization with machine learning},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). E-waste take-back and producer eco-innovation: Empirical analysis of state regulations in the united states. <em>POM</em>, <em>34</em>(10), 2991-3009. (<a href='https://doi.org/10.1177/10591478251328587'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {E-waste take-back regulation in the United States requires producers to manage their products at the end of life. This legislation aims to stimulate product and process innovations that reduce the environmental impact of E-waste. In this study, we employ a staggered difference-in-differences approach to explore the causal relationship between state E-waste regulations and eco-innovation among producers. Our results indicate that E-waste regulations significantly boost the number of eco-patents filed by producers, with the effect intensifying as regulatory pressure increases. Additionally, our findings show that regulated producers tend to focus more on upstream resource efficiency innovations than on downstream waste management. This research offers valuable insights for policymakers and industry practitioners aiming to enhance practices for E-waste management.},
  archive      = {J_POM},
  author       = {Yuqi Peng and Sining Song and Sriram Venkataraman and Yan Dong},
  doi          = {10.1177/10591478251328587},
  journal      = {Production and Operations Management},
  month        = {10},
  number       = {10},
  pages        = {2991-3009},
  shortjournal = {Product. Oper. Manag.},
  title        = {E-waste take-back and producer eco-innovation: Empirical analysis of state regulations in the united states},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Follow my lead? impacts of multidimensional expert reviews on subsequent consumer ratings. <em>POM</em>, <em>34</em>(10), 2970-2990. (<a href='https://doi.org/10.1177/10591478251328212'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To mitigate information asymmetry, Expert Review Programs, in which experts evaluate products on multiple dimensions, have gained traction on platforms. However, the role of multidimensional expert reviews and how they affect consumer behaviors remain unknown. Using an empirical opportunity on an automobile review platform, we investigate how multidimensional expert reviews affect subsequent consumer ratings and the underlying mechanism. Our findings first reveal that expert reviews tend to be neutral and more critical than consumer ratings. We then find that consumers provide reviews with higher ratings following expert reviews due to the information disclosure effect. Decomposing the effect by expert reviews’ multidimensional characteristics, we find the effect is attenuated by multidimensional expert rating valence and multidimensional rating discrepancy between experts and consumers but amplified by multidimensional expert rating variance. Natural language processing of consumer review texts unveils a positive impact of multidimensional expert reviews on consumer satisfaction and a negative impact on consumer disappointment, which speaks to the underlying mechanism behind the information disclosure effect. Lastly, we find that the effect varies with expert characteristics, product characteristics, and information channels, diminishes when multidimensional expert reviews are posted sooner after product launch, and decays over time but persists in the long run. These findings not only advance information theories in understanding expert reviews and multidimensional rating systems but also provide valuable insights for stakeholders, such as platforms, firms, and expert reviewers, to improve review program operations and consumer engagement.},
  archive      = {J_POM},
  author       = {Demei Kong and Karen Xie and Jun Yang},
  doi          = {10.1177/10591478251328212},
  journal      = {Production and Operations Management},
  month        = {10},
  number       = {10},
  pages        = {2970-2990},
  shortjournal = {Product. Oper. Manag.},
  title        = {Follow my lead? impacts of multidimensional expert reviews on subsequent consumer ratings},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). What do we know about the science of science in business and economics? insights from the top 50 journals, 2008–2022. <em>POM</em>, <em>34</em>(10), 2943-2969. (<a href='https://doi.org/10.1177/10591478251334200'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We conduct a descriptive analysis of the performance of disciplines, journals, authors, and universities based on the number of publications in 50 business and economics journals represented in the Financial Times list (FT 50) from 2008 to 2022 using data from the Web of Science. We analyze more than 55,000 papers published by more than 54,000 unique authors during this period to document four sets of findings. First, our analysis suggests that Operations Management and Multidisciplinary areas experienced significant publication growth from 2008 to 2022, increasing their publication and citation share in FT 50 journals, even after accounting for the relative handicap in terms of number of journals in the FT 50 list. Second, the growth in publications of the Operations Management discipline is driven by significant growth in Production and Operations Management and Manufacturing and Service Operations Management . The Journal of Business Ethics is a notable outlier, it alone published nearly 10% of the papers published in the FT 50 list, more than the number of papers published by the five disciplines each: Accounting, Marketing, Multidisciplinary, Operations Management, and Information Systems. Third, we find that the most prolific authors in Management and Organizations, Operations Management, Economics, and Marketing had a higher number of publications during the 2008–2022 period than the most prolific authors of other disciplines. Finally, our analyses of the most prolific 150 worldwide universities published in the FT 50 list suggest that the list is dominated mostly by about a dozen countries that include North American countries (the USA and Canada), European countries (Netherlands, Germany, the UK, France, and Spain), China (including Hong Kong), Australia, and Singapore. We discuss the implications of our findings for ranking organizations, editors, academic associations, individual scientists, administrators, and policymakers.},
  archive      = {J_POM},
  author       = {Sunil Mithas and Alysson Silveira and Gleb Zavadskiy},
  doi          = {10.1177/10591478251334200},
  journal      = {Production and Operations Management},
  month        = {10},
  number       = {10},
  pages        = {2943-2969},
  shortjournal = {Product. Oper. Manag.},
  title        = {What do we know about the science of science in business and economics? insights from the top 50 journals, 2008–2022},
  volume       = {34},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="sw">SW - 7</h2>
<ul>
<li><details>
<summary>
(2025). HiHo: A hierarchical and homogenous subgraph learning model for knowledge graph relation prediction. <em>SW</em>, <em>16</em>(5). (<a href='https://doi.org/10.1177_22104968251361290'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Relation prediction in knowledge graphs (KGs) aims to anticipate the connections between entities. While both transductive and inductive models are incorporated for context comprehension, we need to focus on two primary issues. First, these models only collate relations at each layer of the subgraph, overlooking the potential sequential relationship between different layers. Second, these methods overlook the homogeneity of subgraphs, thus impeding their ability to effectively learn the importance of relationships within the subgraphs. To address this challenge, we propose a hierarchical and homogenous subgraph learning model for KG relation prediction (HiHo). Specifically, we adopt a subgraph-to-sequence mechanism to learn the potential semantic associations between layers in the subgraph of a single entity, and thus model the hierarchy of the subgraph. Then, we implement a common preference inference mechanism that assigns higher weights to co-occurrence relations while learning the importance of each relation in the subgraphs of two entities, and thus models the homogeneity of the subgraph. In our study, we sequentially employ induction on each layer of subgraphs pertaining to the two entities for relation prediction. To assess the efficacy of our method, we perform experiments on five publicly available datasets. The results of our experiments demonstrate that our method surpasses the current state-of-the-art baselines in both transductive and inductive settings.},
  archive      = {J_SW},
  author       = {Jiangtao Ma and Yuke Ma and Fan Zhang and Yanjun Wang and Xiangyang Luo and Chenliang Li and Yaqiong Qiao},
  doi          = {10.1177_22104968251361290},
  journal      = {Semantic Web},
  month        = {9},
  number       = {5},
  shortjournal = {Semantic Web},
  title        = {HiHo: A hierarchical and homogenous subgraph learning model for knowledge graph relation prediction},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transformer-based architectures versus large language models in semantic event extraction: Evaluating strengths and limitations. <em>SW</em>, <em>16</em>(5). (<a href='https://doi.org/10.1177_22104968251363759'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding complex societal events reported on the Web, such as military conflicts and political elections, is crucial in digital humanities, computational social science, and news analyses. While event extraction is a well-studied problem in natural language processing (NLP), there remains a gap in semantic event extraction methods that leverage event ontologies for capturing multifaceted events in knowledge graphs. In this article, we aim to compare two paradigms to address this task of semantic event extraction: the fine-tuning of traditional transformer-based models versus the use of large language models (LLMs). We exemplify these paradigms with two newly developed approaches: T-SEE for transformer-based and L-SEE for LLM-based semantic event extraction. We discuss their complementary strengths and shortcomings to understand the needs and solutions required for semantic event extraction. For comparison, both approaches employ the same dual-stage architecture; the first stages focus on multilabel event classification, and the second on relation extraction. While T-SEE utilises a span prediction transformer model, L-SEE prompts an LLM for event classification and relation extraction, providing the potential event classes and properties. We assess the performances of T-SEE and L-SEE on two novel datasets sourced from DBpedia and Wikidata, and we perform an extensive error analysis. Our work makes substantial contributions to (i) the integration of Semantic Web technologies and NLP, particularly in the underexplored domain of semantic event extraction, and (ii) the understanding of how LLMs can further enhance semantic event extraction and what challenges need to be considered in comparison to traditional approaches.},
  archive      = {J_SW},
  author       = {Tin Kuculo and Sara Abdollahi and Simon Gottschalk},
  doi          = {10.1177_22104968251363759},
  journal      = {Semantic Web},
  month        = {9},
  number       = {5},
  shortjournal = {Semantic Web},
  title        = {Transformer-based architectures versus large language models in semantic event extraction: Evaluating strengths and limitations},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CaLiGraph: A knowledge graph from wikipedia categories and lists. <em>SW</em>, <em>16</em>(5). (<a href='https://doi.org/10.1177_22104968251361349'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs (KGs) are increasingly used for solving or supporting tasks such as question answering or recommendation. To achieve a useful performance on such tasks, it is important that the knowledge modeled by KGs is as correct and complete as possible. While this is an elusive goal for many domains, techniques for automated KG construction (AKGC) serve as a means to approach it. Yet, AKGC has many open challenges, like learning expressive ontologies or incorporating long-tail entities. With CaLiGraph, we present a KG automatically constructed from categories and lists in Wikipedia, offering a rich taxonomy with semantic class descriptions and a broad coverage of entities. We describe its extraction framework and provide details about its purpose, resources, usage, and quality. Further, we evaluate the performance of CaLiGraph on downstream tasks and compare it to other popular KGs.},
  archive      = {J_SW},
  author       = {Nicolas Heist and Heiko Paulheim},
  doi          = {10.1177_22104968251361349},
  journal      = {Semantic Web},
  month        = {9},
  number       = {5},
  shortjournal = {Semantic Web},
  title        = {CaLiGraph: A knowledge graph from wikipedia categories and lists},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GloSIS: The global soil information system web ontology. <em>SW</em>, <em>16</em>(5). (<a href='https://doi.org/10.1177_22104968251363767'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Established in 2012 by members of the Food and Agriculture Organisation of the United Nations, the Global Soil Partnership (GSP) is a global network of stakeholders promoting sound land and soil management practices towards a sustainable world food system. However, soil survey largely remains a local or regional activity, bound to heterogeneous methods and conventions. Recognising the relevance of global and trans-national policies towards sustainable land management practices, the GSP elected data harmonisation and exchange as one of its key lines of action. Building upon international standards and previous work towards a global soil data ontology, an improved domain model was eventually developed within the GSP, the basis for a Global Soil Information System (GloSIS). This work also identified the Semantic Web as a possible avenue to operationalise the domain model. This article presents the GloSIS web ontology, an implementation of the GloSIS domain model with the Web Ontology Language (OWL). Thoroughly employing a host of Semantic Web standards (Sensor, Observation, Sample, and Actuator ontology (SOSA), Simple Knowledge Organisation System (SKOS), GeoSPARQL, QUDT), GloSIS lays out not only a soil data ontology but also an extensive set of ready-to-use code-lists for soil description and physico-chemical analysis. Various examples are provided on the provision and use of GloSIS-compliant linked data, showcasing the contribution of this ontology to the discovery, exploration, integration and access of soil data.},
  archive      = {J_SW},
  author       = {Raul Palma and Bogusz Janiak and Luís M de Sousa and Kathi Schleidt and Tomáš Řezník and Fenny van Egmond and Johan Leenaars and Dimitrios Moshou and Abdul Mounem Mouazen and Peter Wilson and David Medyckyj-Scott and Alistair Ritchie and Yusuf Yigini and Ronald Vargas},
  doi          = {10.1177_22104968251363767},
  journal      = {Semantic Web},
  month        = {9},
  number       = {5},
  shortjournal = {Semantic Web},
  title        = {GloSIS: The global soil information system web ontology},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Algebraic mapping operators for knowledge graph generation. <em>SW</em>, <em>16</em>(5). (<a href='https://doi.org/10.1177_22104968251361350'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in declarative knowledge graph generation have introduced multiple mapping languages and engines, causing a shift in studies towards optimizing the knowledge graph generation process. Although these engines commonly generate the knowledge graphs from heterogeneous data sources, sharing the optimization techniques and features remains challenging due to the lack of formal operational semantics. To address this, we propose a set of algebraic mapping operators that define operational semantics for general mapping processes. This algebra, based on the SPARQL algebra, enables reuse of established definitions and strengthens the link between knowledge graph generation and query engines. To evaluate language independence we translated mapping languages ShExML and the RDF Mapping Language (RML) into our algebraic mapping plan. Our completeness evaluation shows that our algebraic operators cover the operational semantics of RML and partially support ShExML. Additional analysis is required to cover additional features of ShExML such as joining data from two input sources. For performance evaluation, our proof-of-concept algebraic mapping engine exhibits consistent and low memory usage across workloads, getting second place in the Knowledge Graph Construction Workshop's performance challenge. Algebraic mapping operators decouple mapping engines from specific languages, enabling multilingual mapping engines and allowing optimization techniques to be applied independently of the mapping process. This work lays the foundation for theoretical analysis of complexity and expressiveness of mapping languages and enforces consistency in execution semantics of mapping engines. Furthermore, aligning our algebra with SPARQL opens the door to advanced methods such as virtualization for querying heterogeneous data sources.},
  archive      = {J_SW},
  author       = {Sitt Min Oo and Ben De Meester and Ruben Taelman and Pieter Colpaert},
  doi          = {10.1177_22104968251361350},
  journal      = {Semantic Web},
  month        = {9},
  number       = {5},
  shortjournal = {Semantic Web},
  title        = {Algebraic mapping operators for knowledge graph generation},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RePlanIT ontology for digital product passports of ICT: Laptops and data servers. <em>SW</em>, <em>16</em>(5). (<a href='https://doi.org/10.1177_22104968251361274'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing digitisation that we have witnessed in the past few years has resulted in increased information and communications technology (ICT) hardware manufacturing, which is not sustainable due to the growing demand for critical materials and the greenhouse emissions associated with it. A solution is transitioning to a circular economy (CE). To facilitate this, boost the data economy and digital innovation, the European Union has introduced digital product passports (DPPs), which should provide information about a product’s lifetime to bring more transparency into supply chains. However, several challenges, namely the lack of findable, accessible, interoperable, reusable ICT and materials data and tools to support its interpretation for decision-making, are present. Utilising ontologies and knowledge graphs is a possible solution. Although the ontology work in the ICT and materials domains has been on the rise, there is a lack of a unified semantic model that can capture the complex, heterogeneous cross-domain data needed for building DPPs of ICT devices such as laptops and data servers. Motivated by this, we present the RePlanIT ontology for ICT DPPs, which captures knowledge on several levels – ICT device, hardware components, materials and the CE itself. RePlanIT’s specification is based on a literature survey, interviews and inputs from domain experts from both industry and academia. The ontology, its utilisation for building a knowledge graph of DPPs of laptops and data servers and its application have been successfully validated in a real-world case focusing on supporting more sustainable ICT procurement in government.},
  archive      = {J_SW},
  author       = {Anelia Kurteva and Carlo van der Valk and Kathleen McMahon and Alessandro Bozzon and Ruud Balkenende},
  doi          = {10.1177_22104968251361274},
  journal      = {Semantic Web},
  month        = {9},
  number       = {5},
  shortjournal = {Semantic Web},
  title        = {RePlanIT ontology for digital product passports of ICT: Laptops and data servers},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical blockmodeling for knowledge graphs. <em>SW</em>, <em>16</em>(5). (<a href='https://doi.org/10.1177_22104968251377338'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we investigate the use of probabilistic graphical models, specifically stochastic blockmodels, for the purpose of hierarchical entity clustering on knowledge graphs. These models, seldom used in the Semantic Web community, decompose a graph into a set of probability distributions. The parameters of these distributions are then inferred allowing for their subsequent sampling to generate a random graph. In a non-parametric setting, this allows for the induction of hierarchical clusterings without prior constraints on the hierarchy’s structure. Specifically, this is achieved by the integration of the nested Chinese restaurant process and the stick breaking process into the generative model. In this regard, we propose a model leveraging such integration and derive a collapsed Gibbs sampling scheme for its inference. To aid in understanding, we describe the steps in this derivation and provide an implementation for the sampler. We evaluate our model on synthetic and real-world datasets and quantitatively compare against benchmark models. We further evaluate our results qualitatively and find that our model is capable of inducing coherent cluster hierarchies in small scale settings. The work presented in this article provides the first step for the further application of stochastic blockmodels for knowledge graphs on a larger scale. We conclude the article with potential avenues for future work on more scalable inference schemes.},
  archive      = {J_SW},
  author       = {Marcin Pietrasik and Marek Reformat and Anna Wilbik},
  doi          = {10.1177_22104968251377338},
  journal      = {Semantic Web},
  month        = {9},
  number       = {5},
  shortjournal = {Semantic Web},
  title        = {Hierarchical blockmodeling for knowledge graphs},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
