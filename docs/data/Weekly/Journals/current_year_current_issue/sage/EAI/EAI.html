<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>EAI</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="eai">EAI - 11</h2>
<ul>
<li><details>
<summary>
(2025). Automated data bias mitigation technique for algorithmic fairness. <em>EAI</em>, <em>38</em>(3), 436-453. (<a href='https://doi.org/10.1177/30504554251328351'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning fairness enhancement methods based on data bias correction are usually divided into two processes: The determination of sensitive attributes (such as race and gender) and the correction of data bias. In terms of determining sensitive attributes, existing studies tend to rely too heavily on sociological knowledge and neglect the importance of exploring potential sensitive attributes directly from the data itself. The accuracy of this approach is limited when dealing with data that cannot be fully explained by sociological factors. Regarding data bias correction, existing methods are primarily categorized into causality-based and association-based methods. The former requires a deep understanding of the underlying causal structure in the dataset, which is often difficult to achieve in practice. The latter method correlates sensitive attributes with algorithmic results through statistical measures, but this approach often tends to ignore the impact of sensitive attributes on other attributes. In this paper, we formalize the identification of sensitive attributes as a problem solvable through data analysis, without relying on commonly recognized knowledge in social science. We also propose a data pre-processing method that considers the effects of attributes correlated with sensitive attributes to enhance algorithmic fairness by combining the association-based bias reduction method. We evaluated our proposed method on a public dataset. The evaluation results indicate that our method can accurately identify sensitive attributes and improve the fairness of machine learning algorithms compared to existing methods.},
  archive      = {J_EAI},
  author       = {Jiale Shi and Chuitian Rong},
  doi          = {10.1177/30504554251328351},
  journal      = {The European Journal on Artificial Intelligence},
  month        = {8},
  number       = {3},
  pages        = {436-453},
  shortjournal = {Eur. Artif. Intell.},
  title        = {Automated data bias mitigation technique for algorithmic fairness},
  volume       = {38},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Small targets detection in LIDAR point clouds based on deep learning. <em>EAI</em>, <em>38</em>(3), 417-435. (<a href='https://doi.org/10.1177/30504554251328462'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A multifeature fusion small-target detection network (MF-Net) is proposed based on PointRCNN, aimed at enhancing the detection accuracy of small targets in vehicle-mounted LiDAR systems. Semantically controlled farthest point sampling and multisampling strategies are presented to achieve uniform sampling and retain a greater number of small target points. Additionally, a local feature aggregation module is utilized to learn the intensity features of small target point clouds through spatial intensity encoding. Furthermore, PointPillars technology is implemented to convert the three-dimensional point cloud into a pseudo-image, allowing for the extraction of features at various scales using a feature pyramid network. Experimental results demonstrate that MF-Net improves the mean average precision for pedestrian and cyclist detection by 2.49% and 2.88%, respectively, compared to the baseline network PointRCNN. The false detection rate is reduced significantly and the detection accuracy is enhanced across diverse scenarios.},
  archive      = {J_EAI},
  author       = {Zhipeng Zhai and Jinju Shao and Meng Zhang and Jinlei Zhang and Zhibing Duan and Lei Wang},
  doi          = {10.1177/30504554251328462},
  journal      = {The European Journal on Artificial Intelligence},
  month        = {8},
  number       = {3},
  pages        = {417-435},
  shortjournal = {Eur. Artif. Intell.},
  title        = {Small targets detection in LIDAR point clouds based on deep learning},
  volume       = {38},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep node embeddings for the graph coloring problem. <em>EAI</em>, <em>38</em>(3), 405-416. (<a href='https://doi.org/10.1177/30504554251325151'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, there has been a growing trend in utilizing deep learning techniques to solve various NP-hard combinatorial optimization problems, mostly using deep neural networks to generate the solutions directly. In this work, we address a famous combinatorial optimization problem on graphs, the graph coloring problem (GCP), and propose novel ways that train and utilize deep node embeddings to facilitate the problem’s solving. Specifically, we propose to use Transformer to learn the correlation between nodes in graphs. The Transformer learns the node embeddings (feature vectors) such that nodes that might be in the same color in (near-)optimal solutions have close embeddings. To generate the labels, we use a typical GCP heuristic called Tabucol to solve each small training instance multiple times. In this way, the labels are generated more efficiently and robustly as compared to using an exact solver. We then apply the learned embeddings to guide several construction and searching algorithms for the GCP, including Tabucol. Empirical results show that all the algorithms could be improved by utilizing the learned node embeddings, and our methods generalize well to graphs on much larger scales than the training graphs.},
  archive      = {J_EAI},
  author       = {Jiongzhi Zheng and Mingming Jin and Kun He and Jinghui Xue and Li Zhao and Lei Song and Jiang Bian},
  doi          = {10.1177/30504554251325151},
  journal      = {The European Journal on Artificial Intelligence},
  month        = {8},
  number       = {3},
  pages        = {405-416},
  shortjournal = {Eur. Artif. Intell.},
  title        = {Deep node embeddings for the graph coloring problem},
  volume       = {38},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Text-to-image synthesis combining cascade structure and joint attention. <em>EAI</em>, <em>38</em>(3), 390-404. (<a href='https://doi.org/10.1177/30504554251319450'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the text-to-image synthesis with non-stacked network structure only models the global features of the image and the semantic features of the text, it is easy to cause problems such as semantic inconsistency, loss of detail features, and incomplete main content in the generated images. To solve the above problems, this paper proposes a text-to-image generation method (cascaded structure and joint attention generative adversarial network (CSGAN)) that combines cascaded structure and joint attention. After encoding the text, this method utilizes a conditional enhancement module to process it, which enhances the expressive ability of the text features. In order to make the local area of the image better fit the text features, this method designs a joint attention module to solve the problem that the image generation process cannot fully reflect the local details of the text content. By using affine transform mapping visual features and cascade structure to fuse the features of different modules, the integrity of the whole content of the image is effectively guaranteed and the semantic consistency of the text image is improved. Experimental results on the CUB dataset show that compared with the current mainstream non-stacked network model DF-GAN model, the inception score index of the CSGAN model is improved by about 4.01%, and the Fréchet inception distance index is reduced by about 13.36%. These data indicators and visualization results fully demonstrate the effectiveness of the CSGAN model.},
  archive      = {J_EAI},
  author       = {Chao Zhang and Mi Zhou and Cheng Han and Chuanao Bai},
  doi          = {10.1177/30504554251319450},
  journal      = {The European Journal on Artificial Intelligence},
  month        = {8},
  number       = {3},
  pages        = {390-404},
  shortjournal = {Eur. Artif. Intell.},
  title        = {Text-to-image synthesis combining cascade structure and joint attention},
  volume       = {38},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Arithmetic optimization algorithm with mathematical operator for solving spherical minimum spanning tree problem. <em>EAI</em>, <em>38</em>(3), 364-389. (<a href='https://doi.org/10.1177/30504554251319447'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to effectively strengthen the exploration and exploitation capabilities of the arithmetic optimization algorithm (AOA) and the balance of search ability between the two is realized, a novel mathematical operator-based arithmetic optimization algorithm (MAOA) is proposed. Firstly, the exploitation and exploration abilities of the population are improved through mathematical symmetry operators and median operators, respectively. Secondly, the balance between exploration and exploitation of AOA algorithm is effectively strengthened by using sine–cosine operator. Finally, the MAOA algorithm is used to solve the spherical mining spanning tree (sphere MST) and communication network problems. Experimental results show that the proposed MAOA has achieved excellent results in terms of accuracy, robustness, and convergence speed.},
  archive      = {J_EAI},
  author       = {Qifang Luo and Xiaodong Mi and Yuanfei Wei and Yongquan Zhou},
  doi          = {10.1177/30504554251319447},
  journal      = {The European Journal on Artificial Intelligence},
  month        = {8},
  number       = {3},
  pages        = {364-389},
  shortjournal = {Eur. Artif. Intell.},
  title        = {Arithmetic optimization algorithm with mathematical operator for solving spherical minimum spanning tree problem},
  volume       = {38},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Theater scene description for human-scene interaction. <em>EAI</em>, <em>38</em>(3), 348-363. (<a href='https://doi.org/10.1177/30504554251319445'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entertainment venues like theaters are key to social engagement, but the lack of assistive technologies for people with visual impairments limits their participation. Our research aims to enhance theater accessibility using computer vision techniques to detect visual information about objects and actor gestures and convey them to blind audiences through non-visual modalities. In this work, we focus on providing a novel dataset, TS-RGBD, containing theater scenes to guide the development of computer-vision-based systems for theater scene description. It includes RGB, depth, and skeleton sequences captured by Microsoft Kinect in a theatrical setting. The dataset features untrimmed theater scenes as well as trimmed sequences consisting of individual gestures for actor gesture recognition. We test state-of-the-art image captioning models on untrimmed scenes, revealing that dense captioning models generate redundant captions with fixed numbers, leading to imprecise descriptions and a lack of context. These challenges hinder visually impaired individuals from comprehending theater scenes descriptions effectively. Additionally, we assess the performance of skeleton-based graph convolution networks for human action recognition in a theater environment using trimmed skeleton sequences. The results highlight limitations in recognizing human actions in this setting. Based on these findings, we propose solutions for overcoming these challenges, paving the way for future improvements in making theater performances more accessible to individuals with visual impairments.},
  archive      = {J_EAI},
  author       = {Khadidja Delloul and Leyla Benhamida and Slimane Larabi},
  doi          = {10.1177/30504554251319445},
  journal      = {The European Journal on Artificial Intelligence},
  month        = {8},
  number       = {3},
  pages        = {348-363},
  shortjournal = {Eur. Artif. Intell.},
  title        = {Theater scene description for human-scene interaction},
  volume       = {38},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automatic paraphrase generation at phrasal, and sentence level for urdu language: Data and methods. <em>EAI</em>, <em>38</em>(3), 330-347. (<a href='https://doi.org/10.1177/30504554251319449'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Paraphrasing involves rewording a text to maintain its meaning while using different language. In recent years, there has been growing interest among researchers in automatic paraphrase generation (APG). Previous studies have primarily focused on developing corpora and methods for APG tasks in English and other languages. However, there is a lack of comprehensive benchmark corpora and standardized methods specifically designed for APG in Urdu. To address this gap, this study introduces two extensive benchmark corpora: the Urdu Phrasal Paraphrase corpus (UPP-22 corpus) at the phrasal level and the Urdu Sentential Paraphrase corpus (USP-22 corpus) at the sentence level. The UPP-22 corpus contains 3,50,000 paraphrased pairs, while the USP-22 corpus consists of 11,000 paraphrased pairs, both specifically curated for the Urdu APG task. As a second major contribution, this research developed and applied various state-of-the-art deep learning models, including sequence-to-sequence models (using long short-term memory [LSTM], gated recurrent unit [GRU], bidirectional LSTM, and bidirectional GRU) and sequence-to-sequence models with attention mechanisms as baseline methods for the proposed Urdu Paraphrase corpora. Additionally, the study introduced a bidirectional and auto-regressive transformer-based model specifically tailored to these corpora as a third contribution. A fourth significant contribution was the development of a test corpus at the phrasal level, consisting of 10,000 instances, created through automatic translation, followed by manual inspection and correction, to evaluate the performance of APG tasks for the Urdu language. As a fifth major contribution, the study applied and fine-tuned a large language model (GPT-4-Mini) for APG in Urdu, resulting in significant performance improvements. The evaluation was carried out using the standard bilingual evaluation understudy (BLEU) metric. The best results were achieved with BLEU-1 = 75.89 for the UPP-22 corpus and BLEU-1 = 75.16 for the USP-22 corpus using the GPT-4-Mini model, representing a significant improvement over all other models including baseline. These corpora and methodologies will be made publicly available to encourage and promote further research in APG for under-resourced languages such as Urdu.},
  archive      = {J_EAI},
  author       = {Zara Khan and Iqra Muneer and Rao Muhammad Adeel Nawab and Ahmad Mahmood},
  doi          = {10.1177/30504554251319449},
  journal      = {The European Journal on Artificial Intelligence},
  month        = {8},
  number       = {3},
  pages        = {330-347},
  shortjournal = {Eur. Artif. Intell.},
  title        = {Automatic paraphrase generation at phrasal, and sentence level for urdu language: Data and methods},
  volume       = {38},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sentential cross-lingual paraphrase detection for english-urdu language pair. <em>EAI</em>, <em>38</em>(3), 309-329. (<a href='https://doi.org/10.1177/30504554251319446'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to vast digital data collections and paraphrasing tools, researchers have shown growing interest in Cross-lingual Paraphrase Detection (CLPD). Open-access data and tools make paraphrasing easier and detection more challenging. Translation tools further exacerbate the issue by enabling effortless text translation across languages, leading to increased cross-lingual paraphrasing. Most existing CLPD studies focus on European languages, particularly English, while the English-Urdu language pair remains underexplored due to limited standard approaches and benchmark corpora.This study addresses this gap by developing the CLPD Corpus for English-Urdu (CLPD-EU), a gold-standard benchmark corpus at the sentence level. The corpus includes 5,801 sentence pairs, comprising 3,900 paraphrased and 1,901 non-paraphrased instances. Additionally, the study implements classical machine learning methods based on bilingual dictionaries, cross-lingual word embeddings, and transfer learning using sentence transformers.The research further incorporates state-of-the-art Large Language Models (LLMs) such as Mistral and LLaMA, significantly improving detection accuracy. Our proposed Feature Fusion Approach, ‘Comb-ST+BD,’ demonstrates strong performance with an F1 score of 0.739 for the CLPD task. The CLPD-EU corpus will be publicly available to encourage further research in CLPD, especially for under-resourced languages like Urdu.},
  archive      = {J_EAI},
  author       = {Iqra Muneer and Nida Waheed and Muhammad Adnan Ashraf and Rao M Adeel Nawab},
  doi          = {10.1177/30504554251319446},
  journal      = {The European Journal on Artificial Intelligence},
  month        = {8},
  number       = {3},
  pages        = {309-329},
  shortjournal = {Eur. Artif. Intell.},
  title        = {Sentential cross-lingual paraphrase detection for english-urdu language pair},
  volume       = {38},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BiMSA: Multimodal sentiment analysis based on BiGRU and bidirectional interactive attention. <em>EAI</em>, <em>38</em>(3), 296-308. (<a href='https://doi.org/10.1177/30504554251319444'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, the significance of multimodal sentiment analysis is progressively increasing. However, the heterogeneity of multimodal signals poses a challenge in learning modality representation and fusing information. To address it, the BiMSA (multimodal sentiment analysis based on BiGRU and bidirectional interactive attention) is proposed in this paper. In the modality representation learning layer, BiMSA incorporates a structure consisting of BiGRU to extract contextual information from video and audio inputs. Subsequently, modality features are projected into modality internal representations and interactive representations for extracting information. This practice allows the model to take into account more aspects of modality information. In terms of the modality fusion layer, a bidirectional interactive attention mechanism is used to focus on the key representations of key modalities, and integrate multimodal information flexibly and efficiently. Attention weights are concentrated on modality representations that synergistically contribute toward overall sentiment orientation. Additionally, the constraints of similarity loss and difference loss are introduced to align with representations while mitigating redundant information and achieving a better fusion effect. Experimental results on public datasets (CMU-MOSI and CMU-MOSEI) demonstrate the effectiveness of the BiMSA model.},
  archive      = {J_EAI},
  author       = {Qi Wang and Haizheng Yu and Yao Wang and Hong Bian},
  doi          = {10.1177/30504554251319444},
  journal      = {The European Journal on Artificial Intelligence},
  month        = {8},
  number       = {3},
  pages        = {296-308},
  shortjournal = {Eur. Artif. Intell.},
  title        = {BiMSA: Multimodal sentiment analysis based on BiGRU and bidirectional interactive attention},
  volume       = {38},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SAM-YOLO: An improved small object detection model for vehicle detection. <em>EAI</em>, <em>38</em>(3), 279-295. (<a href='https://doi.org/10.1177/30504554251319452'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle detection using computer vision plays a crucial role in accurately recognizing and responding to various road conditions, targets, and signals, particularly within autonomous driving technology. However, traditional vehicle detection algorithms suffer from slow detection speed, low accuracy, and poor robustness. To address these challenges, this paper proposes the simple attention mechanism-you only look once (SAM-YOLO) algorithm. SAM-YOLO incorporates the simple attention mechanism into the YOLOv7 network, allowing for the capture of more detailed information without introducing additional parameters. In this study, we experimentally redesigned the backbone network of SAM-YOLO by replacing the redundant part of the network layer with the C3 module, resulting in improved model performance while maintaining accuracy. The experimental results show that the SAM-YOLO algorithm performs excellently in several evaluation metrics under conventional conditions, especially outperforming other algorithms in accuracy and mean average precision values. In tests on the ExLight dataset facing extreme lighting conditions, SAM-YOLO similarly demonstrated optimal detection capabilities, especially in terms of robustness when dealing with complex lighting variations. These findings emphasize the potential of the SAM-YOLO algorithm for real-time and accurate target detection tasks, especially in environments with highly variable lighting conditions.},
  archive      = {J_EAI},
  author       = {JiaWang Liao and SuYu Jiang and MingHua Chen and ChengJiao Sun},
  doi          = {10.1177/30504554251319452},
  journal      = {The European Journal on Artificial Intelligence},
  month        = {8},
  number       = {3},
  pages        = {279-295},
  shortjournal = {Eur. Artif. Intell.},
  title        = {SAM-YOLO: An improved small object detection model for vehicle detection},
  volume       = {38},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prompt scoring system for dialog summarization. <em>EAI</em>, <em>38</em>(3), 261-278. (<a href='https://doi.org/10.1177/30504554251321829'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in language processing have demonstrated the advanced capabilities of language models. Particularly noteworthy is the heightened prowess of pre-trained large language models in tackling tasks that were a real challenge a few years ago, such as the abstractive summarization of dialogs. An approach to generating summaries involves engineering prompt templates. The easiest way would be by using a static prompt, but it can lead to unreliable outcomes for different classes of dialogs. We implemented a scoring system to enhance the performance of a few-shot training. This involves constructing finely tuned prompts composed of dialog samples with the highest scores. The scoring process is grounded in a set of heuristics that specifically assess the structure and content of the dialogs. The use of the scoring system resulted in enhanced ROUGE scores and positive evaluations from human assessors. These promising results were consistently validated across all three large-scale datasets used in the testing phase.},
  archive      = {J_EAI},
  author       = {George P Prodan and Elena Pelican},
  doi          = {10.1177/30504554251321829},
  journal      = {The European Journal on Artificial Intelligence},
  month        = {8},
  number       = {3},
  pages        = {261-278},
  shortjournal = {Eur. Artif. Intell.},
  title        = {Prompt scoring system for dialog summarization},
  volume       = {38},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
