<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>IJSEKE</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ijseke">IJSEKE - 6</h2>
<ul>
<li><details>
<summary>
(2025). APT: A simple adapter for reusing RGB video transformers in compressed video action recognition. <em>IJSEKE</em>, <em>35</em>(9), 1369-1382. (<a href='https://doi.org/10.1142/S021819402550041X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing adoption of compressed video across diverse applications underscores the demand for efficient action recognition methods. Traditional RGB-based methods face limitations, especially because they depend heavily on computationally intensive optical flow for temporal analysis. We propose a novel method for compressed video action recognition that aims to effectively bridge the gap between compressed-domain and RGB-domain. Specifically, we design a plug-and-play multi-modal feature adapter that enables pretrained RGB-based Transformer models to be directly applied to compressed videos. Our method offers a low-cost cross-domain transfer solution by efficiently fusing I-frame and P-frame within compressed videos, facilitating deep feature alignment and modeling in the compressed domain. Extensive experiments on the UCF101 (93.8%) and HMDB51 (70.7%) datasets demonstrate that the proposed method significantly outperforms state-of-the-art approaches for compressed video action recognition.},
  archive      = {J_IJSEKE},
  author       = {Jiyuan Wang and Huilan Luo},
  doi          = {10.1142/S021819402550041X},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {9},
  pages        = {1369-1382},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {APT: A simple adapter for reusing RGB video transformers in compressed video action recognition},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). VulEPEDE: A function-level vulnerability detection method via enhanced positional encoding and dependency embedding. <em>IJSEKE</em>, <em>35</em>(9), 1341-1368. (<a href='https://doi.org/10.1142/S0218194025500408'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As software complexity increases, integrating vulnerability detection becomes essential to ensure the security and integrity of modern systems. Traditional static and dynamic analysis methods face limitations in efficiency and accuracy, particularly for large-scale vulnerability detection, while existing deep learning methods struggle to fully capture structural information and dependencies in code, leading to incomplete identification of vulnerabilities. In this paper, we propose VulEPEDE, an innovative function-level vulnerability detection method. VulEPEDE leverages Program Dependency Graphs (PDG) to represent function code and constructs a Vulnerability Semantic Dependency Graph (VSDG) using slicing techniques, introducing function parameter nodes as slicing candidates to capture more comprehensive vulnerability trigger chains. It integrates two core modules: the Enhanced Positional Encoding (EPE) module and the Dependency Embedding (DE) module. The EPE module combines node attribute encoding with positional encoding using a Transformer and multi-head attention mechanism to capture complex features and contextual semantics of code, while the DE module learns dependency embeddings between code nodes through convolutional neural networks. We evaluate VulEPEDE on three widely used datasets, comparing its performance against state-of-the-art deep learning-based methods. Experimental results demonstrate that VulEPEDE outperforms the best baseline methods by 1.66%, 17.54%, and 28.96% in F1-score across the three datasets, with considerable computational efficiency.},
  archive      = {J_IJSEKE},
  author       = {Shuailin Yang and Jiadong Ren and Jiazheng Li and Bing Zhang and Ke Xu},
  doi          = {10.1142/S0218194025500408},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {9},
  pages        = {1341-1368},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {VulEPEDE: A function-level vulnerability detection method via enhanced positional encoding and dependency embedding},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DB-DSCN: Image tampering detection using dual branch deep stacked convolutional network. <em>IJSEKE</em>, <em>35</em>(9), 1323-1340. (<a href='https://doi.org/10.1142/S0218194025500366'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the new era of technology with unusual image forging equipment and procedures, digital imaging has become basic. Digital images cannot even be used as evidence anywhere, since it is widely recognized that they may be faked. In order to assist in relieving such derelictions, the problem is examined in an incomprehensible manner. In the digital era, copy-move and splicing of images to produce a fabricated one are commonplace. While the latter entails combining two images to drastically alter the original and produce a new, forged image, copy-move entails copying a portion of the image and pasting it onto another portion of the image. Therefore, to address the limitation of the existing model, a novel hybrid Deep Learning (DL) model is developed. To enhance image details before detecting a tampered image, high pass filtering is employed. The high pass filter might reveal information that has emerged due to the tampered image. To extract the visual semantic features and statistical features, Attention-based Residual Network (AttResNet) and Grey Level Co-occurrence Matrix (GLCM) are utilized. An Attention-based Feature Fusion (AttFF) module is used to fuse the extracted features. A Dual Branch Deep Stacked Convolutional Network (DB-DSCN) is employed to classify the tampered image. The experimental results of the proposed model achieved an accuracy of 98.26%, a precision of 96.28%, a recall of 95.98% and an F 1-score of 96%. The proposed model seems to be a superior model for detecting tampered images compared to existing models. It acquired higher accuracy than other existing models. The performance of the proposed model is evaluated in terms of accuracy, precision, recall and F 1-score, respectively.},
  archive      = {J_IJSEKE},
  author       = {V. M. Ponney and B. L. Velammal and K. Kulothungan},
  doi          = {10.1142/S0218194025500366},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {9},
  pages        = {1323-1340},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {DB-DSCN: Image tampering detection using dual branch deep stacked convolutional network},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-level formal specifications for deep neural networks. <em>IJSEKE</em>, <em>35</em>(9), 1289-1321. (<a href='https://doi.org/10.1142/S0218194025500342'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Obtaining sufficient high-quality labeled data remains a critical challenge for training deep neural networks (DNNs). Recently, a specification-based method has been proposed to systematically define object characteristics for automated data generation. However, this approach typically relies on abstract descriptions, resulting in a gap between specifications and executable data generation. To address this issue, this paper proposes a two-level formal specification approach. Specifically, we apply the first-level specification to describe object characteristics and the second-level specification to define parameters and values suitable for data generation. This paper focuses on discussing both levels of specifications to facilitate human comprehension and machine handling to reduce the gap mentioned above. The performance of this approach is demonstrated through a case study on traffic sign recognition.},
  archive      = {J_IJSEKE},
  author       = {Yanzhao Xia and Shaoying Liu},
  doi          = {10.1142/S0218194025500342},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {9},
  pages        = {1289-1321},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {Two-level formal specifications for deep neural networks},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the combination of classical knowledge engineering tools and LLMs to build automated planning models. <em>IJSEKE</em>, <em>35</em>(9), 1267-1287. (<a href='https://doi.org/10.1142/S0218194025430028'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated Planning (AP) is a problem-solving technique applicable to a wide range of scenarios and goals. It typically requires a complete and accurate description of the planning task expressed in a formal language to generate a solution plan that achieves the goals. However, creating these descriptions can be time-consuming and error-prone, often resulting in unsolvable planning tasks. Planning systems often lack the ability to explain why a task is deemed unsolvable. In this work, we present an integrated knowledge engineering system that allows users to graphically depict AP use cases using transition diagrams, which are automatically converted into a formal language. To facilitate the debugging process, we propose connecting the system with large language models (LLMs) to explore their capabilities in assisting with flawed planning tasks, fixing the model and making the tasks solvable.},
  archive      = {J_IJSEKE},
  author       = {Alba Gragera and Ángel García-Olaya and Fernando Fernández},
  doi          = {10.1142/S0218194025430028},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {9},
  pages        = {1267-1287},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {On the combination of classical knowledge engineering tools and LLMs to build automated planning models},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Applying scrum to knowledge transfer among software developers. <em>IJSEKE</em>, <em>35</em>(9), 1239-1265. (<a href='https://doi.org/10.1142/S0218194023430015'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the teaching-learning processes, research and continuous innovation are encouraged. Now, when talking about innovation, the concept of adapting methodologies that have been successfully applied to speed up and increase the quality of software projects begins to emerge, is the case of agile software development methodologies. Scrum is one of the most widely used methodologies in the software development process, it increases productivity and deliverable quality of software development teams, but there is not much evidence of how to use it to structure learning content and its use to transfer new knowledge in training or software development contexts. To fill this gap, this research analyzes the applicability of Scrum for transferring new knowledge among software developers is developed. In this paper, we describe the details of how to start transferring knowledge using Scrum, guiding the reader through its standards, processes, phases, and objectives. We also report an experiment for improving students’ performance to support the approach’s benefits in the academy context and a case study performed inside the company context.},
  archive      = {J_IJSEKE},
  author       = {Fernando Ibarra-Torres and Matias Urbieta and Nuria Medina-Medina},
  doi          = {10.1142/S0218194023430015},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {9},
  pages        = {1239-1265},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {Applying scrum to knowledge transfer among software developers},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
