<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TROB</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="trob">TROB - 11</h2>
<ul>
<li><details>
<summary>
(2025). MARG: MAstering risky gap terrains for legged robots with elevation mapping. <em>TROB</em>, 1-17. (<a href='https://doi.org/10.1109/TRO.2025.3619041'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Reinforcement Learning (DRL) controllers for quadrupedal locomotion have demonstrated impressive performance on challenging terrains, allowing robots to execute complex skills such as climbing, running, and jumping. However, existing blind locomotion controllers often struggle to ensure safety and efficient traversal through risky gap terrains, which are typically highly complex, requiring robots to perceive terrain information and select appropriate footholds during locomotion accurately. Meanwhile, existing perception-based controllers still present several practical limitations, including a complex multisensor deployment system and expensive computing resource requirements. This paper proposes a DRL controller named MAstering Risky Gap Terrains (MARG), which integrates terrain maps and proprioception to dynamically adjust the action and enhance the robot's stability in these tasks. During the training phase, our controller accelerates policy optimization by selectively incorporating privileged information (e.g., center of mass, friction coefficients) that are available in simulation but unmeasurable directly in real-world deployments due to sensor limitations. We also designed three foot-related rewards to encourage the robot to explore safe footholds. More importantly, a terrain map generation (TMG) model is proposed to reduce the drift existing in mapping and provide accurate terrain maps using only one LiDAR, providing a foundation for zero-shot transfer of the learned policy. The experimental results indicate that MARG maintains stability in various risky terrain tasks.},
  archive      = {J_TROB},
  author       = {Yinzhao Dong and Ji Ma and Liu Zhao and Wanyue Li and Peng Lu},
  doi          = {10.1109/TRO.2025.3619041},
  journal      = {IEEE Transactions on Robotics},
  month        = {10},
  pages        = {1-17},
  shortjournal = {IEEE Trans. Robot.},
  title        = {MARG: MAstering risky gap terrains for legged robots with elevation mapping},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PG-SLAM: Photo-realistic and geometry-aware RGB-D SLAM in dynamic environments. <em>TROB</em>, 1-18. (<a href='https://doi.org/10.1109/TRO.2025.3619073'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simultaneous localization and mapping (SLAM) has achieved impressive performance in static environments. However, SLAM in dynamic environments remains an open question. Many methods directly filter out dynamic objects, resulting in incomplete scene reconstruction and limited accuracy of camera localization. The other works express dynamic objects by point clouds, sparse joints, or coarse meshes, which fails to provide a photo-realistic representation. To overcome the above limitations, we propose a photo-realistic and geometry-aware RGB-D SLAM method based on Gaussian splatting. Our method is composed of three main modules to 1) map the dynamic foreground including non-rigid humans/quadrupeds and rigid items, 2) reconstruct the static background, and 3) localize the camera. To map the foreground, we focus on modeling the deformations and/or motions. We consider the shape priors of humans/quadrupeds and exploit the geometric and appearance constraints of dynamic Gaussians. For background mapping, we design an optimization strategy between neighboring local maps by integrating appearance constraint into geometric alignment. As to camera localization, we leverage both static background and dynamic foreground to increase the number of observations and introduce more constraints. We explore the geometric and appearance constraints by associating 3D Gaussians with 2D optical flows and pixel patches. Experiments on extensive realworld datasets demonstrate that our method outperforms stateof-the-art approaches in terms of camera localization and scene mapping.},
  archive      = {J_TROB},
  author       = {Haoang Li and Xiangqi Meng and Xingxing Zuo and Zhe Liu and Hesheng Wang and Daniel Cremers},
  doi          = {10.1109/TRO.2025.3619073},
  journal      = {IEEE Transactions on Robotics},
  month        = {10},
  pages        = {1-18},
  shortjournal = {IEEE Trans. Robot.},
  title        = {PG-SLAM: Photo-realistic and geometry-aware RGB-D SLAM in dynamic environments},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CCRobot-S: A robotic cable-climbing squad collaborating for fast inspection and heavy-duty maintenance. <em>TROB</em>, 1-20. (<a href='https://doi.org/10.1109/TRO.2025.3619048'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a novel climbing strategy, reconfigurable parallel-type cable-driven climbing designed for long-span, large-scale bridge stay cable robotic applications, which has the potential to revolutionize the stay cable inspection and maintenance practice. The proposed methodology features the development of a Collaborative Climbing Robot Squad (CCRobot-S), which builds upon the design principles of the previous CCRobot series. In this study, CCRobot-S implements a parallel-type cable-driven manipulation design, allowing for reconfigurable kinematic morphology by its movable anchor bases and realizing the capacity of crossing over the stay cables for its flying platform. The collaborative robot squad design liberates the dimensions and scales of the robot's reachable workspace and moves the part of the robotic system that indeed needs to be moved, enhancing the working efficiency and climbing agility. This strategy also utilizes controllable adhesion instead of friction to interact with the bridge cable surface for the flying platform, realizing force multiplication for forceful manipulation. Toward bringing high efficiency and heavy-duty capacity, we propose the applicable climbing frameworks (zero-downtime climbing gait for cable inspection and spider-like climbing gait for cable maintenance) and the optimization frameworks (optimal anchor configuration for the movable anchor bases and optimal grasp arrangement for the flying gripper). This article includes the exploration of the design and climbing gaits of CCRobotS, the formulation of the CCRobot-S model, a comprehensive analysis of its workspace, and its climbing strategy and optimization. Extensive experiments have assessed the proposed climbing strategy's effectiveness and showcased CCRobot-S' capabilities.},
  archive      = {J_TROB},
  author       = {Zhenliang Zheng and Ning Ding and Herbert Werner and Feng Ren and Yongyuan Xu and Wenchao Zhang and Xiaoli Hu and Jianguo Zhang and Tin Lun Lam},
  doi          = {10.1109/TRO.2025.3619048},
  journal      = {IEEE Transactions on Robotics},
  month        = {10},
  pages        = {1-20},
  shortjournal = {IEEE Trans. Robot.},
  title        = {CCRobot-S: A robotic cable-climbing squad collaborating for fast inspection and heavy-duty maintenance},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HiMo: High-speed objects motion compensation in point clouds. <em>TROB</em>, 1-16. (<a href='https://doi.org/10.1109/TRO.2025.3619042'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {LiDAR point cloud is essential for autonomous vehicles, but motion distortions from dynamic objects degrade the data quality. While previous work has considered distortions caused by ego motion, distortions caused by other moving objects remain largely overlooked, leading to errors in object shape and position. This distortion is particularly pronounced in high-speed environments such as highways and in multi-LiDAR configurations, a common setup for heavy vehicles. To address this challenge, we introduce HiMo, a pipeline that repurposes scene flow estimation for non-ego motion compensation, correcting the representation of dynamic objects in point clouds. During the development of HiMo, we observed that existing self-supervised scene flow estimators often produce degenerate or inconsistent estimates under high-speed distortion. We further propose SeFlow++, a real-time scene flow estimator that achieves state-of-the-art performance on both scene flow and motion compensation. Since well-established motion distortion metrics are absent in the literature, we introduce two evaluation metrics: compensation accuracy at a point level and shape similarity of objects. We validate HiMo through extensive experiments on Argoverse 2, ZOD and a newly collected real-world dataset featuring highway driving and multi-LiDAR-equipped heavy vehicles. Our findings show that HiMo improves the geometric consistency and visual fidelity of dynamic objects in LiDAR point clouds, benefiting downstream tasks such as semantic segmentation and 3D detection. See https://kin-zhang.github.io/HiMo for more details.},
  archive      = {J_TROB},
  author       = {Qingwen Zhang and Ajinkya Khoche and Yi Yang and Li Ling and Sina Sharif Mansouri and Olov Andersson and Patric Jensfelt},
  doi          = {10.1109/TRO.2025.3619042},
  journal      = {IEEE Transactions on Robotics},
  month        = {10},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Robot.},
  title        = {HiMo: High-speed objects motion compensation in point clouds},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). OKVIS2-X: Open keyframe-based visual-inertial SLAM configurable with dense depth or LiDAR, and GNSS. <em>TROB</em>, 1-20. (<a href='https://doi.org/10.1109/TRO.2025.3619051'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To empower mobile robots with usable maps as well as highest state estimation accuracy and robustness, we present OKVIS2-X: a state-of-the-art multi-sensor Simultaneous Localization and Mapping (SLAM) system building dense volumetric occupancy maps, while scalable to large environments and operating in realtime. Our unified SLAM framework seamlessly integrates different sensor modalities: visual, inertial, measured or learned depth, LiDAR and Global Navigation Satellite System (GNSS) measurements. Unlike most state-of-the-art SLAM systems, we advocate using dense volumetric map representations when leveraging depth or range-sensing capabilities. We employ an efficient submapping strategy that allows our system to scale to large environments, showcased in sequences of up to 9 kilometers. OKVIS2-X enhances its accuracy and robustness by tightly-coupling the estimator and submaps through map alignment factors. Our system provides globally consistent maps, directly usable for autonomous navigation. To further improve the accuracy of OKVIS2-X, we also incorporate the option of performing online calibration of camera extrinsics. Our system achieves the highest trajectory accuracy in EuRoC against stateof-the-art alternatives, outperforms all competitors in the Hilti22 VI-only benchmark, while also proving competitive in the LiDAR version, and showcases state of the art accuracy in the diverse and large-scale sequences from the VBR dataset. Code available at: https://github.com/ethz-mrl/OKVIS2-X},
  archive      = {J_TROB},
  author       = {Simon Boche and Jaehyung Jung and Sebastian Barbas Laina and Stefan Leutenegger},
  doi          = {10.1109/TRO.2025.3619051},
  journal      = {IEEE Transactions on Robotics},
  month        = {10},
  pages        = {1-20},
  shortjournal = {IEEE Trans. Robot.},
  title        = {OKVIS2-X: Open keyframe-based visual-inertial SLAM configurable with dense depth or LiDAR, and GNSS},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Continual learning of regions for efficient robot localization on large maps. <em>TROB</em>, 1-20. (<a href='https://doi.org/10.1109/TRO.2025.3619058'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of today's SLAM approaches learn the map of the environment in the first stage (referred to as mapping) and subsequently use this static map for planning and navigation. This method is suboptimal in dynamic contexts because changes in the environment can result in poor performance of the localization components essential for loop closure detection and relocalization. To address the limitations of the mapping-navigation dualism, continual SLAM has been proposed, which focuses on methods that can continually update the knowledge of the environment and the corresponding map. However, continual SLAM poses challenges, particularly for real-time navigation of large maps, and many of the existing techniques are not yet mature for practical application. In this paper, we present a continual learning approach aimed at accurate and efficient robot localization on large maps, advancing the goal of continual SLAM. Our approach incrementally trains a region prediction neural network to recognize familiar places and preselect a subset of map nodes for localization and map optimization. We integrate this method into RTAB-Map, a well-known graph-based SLAM system, and validate its practical applicability through assessments on several real-world SLAM datasets.},
  archive      = {J_TROB},
  author       = {Matteo Scucchia and Davide Maltoni},
  doi          = {10.1109/TRO.2025.3619058},
  journal      = {IEEE Transactions on Robotics},
  month        = {10},
  pages        = {1-20},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Continual learning of regions for efficient robot localization on large maps},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Non-submodular visual attention for robot navigation. <em>TROB</em>, 1-20. (<a href='https://doi.org/10.1109/TRO.2025.3619067'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a task-oriented computational framework to enhance Visual-Inertial Navigation (VIN) in robots, addressing challenges such as limited time and energy resources. The framework strategically selects visual features using a Mean Square Error (MSE)-based, non-submodular objective function and a simplified dynamic anticipation model. To address the NP-hardness of this problem, we introduce four polynomial-time approximation algorithms: a classic greedy method with constant-factor guarantees; a low-rank greedy variant that significantly reduces computational complexity; a randomized greedy sampler that balances efficiency and solution quality; and a linearization-based selector based on a first-order Taylor expansion for near-constant-time execution. We establish rigorous performance bounds by leveraging submodularity ratios, curvature, and element-wise curvature analyses. Extensive experiments on both standardized benchmarks and a custom control-aware platform validate our theoretical results, demonstrating that these methods achieve strong approximation guarantees while enabling real-time deployment.},
  archive      = {J_TROB},
  author       = {Reza Vafaee and Kian Behzad and Milad Siami and Luca Carlone and Ali Jadbabaie},
  doi          = {10.1109/TRO.2025.3619067},
  journal      = {IEEE Transactions on Robotics},
  month        = {10},
  pages        = {1-20},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Non-submodular visual attention for robot navigation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Impedance control design framework using commutative map between $SE(3)$ and $\mathfrak {se}(3)$. <em>TROB</em>, 1-20. (<a href='https://doi.org/10.1109/TRO.2025.3619066'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Impedance control is a widely adopted approach that ensures the compliant behavior of robot manipulators as they interact with their environment according to specifically designed dynamics. For tasks involving six degrees of freedom (DoF), it is crucial to appropriately manage the position and orientation of the end-effector by controlling dynamic behavior. However, describing orientational displacement and designing the corresponding rotational impedance can be challenging, especially when we use a minimal representation. The well-known minimal representation for orientation, the Euler angle, suffers from representation singularity. As a remedy, the quaternion or dual quaternion can be an alternative, but with non-minimal representations. This lack of minimal representation, which does not suffer from the representation singularity, often leads to handling the impedance design by directly defining the potential energy function in the matrix Lie group. This paper proposes a framework for the six-DoF impedance control design that takes advantage of Lie group theory with minimal representation, known as the exponential coordinate. Since the exponential coordinate can be treated as the Euclidean variable within the injectivity radius, it allows for the formulation of the impedance control more systematically and familiarly. In our framework, a detour strategy is utilized; the impedance is designed in the Lie group $SE(3)$, and the control is designed in the Lie algebra $\mathfrak {se}(3)$, which is isomorphic to the vector space $\mathbb {R}^{6}$. The group structure of $SE(3)$ can be maintained using the proposed conversion formula between the Lie group and the Lie algebra, called the differential of the exponential map and its time derivative, with a closed-form expression. Experiments with a 6-DoF robot manipulator verified that the proposed impedance control framework effectively reflects the $SE(3)$ group structure and achieves the desired dynamic behavior as the functionality of the impedance control with minimal parameters.},
  archive      = {J_TROB},
  author       = {Jonghyeok Kim and Minchang Sung and Youngjin Choi and Jonghoon Park and Wan Kyun Chung},
  doi          = {10.1109/TRO.2025.3619066},
  journal      = {IEEE Transactions on Robotics},
  month        = {10},
  pages        = {1-20},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Impedance control design framework using commutative map between $SE(3)$ and $\mathfrak {se}(3)$},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contact planning for multi-legged robots under constraints through parallel MCTS. <em>TROB</em>, 1-20. (<a href='https://doi.org/10.1109/TRO.2025.3619054'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contact planning for multi-legged robots is a challenging sequential decision-making problem due to the interplay of gaits, footholds, configurations, and physical constraints from both the robot and the environment. Existing multi-contact planners often fail to find feasible sequences within a limited time in complex scenarios and to ensure physical possibility. We propose a parallel Monte Carlo Tree Search (MCTS)-based planner that leverages multi-constraint reachability to efficiently generate physically valid contact sequences. The method accelerates planning through a hash-driven parallel approach, prioritizing promising candidates while pruning trapped nodes via valueless node evaluation. It employs depth-first backup for long-horizon planning and uses virtual loss to balance parallel exploration. To ensure feasible transitions between contact states, we establish comprehensive reachability conditions for multi-legged robots, incorporating stability, collision avoidance, kinematics, joint torques, and contact constraints into the planning framework. In experiments in sparse foothold environments, our planner outperforms mainstream contact planning approaches in traversability, solution quality and physical feasibility, while achieving a competitive planning speed. Furthermore, simulation and hardware validation on hexapod and humanoid robots exhibit successful locomotion across various terrains while satisfying constraints.},
  archive      = {J_TROB},
  author       = {Peng Xu and Liang Ding and Lei Ye and Tengwei Pang and Tie Liu and Huaiguang Yang and Haibo Gao and Zongquan Deng and Joni Pajarinen},
  doi          = {10.1109/TRO.2025.3619054},
  journal      = {IEEE Transactions on Robotics},
  month        = {10},
  pages        = {1-20},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Contact planning for multi-legged robots under constraints through parallel MCTS},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Asymmetric information enhanced mapping framework for multirobot exploration based on deep reinforcement learning. <em>TROB</em>, 1-17. (<a href='https://doi.org/10.1109/TRO.2025.3619045'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite significant advancements in multirobot technologies, efficiently and collaboratively exploring an unknown environment remains a major challenge. In this paper, we propose AIM-Mapping, an Asymmetric InforMation enhanced Mapping framework based on deep reinforcement learning. The framework fully leverages the privileged information to help construct the environmental representation as well as the supervised signal in an asymmetric actor-critic training framework. Specifically, privileged information is used to evaluate exploration performance through an asymmetric feature representation module and a mutual information evaluation module. The decision-making network employs the trained feature encoder to extract structural information of the environment and integrates it with a topological map constructed based on geometric distance. By leveraging this topological map representation, we apply topological graph matching to assign corresponding boundary points to each robot as long-term goal points. We conduct experiments in both iGibson simulation environments and real-world scenarios. The results demonstrate that the proposed method achieves significant performance improvements compared to existing approaches.},
  archive      = {J_TROB},
  author       = {Jiyu Cheng and Junhui Fan and Xiaolei Li and Paul L. Rosin and Yibin Li and Wei Zhang},
  doi          = {10.1109/TRO.2025.3619045},
  journal      = {IEEE Transactions on Robotics},
  month        = {10},
  pages        = {1-17},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Asymmetric information enhanced mapping framework for multirobot exploration based on deep reinforcement learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LPAC: Learnable perception-action-communication loops with applications to coverage control. <em>TROB</em>, 1-20. (<a href='https://doi.org/10.1109/TRO.2025.3619047'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coverage control is the problem of navigating a robot swarm to collaboratively monitor features or a phenomenon of interest not known a priori. The problem is challenging in decentralized settings with robots that have limited communication and sensing capabilities. We propose a learnable Perception-Action-Communication (LPAC) architecture for the problem, wherein a convolutional neural network (CNN) processes localized perception; a graph neural network (GNN) facilitates robot communications; finally, a shallow multi-layer perceptron (MLP) computes robot actions. The GNN enables collaboration in the robot swarm by computing what information to communicate with nearby robots and how to incorporate received information. Evaluations show that the LPAC models—trained using imitation learning—outperform standard decentralized and centralized coverage control algorithms. The learned policy generalizes to environments different from the training dataset, transfers to larger environments with more robots, and is robust to noisy position estimates. The results indicate the suitability of LPAC architectures for decentralized navigation in robot swarms to achieve collaborative behavior.},
  archive      = {J_TROB},
  author       = {Saurav Agarwal and Ramya Muthukrishnan and Walker Gosrich and Vijay Kumar and Alejandro Ribeiro},
  doi          = {10.1109/TRO.2025.3619047},
  journal      = {IEEE Transactions on Robotics},
  month        = {10},
  pages        = {1-20},
  shortjournal = {IEEE Trans. Robot.},
  title        = {LPAC: Learnable perception-action-communication loops with applications to coverage control},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
