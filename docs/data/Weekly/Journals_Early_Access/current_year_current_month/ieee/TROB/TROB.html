<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TROB</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="trob">TROB - 14</h2>
<ul>
<li><details>
<summary>
(2025). Integration of robot and scene kinematics for sequential mobile manipulation planning. <em>TROB</em>, 1-20. (<a href='https://doi.org/10.1109/TRO.2025.3605261'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a Sequential Mobile Manipulation Planning (SMMP) framework that can solve long-horizon multi-step mobile manipulation tasks with coordinated whole-body motion, even when interacting with articulated objects. By abstracting environmental structures as kinematic models and integrating them with the robot's kinematics, we construct an Augmented Configuration Apace (A-Space) that unifies the previously separate task constraints for navigation and manipulation, while accounting for the joint reachability of the robot base, arm, and manipulated objects. This integration facilitates efficient planning within a tri-level framework: a task planner generates symbolic action sequences to model the evolution of A-Space, an optimization-based motion planner computes continuous trajectories within A-Space to achieve desired configurations for both the robot and scene elements, and an intermediate plan refinement stage selects action goals that ensure long-horizon feasibility. Our simulation studies first confirm that planning in A-Space achieves an 84.6% higher task success rate compared to baseline methods. Validation on real robotic systems demonstrates fluid mobile manipulation involving (i) seven types of rigid and articulated objects across 17 distinct contexts, and (ii) long-horizon tasks of up to 14 sequential steps. Our results highlight the significance of modeling scene kinematics into planning entities, rather than encoding task-specific constraints, offering a scalable and generalizable approach to complex robotic manipulation.},
  archive      = {J_TROB},
  author       = {Ziyuan Jiao and Yida Niu and Zeyu Zhang and Yangyang Wu and Yao Su and Yixin Zhu and Hangxin Liu and Song-Chun Zhu},
  doi          = {10.1109/TRO.2025.3605261},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {1-20},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Integration of robot and scene kinematics for sequential mobile manipulation planning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design, modeling, and experiment of a 3-DoF miniature plate piezoelectric robot. <em>TROB</em>, 1-20. (<a href='https://doi.org/10.1109/TRO.2025.3605254'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The piezoelectric plate robot driven by traveling waves (TWs) boasts a compact structure and excellent load-bearing capacity. However, vibration coupling across the plate restricts its freedom of movement, along with issues such as poor straight-line motion and a large turning radius. Inspired by octopus locomotion, we designed a three-degree-of-freedom (3-DoF) piezoelectric plate robot using a 0.7 mm metal plate. Through drive region division and dynamic modeling, our design achieves fully controllable motion in any planar direction, providing the highest DoF among TW driven plate robots. Weighing just 14.2g, it is lighter and easier to fabricate compared to other 3-DoF piezoelectric robots. The robot demonstrated 3-DoF movement capabilities, climbing (16.5°), dragging (20 g), and carrying (180 g), and can bear over 5,000 times its own body weight. A wireless drive prototype with closed-loop control reduced trajectory errors by more than 80% compared to open-loop control. Experiments involving high-curvature path movement, confined-space “search and rescue” and light focusing highlight its potential in extreme environments and high-precision tasks.},
  archive      = {J_TROB},
  author       = {Yuanshuai Ding and Yongmao Pei},
  doi          = {10.1109/TRO.2025.3605254},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {1-20},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Design, modeling, and experiment of a 3-DoF miniature plate piezoelectric robot},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RUMI: Rummaging using mutual information. <em>TROB</em>, 1-20. (<a href='https://doi.org/10.1109/TRO.2025.3605251'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents Rummaging Using Mutual Information (RUMI), a method for online generation of robot action sequences to gather information about the pose of a known movable object in visually-occluded environments. Focusing on contact-rich rummaging, our approach leverages mutual information between the object pose distribution and robot trajectory for action planning. From an observed partial point cloud, RUMI deduces the compatible object pose distribution and approximates the mutual information of it with workspace occupancy in real time. Based on this, we develop an information gain cost function and a reachability cost function to keep the object within the robot's reach. These are integrated into a model predictive control (MPC) framework with a stochastic dynamics model, updating the pose distribution in a closed loop. Key contributions include a new belief framework for object pose estimation, an efficient information gain computation strategy, and a robust MPC-based control scheme. RUMI demonstrates superior performance in both simulated and real tasks compared to baseline methods.},
  archive      = {J_TROB},
  author       = {Sheng Zhong and Nima Fazeli and Dmitry Berenson},
  doi          = {10.1109/TRO.2025.3605251},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {1-20},
  shortjournal = {IEEE Trans. Robot.},
  title        = {RUMI: Rummaging using mutual information},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tip-growing robots: Design, theory, application. <em>TROB</em>, 1-20. (<a href='https://doi.org/10.1109/TRO.2025.3608701'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Growing robots apically extend through material eversion or deposition at their tip. This endows them with unique capabilities such as follow the leader navigation, long-reach, inherent compliance, and large force delivery bandwidth. Tip-growing robots can therefore conform to sensitive, intricate, and difficult-to-access environments. This review paper categorizes, compares, and critically evaluates state-of-the-art growing robots with emphasis on their designs, fabrication processes, actuation and steering mechanisms, mechanics models, controllers, and applications. Finally, the paper discusses the main challenges that the research area still faces and proposes future directions.},
  archive      = {J_TROB},
  author       = {Shamsa Al Harthy and S.M.Hadi Sadati and Cédric Girerd and Sukjun Kim and Alessio Mondini and Zicong Wu and Brandon Saldarriaga and Carlo A. Seneci and Barbara Mazzolai and Tania K. Morimoto and Christos Bergeles},
  doi          = {10.1109/TRO.2025.3608701},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {1-20},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Tip-growing robots: Design, theory, application},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Curb-tracker: An integrated curb following system for autonomous vehicles. <em>TROB</em>, 1-20. (<a href='https://doi.org/10.1109/TRO.2025.3608695'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Curb following is a critical technology for autonomous road sweeping vehicles. However, existing solutions face two primary challenges: unreliable curb detection and inefficient motion generation. Unreliable curb detection stems from the wide variability in curb dimensions and types, as well as interference from roadside features such as vegetation and infrastructure. Inefficient motion generation occurs when existing methods prioritize tracking accuracy while neglecting task completion efficiency, leading to prolonged operation times. To address these challenges, we propose Curb-Tracker, an integrated curb-following system designed for autonomous vehicles operating in diverse road environments. Firstly, we develop a robust and adaptive curb detection algorithm that leverages a 2.5D elevation map of the local environment and dynamically adjusts key parameters online to ensure reliable detection across varying scenarios. Secondly, to achieve accurate and efficient curb-aligned motion generation, we leverage Model Predictive Contouring Control (MPCC) as a tailored framework specifically designed for the curb-following task to generate an optimal control sequence for the vehicle to maintain a specified lateral offset from the curb while maximizing travel progress along it. The proposed system has been implemented on a Hunter 2.0, a front-wheel Ackerman-steering mobile robot, and has been validated through extensive experiments in both Gazebo simulation and real-world environments. Experimental results demonstrate the effectiveness, adaptability, and robustness of the proposed system across a wide range of road scenarios. Video of real-world experiments is available at https://youtu.be/H1xaV6QdJ10.},
  archive      = {J_TROB},
  author       = {Jiahao Liang and Yuanzhe Wang and Guohao Peng and Zhenyu Wu and Danwei Wang},
  doi          = {10.1109/TRO.2025.3608695},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {1-20},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Curb-tracker: An integrated curb following system for autonomous vehicles},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tactile robotics: An outlook. <em>TROB</em>, 1-20. (<a href='https://doi.org/10.1109/TRO.2025.3608686'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotics research has long sought to give robots the ability to perceive the physical world through touch in an analogous manner to many biological systems. Developing such tactile capabilities is important for numerous emerging applications that require robots to co-exist and interact closely with humans. Consequently, there has been growing interest in tactile sensing, leading to the development of various technologies, including piezoresistive and piezoelectric sensors, capacitive sensors, magnetic sensors, and optical tactile sensors. These diverse approaches utilise different transduction methods and materials to equip robots with distributed sensing capabilities, enabling more effective physical interactions. These advances have been supported in recent years by simulation tools that generate largescale tactile datasets to support sensor designs and algorithms to interpret and improve the utility of tactile data. The integration of tactile sensing with other modalities, such as vision, as well as with action strategies for active tactile perception highlights the growing scope of this field. To further the transformative progress in tactile robotics, a holistic approach is essential. In this outlook article, we examine several challenges associated with the current state of the art in tactile robotics and explore potential solutions to inspire innovations across multiple domains, including manufacturing, healthcare, recycling and agriculture.},
  archive      = {J_TROB},
  author       = {Shan Luo and Nathan F. Lepora and Wenzhen Yuan and Kaspar Althoefer and Gordon Cheng and Ravinder Dahiya},
  doi          = {10.1109/TRO.2025.3608686},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {1-20},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Tactile robotics: An outlook},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quasi-dynamic crowd vetting: Collaborative detection of malicious robots in dynamic communication networks. <em>TROB</em>, 1-17. (<a href='https://doi.org/10.1109/TRO.2025.3608702'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We are interested in the problem where robots traverse through an environment modeled by a graph of discrete sites, and an unknown subset of the multi-robot team is malicious. Previous works require that each robot gathers information about the trustworthiness of all other robots, called trust observations, which can be time consuming in large networks. This paper decreases the time required to estimate trustworthiness by building upon an algorithm that leverages the concept of ‘Crowd Vetting’ and the opinion of trusted neighbors. This allows each robot to estimate trust in dynamic scenarios, where the team size, robot neighborhoods, and robot legitimacy can change. In particular, we employ an assumption that there exists quasi-dynamic time periods, where if a robot's legitimacy remains fixed for a sufficient length of time, its trustworthiness can be characterized. In this setting, we develop a closed-form expression for the critical number of time-steps required for our algorithm to successfully identify the true legitimacy of each robot within a specified failure probability. We show that the number of time-steps required for robots to correctly estimate the trust of all other robots increases logarithmically with the number of robots when robots do not leverage neighboring opinions, called the Direct Protocol. Conversely, for most general graph topologies, the number of time-steps required remains constant as the number of robots increases when our proposed algorithm, called quasi-Dynamic Crowd Vetting (DCV), is used, for a fixed ratio of legitimate to malicious robots. Finally, our theoretical results are successfully validated through simulated persistent surveillance tasks where robots maintain a desired distribution of robots over sites in the environment.},
  archive      = {J_TROB},
  author       = {Matthew Cavorsi and Frederik Mallmann-Trenn and David Saldaña and Stephanie Gil},
  doi          = {10.1109/TRO.2025.3608702},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {1-17},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Quasi-dynamic crowd vetting: Collaborative detection of malicious robots in dynamic communication networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Plan optimal collision-free trajectories with non-convex cost functions using graphs of convex sets. <em>TROB</em>, 1-20. (<a href='https://doi.org/10.1109/TRO.2025.3610175'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recently developed approach to motion planning in Graphs of Convex Sets (GCS) provides an efficient framework for computing shortest-distance collision-free paths using convex optimization. This new motion planner is notably more computationally efficient than popular sampling-based motion planners, but it does not support non-convex cost functions. This paper develops a novel motion planning algorithm, Graph of Convex Sets with General Costs (GCSGC), to solve this problem. A given non-convex cost function is accurately approximated by a multiple-layer ReLU neural network and the configuration space is decomposed into a set of linear-cost regions using the hidden layers of the neural network. These linear-cost regions are intersected with a set of collision-free regions, and the resulting collision-free linear-cost regions are intersected to form the vertices and edges of the motion planner's underlying graph structure. The edge costs have a closed-form solution within each collision-free linear-cost region, but it is non-convex, so the McCormick relaxation is applied to convexify the edge costs. Finally, a graph pre-processing technique is developed to compute a representative graph structure that acts as a heuristic for the edge costs of the underlying GCS and then simplify the underlying graph structure by removing cycles and high-cost paths, which can significantly improve the efficiency of the planner and quality of the produced trajectories. The proposed motion planner is first validated in a 2D configuration space with comparisons between different sized neural networks with and without pre-processing, comparisons between optimal trajectories from GCSGC with shortest-distance trajectories, and comparisons between GCSGC and GCS-SLP. The GCSGC planner is further validated in a complex 7D configuration space by comparing to state-of-the-art multi-query (PRM*, GCS-SLP) and single-query (TrajOpt, BIT*, AIT*, RRT*) planners. The results show that the proposed motion planner is very competitive in terms of computational efficiency, trajectory cost, and memory footprint. Two physical experiments further validate the effectiveness of the proposed motion planner in real-world motion planning applications.},
  archive      = {J_TROB},
  author       = {Charles L. Clark and Biyun Xie},
  doi          = {10.1109/TRO.2025.3610175},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {1-20},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Plan optimal collision-free trajectories with non-convex cost functions using graphs of convex sets},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unilateral active knee exoskeleton to assist individuals with hemiparesis – A pilot study. <em>TROB</em>, 1-14. (<a href='https://doi.org/10.1109/TRO.2025.3610187'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most individuals who experience a stroke exhibit several sensorimotor impairments that limit their independence in everyday activities. Hemiparetic gait is frequently characterized by reduced knee flexion in swing due to knee stiffness or muscle weakness and knee hyperextension or knee buckling in the stance phase. Recently, unilateral-powered orthoses have been designed to overcome the limitations of the passive knee-ankle-foot orthoses. This study presents a unilateral Active Knee Orthosis Exoskeleton, AKO-$\beta$, endowed with a series elastic actuator and designed to assist the knee in flexion and extension movements. The paper describes the system mechatronic design and its characterization on the bench, the control system, and pilot experiments with three post-stroke participants. The device has a weight of 1.78 kg on the user's leg, with a lateral encumbrance of 76 mm. The pilot experiments aimed to verify the effects of the exoskeleton assistance in hemiparetic gait patterns. When walking with the device, participants on average increased the knee flexion on the paretic side by 18.70 deg (+44.9%) during swing and decreased knee hyperextension in stance by 4.50 deg, compared to walking without it. Overall, when walking with the exoskeleton, subjects showed improved Gait Variable Score of the paretic knee profile by 37.5% compared to walking without it. The temporal and spatial gait symmetry indexes did not show clear changes, although an improvement in symmetry was observed in two of the three participants. These preliminary results suggest the potential benefits of the unilateral Active Knee Orthosis exoskeleton to enhance and restore mobility in individuals with hemiparetic gait.},
  archive      = {J_TROB},
  author       = {Andrea Pergolini and Clara Beatriz Sanz-Morère and Chiara Livolsi and Matteo Fantozzi and Filippo Dell'Agnello and Tommaso Ciapetti and Alessandro Maselli and Andrea Baldoni and Emilio Trigili and Simona Crea and Nicola Vitiello},
  doi          = {10.1109/TRO.2025.3610187},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A unilateral active knee exoskeleton to assist individuals with hemiparesis – A pilot study},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Anytime probabilistically constrained provably convergent online belief space planning. <em>TROB</em>, 1-20. (<a href='https://doi.org/10.1109/TRO.2025.3610176'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Taking into account future risk is essential for an autonomously operating robot to find online not only the best but also a safe action to execute. In this paper, we build upon the recently introduced formulation of probabilistic belief-dependent constraints. In our methodology safety can be materialized with any general belief-dependent operator we call payoff. We present an anytime approach employing the Monte Carlo Tree Search (MCTS) method in continuous domains in terms of states, actions and observations and general-belief dependent reward and payoff operators. Unlike previous approaches, our method ensures safety anytime with respect to the currently expanded search tree without relying on the convergence of the search. We prove convergence in probability with an exponential rate of a version of our algorithms and study proposed techniques via extensive simulations. Even with a tiny number of tree queries, the best action found by our approach is much safer than the baseline. Moreover, our approach constantly yields better than the baseline action in terms of objective function. This is because we revise the values and statistics maintained in the search tree and remove from them the contribution of the pruned actions. We rigorously show that our cleaning routine is necessary. Without it, at the limit of convergence of MCTS, an infinite amount of sampled dangerous actions can be detrimental to the objective function.},
  archive      = {J_TROB},
  author       = {Andrey Zhitnikov and Vadim Indelman},
  doi          = {10.1109/TRO.2025.3610176},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {1-20},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Anytime probabilistically constrained provably convergent online belief space planning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High-efficiency vector field by time-optimal spatial iterative learning. <em>TROB</em>, 1-20. (<a href='https://doi.org/10.1109/TRO.2025.3610174'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel model-free spatial iterative learning (IL) framework to enhance the efficiency of vector field (VF) navigation for mobile robots. By integrating the idea of iterative learning control (ILC) with VF, this framework utilizes historical data to enhance navigation efficiency significantly, reducing traversal time and expanding the applicability of IL to rapid navigation. Importantly, it has low time complexity with $O(n)$ per iteration, where $n$ denotes the waypoints number, preventing the significant computational overhead caused by the increasing waypoints in existing methods, which often exceeds $O(n^{2})$, making it well-suited for real-time planning. Moreover, the approach is inherently model-free, leaning on historical data, thus enabling agile navigation with limited reliance on intricate model details. The paper presents a comprehensive theoretical analysis of the stability, time optimality, time complexity, parameter insensitivity, robustness, and usage. Extensive simulations and experiments highlight its efficiency, promising a transformative impact on mobile robot navigation through the proposed IL.},
  archive      = {J_TROB},
  author       = {Shuli Lv and Yan Gao and Quan Quan},
  doi          = {10.1109/TRO.2025.3610174},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {1-20},
  shortjournal = {IEEE Trans. Robot.},
  title        = {High-efficiency vector field by time-optimal spatial iterative learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predictive body awareness in soft robots: A bayesian variational autoencoder fusing multimodal sensory data. <em>TROB</em>, 1-16. (<a href='https://doi.org/10.1109/TRO.2025.3610170'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting the causal flow by fusing multimodal perception is fundamental for constructing the bodily awareness of soft robots. However, forming such a predictive model while fusing the multimodal sensory data of soft robots remains challenging and less explored. In this study, we leverage the free energy principle within a Bayesian probabilistic deep learning framework to merge visual, pressure, and flex sensing signals. Our proposed multimodal association mechanism enhances the fusion process, establishing a robust computational methodology. We train the model using a newly collected dataset that captures the grasping dynamics of a soft gripper equipped with multimodal perception capabilities. By incorporating the current state and image differences, the forward model can predict the soft gripper's physical interaction and movement in the image flow, which amounts to imagining future motion events. Moreover, we showcase effective predictions across modalities as well as for grasping outcomes. Notably, our enhanced variational autoencoder approach can pave the way for unprecedented possibilities of bodily awareness in soft robotics.},
  archive      = {J_TROB},
  author       = {Shuyu Wang and Dongling Liu and Changzeng Fu and Xiaoming Yuan and Peng Shan and Victor C.M. Leung},
  doi          = {10.1109/TRO.2025.3610170},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Predictive body awareness in soft robots: A bayesian variational autoencoder fusing multimodal sensory data},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards accurate, efficient and robust RGB-D simultaneous localization and mapping in challenging environments. <em>TROB</em>, 1-20. (<a href='https://doi.org/10.1109/TRO.2025.3610173'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual Simultaneous Localization and Mapping (SLAM) is crucial to many applications such as self-driving vehicles and robot tasks. However, it is still challenging for existing visual SLAM approaches to achieve good performance in low-texture or illumination-changing scenes. In recent years, some researchers have turned to edge-based SLAM approaches to deal with the challenging scenes, which are more robust than feature-based and direct SLAM methods. Nevertheless, existing edge-based methods are computationally expensive and inferior than other visual SLAM systems in terms of accuracy. In this study, we propose EdgeSLAM, a novel RGB-D edge-based SLAM approach to deal with challenging scenarios that is efficient, accurate, and robust. EdgeSLAM is built on two innovative modules: efficient edge selection and adaptive robust motion estimation. The edge selection module can efficiently select a small set of edge pixels, which significantly improves the computational efficiency without sacrificing the accuracy. The motion estimation module improves the system's accuracy and robustness by adaptively handling outliers in motion estimation. Extensive experiments were conducted on TUM RGBD, ICL-NUIM and ETH3D datasets, and experimental results show that EdgeSLAM significantly outperforms five state-of-the-art (SOTA) methods in terms of efficiency, accuracy, and robustness, which achieves 29.17% accuracy improvements with a high processing speed of up to 120 FPS and a high positioning success rate of 97.06%.},
  archive      = {J_TROB},
  author       = {Hui Zhao and Fuqiang Gu and Jianga Shang and Xianlei Long and Jiarui Dou and Chao Chen and Huayan Pu and Jun Luo},
  doi          = {10.1109/TRO.2025.3610173},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {1-20},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Towards accurate, efficient and robust RGB-D simultaneous localization and mapping in challenging environments},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Time-varying foot placement control for humanoid walking on swaying rigid surface. <em>TROB</em>, 1-20. (<a href='https://doi.org/10.1109/TRO.2025.3612326'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Locomotion on dynamic rigid surface (i.e., rigid surface accelerating in an inertial frame) presents complex challenges for controller design, which are essential to address for deploying humanoid robots in dynamic real-world environments such as moving trains, ships, and airplanes. This paper introduces a real-time, provably stabilizing control approach for humanoid walking on periodically swaying rigid surface. The first key contribution is an analytical extension of the classical angular momentum-based linear inverted pendulum model from static to swaying grounds whose motion period may be different than the robot's gait period. This extension results in a time-varying, nonhomogeneous robot model, which is fundamentally different from the existing pendulum models. We synthesize a discrete footstep control law for the model and derive a new set of sufficient stability conditions that verify the controller's stabilizing effect. Finally, experiments conducted on a Digit humanoid robot, both in simulations and on hardware, demonstrate the framework's effectiveness in addressing bipedal locomotion on swaying ground, even under uncertain surface motions and unknown external pushes.},
  archive      = {J_TROB},
  author       = {Yuan Gao and Victor Paredes and Yukai Gong and Zijian He and Ayonga Hereid and Yan Gu},
  doi          = {10.1109/TRO.2025.3612326},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {1-20},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Time-varying foot placement control for humanoid walking on swaying rigid surface},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
