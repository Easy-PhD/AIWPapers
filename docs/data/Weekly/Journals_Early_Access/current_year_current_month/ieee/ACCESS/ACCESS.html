<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>ACCESS</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="access">ACCESS - 85</h2>
<ul>
<li><details>
<summary>
(2025). A novel machine learning workflow to classify mobile home parks at scale. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3615118'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the built environment is essential to the overall study of population dynamics, grid infrastructure, emergency response, among others. In the United States there are multiple classifications for buildings within the built environment such as residential, signifying family homes while commercial buildings consist of apartments or larger structures which are multi-purpose. While there is a high level of understanding of where these aforementioned structures are located, there is a third class of structures, mobile home parks (MHP) which have been under-represented in the literature despite there being an estimated 2.7 million of them within the United States. Research has shown that individuals who reside in MHP are at higher risk to extreme events due to their location and structural integrity of residence. Attention must now turn to identifying MHP at scale to help first responders and policy makers understand where these at risk populations reside. To address for this gap, we develop a novel methodology to infer MHP at scale based off morphologies derived at a building level. We show that across 3 million buildings in 6 states within the United States it is possible to identify MHP with 83% accuracy. This novel approach to identify MHP from other structures within the built environment using a machine learning approach provides a new tool to leverage in relation to helping at-risk populations.},
  archive      = {J_ACCESS},
  author       = {Clinton Stipek and Sameer Nathawat and Taylor Hauser and Nagendra Singh},
  doi          = {10.1109/ACCESS.2025.3615118},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {A novel machine learning workflow to classify mobile home parks at scale},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-stage genetic algorithm offline parameter optimization of adaptive extended kalman filter for robust battery state-of-charge estimation. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3615885'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately estimating battery state of charge (SOC) in electric vehicle applications (EVs) is crucial to ensure a safe and reliable vehicle operation. However, robust SOC estimation under all possible operating conditions is challenging due to varying load conditions, varying and non-linear battery impedance, sensor inaccuracies, among others. Meanwhile, battery management systems (BMS) are trending toward more compact designs to enhance reliability by reducing wiring and boosting energy density. Hence, minimizing the memory footprint of SOC estimation algorithms is a key challenge, as their design and tuning remain a time-consuming and costly process for the industry. This paper introduces an Adaptive Extended Kalman Filter (AEKF) algorithm with a two-stage genetic algorithm (GA) for parameter optimization. The first stage role is to find the equivalent circuit parameters’ optimal values in a non-SOC-dependent manner. The second GA optimizes the initial AEKF model tuning parameters. To mitigate the randomness of the GA, an algorithm is designed to automatically determine the optimum set of parameters with minimal user intervention. Finally, to avoid calibrating the AEKF to a Coulomb counter, the obtained parameters were tested locally and using an online tool to ensure the robustness of the estimator. The described algorithm achieves a low root mean square error (RMSE) of 0.7% to 2% across various positive and negative temperatures under several drive conditions. With this tool, the AEKF can be rapidly tuned with minimal user effort, providing fast and robust SOC estimation suitable for automotive applications.},
  archive      = {J_ACCESS},
  author       = {Lucas Nahidmobarakeh and Mina Nemetiandoost and Batuhan Sirri Yilmaz and Javier Gazzarri and Xiangchun Zhang and Sebastián Arias and Phil Kollmeyer and Ryan Ahmed},
  doi          = {10.1109/ACCESS.2025.3615885},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Two-stage genetic algorithm offline parameter optimization of adaptive extended kalman filter for robust battery state-of-charge estimation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Paving the roadmap for XAI and IML in healthcare: Data-driven discoveries and the FIXAIH framework. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3616353'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence is revolutionizing healthcare. However, its adoption is hindered by the technical-proficiency gap, the disconnect between AI complexity and clinical interpretability. Although Explainable AI (XAI) and Interpretable Machine Learning (IML) techniques aim to address this gap, fragmented research limits the development of generalizable and practical guidance. In response, we introduce FIXAIH, a dynamic, evidence-based framework that consolidates fragmented research in XAI and IML into a coherent structure to guide implementation in healthcare. It is designed to enhance the transparency, accountability, and efficacy of AI systems -- characteristics essential to meet trust and legal requirements, e.g., in the EU AI Act. FIXAIH uses a machine learning-based methodology to holistically analyze literature to identify key parameters shaping the integration of XAI and IML in clinical contexts. We develop a BERT-based tool and examine 5,083 articles, identifying 13 key parameters across three macro-parameters: Research Methods, Health Disorders, and Disease Prevention. This categorization, refined through review of 200+ studies, clarifies applications, trends, and challenges in healthcare XAI. These parameters serve as design elements for developing and aligning AI systems. Drawing on them, FIXAIH supports diagnostic accuracy, treatment efficacy, and risk prediction through, e.g., feature relevance, bias detection, model refinement, data preparation, and expert-guided adjustments. FIXAIH embeds this methodology and adaptable guidelines at its core, evolving as new evidence becomes available, with the intention to expand through integration of social media, clinical insights, regulatory data, and other sources. This adaptive design supports continuous learning and practical implementation, promoting a trustworthy approach to medical innovation.},
  archive      = {J_ACCESS},
  author       = {Shatha Alghamdi and Rashid Mehmood and Fahad Alqurashi and Ali Alzahrani},
  doi          = {10.1109/ACCESS.2025.3616353},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Paving the roadmap for XAI and IML in healthcare: Data-driven discoveries and the FIXAIH framework},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Point cloud upsampling for accurate surface reconstruction via attention-guided generation. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3616323'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reconstructing accurate surfaces from sparse point clouds remains a fundamental challenge in 3D vision. In this paper, we propose a novel upsampling framework that focuses on surface-aware point generation. Our method comprises two key components. First, we introduce an adaptive query generation module that analyzes local attention information to determine where new points should be placed. These query points guide the generation toward regions of geometric significance. Second, we incorporate the Hyper Chamfer Distance (HCD) loss, which accounts for the distribution of point-wise distances to better capture complex surface structures. Unlike existing methods, our approach effectively combines attention-based guidance and loss-driven precision, leading to more accurate surface reconstruction. Extensive experiments on PU-GAN and PU1K datasets demonstrate that our method consistently outperforms state-of-the-art techniques, especially in terms of the P2F metric. Moreover, the proposed framework maintains robust performance across arbitrary upsampling ratios and under random noise, confirming its reliability and generalizability.},
  archive      = {J_ACCESS},
  author       = {Jong-Su Won and Jong-Ki Han},
  doi          = {10.1109/ACCESS.2025.3616323},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Point cloud upsampling for accurate surface reconstruction via attention-guided generation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An automatic recognition method of electrical wiring diagrams based on optimized YOLO11 and CAD automatic recognition technology. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3616365'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diagram-model consistency of electrical wiring diagrams remains a core challenge for multi-source data collaboration in smart substations, with structural discrepancies between SVG diagrams (design institutes) and CIM/E models (dispatch systems) causing 22% manual comparison errors. To address limitations of existing methods in small-target detection (e.g., 0.08%-area isolating switches), imbalanced component distribution (<10 samples for rare components), and joint topology-text parsing, this work proposes an intelligent framework integrating enhanced YOLO11 with CAD parsing. Key contributions include: an adaptive sliding window mechanism for small-target recognition, hierarchical feature fusion with CBAM attention to distinguish geometrically similar elements, and a DXF spatial rule engine for connection extraction. Evaluations on real-world grid datasets achieve 93.6% mAP@50 (21.1-point improvement over baseline YOLO11), 86% rare-component recognition, 100% text extraction accuracy, 99.4% connection accuracy, and 5.2s/image processing (3.04× faster than conventional approaches). This framework enables comprehensive collaborative parsing of 28 component categories with topological relationships, providing effective technical support for power system digitalization.},
  archive      = {J_ACCESS},
  author       = {Qun Wang and Yizhuo Wang and Lijing Ma and Yiming Xu},
  doi          = {10.1109/ACCESS.2025.3616365},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {An automatic recognition method of electrical wiring diagrams based on optimized YOLO11 and CAD automatic recognition technology},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantifying review informativeness with aspect-aware knowledge graphs and linguistic parsing. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3615992'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing reliance on user reviews for decision-making has elevated the role of online reviews on e-commerce platforms, yet the surge in generic, vague, or promotional content undermines their informativeness and credibility. While existing sentiment analysis and fake review detection methods classify reviews based on polarity or authenticity, they often overlook a critical dimension: how informative and actionable a review truly is. Reviews such as “Great place!” may indicate positive sentiment but lack specific, aspect-level insights needed by consumers or businesses. This deficiency creates a substantial gap in current review analysis systems, which struggle to differentiate between superficial and detailed feedback. Addressing this gap requires an approach capable of capturing both the presence and richness of aspect-specific content. This paper presents a novel knowledge-driven approach for evaluating the informativeness of restaurant reviews by integrating linguistic analysis with Knowledge Graph (KG) representation. The KG is constructed using restaurant reviews from the Yelp dataset to define aspect categories, extract aspect terms, and model their corresponding sentiment relations. The proposed approach systematically identifies and extracts aspect-sentiment pairs related to four critical aspects: food, service, price, and atmosphere, using dependency parsing and a curated lexicon. A custom metric, Aspect-Aware Length-Normalized Information Density (Aspect-Aware LNID), is introduced to quantify the richness and completeness of a review based on its semantic content and aspect coverage. Experimental evaluation on the SemEval 2014 dataset demonstrates the effectiveness of the proposed approach, achieving a 97.5% weighted-average F1-score in aspect category extraction and providing interpretable, scalable, and domain-specific insights. This hybrid approach offers a transparent alternative to opaque deep learning models, enabling fine-grained opinion mining and improved consumer trust in online review platforms.},
  archive      = {J_ACCESS},
  author       = {Rania A. AlQadi and Shereen A. Taie and Asmaa Hashem Sweidan and Esraa Elhariri},
  doi          = {10.1109/ACCESS.2025.3615992},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Quantifying review informativeness with aspect-aware knowledge graphs and linguistic parsing},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Flexible design of broadside-radiating linearly-polarized edge-fed metasurface antennas. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3616581'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we design and fabricate broadside-radiating edge-fed metasurface antennas with linear polarization employing a spatially-varying isotropic reactance; in order to avoid losses, the antenna is not terminated on a matched load. The design is achieved using a deterministic numerical algorithm for the synthesis of metasurfaces, combined with an accurate modeling of the feeding structure. The procedure effectively keeps into account the open-ended layout of the antennas; remarkably, optimization of radiation, and input impedance matching, results in structures that are of standing-wave type or traveling (leaky)-wave type depending on the substrate. In case of leaky-wave type of result, it is shown that the related open stop-band issue is avoided. The performance of the designed antennas is tested by full-wave simulations and measurements of fabricated prototypes.},
  archive      = {J_ACCESS},
  author       = {Lucia Teodorani and Marcello Zucchi and Giorgio Giordanengo and Rossella Gaffoglio and Giuseppe Vecchi},
  doi          = {10.1109/ACCESS.2025.3616581},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Flexible design of broadside-radiating linearly-polarized edge-fed metasurface antennas},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unified cybersecurity framework for smart grids against data integrity attacks using ensemble learning and hybrid encryption. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3616505'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing frequency and sophistication of cyberattacks on smart grid infrastructures have raised critical concerns over data integrity, operational resilience, and real-time response capabilities. This study introduces a unified cybersecurity framework for cyber-physical power systems that integrate high-performance anomaly detection with provably secure cryptographic protection. A comprehensive dataset, built upon the IEEE 24-bus test system, includes a diverse set of operational states and five classes of false data injection attacks (FDIAs), including stealthy and replay-based intrusions. To accurately detect both common and sophisticated threats, we implement a suite of supervised learning models—RF, MLP, and Decision Trees—alongside an ensemble strategy termed MVCC, which achieves up to 99.90% accuracy in binary classification and 99.88% in multiclass settings. For defense at the data level, we deploy a two-tier encryption architecture combining AES-GCM (for confidentiality and authenticity) with RSA-OAEP (for secure key management), demonstrating strong resilience against standard attack models (COA, KPA, CPA, CCA) and achieving nearly uniform ciphertext entropy (7.99 bits/byte). The system’s real-time applicability is validated through the deployment of the RF classifier on a PYNQ-Z2 FPGA platform, attaining sub-second inference latency. Further, unsupervised (DBSCAN, K-Means) and temporal (LSTM) models are incorporated for stealthy anomaly localization and early threat prediction. This work presents a scalable, interpretable, and cryptographically secure solution for protecting next-generation smart grids against evolving data integrity threats.},
  archive      = {J_ACCESS},
  author       = {Archana Pallakonda and K Ravishanmugam and Rayappa David Amar Raj and Sharvesh Sivagnanam and Rama Muni Reddy Yanamala and K. Krishna Prakasha},
  doi          = {10.1109/ACCESS.2025.3616505},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {A unified cybersecurity framework for smart grids against data integrity attacks using ensemble learning and hybrid encryption},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mispronunciation detection and diagnosis for young arabic learners using transfer learning. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3616335'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Improving primary school students’ reading skills supports their academic growth and communication abilities. Pronunciation accuracy is central to reading, especially in Arabic, where small diacritic changes can alter meaning. This is complicated by Arabic’s low-resource nature. This study developed a Mispronunciation Detection and Diagnosis (MDD) system for Arabic learners, allowing teachers and learners to use Computer-Assisted Pronunciation Training (CAPT) for improved instruction and assessment. A pretrained self-supervised learning (SSL) model was fine-tuned to detect phoneme-level pronunciation errors in Modern Standard Arabic using a unique dataset of primary school learner speech from Saudi Arabia. The data were structured, preprocessed, normalized, and aligned to phoneme sequences. The system showed improved phoneme recognition and performance approaching that of a human expert with an F1 score of 71.4%.},
  archive      = {J_ACCESS},
  author       = {Taha Fanoush and Wasfi G. Al-Khatib and Mohammad Amro and Abdulkareem Alzahrani and Moustafa Elshafei},
  doi          = {10.1109/ACCESS.2025.3616335},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Mispronunciation detection and diagnosis for young arabic learners using transfer learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). STAD: Self-supervised transformer for anomaly detection in multi-variate time series data. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3616597'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection in multivariate time series has gained significant attention in past few years. The rarity of anomalies, considerable data volatility, absence of anomaly labels, and need for real-time inference in modern applications makes it a challenging problem. A robust training mechanism is desired that can accurately detect anomalous points in dataset with significantly large sized normal data. Moreover, multivariate data recorded by multiple sensors significantly varies from normal values in case of any defect. It is crucial to detect which specific sensor’s data are abnormal for system analysis and correction. To address these issues, we present a self-supervised transformer for anomaly detection, STAD, which enables robust learning from unlabeled data by synthesizing pseudo-anomalies during training. The research contributions are manifold. Firstly, a synthetic anomaly injection method is developed for anomaly generation and self-supervised training on critical anomalous behaviors. Secondly, a multi-head context attention module is designed and embedded with Transformer architecture to map the local and global associations, effectively distinguishing rare anomalies. Lastly, we propose attentive class activation tokens mapping mechanism that facilitates anomaly attribution by tracing the influence of individual sensor inputs through the Transformer model, offering transparent and interpretable insights. Extensive experiments conducted on eight real-world datasets demonstrate that STAD consistently outperforms state-of-the-art unsupervised and semi-supervised approaches, achieving superior F1 scores and interpretability while maintaining computational efficiency suitable for real-time deployment.},
  archive      = {J_ACCESS},
  author       = {Saba Arshad and Minho Ha and Tae-Hyoung Park},
  doi          = {10.1109/ACCESS.2025.3616597},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {STAD: Self-supervised transformer for anomaly detection in multi-variate time series data},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Alternating MSA and mo-QEA to design slow-time coded PRF-set in pulse-doppler radar. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3616316'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel framework based on a multivariable hybrid optimization algorithm that integrates single-objective modified simulated annealing (MSA) and multi-objective quantum-inspired evolutionary algorithm (Mo-QEA) layers based on the impact of the slow-time phase coding for minimizing unwanted signals at the output of matching filters, on the frequency spectrum of pulsed-Doppler radars. Slow-time codes alter the spectrum’s structure and result in increasing the blind areas within the blind-zone map (BZM). The hybrid framework comprises two layers that identify the optimum pulse repetition frequency (PRF) set and slow-time code by considering spectrum disturbances. The first layer employs the MSA for PRF set optimization. Modifications to the SA include restructured loops based on the perturbation functions. The outer loop considers the overall PRF set structure (overall direction and step—ODS), while the inner loop conducts a sequential search based on the cost function’s standard deviation and small increments. The output of this layer serves as the foundation in the subsequent layer, where the phase sequence of each PRF is optimized to concurrently minimize blind areas due to the M of N criterion and grating lobes through Mo-QEA. Innovations are mutation-like operators and tournament selection to enhance the diversity of generated solutions alongside rotation gates in quantum computing. Our research highlights a previously unexplored relationship between BZM and slow-time coding, demonstrating improved performance for each layer compared to existing studies.},
  archive      = {J_ACCESS},
  author       = {Aata Nokhostin Roohi and Hossein Soleimani and Mohammad Soleimani},
  doi          = {10.1109/ACCESS.2025.3616316},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Alternating MSA and mo-QEA to design slow-time coded PRF-set in pulse-doppler radar},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Performance enhancement of incremental cooperative NOMA via partial relay selection. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3616386'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Improving spectrum efficiency (SE) and energy efficiency (EE) remains a fundamental requirement for future wireless communication systems. To address this, we present a novel cooperative relaying strategy built on Incremental Relaying with Partial Relay Selection (IR-RS) using a Decode-and-Forward (DF) protocol (IR-RS-DF), tailored for Cooperative Non-Orthogonal Multiple Access (C-NOMA) networks. In this approach, a near user (NU) is selected dynamically based on its instantaneous signal-to-noise ratio (SNR) to serve as a DF relay for assisting a far user (FU), especially when the FU suffers from poor direct transmission conditions. To enhance energy utilization, the system incorporates a feedback-aided incremental relaying mechanism, which selectively engages relays only when necessary, thereby avoiding unnecessary retransmissions and reducing power consumption. We conduct a comprehensive statistical evaluation of key performance metrics such as bit error rate (BER), ergodic capacity (EC), system throughput, outage probability (OP), SE, and average energy savings over Rayleigh fading channels. Simulation outcomes validate that the proposed IR-RS scheme, when integrated with C-NOMA, consistently outperforms conventional IR-DF approaches across all evaluated parameters, showcasing its effectiveness for high-efficiency and energy-aware next-generation wireless networks.},
  archive      = {J_ACCESS},
  author       = {Gandlapalli Nagesham and Suseela Vappangi},
  doi          = {10.1109/ACCESS.2025.3616386},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Performance enhancement of incremental cooperative NOMA via partial relay selection},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generalization of knowledge transfer with user reviews for cross-domain recommendation. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3616497'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-domain recommendation systems have demonstrated the potential to address data sparsity and cold-start problems. However, current approaches primarily rely on domain-shareable attributes, such as overlapping user bases or identical contexts, to facilitate knowledge transfer, limiting their generalizability without these elements. To overcome these limitations, we propose exploiting review texts, which are ubiquitous across most e-commerce platforms. Our model, termed SER, incorporates three distinct text analysis modules, guided by a single discriminator to achieve disentangled representation learning. We introduce a novel optimization strategy that not only improves domain disentanglement but also minimizes the transfer of adverse information from the source domain. Furthermore, we have expanded our model’s encoding network from a single to multiple domains, enhancing its efficacy for review-based recommendation systems. Through comprehensive experiments and ablation studies, we establish that our approach is more efficient, robust, and scalable than existing single and cross-domain recommendation methods. This paper is an extension of our prior work from CIKM ’22 [1], offering additional insights, further experimental results, and a comprehensive theoretical analysis.},
  archive      = {J_ACCESS},
  author       = {Yoonhyuk Choi and Chong-Kwon Kim},
  doi          = {10.1109/ACCESS.2025.3616497},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Generalization of knowledge transfer with user reviews for cross-domain recommendation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A review on crop residue measurement and sensing. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3616603'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crop residue plays a crucial role in diverse areas of soil, biomass, crop yield, and the environment by impacting aspects such as soil organic matter, erosion, nutrient leaching, soil moisture and temperature, plant emergence, in turn influencing plant biomass and crop yields. Measuring crop residue coverage has been a long-term practice, primarily for monitoring purposes by agencies for various programs. More recently, increased research effort has been focused on improving the means and mechanisms of measuring and sensing crop residue efficiently and on large scales for both monitoring and improved agricultural decision-making insights. This review attempts to provide an overview of crop residue measurement and sensing, presenting a holistic review of the different measurement techniques available. It also highlights how research has shifted from field-based measurement to the use of diverse sensing approaches and future directions. Traditional methods of crop residue measurement are reviewed and the literature on more modern sensing approaches is summarized through categorization of the approaches based on sensing scale of satellite-, UAV-, and ground-based systems. Key findings highlight the growing shift toward high-resolution UAV sensing and the increasing use of machine learning models for improved classification. Identified critical challenges, particularly in satellite sensing, include spectral similarity between residue and soil, influence of moisture, and limited real-time application. The review aims to provide a summary of the current state of crop residue sensing with insights into potential areas for opportunities, especially through on-machine sensing systems, emphasizing the need for real-time, integrated, and adaptive residue coverage sensing solutions.},
  archive      = {J_ACCESS},
  author       = {Sagar Regmi and Fengqing Qiu and Cody Allen},
  doi          = {10.1109/ACCESS.2025.3616603},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {A review on crop residue measurement and sensing},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predictive state-aware deep reinforcement learning with hyper-heuristic for resolving conflicting objectives in scientific workflow scheduling. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3616511'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scientific workflows in cloud environments are highly complex and dynamic, necessitating intelligent and flexible scheduling solutions to handle important factors, including resource heterogeneity, budget constraints, deadlines, and ever-changing workload requirements. In contrast to traditional scheduling methods, a model with predictive ability and adaptability is required to manage these complex challenges effectively. Hence, this work intends to address the challenges associated with scheduling scientific workflows, balancing conflicting objectives, such as cost and deadline, managing intricate inter-task workflow dependencies, and dynamic resource availability. To accomplish this goal, this work presents a predictive state-aware deep reinforcement learning with a hyper-heuristic for deadline and budget-aware workflow scheduling optimization. Initially, the proposed system applies a Multihead Graph Attention Network (MGAN) to describe complex interactions between workflow tasks and cloud resources in order to predict the state for modeling an accurate environment. Moreover, the design of hyper-heuristic generation with Deep Q-Network (DQN) improves deadline and budget-aware decision-making in the uncertain workflow scheduling environment. Experiments show that the proposed method outperforms state-of-the-art approaches in terms of deadline and cost-effectiveness, providing a reliable and intelligent strategy for scheduling scientific workflows.},
  archive      = {J_ACCESS},
  author       = {Awadh Salem Bajaher and Nor Asilah Wati Abdul Hamid and Idawaty Ahmad and Zurina Mohd Hanapi},
  doi          = {10.1109/ACCESS.2025.3616511},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Predictive state-aware deep reinforcement learning with hyper-heuristic for resolving conflicting objectives in scientific workflow scheduling},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-STAR-RIS-assisted multi-user communication with symbiotic RIS-feedback channels and BS-user direct links. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3616285'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern urban communication networks face challenges such as signal propagation blockages, which can be effectively mitigated using simultaneously transmitting and reflecting reconfigurable intelligent surfaces (STAR-RIS). This paper explores the integration of multiple STAR-RISs into a symbiotic radio framework to enhance overall network performance, supporting both primary users and STAR-RISs that transmit their own data over the shared spectrum. The system enables RIS-feedback links within the same spectrum while accounting for direct links between the base station (BS) and user equipments (UEs). Two optimization problems are formulated based on different symbiotic resource-sharing policies and are equivalently transformed into weighted minimum mean square error (WMMSE) problems, which are then solved using the block coordinate descent method. Furthermore, an iterative penalty dual decomposition is adopted to determine the optimal BS beamformer and the STAR-RIS transmitting and reflecting coefficients. The effectiveness of the proposed STAR-RIS optimization framework is demonstrated through in-depth evaluation results. The findings indicate that deploying multiple STAR-RISs significantly enhances overall communication performance. While direct BS-to-UE links enhance user performance, they negatively impact RIS feedback performance. Moreover, performance trends vary according to the selected symbiotic resource-sharing policy.},
  archive      = {J_ACCESS},
  author       = {Bakunda John Ngunga and Ji-Hoon Yun},
  doi          = {10.1109/ACCESS.2025.3616285},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Multi-STAR-RIS-assisted multi-user communication with symbiotic RIS-feedback channels and BS-user direct links},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Low-side lobes 3D printed slotted waveguide antenna array for millimeter-wave communication systems. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3616275'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a 3D printed slotted waveguide antenna array is proposed for millimeter-wave communication systems at 28 GHz. The design method consists of the characterization of an isolated slot and then development of the linear and planar arrays. The proposed linear and planar arrays are 3D printed and metallized using a low-cost technique. A non-uniform 3D printed waveguide-based feeding is also designed to feed the planar array for achieving low-side lobes (< -20 dB) in the E-plane. Corrugations are added to reduce the side lobes of the planar array at the edges. The proposed antenna design is validated through experimental results suggesting an operating bandwidth of 15.8% between 26.45 GHz and 31 GHz for the linear array and 14.2% between 26.4 GHz and 30.4 GHz for the planar array with corrugations. The linear and planar arrays have high gain performance greater than 12.0 dBi and 19.0 dBi, respectively, over their operating bandwidths. The proposed arrays are suitable candidates for various applications operating in the millimeter-wave frequency bands, featuring cost-effectiveness, reduced weight, high gain, and excellent overall performance in terms of radiation.},
  archive      = {J_ACCESS},
  author       = {Zia Ullah Khan and Shaker Alkaraki and Rifaqat Hussain and Khaled A. Aljaloud and Tian Hong Loh and Akram Alomainy},
  doi          = {10.1109/ACCESS.2025.3616275},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Low-side lobes 3D printed slotted waveguide antenna array for millimeter-wave communication systems},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning techniques to improve the cognitive workload classification using multimodal sensors’ data. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3616788'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using machine learning applied to multimodal physiological data allows the classification of cognitiveworkload (low, moderate, or high load) during task performance. However, current techniques, such as multisensor data fusion (e.g. electroencephalogram, heart rate, eye movements, and other physiological signals), suffer from excessive dimensionality, intersubject variability, imbalanced feature vectors, and poor data alignment between sensors. This paper contributes three crucial points to addressing these difficulties and improving the performance in the classification of cognitive workload. First, it presents a novel theoretical model that explains the performance benefits of multimodal sensor fusion. Second, it introduces a feature augmentation strategy based on novel initial centroids optimizer techniques using k-means clustering that are intended to improve feature robustness in high-dimensional multisensor data. Third, it creates a hybrid learning pipeline that combines supervised and unsupervised methods, such as K-Nearest Neighbor (KNN), Random Forest (RF), Linear Discriminant Analysis (LDA), and ensemble stacking, to improve cross-task generalisability and classification accuracy. When evaluated across eight multimodal sensor datasets (one public and seven self-made), at first, feature importance analysis corroborated the contribution of the augmented features. Secondly, the applied technique consistently improves the binary and multiclass workload classifications. Statistical tests proved the significance of performance gains. Thus, the results show that the proposed methods are useful in improving the measurement of cognitive workload from multisensor data.},
  archive      = {J_ACCESS},
  author       = {Patient Zihisire Muke and Adrianna Kozierkiewicz},
  doi          = {10.1109/ACCESS.2025.3616788},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Machine learning techniques to improve the cognitive workload classification using multimodal sensors’ data},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Group-based corotational FEM for real-time large deformation simulation. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3616629'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time simulation of large deformations in soft bodies has long faced a trade-off between computational efficiency and physical accuracy. This paper presents a novel Local Linear Corotated Finite Element Method that addresses this challenge through a hybrid strategy combining direct and iterative solvers. Our method decomposes the simulation domain into element groups; the dynamics within each group are resolved using a pre-computed direct method, while inter-group interactions are handled by efficient iterative constraints. This domain decomposition enables significant pre-computation, replacing runtime equation solving with fast matrix-vector multiplications. Experimental results demonstrate that the method achieves a better balance of speed and accuracy, demonstrating higher fidelity than similarly fast methods. The method supports anisotropic materials and achieves low volume change (2.95% error) under nearly incompressible conditions. Furthermore, its group-based architecture exhibits high scalability on multi-core processors, reducing computation time to 19.6 ms for a 120,000-tetrahedron model using 64 threads. These characteristics make our method well-suited for demanding applications such as surgical simulation, haptic feedback systems, and real-time digital twins, where both accuracy and performance are critical.},
  archive      = {J_ACCESS},
  author       = {Siyu Wang and Yunxiu Xu and Shoichi Hasegawa},
  doi          = {10.1109/ACCESS.2025.3616629},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Group-based corotational FEM for real-time large deformation simulation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). XAI-SkinCADx: A six-stage explainable deep ensemble framework for skin cancer diagnosis and risk-based clinical recommendations. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3616738'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fastest growing and deadliest cancer, skin cancer, requires diagnostic solutions that are accurate, understandable, and therapeutically actionable. Our six-stage deep ensemble diagnostic framework, XAI-SkinCADx, employs hybrid feature extraction, deep learning ensembles, understandable AI, and clinical recommendation creation to meet this need. The 2367 dermoscopy images belonging to nine distinct classes of the ISIC skin cancer dataset are used to train the framework. Adding 5,023 new images makes the dataset richer and better balanced across the classes. A comprehensive performance evaluation is ensured by using the dataset with an 80:20 train-data/test-data split. It begins with hand-designed feature extraction using GLCM-based dimensionality reduction and visualization and Local Binary Patterns (LBP) visualization. Three convolutional neural networks are then employed to extract specific spatial features: DV-25 (DenseNet201 + VGG16), DE-25 (DenseNet201 + EfficientNetB5), and DM-25 (DenseNet201 + MobileNetV2). Temporal patterns are described with bidirectional long-short-term memory (BiLSTM) and finally classified with multiclass SVM. The accuracy is 95.63%, precision is 96.2%, recall is 95.7%, F1 score is 95.9%, and area under curve is 0.97. We interpret it using Grad-CAM++ and LIME. Compared to Grad-CAM++, LIME had better localization accuracy (IoU: 0.78, Dice: 0.87) while Grad-CAM++ had worse accuracy (IoU: 0.70, Dice: 0.81). The best performing classes with LIME interpretability, Vascular Lesion, Seborrhoeic Keratosis, and Dermatofibroma, respectively, with Dice scores of 0.91, 0.89, and 0.87 respectively. For providing patients with personalized suggestions independent of other information, a dermatology-focused LIME-based recommendation platform was designed. The timely dermatology consultation and decreased clinical burden are led by the classification by the system of the disorders as low-risk, medium-risk, and high-risk. By integrating accuracy, clarity, and utility, XAI-SkinCADx creates a new benchmark for applying AI in the diagnosis of skin disease, enabling physicians to make well-informed and trusted decisions.},
  archive      = {J_ACCESS},
  author       = {Akella S Narasimha Raju and G. Sujatha and Ranjith Kumar Gatla and Shilpa Ankalaki and Geetabai S Hukkeri},
  doi          = {10.1109/ACCESS.2025.3616738},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {XAI-SkinCADx: A six-stage explainable deep ensemble framework for skin cancer diagnosis and risk-based clinical recommendations},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A robust integrated control framework for trajectory tracking of the distributed drive autonomous electric vehicles. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3616936'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of coordinated control for autonomous electric vehicles has attracted many attentions in the literature. However, the controllers employing four independent torque and brake, and active front steering actuators still need more investigation. In this paper, an integrated control structure is proposed to navigate the autonomous vehicle in trajectory tracking task at high speeds. A kinematic-based approach is introduced to estimate the longitudinal forces of each wheel. The steering angle is designed based on a robust sliding mode control, which is responsible for the convergence of the lateral errors to zero. The proof of stability for both longitudinal and lateral controllers in the integrated framework are provide based on the Lyapunov’s stability theorem. Finally, a co-simulation is performed in MATLAB/Simulink and Carsim software to appraise the performance of the control system. The results show that the control method is able to perform the trajectory tracking in high-speed lane change. Additionally, the proposed control system performs better in terms of maximum amplitude of errors and root mean square of errors when compared to the results of other research. Furthermore, the proposed robust control framework shows promising results in the presence of external disturbance and parametric uncertainties.},
  archive      = {J_ACCESS},
  author       = {Hamid Rahmanei and Abbas Aliabadi and Ali Ghaffari and Shahram Azadi},
  doi          = {10.1109/ACCESS.2025.3616936},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {A robust integrated control framework for trajectory tracking of the distributed drive autonomous electric vehicles},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Time-evolving fairness and accuracy in recommendation systems: A stereotype-based framework for addressing trade-offs. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3616855'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent research has raised critical concerns about how offline evaluations of recommender systems (RS) are conducted, particularly regarding issues such as data leakage, temporal bias, and limited metric scope. When it comes to evaluation, the accuracy of recommendations and ranked lists offers a narrow view of the performance, usability, customer satisfaction, and risks of an RS. Among several other desirable properties of an RS, fairness has rightfully gained a prominent place in the research community. Trade-offs have been documented between conflicting metrics, but no work has addressed these as a dynamic time-varying properties. By proposing a novel experimental framework that models accuracy and fairness as evolving, non-static properties of RS, we aim to provide a new way of examining RS properties and present fresh evidence on trade-offs. The significance of this topic lies in its implications for real-world deployment, where fairness across users and items, especially in multi-stakeholder contexts, changes over time and must be balanced with predictive accuracy. By re-framing fairness using stereotype-based control groups, we enable more nuanced and dynamic assessments. We apply this framework across multiple real-world datasets (e.g., MovieLens+IMDb, Amazon), simulating user and item cold-start scenarios in a walk-forward evaluation setup. The results highlight the complex trade-offs between competing metrics and offer actionable insights for the design of fairer, more robust recommender systems.},
  archive      = {J_ACCESS},
  author       = {Nourah A. AlRossais},
  doi          = {10.1109/ACCESS.2025.3616855},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Time-evolving fairness and accuracy in recommendation systems: A stereotype-based framework for addressing trade-offs},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advancements in material decomposition techniques for spectral CT: A comparative analysis of traditional and AI-driven methods. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3616950'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Material Decomposition (MD) in Computed Tomography (CT) imaging is undergoing a significant transformation as it shifts towards the integration of Machine Learning (ML) and Artificial Intelligence (AI) frameworks. The combination of spectral (multi-energy) CT and AI-based MD techniques have the potential to enhance the management of MD-related tasks in terms of diagnostic efficiency, accuracy, and early diagnosis at high spatial resolution. Despite the challenges posed by patient exposure to ionizing radiation, image noise, and image distortions caused by artifacts, AI-based medical diagnostic techniques show great promise for the development of intelligent MD systems. In this article, we provide a comprehensive and categorized review and analysis of traditional MD and modern AI-based MD techniques for both the image and projection domains. We highlight each approach’s distinctive features, advantages, and disadvantages, as well as the intrinsic features and critical attributes of the AI-based MD techniques. Finally, we conclude by presenting key observations and laying a strong foundation for future research to design and implement AI-based MD techniques. Our aim is to provide a comprehensive understanding of the current state of the field and to encourage further exploration of this exciting and rapidly evolving area.},
  archive      = {J_ACCESS},
  author       = {Naveed Ilyas and Farhat Naseer and Osama Sikander Khan and Hamza Ilyas and Osama Bin Yaqoob and Abderaouf Behouch and Saiqa Sagheer and Moid Sandhu and Mohsin Raza Jafri and Aamir Raja},
  doi          = {10.1109/ACCESS.2025.3616950},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Advancements in material decomposition techniques for spectral CT: A comparative analysis of traditional and AI-driven methods},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A sacrificial porous silicon layer-based resistive chemical vapor sensor. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3616777'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, a resistive gas sensor based on a sacrificial porous silicon layer was fabricated and investigated for its capability to detect various volatile organic compounds (VOCs) at room temperature. The porous structure was formed via electrochemical anodization of low-resistivity p-type crystalline silicon and was subsequently detached from the substrate to form the sensor structure. Interdigitated aluminum electrodes were deposited on the surface of borosilicate glass to enable electrical measurements, and then the porous silicon layer was transferred onto the aluminum IDE. The sensor exhibited repeatable and reversible responses to a range of VOCs including acetone, methanol, ethanol, 2-propanol, 1-butanol, and n-heptane. Among these, acetone produced the highest response (Ig/Ia = 2.2), at the highest concentration (7700 ppm), correlating with its high polarity. Notably, the sensor exhibited an atypical increase in current upon VOC exposure at room temperature, which was attributed to surface-state passivation and dielectric modulation effects within the electrically isolated porous matrix. However, this effect reversed at temperatures above approximately 60°C, where the sensor displayed conventional p-type behavior marked by a decrease in current under reducing gas exposure. These findings demonstrate that structurally isolated porous silicon layers can serve as effective platforms for low-power VOC detection at room temperature, with their sensing behavior strongly influenced by surface interactions, temperature, and analyte properties.},
  archive      = {J_ACCESS},
  author       = {T. Seven and O. Coban},
  doi          = {10.1109/ACCESS.2025.3616777},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {A sacrificial porous silicon layer-based resistive chemical vapor sensor},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Domain-adaptive full-face gaze estimation via novel-view-synthesis and feature disentanglement. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3616770'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Along with the recent development of deep neural networks, appearance-based gaze estimation has succeeded considerably when training and testing within the same domain. Compared to the within-domain task, the variance of different domains makes the cross-domain performance drop severely, preventing gaze estimation deployment in real-world applications. Among all the factors, the ranges of head pose and gaze are believed to play significant roles in the final performance of gaze estimation, while collecting large ranges of data is expensive. This work proposes an effective model training pipeline consisting of a training data synthesis and a gaze estimation model for unsupervised domain adaptation. The proposed data synthesis leverages the single-image 3D reconstruction to expand the range of the head poses from the source domain without requiring a 3D facial shape dataset. To bridge the inevitable gap between synthetic and real images, we further propose an unsupervised domain adaptation method suitable for synthetic full-face data. We propose a disentangling autoencoder network to separate gaze-related features and introduce background augmentation consistency loss to utilize the characteristics of the synthetic source domain. Through comprehensive experiments, it shows that the model using only our synthetic training data can perform comparably to real data extended with a large label range. Our proposed domain adaptation approach further improves the performance on multiple target domains. The data are available at https://github.com/ut-vision/Gaze-NV-Rendering.},
  archive      = {J_ACCESS},
  author       = {Jiawei Qin and Takuru Shimoyama and Xucong Zhang and Yusuke Sugano},
  doi          = {10.1109/ACCESS.2025.3616770},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Domain-adaptive full-face gaze estimation via novel-view-synthesis and feature disentanglement},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-teacher guided denoising distillation for anomaly detection. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3616789'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, knowledge distillation-based approaches have demonstrated efficacy in unsupervised anomaly detection. These methods typically compute pointwise feature discrepancies between teacher and student (T–S) to localize anomalies. However, this paradigm suffers from two issues that degrade performance: (1) some normal regions exhibit large feature differences between T-S networks (leading to false detections), while (2) certain anomalous regions produce small differences (causing missed detections). To address this, we propose a Dual-Teacher Guided Denoising (DTGD) distillation framework that reformulates anomaly detection as a noise-removal task, where anomalies are treated as noise. Specifically, the DTGD framework includes a normal teacher, an anomaly teacher, and a denoising encoder-decoder student. The normal teacher encodes pristine normal data, and the anomaly teacher captures potential anomaly features from synthetic anomalies, guiding the student network to retain normal features and expel noise. After each encoder block of the student, our teacher-guided noise removal (TNR) module injects knowledge from the anomaly teacher, explicitly teaching the student which features to preserve. Furthermore, consistency loss and dissimilarity loss functions enforce consistency with the normal teacher in both encoder/decoder outputs and increase dissimilarity of anomaly-related features from the anomaly teacher via pixel-wise supervision. Experiments on anomaly detection datasets demonstrate that DTGD achieves advanced localization accuracy and produces sharper anomaly maps, reducing both false positives and false negatives.},
  archive      = {J_ACCESS},
  author       = {Ning Li and Ajian Liu and Chaohao Jiang and Suigu Tang and Yongze Li and Yanyan Liang},
  doi          = {10.1109/ACCESS.2025.3616789},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Dual-teacher guided denoising distillation for anomaly detection},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CSD: Channel selection dropout for regularization of convolutional neural networks. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3616631'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we present a novel approach, Channel Selection Dropout (CSD), designed to regularize deep convolutional neural network (CNN) architectures. Unlike standard Dropout, which randomly deactivates neurons in fully connected layers, CSD works on the image channels within the sequence of convolutional layers. Specifically, CSD is composed of three modules, i.e., Channel Process Module, Channel Drop Module, and Scale Module. CSD primarily emphasizes channels to identify significant channels based on activation values. It preserves channels that possess values above a user-defined threshold α. Channels that are less significant are set to a value of zero. CSD does not add any extra expenses during the CNN architecture training phase. It is used only during training and deployed only at a minimal computational cost. In the testing phase, the network retains its original state, resulting in no added expenses for inference. Moreover, CSD integration into current networks does not require re-pretraining on ImageNet. This makes it fit seamlessly with other datasets. Finally, the performance of CSD with ResNet-18, ResNet-50, and VGGNet-16 is experimentally evaluated across multiple datasets. Our results demonstrate that setting α= 0.60 significantly enhances performance, with most results reaching over 95% accuracy on the benchmark datasets. However, the performance of α may vary, and it can be adjusted based on the specific dataset and architecture used. The comprehensive results clarify that CSD consistently enhances performance over the baselines. This method can be applied in future CNN applications to mitigate overfitting, particularly in image segmentation, Vision Transformers (ViT), and medical imaging.},
  archive      = {J_ACCESS},
  author       = {Imrus Salehin and Dae-Ki Kang},
  doi          = {10.1109/ACCESS.2025.3616631},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {CSD: Channel selection dropout for regularization of convolutional neural networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Accelerating first-order secure ML-KEM with masked SHA-3: Cost, randomness, and security evaluation. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3616775'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hash functions are fundamental for ensuring authenticity and integrity in digital communications. Their importance has grown with the advent of Post-Quantum Cryptography (PQC), as many newly standardized PQC algorithms, such as ML-KEM, heavily rely on hash functions for pseudo-random number generation. Among available standards, SHA-3, published by NIST in 2015, is the recommended choice for PQC applications. However, its adoption in embedded platforms remains limited, particularly in the presence of security threats such as side-channel attacks (SCAs). To mitigate SCAs, masking techniques are widely employed, but their implementation on SHA-3 accelerators is complex due to the non-linearity of the Keccak function. Domain-Oriented Masking (DOM) provides strong security guarantees but requires a significant amount of randomness, introducing additional implementation costs often overlooked in the literature. For instance, existing DOM implementations of Keccak demand 1600 bits of fresh randomness per clock cycle, raising practical concerns about randomness generation and deployment overhead. In this work, we present a hardware accelerator supporting all the SHA-3 functions with first-order masking countermeasure based on a DOM implementation of the Keccak core. For the generation of the randomness required by the DOM countermeasure, we implemented a randomness dispatcher based on Trivium and Bivium ciphers, and we evaluated the cost in terms of area of the circuit in FPGA and ASIC of the countermeasure and of the randomness generation. In addition, we assess its security through Test Vector Leakage Assessment on FPGA. Finally, the accelerator is integrated into a RISC-V-based 32-bit SoC and used to accelerate a first-order masked implementation of ML-KEM, achieving a speed-up ranging from 95x to 264x for the SHA-3-based functions of the KEM decapsulation.},
  archive      = {J_ACCESS},
  author       = {Stefano Di Matteo and Diamante Simone Crescenzo and Rafael Carrera Rodriguez and Emanuele Valea and Florent Bruguier and Pascal Benoit},
  doi          = {10.1109/ACCESS.2025.3616775},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Accelerating first-order secure ML-KEM with masked SHA-3: Cost, randomness, and security evaluation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fed-CALiBER: Federated lightweight BERT intrusion detection on CAN bus protocol in autonomous vehicle. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3616784'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in autonomous vehicle (AV) technology have highlighted critical cybersecurity vulnerabilities within In-Vehicle Networks (IVNs), particularly the Controller Area Network (CAN) bus. While numerous Intrusion Detection Systems (IDS) exist, significant gaps remain in addressing resource efficiency and the challenge of Non Independent and Identically Distributed (Non-IID) data in distributed vehicular environments. This study proposes Fed-CALiBER, a novel framework that synergistically combines a compact, pre-trained Lightweight BERT model with a Federated Learning (FL) architecture. By training collaboratively on distinct datasets assigned to Raspberry Pi edge clients, our approach preserves data privacy by keeping raw data localized and is explicitly designed to enhance generalization across Non-IID data distributions. With a reduced communication overhead by transmitting a small parameter footprint (approx. 13 MB) during federated updates, Fed-CALiBER minimizes network overhead during parameter aggregation. Our two-cycle experimental results demonstrate that the federated global model significantly outperforms standalone models in cross-dataset generalization—improving F1-scores on unseen datasets from as lowas 71.39% to over 96.59%—and successfully adapts to shifting data distributions. The framework is validated as a practical edge solution, achieving real-time inference (3–4 ms per sample) with low computational overhead on Raspberry Pi clients, representing a lightweight edge client.},
  archive      = {J_ACCESS},
  author       = {Hamman A. Bimmo and Budi Rahardjo},
  doi          = {10.1109/ACCESS.2025.3616784},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Fed-CALiBER: Federated lightweight BERT intrusion detection on CAN bus protocol in autonomous vehicle},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic heuristic optimisation in high-order runge-kutta schemes using reinforcement learning and genetic algorithms. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3616741'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a hybrid optimisation framework that integrates Genetic Algorithms (GAs) and Reinforcement Learning (RL) for the construction of high-order Runge–Kutta (RK) schemes. Such schemes underpin accurate and efficient time integration in computational science and engineering, with applications ranging from fluid dynamics and chemical kinetics to orbital mechanics and neural ODEs. Traditional optimisation of RK coefficients with interior-point solvers becomes increasingly infeasible as stage counts grow, due to the rapid increase in parameters and the highly nonconvex nature of the feasible region. Our approach addresses this by introducing dynamic algebraic heuristics that contract the search space through symbolic relations among coefficients. GA provides global exploration via mutation, while RL adaptively refines candidate heuristics based on reward signals, guiding optimisation towards stable regions while strictly enforcing order conditions. Empirical studies on third-order Extended-Stability Runge–Kutta (ESRK) schemes show reductions in Interior point optimiser (IPOPT) iteration counts of up to 36.7% for a-coefficients, with additional improvements of 32.5% and 24.5% for b- and c-coefficients. Statistical validation using t-tests and ANOVA confirms the significance of these improvements. Symbolic verification demonstrates that the discovered heuristics generalise across stage counts, maintaining full rank of the order-condition Jacobians and preserving third-order accuracy. Benchmark tests on Ordinary Differential Equations (ODE) and Partial Differential Equations (PDE) systems, including the Brusselator, confirm both expected convergence and efficiency gains. These results establish GA–RL-guided optimisation as a scalable, robust methodology for designing advanced RK integrators, with potential to extend stability-optimised schemes to both classical simulations and modern machine learning contexts.},
  archive      = {J_ACCESS},
  author       = {Gavin-Lee Goodship and Stephen O’Sullivan and Luis Miralles-Pechuán},
  doi          = {10.1109/ACCESS.2025.3616741},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Dynamic heuristic optimisation in high-order runge-kutta schemes using reinforcement learning and genetic algorithms},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Topology and energy aware approximate algorithm for QoS-based resource slicing in 5G core networks. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3616851'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a multi-objective optimization framework for network function virtualization (NFV) resource assignment in 5G core networks, targeting the minimization of both resource cost and server energy consumption subject to stringent quality of service (QoS) constraints for diverse services. This problem considers the assignment of CPU and bandwidth resources to servers and links, subject to network resource constraints. Given the dynamic nature of 5G core networks, where bandwidth and CPU processing demands fluctuate due to time-varying demand, user mobility, diverse QoS requirements, potential link failures, server outages, and the coexistence of multiple virtual networks (VNs), a dynamic resource assignment strategy is adopted in this work as opposed to static approaches in previous works. The majorization-minimization approach is used to handle the resulting mixed integer nonlinear programming problem, and an approximation-based algorithm for core network resource assignment (ACNRA) with an affordable computational complexity is proposed. The simulation results demonstrate the effectiveness of the proposed algorithm in reducing both network resource costs and server energy consumption. Statistical analysis of these results shows that our proposed method outperforms benchmark algorithms, achieving average reductions of 5.92% and 10.28% in resource cost, and 5.43% and 10.10% in energy consumption.},
  archive      = {J_ACCESS},
  author       = {Ehsan Sargolzaei and Mehdi Rasti and Siavash Khorsandi},
  doi          = {10.1109/ACCESS.2025.3616851},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Topology and energy aware approximate algorithm for QoS-based resource slicing in 5G core networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An integrated risk assessment framework for construction sites using pythagorean fuzzy AHP and Classic/Fuzzy fine-kinney method. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3616616'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The construction industry demonstrates heightened occupational hazard exposure due to the confluence of multifaceted operational processes, variable workplace dynamics, and statistically significant accident occurrence rates. Effective risk assessment is therefore critical for improving workplace safety and guiding preventive actions. This study proposes an integrated risk assessment framework that combines the classical and fuzzy Fine-Kinney methods with the Pythagorean Fuzzy Analytic Hierarchy Process (PFAHP). The key contributions are: (i) identification of 26 hazards across four operational areas (office, storage, transportation, and pressure testing), (ii) incorporation of activity-specific weights using PFAHP, and (iii) comparative evaluation of classical vs. fuzzy Fine-Kinney scores. The results demonstrate that fuzzy-based evaluations significantly change hazard rankings (e.g., office fire hazard moved from 8th to 2nd), while PFAHP weighting shifts the relative importance of operational domains. These findings highlight the advantages of combining uncertainty modeling and activity-based weighting to achieve more context-aware risk prioritization. The proposed method provides a practical and scalable framework for occupational health and safety risk evaluation in high-risk industries.},
  archive      = {J_ACCESS},
  author       = {Mustafa Demirbilek and Sevim Özulukale Demirbilek},
  doi          = {10.1109/ACCESS.2025.3616616},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {An integrated risk assessment framework for construction sites using pythagorean fuzzy AHP and Classic/Fuzzy fine-kinney method},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Preventing witness leakage in adaptor signatures. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3616813'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adaptor signature schemes allow two parties to trade fairly. When a valid signature is revealed, the secret witness can also be extracted. This is useful in blockchain settings such as atomic swaps and fair exchange. However, if an adversary obtains both the pre-signature and the full signature, they can extract the witness. To fix this, we introduce a secret value aux into the extract algorithm. Only those who know aux can extract the witness. We also find that the adaptor algorithm must use aux to remain secure. In a fair exchange, the buyer extracts the witness, and the seller runs the adaptor algorithm. Since both parts need aux, both parties must share it. The auxiliary secret aux can be shared using various methods such as non-interactive key exchange (NIKE), interactive key exchange (IKE), and key encapsulation mechanism (KEM). We show that our scheme is aEUF-CMA secure, allows witness extraction only with the shared secret aux, and introduces a new property called witness hiding, which ensures the witness remains hidden without aux. Our contributions are: (1) We show that adaptor signatures can leak the witness if both the pre-signature and full signature are seen, (2) We fix this by adding a shared secret aux that only the right party knows, (3)We define and prove a new security idea called witness hiding, and (4)We give an example using Schnorr signatures and show how to share aux using simple methods like NIKE.},
  archive      = {J_ACCESS},
  author       = {Hsu Jen-Chieh and Tso Raylin},
  doi          = {10.1109/ACCESS.2025.3616813},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Preventing witness leakage in adaptor signatures},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bridging system development perspectives and quantitative analysis of user adoption in educational information systems. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3616630'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sustaining digital platform adoption in computer science requires both robust system design and quantitative evaluation of user behavior and system performance. System Quality (SQ) encompassing reliability, responsiveness, security, and usability, is a critical determinant of adoption. However, most studies grounded in the Technology Acceptance Model (TAM) and Task–Technology Fit (TTF) have overlooked objective SQ metrics and the moderating influence of Digital Skills (DS). This study introduces the Digital Educational Systems Adoption Framework (DESAF), which integrates TAM, TTF, and DS to analyze adoption of the Graduate Academic Information System Services (GAISS). A mixed-method design combined three years of Microsoft IIS server log data (2022–2024) with 550 user survey responses. SQ was quantified through request volumes, response times, error rates, and downtime, and analyzed alongside behavioral constructs using structural equation modeling in SmartPLS 4. Results indicate that SQ strongly predicts DS (β = 0.416, p < 0.001) and actual system use (β = 0.251, p < 0.001), while DS significantly enhances perceived ease of use, usefulness, satisfaction, and actual use (β = 0.151, p < 0.001), confirming its dual role as both predictor and moderator. System performance improved substantially as average response times decreased from 526 ms to 305 ms and downtime from 3.67% to 2.86%, while annual requests rose from 155,000 to 966,000. Yet, feature expansion increased error rates to 14.88%, highlighting a trade-off between performance and complexity. The validated DESAF model advances computer science by bridging software performance engineering and behavioral modeling, offering an evidence-based framework for adaptive, user-centered platforms sustained through longitudinal performance monitoring.},
  archive      = {J_ACCESS},
  author       = {Paniti Netinant and Sorapak Pukdesree and Meennapa Rukhiran},
  doi          = {10.1109/ACCESS.2025.3616630},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Bridging system development perspectives and quantitative analysis of user adoption in educational information systems},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The role of nature-based solutions in improving temperature and noise-related comfort in compact urban areas. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3616791'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Urban areas are increasingly affected by environmental stressors such as elevated temperatures and excessive noise, which compromise the usability of public spaces. Nature-based solutions (NBS) are gaining recognition as context-sensitive interventions to mitigate such issues, yet their effective implementation, especially in compact urban areas, depends on specific spatial and morphological conditions. This study evaluates the spatial feasibility of four NBS types: green roofs, vertical greenery, and natural terrain with high or low vegetation across four pilot streets in Ljubljana, each representing a distinct urban typology. Using high-resolution environmental data and discomfort analysis (Ravnikar et al., in press), we developed spatial suitability criteria based on a targeted literature review and technical guidelines. These were operationalised in a GIS-based overlay analysis to identify feasible implementation sites. The results confirm that spatial constraints such as limited open space, unfavourable façade orientation, and underground infrastructure—often restrict the capacity of NBS to deliver meaningful improvements. While some interventions are feasible, their impact remains fragmentary, highlighting the need to consider spatial and technical requirements from the earliest planning stages. Proactive integration of NBS into spatial development is essential to move beyond isolated interventions and achieve systemic environmental benefits.},
  archive      = {J_ACCESS},
  author       = {Živa Ravnikar and Alfonso Bahillo and Barbara Goličnik Marušić},
  doi          = {10.1109/ACCESS.2025.3616791},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {The role of nature-based solutions in improving temperature and noise-related comfort in compact urban areas},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). From systematic to intelligent: Assessing AI-empowered optimization techniques for analog building block sizing. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3616647'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a comprehensive, design-insight-based comparison between an artificial intelligence (AI)-empowered optimization-based analog building block sizing framework and the conventional manual design methodology. Although recent AI-empowered approaches are showing high performance, conventional systematic manual design methods such as the gm/ID-based sizing are still the most widely used methods in the analog IC design community. This raises the necessity of the comprehensive comparative analyses between the two kinds of methods. To fill this gap, this paper compares the optimal designs obtained by a typical method of the former with those obtained by the latter method in the literature/industry. Four case studies, including a comparator, an amplifier (both standard and low power design), and an oscillator, using technology nodes ranging from 0.35 μm to 65 nm, are presented. Detailed performance evaluations and design insights are presented for each case study, with silicon validation provided for three designs. Our findings highlight that AI-empowered sizing not only meets but often surpasses conventional designs in key performance metrics, while still benefiting from designer interaction to align with design intents.},
  archive      = {J_ACCESS},
  author       = {Yijia Hao and Miguel Gandara and Srinjoy Mitra and Maarten Strackx and Sandy Cochran and Francisco V. Fernandez and Shaolan Li and Bo Liu},
  doi          = {10.1109/ACCESS.2025.3616647},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {From systematic to intelligent: Assessing AI-empowered optimization techniques for analog building block sizing},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new image sharpening filter based on gradient and retinex-inspired contrast. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3617230'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image edges are essential for understanding and processing the content of the acquired scene, but a clear edge detection is not always possible. Unfavorable environmental conditions, poor lighting, incorrect camera settings and/or vibrations may produce blurry or dark images with unclear content and details. Local spatial filters are integrated into many hardware and software as sharpening tools, but choosing the most adequate filter and its parameters is usually non trivial. This work proposes a new filter, whose kernel is computed by comparing over a pre-defined window the image Prewitt gradient with an image contrast measure inspired by Retinex theory. The experiments, carried out on public real-world images with different edge visibility, show that the proposed image-aware filter efficaciously increases the edge visibility with low computational cost and performs better than a standard Laplacian filter. As an usage example, the sharpening filter is here applied to medical images of retinal fundus: improving the clarity and detail of these images is essential for visualizing and analysing anatomical structures, identifying abnormalities, and assisting in diagnosis and treatments. Finally, a hardware architecture of the sharpening filter, partially integrating on-chip the gradient and contrast computation, is outlined. Such an integration could be beneficial for enhancing in real-time the quality of pictures captured by devices with limited power resources, with an average consumption of ∼ 28 μW and ∼ 30 kb of embedded memory in case of a color VGA image. The data obtained in filter validation experiments show a marked increase in the Prewitt’s gradient magnitudes in 100% of cases and in the edge thickness in a percentage ranging from 73.3% to 100% of cases, without visibly affecting the image naturalness.},
  archive      = {J_ACCESS},
  author       = {Michela Lecca and Massimo Gottardi and Paola Lecca},
  doi          = {10.1109/ACCESS.2025.3617230},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {A new image sharpening filter based on gradient and retinex-inspired contrast},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing self-supervised autoencoders for IoT sensor data using memory-augmented adaptive simulated annealing. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3617338'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of the Internet of Things (IoT) has given rise to unprecedented volumes of unlabeled sensor data due to its constantly evolving nature. This phenomenon has created an acute need for learning models capable of intelligently use such data devoid of expensive manual labeling. Self-Supervised Learning (SSL) has recently arisen as an efficient paradigm to meet this challenge by directly deriving informative representations from unlabeled data. Nevertheless, the practical application of SSL models is hindered by their over-dependence on hyperparameter tuning, which remains a central challenge. In addressing this challenge, we introduce an MA-ASA (Memory-Augmented Adaptive Simulated Annealing) framework for hyperparameter tuning that has been optimized to this specificity. This framework is built on the concepts of temperature-adaptive mechanisms, short-term memory buffers to mitigate repetitive evaluations, and stagnation-initiated restarts, offering greater efficiency in dealing with hyperparameter space complexities. The proposed method employs a two-step framework consisting of denoising convolutional autoencoder (dCae) SSL pretraining on unlabeled data and logistic regression downstream classification on sparse labeled data. The approach was tested on UCI HAR, MHEALTH, and Environmental Sensor Telemetry datasets achieving classification accuracies of 96.00%, 97.33%, and 99.25%, respectively. The results showcase that the MA-ASA-based optimization strategy improves the performance and generalization of SSL models relative to other IoT domains, all while retaining computational efficiency and scalability.},
  archive      = {J_ACCESS},
  author       = {Mohammed Majid Abdulrazzaq and Nehad T. A. Ramaha and Alaa Ali Hameed},
  doi          = {10.1109/ACCESS.2025.3617338},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Optimizing self-supervised autoencoders for IoT sensor data using memory-augmented adaptive simulated annealing},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gaze data imbalance: An overlooked challenge in appearance-based gaze estimation. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3617076'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data imbalance exists in appearance-based gaze estimation datasets, hurting the model’s generalizability and fairness. Unfortunately, this aspect is usually overlooked, and researchers focus mainly on developing more and more sophisticated gaze estimation neural networks. In this work, we identify two types of imbalance in gaze estimation data. The first is related to the uneven distribution of ground truth gaze vectors, and the second one comes from the uneven ethnicity distribution of dataset participants. We prove the negative impact of both of them on the model’s generalizability. Therefore, we propose Uniform Gaze Sampling and Uniform Ethnicity Sampling, simple yet effective re-sampling techniques tailored for gaze estimation. Moreover, we introduce balanced metrics, i.e., Balanced Gaze Error and Balanced Ethnicity Error, for a fair performance evaluation. Finally, we demonstrate the usefulness of the proposed methods and metrics on four benchmarks. To the best of our knowledge, we are the first to address data imbalance in gaze estimation comprehensively.},
  archive      = {J_ACCESS},
  author       = {Jan Glinko},
  doi          = {10.1109/ACCESS.2025.3617076},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Gaze data imbalance: An overlooked challenge in appearance-based gaze estimation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SignForensics: A robust framework for forensic offline signature verification with enhanced detection, noise removal, and multi-stage authentication. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3617221'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reliable signature authentication is essential across fields where identity verification is critical. Despite advances in machine learning, validating handwritten signatures remains challenging due to inherent variability in individual writing styles. Most current methods focus exclusively on verification, assuming signatures are already isolated and noise-free—an assumption rarely met in real-world scenarios. In this paper, we present a comprehensive framework called SignForensics for robust signature authentication, directly extracting and refining signatures from real-world documents. Our system employs YOLOv10 for signature detection and extraction, and leverages CycleGAN to effectively remove residual visual noise, producing noise-free samples optimized for downstream analysis. To evaluate authenticity, we developed specialized SigNet and CapsNet neural networks, achieving strong generalization and accuracy. Our method outperforms current state-of-the-art techniques, reaching 100% accuracy on the CEDAR dataset, 94.79% on the HINDI dataset, and 96.52% on the BENGALI dataset, remaining robust across writer-independent settings and previously unseen samples.},
  archive      = {J_ACCESS},
  author       = {Giovanni Piccinini and Luca Guarnera and Sebastiano Battiato},
  doi          = {10.1109/ACCESS.2025.3617221},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {SignForensics: A robust framework for forensic offline signature verification with enhanced detection, noise removal, and multi-stage authentication},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A self-adaptive intrusion detection system for zero-day attacks using deep Q-networks. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3617792'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-day attacks remain among the most formidable threats to modern cybersecurity, exploiting undisclosed vulnerabilities that bypass conventional detection mechanisms. In this paper, we propose a self-learning intrusion detection system (IDS) based on Deep Q-Networks (DQNs), a reinforcement learning approach capable of autonomously classifying network traffic without dependence on predefined signatures or labeled training data. Leveraging the UGRansome dataset, the model is evaluated under two experimental scenarios: a conventional random split and a more rigorous zero-day split, where ransomware families in the test set are entirely excluded from training. In binary classification, the proposed system achieves 97.6% accuracy (F1-score: 0.98) in the random split and 95.9% accuracy (F1-score: 0.96) in the zero-day setup, consistently prioritizing high recall for ransomware detection. In multiclass classification, it attains 97.0% and 92.0% accuracy in the random and zero-day splits, respectively. These results underscore the potential of reinforcement learning as a robust and adaptive foundation for real-time intrusion detection in evolving threat landscapes.},
  archive      = {J_ACCESS},
  author       = {Mouhammd Alkasassbeh and Ebtehal H. Omoush and Mohammad Almseidin and Amjad Aldweesh},
  doi          = {10.1109/ACCESS.2025.3617792},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {A self-adaptive intrusion detection system for zero-day attacks using deep Q-networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A roadmap towards neurosymbolic approaches in AI design. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3617771'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neurosymbolic Artificial Intelligence (NS-AI) integrates two central paradigms in artificial intelligence (AI). The first is connectionist (or sub-symbolic) AI, which enables scalable and efficient statistical learning. The second is symbolic reasoning, which provides formal reasoning and explainability. This study conducted a systematic review of NS-AI architectures published between 2013 and 2024, synthesizing the structural patterns and integration strategies in 319 peer-reviewed publications. From this corpus, 18 representative approaches were selected based on their methodological rigor, symbolic fidelity, and conceptual novelty. These approaches were subsequently classified into three architectural paradigms: Sequential, Multi-Integration, and Hybrid. Based on this classification, a five-stage symbolic integration framework is proposed, comprising (i) data preprocessing, (ii) neural–symbolic embedding, (iii) incorporation of domain knowledge, (iv) logical reasoning modules, and (v) symbolic postprocessing. The findings indicate that multistage symbolic integration, particularly when embedded within neural layers and reasoning components, improves system explainability, robustness, and semantic alignment. Comparative analysis further reveals a fundamental trade-off: architectures grounded in formal logic exhibit higher precision and verifiability, whereas those employing representational-symbolic languages yield greater interpretability and flexibility. The resulting generic architecture provides a modular design blueprint for future NS-AI systems, supporting scalable, transparent, and semantically grounded AI development.},
  archive      = {J_ACCESS},
  author       = {Prashani Jayasingha Arachchige and Bogdan Iancu and Johan Lilius},
  doi          = {10.1109/ACCESS.2025.3617771},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {A roadmap towards neurosymbolic approaches in AI design},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Low junction capacitance PIN and avalanche photodiodes in 180 nm CMOS. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3617104'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a comprehensive study of low-capacitance PIN photodiodes and avalanche photodiodes (APDs) implemented in 180 nm CMOS. The approach utilizes the dot-shaped cathode design to achieve hemispherical space-charge regions, effectively decoupling the photosensitive area from the junction capacitance and thus optimizing device performance for optical communication applications. Key device parameters—capacitance, bandwidth, light-sensitive area, and excess noise—are characterized and compared. All devices were fabricated on the same wafer for direct performance comparison. The presented dot-cathode photodiodes achieve significantly reduced total and normalized (per area) capacitance without compromising bandwidth compared to planar APDs. Among them, electric field line crowding (EFLC) based APDs demonstrate superior performance with the highest responsivity (0.4AW−1 @642 nm), lowest capacitance per area (1.58 aF μm−2), and low excess noise (F = 1.8 @ M = 10) with a bandwidth of 1.6 GHz. In contrast, the presented N+/P-well (NPPW) based APDs exhibit high excess noise making them unsuitable for data receiver applications. Notably, the only PIN device presented, uniquely operates in PIN mode with maximum bandwidth, while all other devices show reduced bandwidth unless they are operated in APD mode.},
  archive      = {J_ACCESS},
  author       = {Christoph Gasser and Seyed Saman Kohneh Poushi and Simon Michael Laube and Kerstin Schneider-Hornstein and Horst Zimmermann},
  doi          = {10.1109/ACCESS.2025.3617104},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Low junction capacitance PIN and avalanche photodiodes in 180 nm CMOS},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generating measurement-based synthetic received signal power data for 6G sub-terahertz research with micromobility and blockage. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3617323'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockage of propagation paths between the base station (BS) and user equipment (UE), as well as the micromobility of the UE, are known to be critical phenomena affecting the performance of 6G subterahertz/terahertz (sub-THz/THz, 0.1–0.3/0.3–3 THz) cellular systems. The development of functions that target the performance improvement of such systems requires understanding of the dynamics of the received signal. However, measurements of the signal received power (SRP) reported to date are limited to the blockage and micromobility phenomena in isolation. In this study, by utilizing individual measurements of blockage and micromobility processes, we propose a procedure for generating synthetic time series of the received signal strength simultaneously capturing blockage, micromobility, and beam-tracking procedures. Our results reveal that out of all the considered applications, only the most dynamic ones, racing game and VR, are characterized by significant differences between on-demand and regular beam tracking with 4-6.5 bits/Hz/s spectral efficiency degradation in the case of on-demand beam tracking as compared to the regular one. For applications with high-speed micromobility (VR watching and race gaming), the minimal beam tracking interval is 80 ms, whereas for low-speed applications, a period of 320 ms and even sometimes 1000 ms is sufficient. Our results show that the availability of information regarding the type of application allows one to decrease the overhead required for beam tracking by up to 20-30 times. The traces produced can be further utilized for various tasks, including the development of statistical tests for discriminating blockage and micromobility events, designing blockage detection algorithms, and improving beam tracking procedures. We made the data produced available to the research community.},
  archive      = {J_ACCESS},
  author       = {Vitalii Beschastnyi and Margarita Ershova and Darya Ostrikova and Vladislav Prosvirov and Alexander Shurakov and Yuliya Gaidamaka and Yevgeni Koucheryavy and Gregory Gol’tsman},
  doi          = {10.1109/ACCESS.2025.3617323},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Generating measurement-based synthetic received signal power data for 6G sub-terahertz research with micromobility and blockage},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Restricted bayesian lasso regression with inequality constraints. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3617498'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we investigate the utilization of the restricted Bayesian lasso regression, focusing on high-dimensional models that incorporate linear inequality constraints on the coefficients. The lasso technique, recognized for its effectiveness in variable selection and regularization, is further refined by embedding a Bayesian framework that integrates prior knowledge and addresses uncertainty in coefficient estimates. We examine subspace inequality constraints and outline the theoretical foundations of the restricted Bayesian lasso, including the formulation of prior distributions and the computational methods used to obtain posterior distributions. Through simulation studies and real-world data applications, we aim to illustrate the advantages of this methodology compared to traditional Bayesian lasso regression, with particular emphasis on enhancements in estimation accuracy, prediction performance, and variable selection efficiency.},
  archive      = {J_ACCESS},
  author       = {S. Seifollahi and M. Arashi and I. Al-Hasani},
  doi          = {10.1109/ACCESS.2025.3617498},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Restricted bayesian lasso regression with inequality constraints},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PlanTEA-WM: A multi-user web platform for routine planning and anticipating everyday situations in individuals with autism spectrum disorder. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3617152'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {PlanTEA-WM is an innovative web platform designed to enhance planning, anticipating and exposing anxiogenic situations for individuals with Autism Spectrum Disorder (ASD). Conceived as an evolution of the PlanTEA mobile application, this multi-user solution facilitates the creation of visual routines through pictograms, integrating Large Language Models (LLMs) to automate and simplify the routine-generation process. PlanTEA-WM offers essential functionalities such as a shared calendar, an invitation system for collaboration among families, educators, and therapists, and plan exportation in versatile formats like XML and PDF. To improve accessibility and collaborative use, PlanTEA-WM stores user data in a remote database, allowing real-time collaboration and access from multiple devices. The platform has been preliminarily evaluated in collaboration with specialized autism associations, with results indicating high usability, accessibility, and overall acceptance. These findings highlight its potential to foster autonomy in individuals with ASD and strengthen coordination within their support environments.},
  archive      = {J_ACCESS},
  author       = {José Lara and Carmen Lacave and Ana I. Molina},
  doi          = {10.1109/ACCESS.2025.3617152},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {PlanTEA-WM: A multi-user web platform for routine planning and anticipating everyday situations in individuals with autism spectrum disorder},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fuzzy linear programming formulation for time prediction in product delivery. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3617385'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The product delivery process is a set of steps to transport a product of an origin to a delivery point. Nowadays, there are different platforms or software based on classical algorithms for network optimization that help develop routes. Although these informatics systems provide vehicle routes, their prediction time has low accuracy compared to real times in the product distribution, since these systems do not consider the elements that affect route planning, i.e., despite providing vehicle routes, these software systems have low prediction accuracy. To address this problem, an alternative is to use artificial intelligence systems that consider the knowledge of the product delivery planning into route optimization models, thus increasing the time accuracy, but adding the challenge of having to interpret correctly the vehicle route ambiguities. Motivated by the latter, we propose a new fuzzy linear programming formulation to predict delivery times for products. Unlike previous studies, our methodology considers various parameters in the distribution process and offers an effective way to identify which parameters should be used. Our strategy combines the abstraction power of fuzzy logic and the result that provides a route optimization analysis, i.e., this work brings the best of the two worlds to address the difficult problem of shortest-route in product delivery. For that, our methodology has three steps. First, we introduce our formulation that incorporates a Fuzzy Inference System (FIS) into linear programming to achieve accurate time predictions in product delivery. Second, we propose a fuzzy adjustment coefficient to consider the uncertain factors in product distribution and the expertise of the delivery staff. Finally, we develop a Geographic Information System (GIS) to visualize the distribution route and its time. On the other hand, we evaluate this methodology in the routes of a soft drink company using statistical analyses. Experimental results are feasible and promising. For example, in real-world scenarios, our approach reduced the Mean Absolute Percentage Error (MAPE) by 56% compared to methods that utilize artificial intelligence.},
  archive      = {J_ACCESS},
  author       = {J. A. De Jesús Osuna-Coutiño and Elías Neftalí Escobar Gómez and Alejandro Medina Santiago and Abiel Aguilar-González and Madain Pérez-Patricio and Irvin Hussein Lopez-Nava},
  doi          = {10.1109/ACCESS.2025.3617385},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Fuzzy linear programming formulation for time prediction in product delivery},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inhalation motion analysis and visualization of error areas using two inertial measurement unit sensors. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3617064'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Asthma and chronic obstructive pulmonary disease (COPD) are common respiratory diseases, and proper use of inhalers is crucial for effective symptom management. However, many patients use their inhalers incorrectly. This study proposes a method for evaluating inhaler-use behavior by employing inertial sensors to monitor patients with bronchial asthma or COPD. By augmenting an Ellipta™ inhaler with inertial measurement units, this study evaluates patient inhalation motions using the acquired motion data. Compared with conventional methods, the proposed method is less affected by external factors such as ambient sound and temperature and can be applied outside clinical settings. The evaluation process uses a linear discriminant analysis algorithm to identify key characteristic variables associated with specific inhaler-use errors, and a judgment method using these variables is proposed. A dynamic programming matching algorithm is then applied to assess correctness. Experimental results indicate that the proposed method achieves high discriminant accuracy. By considering waveform similarity, it enables error visualization unlike contemporary methods. The proposed inhalation method and accompanying dataset offer valuable guidance for future research and practical feedback for patients.},
  archive      = {J_ACCESS},
  author       = {Shunya Takano and Atsushi Hasegawa and Tomoyuki Shimono and Katsunori Masaki and Hideo Nakada and Jun Hakamata and Hiroki Kabata and Jun Miyata and Koichi Fukunaga},
  doi          = {10.1109/ACCESS.2025.3617064},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Inhalation motion analysis and visualization of error areas using two inertial measurement unit sensors},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interference management in private 5G networks via interference source localization and radio environment map construction. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3617014'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Private 5G (P5G) networks are driving large-scale industrial and enterprise internet of things (IoT) deployments. However, uncoordinated P5G deployments can lead to unintended signal leakage and inter-network interference between neighboring P5G systems. Constructing a radio environment map (REM) is a practical way to visualize and manage such interference. It typically relies on spatially regular measurements, but drive-test-based data are often sparse and spatially irregular. Furthermore, since signal strength inherently includes path loss, the spatial distribution becomes non-stationary and unsuitable for direct interpolation under sparse and spatially irregular sampling conditions. Removing the path loss component requires knowledge of the interference source location, but the source location is generally unknown in real-world scenarios. To address these challenges, this paper proposes a measurement-based method to detect, localize, and map interference leakage. A novel localization algorithm is introduced to estimate the leakage source using only sparse and irregular measurements. The estimated source location enables decomposition of path loss and shadow fading, supporting accurate REM construction through spatial interpolation. Field measurements validate the effectiveness of the proposed approach in enabling interference diagnosis and providing spatial evidence aligned with regulatory requirements for safe coexistence between neighboring P5G networks.},
  archive      = {J_ACCESS},
  author       = {Kyung-Won Kim and Eun Sook Jin and Kyung-Yul Cheon and Hewon Cho and Hyeonsik Yoon and Hyeyeon Kwon and Seungkeun Park},
  doi          = {10.1109/ACCESS.2025.3617014},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Interference management in private 5G networks via interference source localization and radio environment map construction},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Application of ensemble method to predict individual pork prices using multi-source information. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3616969'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The role of pork in the food industry’s supply chain is crucial, and the price of pork has a significant impact on both consumers’ quality of life and the swine industry. Previous research has attempted to improve the accuracy of pork price trend predictions by incorporating various external factors and enhancing artificial neural networks. In contrast, this study aims to predict the auction price of individual pork, enabling real-time price predicting at the modern slaughterhouse. To achieve this, multi-source data were gathered, including the characteristics of individual pork and external factors influencing pork prices. This study proposes a stacking ensemble method that combines multiple machine learning and deep learning models, leveraging their diverse strengths to enhance overall performance and improve generalization to unseen data. The experimental results demonstrate that the proposed method not only achieves the lowest mean absolute percentage error of 3.262, but also accurately predicts individual pork prices and outperforms standalone machine learning and deep learning models across various scenarios.},
  archive      = {J_ACCESS},
  author       = {Kyungchang Jeong and Eunyoung Ko and Gyuchan Jo and Hongseok Oh and Ji-Hoon Jeong and Yuan H. Brad Kim and Jungseok Choi and Euijong Lee},
  doi          = {10.1109/ACCESS.2025.3616969},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Application of ensemble method to predict individual pork prices using multi-source information},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic multi-objective evolutionary algorithm based on spectral clustering prediction. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3617239'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the challenge of rapidly tracking the new Pareto optimal set (PS) after environmental changes in dynamic multi-objective optimization problems (DMOPs), this paper proposes a dynamic multi-objective evolutionary algorithm (DMOEA) based on spectral clustering prediction (SCP). The algorithm first applies spectral clustering to the PS from historical moments to automatically identify multiple subclasses of the PS. When environmental changes occur, the algorithm uses historical information to predict the centroids and shapes of each subclass, thereby constructing a new initial population. Experimental results on 14 standard dynamic test problems indicate that the proposed SCP-DMOEA outperforms four typical algorithms—PPS, MDP, KTM, and RNN—in handling various change characteristics in most test functions. These characteristics include translation or rotation changes of the PS, correlations between decision variables, and time-varying mixed Pareto optimal fronts (PFs), including variations in convexity and concavity. In particular, SCP-DMOEA also shows superior performance when handling optimization problems with more complex PF changes, such as the position of the PF continuously changes over time, the objective vector oscillates among several modes, and the PFs are discontinuous.},
  archive      = {J_ACCESS},
  author       = {Zhao-jun Sheng and Er-chao Li},
  doi          = {10.1109/ACCESS.2025.3617239},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Dynamic multi-objective evolutionary algorithm based on spectral clustering prediction},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BoundMatch: Boundary detection applied to semi-supervised segmentation. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3617037'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised semantic segmentation (SS-SS) aims to mitigate the heavy annotation burden of dense pixel labeling by leveraging abundant unlabeled images alongside a small labeled set. While current consistency regularization methods achieve strong results, most do not explicitly model boundaries as a separate learning objective. In this paper, we propose BoundMatch, a novel multi-task SS‑SS framework that explicitly integrates semantic boundary detection into a teacher-student consistency regularization pipeline. Our core mechanism, Boundary Consistency Regularized Multi-Task Learning (BCRM), enforces prediction agreement between teacher and student models on both segmentation masks and detailed semantic boundaries, providing complementary supervision from two independent tasks. To further enhance performance and encourage sharper boundaries, BoundMatch incorporates two lightweight fusion modules: Boundary-Semantic Fusion (BSF) injects learned boundary cues into the segmentation decoder, while Spatial Gradient Fusion (SGF) refines boundary predictions using mask gradients, yielding more reliable boundary pseudo-labels. This framework is built upon SAMTH, a strong teacher-student baseline featuring a Harmonious Batch Normalization (HBN) update strategy for improved stability. Extensive experiments on diverse datasets including Cityscapes and Pascal VOC show that BoundMatch achieves competitive performance against current state-of-the-art methods. Our approach achieves state-of-the-art results on the new Cityscapes benchmark with DINOv2 foundation model. Ablation studies highlight BoundMatch’s ability to improve boundary-specific evaluation metrics, its effectiveness in realistic large-scale unlabeled data scenario, and applicability to lightweight architectures for mobile deployment.},
  archive      = {J_ACCESS},
  author       = {Haruya Ishikawa and Yoshimitsu Aoki},
  doi          = {10.1109/ACCESS.2025.3617037},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {BoundMatch: Boundary detection applied to semi-supervised segmentation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the design of a two-dimensional sensor calibration processor using a variable polynomial computation for enhancing sensor non-linearity. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3617149'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a hardware architecture for two-dimensional sensor calibration based on a segmented polynomial computation framework, which divides the input space into multiple regions and applies a locally optimized calibration function to each. To determine optimal segment boundaries, the system incorporates an Adaptive Segmentation Module (ASM) that automatically analyzes sensor characteristics and selects boundary configurations that minimize global calibration error. At the algorithmic level, the proposed method integrates a Simplified Progressive Polynomial Calibration (SPPC) technique, which addresses the exponential growth in polynomial order observed in conventional Progressive Polynomial Calibration (PPC) methods as the number of calibration points increases. SPPC mitigates this complexity through a linear-order growth strategy while preserving high calibration accuracy within each segment. The system is implemented on a RISC-V-based System-on-Chip (SoC) equipped with a dedicated Sensor Calibration Module (SCM) optimized for 8-bit signed fixed-point arithmetic. The proposed approach was validated through MATLAB simulations and RTL-level hardware implementation. Experimental results demonstrated up to an 80% reduction in execution time compared to conventional PPC and a 2.35% improvement in calibration accuracy through segmented calibration. Notably, the ASM-based segmentation achieved up to a 5.87% reduction in calibration error compared to non-segmented methods, even under varying input conditions, effectively reducing the need for manual tuning. These results confirm that the proposed architecture provides a high-performance, hardware-efficient, and adaptive solution for real-time calibration of sensors affected by nonlinearities and cross-sensitivity, making it well-suited for a wide range of embedded sensing applications.},
  archive      = {J_ACCESS},
  author       = {Jaelim Lee and Minjae Kwak and Dongsun Kim},
  doi          = {10.1109/ACCESS.2025.3617149},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {On the design of a two-dimensional sensor calibration processor using a variable polynomial computation for enhancing sensor non-linearity},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A high-speed power flow method based on equivalent resistance for realtime simulators of MVDC distribution networks. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3617039'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medium-voltage direct current (MVDC) distribution networks have garnered significant attention due to their ability to enhance power distribution in modern grids. To efficiently operate the networks, an energy management system (EMS) is required, and it is imperative to validate applications in the EMS under a realistic environment using real-time simulators with a high-speed network analysis engine for power flow. However, classical NR-based methods are not suitable as analytical engines for real-time simulators due to their prolonged computation times resulting from complex numerical calculations. For application to real-time simulators that require high-speed computational capabilities, this paper presents a fast power flow method based on equivalent resistance for real-time simulators of MVDC distribution networks. In the proposed method, the injected power at each node is transformed into an equivalent resistance enabling a direct circuit analysis for a simple resistive circuit based on Kirchhoff’s law, which reduces computation time significantly compared with the classical NR-based method. Case studies on various test systems demonstrate the effectiveness of the proposed method, which exhibits a high degree of accuracy and a high-speed computation capability when compared with the classical NR-based method.},
  archive      = {J_ACCESS},
  author       = {Ruihua Zhang and Seong-Il Lim and Yun-Sik Oh},
  doi          = {10.1109/ACCESS.2025.3617039},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {A high-speed power flow method based on equivalent resistance for realtime simulators of MVDC distribution networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Airborne wind energy potential in türkiye: A study of wind resource, life cycle assessment, and techno-economic analysis. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3617247'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper provides an integrated assessment of Airborne Wind Energy (AWE) systems in Türkiye, evaluating their potential as a future renewable energy source. The study addresses key questions of resource availability, environmental impact, and economic viability through a threefold methodology applied to ten regions: (1) probabilistic wind modeling to accurately characterize high-altitude resources, (2) a comparative life-cycle assessment (LCA) to quantify environmental impacts against conventional turbines, and (3) a techno-economic analysis (TEA) to determine financial viability. Our results indicate that the Gamma distribution generally provides the most accurate model for the high-altitude wind profiles studied (R2 > 0.997). The LCA reveals a compelling environmental case for AWE, with a global warming potential as low as 14.8 gCO2-eq/kWh in prime locations. The TEA projects a highly competitive levelized cost of electricity (LCOE), ranging from $0.042/kWh in wind-rich areas like Çanakkale to over $0.16/kWh in less ideal sites.With an internal rate of return exceeding 18% in the most favorable regions, the study concludes that AWE systems appear to be a technically promising and economically viable option for Türkiye, capable of matching or even outperforming conventional wind power in select locations.},
  archive      = {J_ACCESS},
  author       = {Ahmet Emre Onay and Emrah Dokur},
  doi          = {10.1109/ACCESS.2025.3617247},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Airborne wind energy potential in türkiye: A study of wind resource, life cycle assessment, and techno-economic analysis},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HiTrans-SAM: Hierarchical transformer encoder and SAM-augmented inputs for multi-scale remote sensing image segmentation. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3617388'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic segmentation of remote sensing images is challenging due to complex scenes, substantial variations in object scales, and ambiguous boundaries. In this study, we propose a novel method, HiTrans-SAM: Hierarchical Transformer Encoder and SAM-Augmented Inputs for Multi-Scale Remote Sensing Image Segmentation. The framework adopts an encoder-decoder architecture. First, prior to encoding, the input image is enhanced using SAM to incorporate boundary prior maps generated by SAM, thereby mitigating boundary ambiguity. Subsequently, a Hierarchical Transformer Encoder is integrated into the encoding network to facilitate information propagation. This module captures high-resolution spatial details while effectively leveraging global contextual relationships. During the decoding phase, multi-scale feature fusion is performed to ensure comprehensive utilization of features across varying scales, ultimately improving segmentation accuracy. Experiments on the LoveDA and Potsdam datasets demonstrate state-of-the-art performance, achieving mean Intersection over Union (mIoU) values of 53.52% (LoveDA), 79.45% (Potsdam) and 75.12%(Vaihingen), significantly outperforming existing methods. The results validate the algorithm’s efficacy in enhancing segmentation accuracy through boundary refinement, context modeling, and multi-scale feature fusion.},
  archive      = {J_ACCESS},
  author       = {Yulian Li and Jiyang Gao and Yikang Du and Yuxuan Xiao and Zhengjie Gao and Haitao Huang},
  doi          = {10.1109/ACCESS.2025.3617388},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {HiTrans-SAM: Hierarchical transformer encoder and SAM-augmented inputs for multi-scale remote sensing image segmentation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A convolutional neural network to spiking neural network conversion framework for seismic denoising. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3617570'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the application of Spiking Neural Network (SNN) in seismic signal denoising by developing a Convolutional Neural Network (CNN) to SNN conversion framework. We focus on two challenges: optimal spike encoding strategy adaptation for seismic data; and denoising performance preservation during CNN-SNN conversion. Through systematic experiments on the public Marmousi 2 dataset and field data from Sichuan Basin, we demonstrate that SNN can feasibly serve as an alternative to traditional CNN for seismic denoising tasks. The proposed framework demonstrates that count-rate encoding preserves critical seismic temporal features far more effectively than time-to-first-spike coding, owing to its inherent alignment with the network’s synchronous, rate-based representation. Our neuron optimization strategy combines soft reset mechanisms with adaptive thresholding, demonstrating enhanced performance that narrows the gap between native CNN and converted SNN implementations. To enable rigorous evaluation, we introduce a baseline alignment scheme ensuring fair comparison between the native CNN and its CNN-SNN converted architecture. This work demonstrates the first successful application of SNN to seismic signal denoising, offering a bio-inspired alternative to conventional CNN while preserving comparable signal-to-noise ratio performance.},
  archive      = {J_ACCESS},
  author       = {Shuna Chen and Zhege Liu and Ziyu Qin and Xinyi Liu and Yajuan Xue and Junxing Cao},
  doi          = {10.1109/ACCESS.2025.3617570},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {A convolutional neural network to spiking neural network conversion framework for seismic denoising},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Non-control-data attacks and defenses: A review. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3617245'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, non-control-data attacks have become a research hotspot in the field of network security, driven by the increasing number of defense methods against control-flow hijacking attacks. These attacks exploit memory vulnerabilities to modify non-control data within a program, thereby altering its behavior without compromising control-flow integrity. Research has shown that non-control-data attacks can be just as damaging as control-flow hijacking attacks and are even Turing complete, making them a serious security threat. However, despite being discovered long ago, the threat of non-control-data attacks has not been adequately addressed. In this review, we first classify non-control-data attacks into two categories based on their evolution: security-sensitive function attacks and data-oriented programming (DOP) attacks. Subsequently, based on the non-control-data attack model, we categorize existing defense methods into three main strategies: memory safety, data confidentiality, and data integrity protection. We then analyze recent defense techniques specifically designed for DOP attacks. Finally, we identify the key challenges hindering the widespread adoption of defenses against non-control-data attacks and explore future research directions in this field.},
  archive      = {J_ACCESS},
  author       = {Chong Lei and Bahari Belaton},
  doi          = {10.1109/ACCESS.2025.3617245},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Non-control-data attacks and defenses: A review},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A cost-effective and flexible decision-making method for multi-objective finite control set model predictive control. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3617649'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-objective finite control set-model predictive control (FCS-MPC) plays a prominent role in controlling modern power converters and electric drives. However, selecting weighting factors (WFs) remains challenging, particularly when considering additional control objectives (ACOs). To address this challenge, this paper proposes a straightforward, cost-effective, and flexible decision-making (DM) method for multi-objective FCS-MPC strategies. The proposed hierarchical structure DM method utilises the Euclidean norm to individually evaluate the main and additional control performances. Because it allows for the expansion of the number of hierarchical stages and does not require a sorting algorithm, it stands out as a flexible and technically effective solution among existing DM techniques for the given problem. To demonstrate its effectiveness, it is applied to the model predictive torque control (MPTC) strategy to drive a permanent magnet synchronous motor. The MPTC with the proposed DM method is tested under various operating conditions and compared with the conventional MPTC. The experimental results confirm the ability of the proposed DM technique to handle ACOs in conjunction with the main control objectives and system constraints, while also demonstrating increased flexibility, enhanced control performance, and reduced computational demand.},
  archive      = {J_ACCESS},
  author       = {Emrah Zerdali and Jacopo Riccio and Jakson Bonaldo and Marco Rivera and Pat Wheeler and Michele Degano},
  doi          = {10.1109/ACCESS.2025.3617649},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {A cost-effective and flexible decision-making method for multi-objective finite control set model predictive control},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DSCP-UNet: A tunnel crack segmentation algorithm based on lightweight diminutive size and colossal perception. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3617337'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To effectively enhance the ability to detect surface crack defects in tunnels under tunnel conditions, this paper proposes a new tunnel crack segmentation algorithm using light-weight diminutive size and colossal perception UNet (DSCP-UNet). This method integrates a diminutive group convolution (DGConv) module and a self-adaptive pooling (SAPool) module into the UNet architecture, resulting in a segmentation network that balances lightweight design with strong perceptual capability. In the constructed DSCP-UNet model, the conventional convolutional backbone is replaced by DGConv, significantly reducing the number of model parameters. Aconvolutional block attention module (CBAM) is introduced to enhance the model’s focus on crack features, forming an efficient crack recognition network. The pyramid attention with sampling group (PASG) module is also investigated to improve the model’s ability to discriminate multi-scale crack features. Using collected tunnel crack images, the proposed DSCP-UNet achieves a model size of only 3.85 MB and demonstrates superior performance in tunnel crack segmentation tasks. Based on the collected images of surface cracks in the tunnel, we verified the rationality of the proposed algorithm. Meanwhile, by comparing with other models, it was found that the algorithm proposed in this paper has high robustness.},
  archive      = {J_ACCESS},
  author       = {Weihua Shi},
  doi          = {10.1109/ACCESS.2025.3617337},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {DSCP-UNet: A tunnel crack segmentation algorithm based on lightweight diminutive size and colossal perception},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-supervised depth estimation and 3D reconstruction with layer-wise LoRA of foundation model in endoscopy. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3617567'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depth estimation is crucial for 3D reconstruction and surgical navigation, providing critical insights for endoscopic procedures. While foundation models excel in depth estimation for natural images, their performance in the medical domain remains limited, particularly under challenging conditions like brightness fluctuations. This study develops a robust self-supervised framework for monocular depth estimation to address these challenges. We introduce a layer-wise low-rank adaptation (LW-LoRA) of the Depth-Anything-V2 foundation model, tailored for endoscopic data. Unlike conventional fine-tuning, LW-LoRA adjusts the LoRA rank across encoder layers for efficient training. The method integrates residual convolutional blocks (ResConv) to capture fine-grained details and a multi-head attention-based pose network to enhance camera pose estimation, ensuring accurate 3D reconstructions. A multi-scale SSIM-based reprojection loss refines depth predictions, while a brightness calibration module ensures robustness against illumination inconsistencies. During training, the backbone encoder is frozen, optimizing only the LoRA layers for efficiency. Extensive evaluations on the SCARED dataset highlight the superior performance of our framework, offering faster inference and high-quality depth maps. Zero-shot testing on Hamlyn and clinical datasets confirms its generalization across diverse data types. Our framework efficiently adapts the foundation model for depth estimation in the medical domain, addressing challenges in endoscopic imaging, such as brightness variations and fine-detail preservation. It enables accurate, dense 3D point cloud reconstructions, ensuring reliable performance in clinical settings.},
  archive      = {J_ACCESS},
  author       = {Saad Khalil and Sol Kim and Bo-In Lee and Youngbae Hwang},
  doi          = {10.1109/ACCESS.2025.3617567},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Self-supervised depth estimation and 3D reconstruction with layer-wise LoRA of foundation model in endoscopy},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Millimeter-wave conical beam antennas for drone and vehicle communications. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3617174'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this contribution, novel designs of circular planar antennas capable of generating conical beam (CB) radiation patterns for millimeter-wave (mmWave) drone and vehicle communications are presented. The proposed geometry of the antenna comprises a circular patch surrounded by 18 quarter-wavelength bent stubs/corrugations and underneath coaxial feed that support the TM01 mode and produce a narrow-band linearly polarized (LP) CB radiation pattern. To increase the antenna bandwidth by improving impedance matching, six radial line slots were strategically placed in the top-patch, each oriented at 60° with respect to each other and rotated by 30° along the axis alignment. This configuration significantly improved the antenna’s bandwidth and maintains the beam at constant angle. Through optimization of the physical dimensions of the design, LP-CB antenna achieved a peak gain of 9.2 dBi with less than 1.5 dB variation across the bandwidth between 24.2 to 30 GHz. Moreover, gain patterns are circularly symmetric with very low-ripple at different elevation angles. By using the same top layer, and introducing three rings of tilted slots (6, 12 and 12 slots in each ring) in the ground plane, a second antenna is designed which is circularly polarized (CP) with a 3 dB axial ratio (AR) bandwidth from 27.5 to 30.8 GHz. Across the operating band, the beam points at the elevation angle of 24° ± 1° for both the antennas. The simulated and measured results demonstrate that both the proposed antennas can achieve a -10 dB impedance bandwidth (IBW) of more than 22.2% for the LP design, 10.5% in the CP design, and both exhibit stable and consistent radiation patterns with efficiency values of better than 80%. Excellent agreement between simulations and measurements was achieved. A simple planar geometry with wide bandwidth, high gain, and good CB radiation performance makes the designs promising candidates for 5G mmWave communications.},
  archive      = {J_ACCESS},
  author       = {Amitkumar Patel and William Whittow and Chinthana Panagamuwa},
  doi          = {10.1109/ACCESS.2025.3617174},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Millimeter-wave conical beam antennas for drone and vehicle communications},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GenPure: Foundation-model-guided multi-stage purification framework for black-box evasion of deepfake detectors. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3617447'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although deepfake detection methodologies have advanced considerably, they remain susceptible to evasion techniques, a critical vulnerability in forensic systems. Most detection approaches that rely on generator-specific artifacts or high-frequency fingerprints become susceptible to circumvention when these discriminative features are eliminated. As a means to expose such blind spots in state-of-the-art forensics, we introduce GenPure, a novel multi-stage purification framework that systematically removes both low- and high-level synthetic cues, enabling generated images to bypass diverse detectors under a strict black-box setting. In the GenPure detection evasion pipeline, a U-Net-based reconstruction module with multi-scale, spatially adaptive Gaussian kernels first attenuates synthetic artifacts while preserving perceptual fidelity. Next, a vision foundation model—intentionally unbiased toward authentic-synthetic classification—aligns the attenuated images with authentic image characteristics by minimizing distribution discrepancies in latent space. Finally, reference-guided statistical color recalibration restores natural tone and further masks residual forensic cues. The framework requires no detector knowledge or additional training and generalizes across generator types, resolutions, and content domains. Extensive experiments demonstrated state-of-the-art evasion performance across multiple unseen generative sources and detection systems without degrading visual quality. The results exposed persistent structural weaknesses in current forensic pipelines and underscore the need for semantically grounded, manipulation-invariant defenses.},
  archive      = {J_ACCESS},
  author       = {Yuyang Sun and Ching-Chun Chang and Isao Echizen},
  doi          = {10.1109/ACCESS.2025.3617447},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {GenPure: Foundation-model-guided multi-stage purification framework for black-box evasion of deepfake detectors},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Time-series U-net with recurrence for noise-robust imaging photoplethysmography. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3617284'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote estimation of vital signs enables health monitoring for situations in which contact-based devices are either not available, too intrusive, or too expensive. In this paper, we present a modular pipeline for pulse signal estimation from video of the face that achieves state-of-the-art results on publicly available datasets. Our imaging photoplethysmography (iPPG) system consists of three modules: face and landmark detection, time-series extraction, and pulse signal/pulse rate estimation. The pulse signal estimation module, which we call TURNIP (Time-Series U-Net with Recurrence for Noise-Robust Imaging Photoplethysmography), allows the system to faithfully reconstruct the underlying pulse signal waveform and uses it to measure pulse rate and pulse rate variability metrics, even in the presence of motion. When parts of the face are occluded due to extreme head poses, our system explicitly detects such “self-occluded” regions and maintains estimation robustness despite the missing information. Our algorithm provides reliable pulse rate estimates without the need for specialized sensors or contact with the skin, outperforming previous iPPG methods on both color (RGB) and near-infrared (NIR) datasets.},
  archive      = {J_ACCESS},
  author       = {Vineet R. Shenoy and Shaoju Wu and Armand Comas and Suhas Lohit and Hassan Mansour and Tim K. Marks},
  doi          = {10.1109/ACCESS.2025.3617284},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Time-series U-net with recurrence for noise-robust imaging photoplethysmography},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fault detection isolation and localization (FDIL) scheme: A robust ML framework with novel architecture for fault localization. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3617464'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault detection, classification, and location estimation are paramount in transmission lines to ensure uninterrupted power supply, enhance reliability, and safety. Faster and more accurate fault localization is critical for prompt repair and efficient power restoration, thus minimizing economic losses. This paper presents a novel Fault Detection Isolation and Localization (FDIL) scheme, a machine learning (ML)-based framework, to increase the accuracy of fault location (FL) prediction. The proposed framework utilizes the phasor voltage, current, and frequency data obtained from optimally placed Phasor Measurement Units (PMUs) for fault detection, isolation, and localization. This paper also proposes a hybrid deep learning-based approach using Bidirectional Long Short-Term Memory (Bi-LSTM) networks and an attention mechanism for FL prediction. Extensive simulations using the IEEE 9-bus system, with different types and locations of faults, are performed on the OPAL-RT simulator-based testbed to generate and train the ML models. The performance of the proposed scheme is evaluated by calculating the Mean Absolute Error (MAE), Mean Squared Error (MSE), and R-squared (R2) metric. The results demonstrate that the proposed approach achieves high accuracy in FL prediction, with an MAE of 0.0228 km, an MSE of 0.001, and an R2 of 0.9894. Compared to the best-performing technique reported in the literature (CNN-LSTM, MAE = 0.211km), the proposed approach achieves an 89.2% reduction in localization error. The proposed scheme and model outperform the contemporary model, as reported in various literature, making it an effective solution for real-time fault monitoring in transmission systems.},
  archive      = {J_ACCESS},
  author       = {Rajendra Shrestha and Manohar Chamana and Mostafa Mohammadpourfard and Larissa Souto and Stephen Bayne},
  doi          = {10.1109/ACCESS.2025.3617464},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Fault detection isolation and localization (FDIL) scheme: A robust ML framework with novel architecture for fault localization},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing test case prioritization with meta deep reinforcement learning in continuous integration. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3617387'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software developers use Continuous Integration (CI) environments to reduce integration issues and expedite development cycles. Regression testing is an important part of CI practice, as it includes reconducting all test cases to guarantee system stability after upgrades. However, as test suites grow, this process becomes increasingly resource-intensive and time-consuming. While many Test Case Prioritization (TCP) techniques have been proposed to address this challenge, previous approaches often rely on static configurations and lack the adaptability needed to handle the dynamic nature of CI environments and different dataset complexities. To address these gaps, this study presents a novel TCP framework based on Deep Reinforcement Learning (DRL), integrating a pairwise ranking model with state-of-the-art DRL algorithms, including A2C, DQN, PPO, and TRPO. The proposed framework improves prioritization accuracy and execution efficiency, particularly when combined with an optimal cycle count strategy. An adaptive training framework based on Meta-Deep Reinforcement Learning (meta-DRL) was introduced to further enhance the adaptability of the framework. This component allows the DRL agent to assess its performance during training and dynamically modify the essential hyperparameters, thereby enhancing its ability to develop successful prioritizing methods over time. Finally, the results of the proposed methodology demonstrate that Meta-Deep Reinforcement Learning (meta-DRL) significantly reduces the training time and achieves a 60% reduction compared to existing approaches. These findings show the efficiency of Meta-DRL-based TCP in providing a scalable and adaptive solution for enhancing regression testing in CI environments.},
  archive      = {J_ACCESS},
  author       = {Nahlah A. AlRakban and Mubarak Alrashoud and M. Abdullah-Al-Wadud},
  doi          = {10.1109/ACCESS.2025.3617387},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Optimizing test case prioritization with meta deep reinforcement learning in continuous integration},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A scalable framework for big data analytics in psychological research: Leveraging distributed systems and cluster management. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3617120'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anxiety and depression are prevalent psychological disorders that can occur throughout life, with a notably higher prevalence among women during the perinatal period, encompassing pregnancy and the postpartum phase. The early detection and monitoring of these conditions are crucial for timely intervention and improved patient outcomes. Although healthcare analytics has progressed considerably, the extraction of actionable insights from large-scale patient data remains computationally intensive, especially under instant processing constraints. Furthermore, conventional healthcare infrastructures frequently lack the scalability, computational efficiency, and architectural flexibility required to integrate machine learning models into clinical workflows effectively. To address these challenges, the proposed distributed computing framework employs Apache Kafka for instant data streaming, Apache Spark for efficient in-memory machine learning–based analytics, and Kubernetes for orchestrating scalable, fault-tolerant deployment. This architectural configuration facilitates continuous data ingestion, accelerates analytical processing, and ensures system resilience, thereby enabling the timely identification of psychological conditions such as anxiety and depression during the perinatal period. Unlike schematic or batch-only prior work, we provide a production-ready, streaming-first clinical deployment and an empirical scaling analysis linking executors to end-to-end diagnostic latency and resource efficiency. Performance evaluations demonstrate the efficiency and scalability of the proposed system, highlighting its potential for real-world applications in healthcare analytics.},
  archive      = {J_ACCESS},
  author       = {Nur Banu Oğur and Celal Çeken and Yavuz Selim Oğur and Esra Yazici},
  doi          = {10.1109/ACCESS.2025.3617120},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {A scalable framework for big data analytics in psychological research: Leveraging distributed systems and cluster management},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Objective quality evaluation and enhancement of images affected by adverse weather conditions. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3617090'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, there has been a surge in algorithms aimed at enhancing the perceptual quality of images degraded by adverse weather conditions such as snow, haze, and rain. However, limited attention has been given to evaluating the visual quality of these enhanced images or leveraging perceptual quality assessment metrics as loss functions to generate visually compelling results. This paper introduces the Adverse Weather Affected Image (AWAI) dataset, consisting of 2,800 real-world weather-degraded images and their enhanced counterparts, annotated with subjective perceptual quality scores. We also propose a novel no-reference weather-aware image quality assessment (NRWIQA) algorithm designed for such images to enable quantitative evaluation of enhancement quality. Unlike existing methods that use generic features trained on natural images, our approach extracts deep features sensitive to weather-induced artifacts. A multiscale feature extraction strategy, fused via a cross-attention mechanism, is used to capture degradations across different scales. These features are further refined using a transformer to predict perceptual quality scores. The experimental results demonstrate that the proposed NRWIQA algorithm significantly outperforms existing methods, achieving up to 17.61% improvement in SROCC, highlighting its effectiveness in assessing the quality of images affected by adverse weather conditions.},
  archive      = {J_ACCESS},
  author       = {Ambreen Bashir and Vinit Jakhetiya and Badri Narayan Subudhi},
  doi          = {10.1109/ACCESS.2025.3617090},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Objective quality evaluation and enhancement of images affected by adverse weather conditions},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel adversarial gray-box attack on DCT-based face deepfake detectors. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3617766'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, several techniques have been developed to detect deepfake images, with particular success of approaches that exploit analytical traces (e.g. frequency domain features), such as those derived from the Discrete Cosine Transform (DCT). Despite their effectiveness, these detectors remain vulnerable to adversarial attacks. In this paper, we introduce a novel gray-box adversarial attack specifically designed to evade DCT-based deepfake detectors. Our method accurately tunes the AC coefficient statistics of synthetic images to closely match those of real ones, while preserving high visual quality. The attack assumes full knowledge of the DCT feature extraction process, but not access to the internal parameters of the classifiers. We evaluate the proposed method against a set of DCT-based detectors using deepfakes generated from both Generative Adversarial Networks (GANs) and Diffusion Models (DMs). Experimental results show significant degradation in detection performance, exposing critical weaknesses in systems traditionally considered interpretable and robust. This work raises important concerns about the reliability of frequency domain detectors in forensic and cybersecurity applications.},
  archive      = {J_ACCESS},
  author       = {Francesco Guarnera and Luca Guarnera and Alessandro Ortis and Sebastiano Battiato and Giovanni Puglisi},
  doi          = {10.1109/ACCESS.2025.3617766},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {A novel adversarial gray-box attack on DCT-based face deepfake detectors},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A feedback-driven federated zero-shot learning framework for adaptive detection of evolving banking malware. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3617219'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rise of digital banking has increased the frequency and sophistication of banking malware attacks, highlighting the need for privacy-preserving and adaptive detection frameworks. While Federated Learning (FL) offers a promising alternative to centralized detection by enabling collaborative model training without raw data sharing, its performance declines in the presence of evolving, previously unseen malware behaviors, especially under non-IID (non-independent and identically distributed) conditions. To address these challenges, we propose a hybrid FL and Zero-Shot Learning (ZSL) framework enhanced with a feedback-driven continual learning loop for resilient malware detection. Our approach assigns three federated clients disjoint banking malware datasets comprising Zeus, Emotet, TrickBot, and benign samples under a non-IID setting, simulating real-world institutional threat exposure. Two additional datasets: one with malware variants and another synthetically generated to reflect evolved behavior are used exclusively for testing. Among multiple deep learning architectures evaluated, a Multilayer Perceptron (MLP) is selected as the best-performing model and personalized at each client. ZSL operates during inference to reclassify low-confidence samples using semantic embeddings, and those with high cosine similarity are selectively reintegrated into FL training, supporting continual adaptation through feedback, without compromising data privacy. Experimental results show that the proposed FL-ZSL-feedback pipeline achieves an average improvement of 8.49% in correctly classifying samples with high confidence over baseline FL model across all clients and datasets. These findings validate the effectiveness of our framework in delivering privacy-aware, adaptive banking malware detection in dynamic, distributed environments.},
  archive      = {J_ACCESS},
  author       = {Nahid Ferdous Aurna and Yuzo Taenaka and Youki Kadobayashi},
  doi          = {10.1109/ACCESS.2025.3617219},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {A feedback-driven federated zero-shot learning framework for adaptive detection of evolving banking malware},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Simulation and coordination of autonomous bio-inspired underwater agents. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3617767'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the preliminary results of the MAXFISH project, which aims to develop an integrated methodological and technological framework for modeling, simulating, and controlling coordinated bio-inspired robotic fish shoals. The system combines a digital twin platform, realized in MATLAB/Simulink, with a max-plus algebraic model to address multi-agent coordination for underwater survey and monitoring missions. The digital twin enables the estimation of travel times based on the kinematic and dynamic behavior of the robotic fish, while the max-plus framework allows formal scheduling analysis of cyclic exploration tasks, ensuring mutual exclusion on shared resources and respecting mission constraints. A Graphical User Interface (GUI) further supports mission planning, enabling users to define points of interest and automatically compute overall mission times. The novelty of this approach lies in the integration of max-plus algebra techniques with simulation tools for underwater inspections. The proposed framework also supports Hardware-in-the-Loop (HIL) and Software-in-the-Loop (SIL) testing, facilitating the validation of coordination strategies with real robotic agents and communication buoys. Preliminary results demonstrate the feasibility of this hybrid simulation and its potential to streamline the deployment of coordinated multi-agent underwater systems.},
  archive      = {J_ACCESS},
  author       = {D. Scaradozzi and V. Bartolucci and F. Gioiello and D. Costa and B. Castagna and E. Zattoni and G. Antonelli and D. Di Vito and A. Marino and F. Arrichiello and P. Di Lillo and S. Chiaverini and G. Gillini},
  doi          = {10.1109/ACCESS.2025.3617767},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Simulation and coordination of autonomous bio-inspired underwater agents},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). StructMamba: Structured harmonic and temporal music analysis via dual-axis mamba and attention. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3617184'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modeling musical audio requires capturing hierarchical relationships between harmonic textures, rhythmic motifs, and long-range structural repetitions. Convolutional networks extract local features efficiently, while transformers provide global modeling, yet both face mismatches with musical structure. In this work we introduce StructMamba, a dual-axis architecture that unifies state-space modeling with global two-dimensional attention. Our design decomposes spectrogram modeling into frequency-wise and time-wise Mamba modules, enabling independent learning of harmonic and rhythmic dependencies before fusing them through structured attention. Evaluated on benchmark tasks in genre classification, onset detection, and structural segmentation, StructMamba outperforms strong CNN, transformer, and hybrid baselines, while maintaining stability in low-resource settings. Beyond accuracy, its internal representations align with music-theoretic constructs such as motifs, downbeats, and sectional boundaries, offering rare interpretability for deep audio models. These findings position StructMamba as an efficient and musically aligned solution for time–frequency audio modeling, with practical implications for music education, annotation, and production.},
  archive      = {J_ACCESS},
  author       = {Amit Kumar Bairwa and Siddhanth Bhat and Tanishk Sawant and Manoj Kumar Bohra},
  doi          = {10.1109/ACCESS.2025.3617184},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {StructMamba: Structured harmonic and temporal music analysis via dual-axis mamba and attention},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An oversampling-enhanced multi-class imbalanced classification framework for patient health status prediction using patient-reported outcomes. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3617316'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Patient-reported outcomes (PROs), directly captured from cancer patients undergoing radiation therapy, play a crucial role in guiding clinicians’ counseling on treatment-related toxicities. Accurate prediction and assessment of symptoms and health status linked to PROs are essential for improving clinical decision-making and planning post-treatment support as patients transition into survivorship. However, raw PRO data collected in clinical settings presents two inherent challenges, including data sparsity (due to incomplete item responses) and imbalanced toxicity distributions. These factors complicate predictive modeling. This study investigates machine learning techniques to address these challenges by predicting outcomes such as pain and sleep disturbances using PRO datasets from a cancer therapy center. We implement advanced classifiers (i.e., RF, XGBoost, GB, SVM, MLP-Bagging, and LR) for multi-class imbalance tasks across three cancers. To address minority underrepresentation, we apply oversampling while preserving class ratios. Experimental results demonstrate RF and XGBoost’s strong generalization, highlighting their utility in categorizing post-therapy severity levels for clinical decision support.},
  archive      = {J_ACCESS},
  author       = {Yang Yan and Zhong Chen and Cai Xu and Xinglei Shen and Jay Shiao and John Einck and Ronald C Chen and Hao Gao},
  doi          = {10.1109/ACCESS.2025.3617316},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {An oversampling-enhanced multi-class imbalanced classification framework for patient health status prediction using patient-reported outcomes},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HP-BERT: A framework for longitudinal study of hinduphobia on social media via language models. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3617514'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the COVID-19 pandemic, community tensions intensified, contributing to discriminatory sentiments against various religious groups, including Hindu communities. Large language models (LLMs) have shown promise for natural language processing tasks and social media analysis, enabling longitudinal studies of platforms like X (formerly Twitter).We present a computational framework for analyzing anti-Hindu sentiment (Hinduphobia) during the COVID-19 period, introducing an abuse detection and sentiment analysis approach for longitudinal analysis on X (Twitter). We curate and release a "Hinduphobic COVID-19 X (Twitter) Dataset" containing 8,000 annotated and manually verified tweets. Using this dataset, we develop the Hinduphobic BERT (HP-BERT) model through fine-tuning. HP-BERT achieves 94.72% accuracy, outperforming baseline applications of five transformer models to our specific task. The model incorporates multi-label sentiment analysis capabilities through additional fine-tuning on the "SenWave Dataset". Our analysis encompasses approximately 27.4 million tweets from six countries: Australia, Brazil, India, Indonesia, Japan, and the United Kingdom. Statistical analysis reveals moderate correlations (r = 0.312-0.428) between COVID-19 case increases and Hinduphobic content volume, highlighting how pandemic-related stress may contribute to discriminatory discourse. This study provides evidence of social media-based religious discrimination during a COVID-19 crisis.},
  archive      = {J_ACCESS},
  author       = {Ashutosh Singh and Rohitash Chandra},
  doi          = {10.1109/ACCESS.2025.3617514},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {HP-BERT: A framework for longitudinal study of hinduphobia on social media via language models},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving remaining useful life prediction with synthetic data and black box adversarial reprogramming. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3617781'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predictive maintenance is essential in modern manufacturing for improving the reliability and efficiency of machinery. A central challenge lies in accurately estimating the remaining useful life (RUL) of critical components such as ball bearings, especially when real-world labeled data is scarce. This study addresses this challenge by combining physics-informed simulation with a regression-based transfer learning approach. A 5-degree-of-freedom simulation model was developed to replicate the lifecycle of ball bearings under varying operating conditions, generating synthetic run-to-failure vibration data. The synthetic signals were segmented and processed using statistical and time-frequency features, with dimensionality reduction performed via statistical relevance and multicollinearity filtering. Tree-based regression models—Random Forest, Gradient Boosting, and XGBoost—were trained on the synthetic data and optimized via Bayesian hyperparameter tuning. To bridge the domain gap, the Black Box Adversarial Reprogramming (BAR) algorithm was applied to adapt these models for real-world data without retraining. Performance was evaluated across twelve structured transfer tasks using RMSE, MAE, and R2 metrics. Results showed that BAR-enhanced models consistently outperformed their unadapted counterparts, with the Gradient Boosting Regressor achieving an RMSE of 10.25 and R2 of 0.87 on the best transfer task. A statistical evaluation over 100 iterations confirmed the effectiveness of the approach, while highlighting its stochastic nature. Overall, the integration of physics-based data generation with BAR-based transfer learning offers a scalable and model-independent solution for accurate RUL prediction under data-constrained conditions.},
  archive      = {J_ACCESS},
  author       = {Alexander Bott and Jan Corduan and Moritz Siems and Alexander Puchta and Jürgen Fleischer},
  doi          = {10.1109/ACCESS.2025.3617781},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Improving remaining useful life prediction with synthetic data and black box adversarial reprogramming},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comprehensive evaluation of irradiance transposition models at high temporal resolution in hot desert conditions. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3617653'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The tilted irradiance, or Plane-Of-Array (POA) irradiance, refers to the solar radiation that strikes a tilted surface, such as a photovoltaic (PV) panel. Accurate estimation of POA is essential for designing efficient solar systems and predicting energy output. POA can be calculated using transposition models, that consider factors such as solar radiation components (direct and diffuse) and geometrical parameters like the tilt and azimuth angles. This study evaluates the performance of several widely used transposition models in the hot desert (BWh) climate of Doha, Qatar, using high-resolution (1-minute) irradiance data. A dataset spanning more than a year was analyzed with consideration of factors such as albedo, solar zenith angle, cloud cover, precipitation, and air quality. Several performance indicators including relative RMSE, relative MBE, and a risk index, were utilized. Among the tested models, Perez and Perez-Driesse provided the closest agreement with POA irradiance at two south-facing tilt angles, showing stable performance across seasons, while Hay-Davies emerged as least risky model. The analysis also revealed greater sensitivity to albedo at higher tilt angle. Model accuracy declined during cloudy and rainy periods, but improved during clear, dust-prone months. These findings highlight Qatar’s favorable atmospheric conditions for accurate POA modeling, supporting applications such as PV tilt optimization and system sizing, while underscoring the need for refined model tuning to address performance limitations under cloudy conditions.},
  archive      = {J_ACCESS},
  author       = {Abdul Wahab Ziaullah and Dunia Bachour and Daniel Perez-Astudillo},
  doi          = {10.1109/ACCESS.2025.3617653},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Comprehensive evaluation of irradiance transposition models at high temporal resolution in hot desert conditions},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Boosting the performance of image restoration models through training with deep-feature auxiliary guidance. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3617488'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many neural network architectures have been proposed for image restoration to improve the accuracy of restored images while maintaining reasonable computational costs. However, most previous studies have primarily focused on designing new architectures, with relatively less attention on optimizing training strategies. In this paper, we introduce deep-feature auxiliary guidance (DFAG), a novel training method that enhances the accuracy of image restoration models without increasing inference time or modifying their structures. DFAG adds auxiliary losses to the feature maps at each multi-scale level during training, which stabilizes deep feature learning and improves feature quality. All modules used for DFAG are only active during training and are removed for inference, resulting in no additional computational cost.We validate DFAG on various multi-scale encoder-decoder-based image restoration models. Our experiments demonstrate consistent performance improvements across multiple tasks, including real image denoising, Gaussian denoising, motion deblurring, JPEG artifact reduction, and super-resolution. Our results highlight that DFAG is an effective strategy to boost restoration performance without any architectural modifications. The source code and pre-trained models will be released.},
  archive      = {J_ACCESS},
  author       = {Cheolhun Jang and Daehyun Ji and Nam Ik Cho},
  doi          = {10.1109/ACCESS.2025.3617488},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Boosting the performance of image restoration models through training with deep-feature auxiliary guidance},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient diving control scheme for autonomous underwater vehicle experiencing actuator failure: A multi-layer cubature kalman filter-based nonlinear model predictive control approach. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3617538'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous underwater vehicles (AUVs) are primarily capable of withstanding prolonged periods in unstructured marine environments. These are subject to several uncertainties, including the effects of underwater currents or drift, topography, water pressure, and other factors. The inherent motion of the vehicle is influenced by buoyancy or mass error and other slowly varying hydrodynamic coefficients. Moreover, an AUV faces various types of undetected faults during its mission execution. The use of large-dimensional, rigorous onboard sensor data from real-time AUV operations, subject to the limited power capacity and the presence of other acoustic issues, makes it more challenging for the control community from both stability and positioning accuracy perspectives. Hence, an anti-disturbance stabilized control mechanism is intended to perform a variety of underwater tasks in various uncertain oceanic environments. A two-stage high-degree cubature information filter (TSHDCIF) is designed to effectively observe unmatched external disturbances, uncertain hydrodynamic parameters, and actuator faultiness. A nonlinear model predictive control (NMPC) scheme incorporated with the TSHDCIF observer is proposed in this work. Various realistic scenario-based result sets, including 1) effects on ocean currents, 2) variations in hydrodynamic parameters, and 3) loss of actuator effectiveness, are addressed in this study. The control solution is compared with the baseline NMPC scheme to examine its efficacy, including depth accuracy, control aggression, convergence analysis, and computation time per iteration. Based on the analysis, the TSHDCIF-NMPC scheme outperforms the traditional NMPC scheme by 5.49% in terms of RMSE (root mean square error) and 1.73% in terms of mean square deviation (MSD). The stability of the closed-loop system is explored using the Lyapunov theorem. Thus, it is recommended to use the TSHDCIF-NMPC scheme for systems such as AUV for better efficacy, as mentioned above.},
  archive      = {J_ACCESS},
  author       = {Atanu Panda and Subhasish Mahapatra and Siddhartha Vadapalli and Rames C. Panda},
  doi          = {10.1109/ACCESS.2025.3617538},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {An efficient diving control scheme for autonomous underwater vehicle experiencing actuator failure: A multi-layer cubature kalman filter-based nonlinear model predictive control approach},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Vision-based relative pose estimation of non-cooperative spacecraft using time-of-flight camera. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3617328'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with a vision-based pose estimation of a target using a time-of-flight (ToF) camera. In particular, a relative pose estimation algorithm for non-cooperative targets that lack markers or accessible sensor is proposed. The proposed method, called the CSAC-ICP algorithm, combines a feature-based coarse registration method, known as Corner Random Sample Consensus (CSAC), with the well-known Iterative Closest Point (ICP) algorithm to ensure both accuracy and robustness. Here, 3D corner points are adopted as primary features. The corner points are obtained by first converting 3D point clouds into 2D images from which line features are extracted and then re-projected into 3D lines, enabling 3D corner points computation. This reduces the computation on a large number of 3D points, ensuring real-time performance. Furthermore, an extended Kalman filter (EKF) is integrated with the proposed pose estimation algorithm in a loosely coupled manner, not only to continuously provide the target pose information for a moving target, but also to reduce measurement noises due to the motion. Because feature-based coarse registration takes advantage of the global optimization strategy, the proposed method can avoid the inherent pitfall of the standalone ICP method, in which the optimization process may fall into a local minimum and lead to incorrect pose calculation under certain conditions. Moreover, the proposed pose estimation scheme minimizes the dependency on the prior knowledge about the target object’s shape by taking advantage of the RANSAC-based registration. Numerical simulation is set up to validate the functionality of the algorithm using simulated 3D point clouds, confirming the accuracy performance under controlled target motion. In addition, the proposed algorithm is implemented and tested on an actual hardware platform, which demonstrates the feasibility of real-time relative pose estimation for non-cooperative targets within the space environment. Moreover, the proposed pose estimation scheme reduces reliance on prior knowledge of the target object’s geometry by using RANSAC-based registration. The simulation results show that the proposed CSAC-ICP algorithm achieves 30% faster computation and 50% higher accuracy compared to the standalone ICP method. Experimental validation further confirms that 3D corner features can be extracted at a rate of 30 frames per second. In addition, the pose estimation achieves an accuracy of up to 3 degrees for rotational motion and within 0.02 meters for translational motion along along all three axes, demonstrating the feasibility and superior performance of the proposed algorithm in real-world scenarios.},
  archive      = {J_ACCESS},
  author       = {Sangdo Park and Minsik Oh and HeokJune You and Dongwon Jung},
  doi          = {10.1109/ACCESS.2025.3617328},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Vision-based relative pose estimation of non-cooperative spacecraft using time-of-flight camera},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal guaranteed-cost composite nonlinear feedback cruise control for heavy-haul trains. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3617101'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To enhance transient control performance and achieve multi-objective optimization in terms of speed tracking accuracy, safety, and energy consumption, this paper explores a novel fuzzy optimal guaranteed-cost composite nonlinear feedback (CNF) cruise control strategy for heavy-haul trains, taking into account parameter uncertainties and asymmetric input saturation.Ahigh-order nonlinear multiple-mass-point dynamics model is first established and then simplified into a lower-dimensional uncertain Takagi-Sugeno fuzzy error dynamics model through the application of the fencing concept and sector nonlinearity technique, which facilitates the controller design process. Employing the non-parallel distributed compensation approach along with Finsler’s lemma, a convex optimization problem is formulated to minimize an upper bound on train performance and stabilize the system. The corresponding sufficient conditions are deduced in terms of linear matrix inequalities. The proposed control strategy effectively integrates the benefits of CNF control with those of guaranteed-cost control methodologies. Numerical simulations comparing with different control methods are carried out using MATLAB/Simulink. The results of these comparisons demonstrate both the effectiveness and superiority of the proposed approach.},
  archive      = {J_ACCESS},
  author       = {Jia Wang and Qian Zhang and Zhiqiang Chen and Yougen Xu and Zhiwen Liu},
  doi          = {10.1109/ACCESS.2025.3617101},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Optimal guaranteed-cost composite nonlinear feedback cruise control for heavy-haul trains},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reasoning beyond length limits: Improving accuracy in long-context question answering with small-scale language models. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3617449'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long-context question answering (QA) remains a significant challenge, particularly when using small-scale language models (SLLMs) with limited computational capacity. Despite their efficiency, SLLMs often struggle to capture complex reasoning patterns and synthesize information from lengthy documents due to constraints in context size and inference depth. Traditional retrieval-augmented generation (RAG) approaches offer partial relief but typically fall short when precise reasoning across multiple passages is required. In this study, we present a novel, lightweight framework designed to improve long-context QA performance in SLLMs by combining two key strategies: (1) instruction-tuned embedding-based retrieval for extracting semantically aligned context, and (2) a question rephrasing mechanism that decomposes complex queries into stepwise subquestions. This dual strategy enables structured reasoning without the need for additional training or model fine-tuning. Experiments on the LongBench and LongBench v2 benchmarks demonstrate consistent performance improvements, with gains of up to 5% over strong baselines. Our method is model-agnostic, effective across diverse input lengths and task difficulties, and compatible with a wide range of SLLMs, including LLaMA and GLM. The proposed approach offers a practical, generalizable solution for deploying robust QA systems in resource-constrained environments.},
  archive      = {J_ACCESS},
  author       = {Minyoung Kyoung and Joon-Ho Lim and Youngsoo Kim},
  doi          = {10.1109/ACCESS.2025.3617449},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Reasoning beyond length limits: Improving accuracy in long-context question answering with small-scale language models},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hierarchical probabilistic deep learning approach for contextual anomaly detection in mixed-type tabular data. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3617799'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contextual anomaly is a subtype of anomaly that, when observed in isolation, may not have the characteristics of an anomaly but becomes an anomaly when observed within a given context. Contextual anomaly detection is applied in several areas, such as industrial production process control, computer network security, and financial fraud detection. Probabilistic approaches to solving this problem are often neglected or insufficiently researched compared to numerous other anomaly detection techniques, and efficient algorithms for mixed-type tabular data are generally lacking. In this paper, we present a Hierarchical Variational Autoencoder for contextual anomaly detection, a new promising approach based on probabilistic modeling with a hierarchy of two levels: contextual and common. The trained model predicts the conditional likelihood of an event with respect to the observed context, which is used to distinguish between anomalies and regular data. We experimentally confirm the improvement of the results compared to a benchmark model that does not consider contextual information.},
  archive      = {J_ACCESS},
  author       = {Lovre Mrčela and Zvonko Kostanjčar},
  doi          = {10.1109/ACCESS.2025.3617799},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {A hierarchical probabilistic deep learning approach for contextual anomaly detection in mixed-type tabular data},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Balloon pin-array gripper: Modeling of holding force generation mechanism and parametric grasping analysis. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3617151'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents both theoretical and experimental investigations of the shape-dependent grasping performance of the "balloon pin-array gripper," which integrates a pin-array structure with flexible inflatable balloons. First, we develop a theoretical model that captures the nonlinear expansion behavior of the balloon membrane and formulates the mechanism of holding force generation when multiple balloons simultaneously contact an axisymmetric object. Each balloon is assumed to expand until it reaches a specified compression depth, with the difference between internal pressure and membrane tension modeled as the contact pressure, which generates normal and frictional forces. Subsequently, we introduce a parametric evaluation method using axisymmetric objects, such as cylinders, conical frustums, and spheres. By systematically varying geometrical parameters, such as the height, radius, and base angle, we experimentally measure the holding force and analyze its dependence on contact area, surface orientation, and pin-array discreteness. The experimental results show reasonable agreement with the theoretical predictions with an overall coefficient of determination of R2 = 0.63. We also demonstrate that the gripper can establish contact and generate holding force even on challenging geometries, such as downward-facing surfaces. However, several simplifying assumptions in the model—such as the omission of balloon stress distribution and balloon-to-balloon interference—are presented and discussed as limitations. Future improvements are expected to involve pressure distribution measurements and finite-element analysis. These findings provide valuable insights into the grasping mechanisms of pneumatically actuated grippers and serve as a basis for optimizing design parameters and evaluating scaling limitations.},
  archive      = {J_ACCESS},
  author       = {Yuto Kemmotsu and Kazuki Abe and Masahiro Watanabe and Kenjiro Tadakuma},
  doi          = {10.1109/ACCESS.2025.3617151},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Balloon pin-array gripper: Modeling of holding force generation mechanism and parametric grasping analysis},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive fine-grained pruning via binary search for efficient environmental sound classification. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3617879'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The overparameterization of pretrained transformers limits their efficiency in Environmental Sound Classification (ESC), incurring high memory and computational overhead. Pruning redundant parameters is a common remedy, yet fine-grained pruning at the intra-layer level remains difficult due to the large combinatorial search space and the risk of accuracy degradation. In this paper, we propose Adaptive Fine-Grained Pruning (AFP), an adaptive pruning method operating at intra-layer granularity under a user-defined performance constraint. AFP estimates the importance of prunable components by accumulating gradients during fine-tuning and then performs a binary search over the importance-ranked substructure space in a coarse-to-fine manner to identify the smallest submodel that satisfies the constraint. AFP avoids post-pruning gradient recalibration and efficiently identifies the smallest submodel via binary search, without traversing the full substructure space. Experiments show that AFP adaptively achieves up to 66.56% and 45.84% parameter reductions on the standard Audio Spectrogram Transformer for ESC-50 and UrbanSound8K, respectively, within a 2% drop in accuracy, outperforming popular baselines of static pruning or layer-level pruning in both pruning effectiveness and search efficiency.},
  archive      = {J_ACCESS},
  author       = {Changlong Wang and Akinori Ito and Takashi Nose},
  doi          = {10.1109/ACCESS.2025.3617879},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Adaptive fine-grained pruning via binary search for efficient environmental sound classification},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Implementation of a radio-over-fiber system based on UFCM for the coming 6G mobile networks. <em>ACCESS</em>, 1. (<a href='https://doi.org/10.1109/ACCESS.2025.3616962'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A sixth-generation (6G) front-haul link based on a Radio-over-Fiber (RoF) technology is a solution that guarantees larger bandwidth, and higher data rates comparing with its predecessor cellular networks. This paper presents the radio frequency (RF) signal transmission in a passive optical network (PON). The developed method aims to obtain different parameters to evaluate the performance of the proposed scheme as part of a 6G network. In this context, the RF signal is created with configurable universal filtered multi-carrier (UFMC), and the modulation scheme is modified to study the link’s behavior and to increase the system transmission speed. The first part of the analysis combines RF and optical systems in a co-simulation between MATLAB and OptSim. Meanwhile, the second part reports a real-world implementation of the front-haul link. The objective is to compare the simulation with the real-world results of the designed solution. For this purpose, we find the optimal configuration regarding the bit error rate (BER) and error vector magnitude (EVM). In the real implementation, once the front-haul link is configured optimally, the RF signal is transmitted through a universal software radio peripheral (USRP). This enables the measurement of the Received Signal Strength Indicator (RSSI) and the analysis of a 6G sector in a controlled environment. We demonstrate that the implemented solution successfully achieves the required receiver in the PON and ensures minimal received power at the User Equipment (UE). The designed scheme provides an appropriate speed to transmit bursts of data with a very high transfer rate and ultra-low latency, which are essential features for new services in 6G.},
  archive      = {J_ACCESS},
  author       = {Melanny Davila and Berenice Arguero and Christian Tipantuña and Germán V. Arévalo and Jossue Camacho and Carla Parra and Xavier Hesselbach},
  doi          = {10.1109/ACCESS.2025.3616962},
  journal      = {IEEE Access},
  month        = {10},
  pages        = {1},
  shortjournal = {IEEE Access},
  title        = {Implementation of a radio-over-fiber system based on UFCM for the coming 6G mobile networks},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
