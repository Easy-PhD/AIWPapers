<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TAI</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tai">TAI - 2</h2>
<ul>
<li><details>
<summary>
(2025). Ent-BAM: A generative framework for biomedical argument mining enriched with entity information. <em>TAI</em>, 1-10. (<a href='https://doi.org/10.1109/TAI.2025.3616076'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biomedical Argument Mining (BAM) aims to identify and extract argumentative structures, specifically, Argumentative Components (ACs) and Argumentative Relations (ARs), within biomedical texts. Primary challenges in BAM arise from the rich presence of specialized terms and a diverse range of entities. These entities often occur within ACs and co-occur in ARs, providing valuable cues for identifying ACs and ARs. Most of the existing approaches do not leverage these cues. This paper presents Ent-BAM, a BAM framework that incorporates entity (co-)occurrence information in a text-to-text generation paradigm. Plain text serves as the input, and the output is formatted in Augmented Natural Language (ANL). First, we employ a prompt-based strategy using a large language model (LLM) to extract (co-)occurred entities from the standard BAM dataset. Then, we construct the ANL output by embedding AC and AR labels, along with those extracted entities, within a single sequence. Ent-BAM significantly outperforms existing state-of-the-art (SoTA) methods by an average task margin of up to 4.86% Micro F1 Score, highlighting the strong potential of our approach.},
  archive      = {J_TAI},
  author       = {Nilmadhab Das and Yash Sunil Choudhary and V. Vijaya Saradhi and Ashish Anand},
  doi          = {10.1109/TAI.2025.3616076},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {10},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Ent-BAM: A generative framework for biomedical argument mining enriched with entity information},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Securing IoT: Unveiling attacks with multiview-multitask learning. <em>TAI</em>, 1-13. (<a href='https://doi.org/10.1109/TAI.2025.3615565'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid expansion and use of day-to-day IoT applications, cybercriminals are exploiting an increasingly wide attack surface and are capable of executing many successful attacks, leading to significant losses for individuals and organizations. The existing defense mechanisms often rely on single-view, single-task models that utilize a single feature set to perform one specific task. However, modern IoT systems are multifaceted, heterogeneous, and resource-constrained, posing considerable challenges for developing unified and scalable defense solutions. To address this, we propose a novel hybrid model called M2VT that integrates Multi-View Learning (MVL) and Multi-Task Learning (MTL) for effective cyber-attack defense. The model simultaneously processes three distinct subsets of relevant features (views) to perform three interrelated tasks: attack detection, attack category classification, and attack type classification. The model leverages AutoEncoder (AE) and Long Short-Term Memory (LSTM) networks to extract task-specific spatial and temporal features, enhancing both efficiency and cost-effectiveness. The M2VT model is evaluated using four publicly available IoT benchmark datasets and one testbed dataset. Across all tasks and datasets, the model achieves over 96% accuracy, consistently outperforming state-of-the-art approaches. The parallel execution of MVL and MTL, combined with taskspecific feature subsets, significantly boosts performance. The implementation of M2VT is publicly available in our code repository 1.},
  archive      = {J_TAI},
  author       = {Urkhimbam Boby Clinton and Nazrul Hoque and Shahid Raza and Monowar Bhuyan},
  doi          = {10.1109/TAI.2025.3615565},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {10},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Securing IoT: Unveiling attacks with multiview-multitask learning},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
