<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TC</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tc">TC - 17</h2>
<ul>
<li><details>
<summary>
(2025). BaDFL: Mitigating model poisoning in decentralized federated learning. <em>TC</em>, 1-12. (<a href='https://doi.org/10.1109/TC.2025.3603683'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decentralized federated learning (DFL) has gained significant attention due to its ability to facilitate collaborative model training without relying on a central server. However, it is highly vulnerable to backdoor attacks, where malicious participants can manipulate model updates to embed hidden functionalities. In this paper, we propose BaDFL, a novel Backdoor Attack defense mechanism for Decentralized Federated Learning. BaDFL enhances robustness by applying strategic model clipping at the local update level. To the best of our knowledge, BaDFL is the first decentralized federated learning algorithm with theoretical guarantees against model poisoning attacks. Specifically, BaDFL achieves an asymptotically optimal convergence rate of $O(\frac{1}{\sqrt{nT}})$, where n is the number of nodes and T is the global maximum iteration number. Furthermore, we provide a comprehensive analysis under two different attack scenarios, showing that BaDFL maintains robustness within a specific defense radius. Extensive experimental results show that, on average, BaDFL can effectively defend against model poisoning within 6 mitigation rounds, with less than a 1% drop in accuracy.},
  archive      = {J_TC},
  author       = {Yuan Yuan and Anhao Zhou and Xiao Zhang and Yifei Zou and Yangguang Shi and Dongxiao Yu},
  doi          = {10.1109/TC.2025.3603683},
  journal      = {IEEE Transactions on Computers},
  month        = {9},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Comput.},
  title        = {BaDFL: Mitigating model poisoning in decentralized federated learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ecomap: Sustainability-driven optimization of multi-tenant DNN execution on edge servers. <em>TC</em>, 1-13. (<a href='https://doi.org/10.1109/TC.2025.3604487'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge computing systems struggle to efficiently manage multiple concurrent deep neural network (DNN) workloads while meeting strict latency requirements, minimizing power consumption, and maintaining environmental sustainability. This paper introduces Ecomap, a sustainability-driven framework that dynamically adjusts the maximum power threshold of edge devices based on real-time carbon intensity. Ecomap incorporates the innovative use of mixed-quality models, allowing it to dynamically replace computationally heavy DNNs with lighter alternatives when latency constraints are violated, ensuring service responsiveness with minimal accuracy loss. Additionally, it employs a transformer-based estimator to guide efficient workload mappings. Experimental results using NVIDIA Jetson AGX Xavier demonstrate that Ecomap reduces carbon emissions by an average of 30% and achieves a 25% lower carbon delay product (CDP) compared to state-of-the-art methods, while maintaining comparable or better latency and power efficiency.},
  archive      = {J_TC},
  author       = {Varatheepan Paramanayakam and Andreas Karatzas and Dimitrios Stamoulis and Iraklis Anagnostopoulos},
  doi          = {10.1109/TC.2025.3604487},
  journal      = {IEEE Transactions on Computers},
  month        = {9},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Comput.},
  title        = {Ecomap: Sustainability-driven optimization of multi-tenant DNN execution on edge servers},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Low-storage verifiable data streaming with efficient revocation approach. <em>TC</em>, 1-12. (<a href='https://doi.org/10.1109/TC.2025.3604531'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Verifiable data streaming (VDS) is proposed to authenticate a sequence of ordered data, such that the misbehavior on the data returned by cloud server can be effectively detected. VDS also allows to efficiently replace the outsourced data by another value. However, the old authentication information can make the expired data pass the verification. To prevent this attack, VDS schemes must provide a revocation approach to revoke the old authentication information. The current approach employs the tree-like authentication structure or cryptographic accumulator, which will influence the efficiency of the VDS scheme. In this work, we find an approach to construct the low-storage VDS scheme supporting efficient revocation. Towards this end, we fully exploit the property of chameleon hash function with ephemeral trapdoor to propose a signature, which is the crucial step to construct the VDS scheme. In our VDS scheme, the size of the authentication information can be reduced to be less than the scale of the data streaming (i.e., low storage). Furthermore, the client is able to revoke the old authentication information in an efficient manner, where she only needs to release a message (i.e., efficient revocation). The performance evaluation shows that the proposed VDS scheme is efficient and practical.},
  archive      = {J_TC},
  author       = {Haining Yang and Dengguo Feng and Jing Qin},
  doi          = {10.1109/TC.2025.3604531},
  journal      = {IEEE Transactions on Computers},
  month        = {9},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Comput.},
  title        = {Low-storage verifiable data streaming with efficient revocation approach},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CoFormer: Collaborating with heterogeneous edge devices for scalable transformer inference. <em>TC</em>, 1-14. (<a href='https://doi.org/10.1109/TC.2025.3604473'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The impressive performance of transformer models has sparked the deployment of intelligent applications on resource-constrained edge devices. However, ensuring high-quality service for real-time edge systems is a significant challenge due to the considerable computational demands and resource requirements of these models. Existing strategies typically either offload transformer computations to other devices or directly deploy compressed models on individual edge devices. These strategies, however, result in either considerable communication overhead or suboptimal trade-offs between accuracy and efficiency. To tackle these challenges, we propose a collaborative inference system for general transformer models, termed CoFormer. The central idea behind CoFormer is to exploit the divisibility and integrability of transformer. An off-the-shelf large transformer can be decomposed into multiple smaller models for distributed inference, and their intermediate results are aggregated to generate the final output. We formulate an optimization problem to minimize both inference latency and accuracy degradation under heterogeneous hardware constraints. DeBo algorithm is proposed to first solve the optimization problem to derive the decomposition policy, and then progressively calibrate decomposed models to restore performance. We demonstrate the capability to support a wide range of transformer models on heterogeneous edge devices, achieving up to 3.1× inference speedup with large transformer models. Notably, CoFormer enables the efficient inference of GPT2-XL with 1.6 billion parameters on edge devices, reducing memory requirements by 76.3%. CoFormer can also reduce energy consumption by approximately 40% while maintaining satisfactory inference performance.},
  archive      = {J_TC},
  author       = {Guanyu Xu and Zhiwei Hao and Li Shen and Yong Luo and Fuhui Sun and Xiaoyan Wang and Han Hu and Yonggang Wen},
  doi          = {10.1109/TC.2025.3604473},
  journal      = {IEEE Transactions on Computers},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Comput.},
  title        = {CoFormer: Collaborating with heterogeneous edge devices for scalable transformer inference},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient conjunctive geometric range query over encrypted spatial data with learned index. <em>TC</em>, 1-14. (<a href='https://doi.org/10.1109/TC.2025.3604470'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing popularity of geo-positioning technologies and mobile Internet, spatial data query services have attracted extensive attention. To protect the confidentiality of sensitive information outsourced to cloud servers, much efforts have been devoted to designing geometric range query schemes over encrypted spatial data without affecting availability. However, existing works focus on the privacy-preserving schemes with traditional tree indexes, causing more computing and storage issues. In this paper, we propose an efficient conjunctive geometric range query scheme over encrypted spatial data with a learned index. In particular, we design a new privacy-preserving learned index for spatial data to reduce the search space and storage overhead. The main idea is to add noise disturbance to the objective function instead of directly adding it to output results, reducing the leakage of private information and ensuring the correctness of output results. Moreover, we propose a spatial segmentation algorithm to avoid accessing a large number of unnecessary Z codes in the query process. The formal security analysis shows that our scheme ensures index data security and query privacy. Simulation results show that the query efficiency is improved while the storage overhead is significantly reduced compared with the state-of-the-art schemes.},
  archive      = {J_TC},
  author       = {Mingyue Li and Chunfu Jia and Ruizhong Du and Guanxiong Ha},
  doi          = {10.1109/TC.2025.3604470},
  journal      = {IEEE Transactions on Computers},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Comput.},
  title        = {Efficient conjunctive geometric range query over encrypted spatial data with learned index},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). StageWise: Accelerating persistent key-value stores by thread model redesigning. <em>TC</em>, 1-14. (<a href='https://doi.org/10.1109/TC.2025.3605763'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the emergence of fast NVMe SSDs, key-value stores are becoming more CPU-efficient in order to reap their bandwidth. However, current CPU-optimized key-value stores adopt suboptimal intra- and inter-thread models, hence incurring memory-level stalling and load imbalance that hinder cores from realizing their full potential. We present STAGEWISE, an CPU-efficient key-value store on fast NVMe SSDs with high throughput. To achieve this, we introduce a new thread model for StageWise to process KV requests. Specifically, STAGEWISE converts the processing of each KV request into multiple asynchronous stages, and thus enables pipelining across all stages. STAGEWISE further introduces a client-driven share-index architecture to ease inter-thread load imbalance and maximize the pipelining opportunity. Guided by Little’s Law, STAGEWISE improves concurrency, and therefore efficiently uses CPU to reach higher throughput. Extensive experimental results show that STAGEWISE outperforms CPUoptimized key-value stores (e.g., KVell) by up to 3.5× with writeintensive workloads, and storage-optimized ones (e.g., RocksDB) by over an order of magnitude. STAGEWISE also shows higher read performance and excellent scalability under various workloads.},
  archive      = {J_TC},
  author       = {Zeqi Li and Youmin Chen and Qing Wang and Youyou Lu and Jiwu Shu},
  doi          = {10.1109/TC.2025.3605763},
  journal      = {IEEE Transactions on Computers},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Comput.},
  title        = {StageWise: Accelerating persistent key-value stores by thread model redesigning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Competition-style sorting networks (CSN): A framework for hardware-based sorting operations. <em>TC</em>, 1-14. (<a href='https://doi.org/10.1109/TC.2025.3605766'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sorting operations are considered to be a significant part of any computer system and are widely used in many applications. In applications where sorting has to be efficiently accomplished (i.e., in O(1) time) on small-sized entries, hardware accelerators, such as ASICs, FPGAs, or GPUs, are used to speed up the sorting operations. In the literature, the bitonic sort algorithm (or variants thereof) is still considered to be the most commonly used approach in many hardware sort implementations for decades. However, the time complexity of the bitonic sort is O((log(n))2) for sorting n elements, which does not satisfy the constant-time constraint we demand for our setting. In this paper, we propose competition-style sorting networks (CSNs), a framework for designing hardware-based competition-style class of sorting networks that captures all forms of two-stage sorting networks where the first stage (competition) consists of pairwise comparisons and the second stage (evaluation) ranks the entries and sorts them. To illustrate the utility of this framework, we develop and test one instance of this design, called the Competition Sort Algorithm (CSA), which has a time complexity of O(1), and specifically, one clock cycle. We implemented and tested CSA on both an Intel Cyclone V FPGA and the NVIDIA Quadro T1000 GPU then measured its gain, which combines the trade-offs between the relative speedup and the relative area increase, against the bitonic sort. Our results show that the CSA achieves a significant gain of up to 11.01× on the FPGA and a relative speedup of up to 3.32× on the GPU. We also compare the area, power, and latency of CSA with the bitonic sort algorithm on the FPGA.},
  archive      = {J_TC},
  author       = {Abbas A. Fairouz and Jassim M. Aljuraidan and Ameer Mohammed},
  doi          = {10.1109/TC.2025.3605766},
  journal      = {IEEE Transactions on Computers},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Comput.},
  title        = {Competition-style sorting networks (CSN): A framework for hardware-based sorting operations},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatial-temporal embodied carbon models with dual carbon attribution for embodied carbon accounting of computer systems. <em>TC</em>, 1-13. (<a href='https://doi.org/10.1109/TC.2025.3605743'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Embodied carbon is the carbon emissions in the manufacturing process of products, which dominates the overall carbon footprint in many industries. Existing studies derive the embodied carbon through life cycle analysis (LCA) reports. Current LCA reports only provide the carbon emission of a product class, e.g. 28nm CPU, whereas a product instance can be made in various regions and time periods. Carbon emissions depend on the electricity generation process, which has spatial-temporal dynamics. Therefore, the embodied carbon of a product instance can differ from its product class. Additionally, different carbon attribution methods (e.g., location-based and market-based) can affect the carbon emissions of electricity, thus further affecting the embodied carbon of products. In this paper, we present new Spatial-Temporal Embodied Carbon (STEC) accounting models with dual attribution methods. We observe significant differences between STEC and current models, e.g., for 7nm CPU the difference is 13.69%. We further examine the impact of STEC models on existing embodied carbon accounting schemes on computer applications, such as Large Language Model (LLM) training and LLM inference. We observe that using STEC results in much greater differences in the embodied carbon of certain applications as compared to others (e.g., 32.26% vs. 6.35%).},
  archive      = {J_TC},
  author       = {Xiaoyang Zhang and Yijie Yang and Dan Wang},
  doi          = {10.1109/TC.2025.3605743},
  journal      = {IEEE Transactions on Computers},
  month        = {9},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Comput.},
  title        = {Spatial-temporal embodied carbon models with dual carbon attribution for embodied carbon accounting of computer systems},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). OOLU: An operation-based optimized sparse LU decomposition accelerator for circuit simulation. <em>TC</em>, 1-14. (<a href='https://doi.org/10.1109/TC.2025.3605751'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As scientific and engineering challenges grow in complexity and scale, the demand for effective solutions for sparse matrix computations becomes increasingly critical. LU decomposition, known for its ability to reduce computational load and enhance numerical stability, serves as a promising approach. This study focuses on accelerating sparse LU decomposition for circuit simulations, addressing the prolonged simulation times caused by large circuit matrices. We present a novel Operation-based Optimized LU (OOLU) decomposition architecture that significantly improves circuit analysis efficiency. OOLU employs a VLIW-like processing element array and incorporates a scheduler that decomposes computations into a fine-grained operational task flow graph, maximizing inter-operation parallelism. Specialized scheduling and data mapping strategies are applied to align with the adaptable pipelined framework and the characteristics of circuit matrices. The OOLU architecture is prototyped on an FPGA and validated through extensive tests on the University of Florida sparse matrix collection, benchmarked against multiple platforms. The accelerator achieves speedups ranging from 3.48× to 32.25× (average 12.51×) over the KLU software package. It also delivers average speedups of 2.64× over a prior FPGA accelerator and 25.18× and 32.27× over the GPU accelerators STRUMPACK and SFLU, respectively, highlighting the substantial efficiency gains our approach delivers.},
  archive      = {J_TC},
  author       = {Ke Hu and Fan Yang},
  doi          = {10.1109/TC.2025.3605751},
  journal      = {IEEE Transactions on Computers},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Comput.},
  title        = {OOLU: An operation-based optimized sparse LU decomposition accelerator for circuit simulation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). JCSRC: Joint client selection and resource configuration for energy-efficient multi-task federated learning. <em>TC</em>, 1-14. (<a href='https://doi.org/10.1109/TC.2025.3605765'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) enables privacy-preserving distributed machine learning by training models on edge client devices using their local data without revealing their raw data. In edge environments, various applications require different neural network models, making it crucial to perform joint training of multiple models on edge devices, known as multi-task FL. While existing multi-task FL approaches enhance resource utilization on edge devices through adaptive resource configuration or client selection, optimizing either of these aspects alone may lead to suboptimality. Therefore, in this paper, we explore a joint client selection and resource configuration method called JCSRC for multi-task FL, aiming to maximize energy efficiency in environments with limited computation and communication resources and heterogeneous client devices. Firstly, we formalize this problem as a mixed-integer nonlinear programming problem considering all these characteristics and prove its NP-hardness. To address this problem, we first design a multi-agent reinforcement learning (MARL)-based client selection method that selects appropriate clients for each task to train their models. The MARL method makes client selection decisions based on the clients’ data quality, energy efficiency, communication, and computation capacity to ensure fast convergence and energy efficiency. Then, we design a particle swarm optimization (PSO)-based resource configuration scheme that configures appropriate computation and bandwidth resources for each task on each client. The PSO scheme makes resource configuration decisions based on theoretically derived optimal CPU frequency and bandwidth to achieve high energy efficiency. Finally, we carry out extensive simulations and testbed-based experiments to validate our proposed JCSRC. The results demonstrate that, in comparison to state-of-the-art solutions, JCSRC can save energy consumption by up to 59% to achieve the target accuracy.},
  archive      = {J_TC},
  author       = {Junpeng Ke and Junlong Zhou and Dan Meng and Yue Zeng and Yizhou Shi and Xiangmou Qu and Song Guo},
  doi          = {10.1109/TC.2025.3605765},
  journal      = {IEEE Transactions on Computers},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Comput.},
  title        = {JCSRC: Joint client selection and resource configuration for energy-efficient multi-task federated learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid approach to refine WCRT bounds for DAG scheduling using anomaly classification. <em>TC</em>, 1-14. (<a href='https://doi.org/10.1109/TC.2025.3603674'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by the performance demands and stringent timing requirements of safety-critical systems like avionics and autonomous vehicles, research has focused on providing timing guarantees for the scheduling of Directed Acyclic Graph (DAG) tasks in multicore systems. The structural complexity and timing anomalies make this problem challenging. Existing methods bound the Worst-Case Response Time (WCRT) of tasks through static analysis, but these bounds are complicated, difficult to validate, and often remain pessimistic for many scheduling scenarios. Runtime intervention can be effective in eliminating timing anomalies and providing timing guarantees; however, it is ineffective for anomaly-free scheduling scenarios, leads to non-work-conserving schedules, and incurs additional overhead. This paper proposes a hybrid approach to identify timing anomalies in DAG scheduling scenarios within a system, providing tighter WCRT solutions. The static analysis first offers a sufficient anomaly test to directly identify some anomaly-free DAG scheduling scenarios. Leveraging a wide range of scheduling data collected from the running system or its simulator, we then apply a machine learning approach to train a binary classification model, achieving an accuracy of 99.5%. Identifying the anomaly status enables the application of more precise WCRT bounds for different scheduling scenarios, leading to improved system performance. Specifically, we shorten the WCRT bounds for anomaly-free DAG scheduling by an average of up to 21.58%, with a maximum reduction of up to 55.47% compared to the state-of-the-art method.},
  archive      = {J_TC},
  author       = {Nan Chen and Xiaotian Dai and Alan Burns and Iain Bate},
  doi          = {10.1109/TC.2025.3603674},
  journal      = {IEEE Transactions on Computers},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Comput.},
  title        = {A hybrid approach to refine WCRT bounds for DAG scheduling using anomaly classification},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stochastic modeling of intrusion tolerant systems based on redundancy and diversity. <em>TC</em>, 1-14. (<a href='https://doi.org/10.1109/TC.2025.3606189'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To cope with unforeseen attacks to software systems in critical application domains, redundancy-based ITSs schemes are among popular countermeasures to deploy. Designing the adequate ITS for the stated security requirements calls for stochastic analysis supports, able to assess the impact of variety of attack patterns on different ITS configurations. As contribution to this purpose, a stochastic model for ITS is proposed, whose novel aspects are the ability to account for both camouflaging components and for correlation aspects between the security failures affecting the diverse implementations of the software cyber protections adopted in the ITS. Extensive analyses are conducted to show the applicability of the model; the obtained results allow to understand the limits and strengths of selected ITS configurations when subject to attacks occurring in unfavorable conditions for the defender.},
  archive      = {J_TC},
  author       = {Silvano Chiaradonna and Felicita Di Giandomenico and Giulio Masetti},
  doi          = {10.1109/TC.2025.3606189},
  journal      = {IEEE Transactions on Computers},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Comput.},
  title        = {Stochastic modeling of intrusion tolerant systems based on redundancy and diversity},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DIVIDE: Efficient RowHammer defense via in-DRAM cache-based hot data isolation. <em>TC</em>, 1-14. (<a href='https://doi.org/10.1109/TC.2025.3603729'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RowHammer poses a serious reliability challenge to modern DRAM systems. As technology scales down, DRAM resistance to RowHammer has decreased by 30× over the past decade, causing an increasing number of benign applications to suffer from this issue. However, existing defense mechanisms have three limitations: 1) they rely on inefficient mitigation techniques, such as time-consuming victim row refresh; 2) they do not reduce the number of effective RowHammer attacks, leading to frequent mitigations; and 3) they fail to recognize that frequently accessed data is not only a root cause of RowHammer but also presents an opportunity for performance optimization. In this paper, we observe that frequently accessed hot data plays a distinct role in security and efficiency: it can induce RowHammer by interfering with adjacent cold data, while also being performance-critical due to its frequent accesses. To this end, we propose Data Isolation via In-DRAM Cache (DIVIDE), a novel defense mechanism that leverages in-DRAM cache to isolate and exploit hot data. DIVIDE offers three key benefits: 1) It reduces the number of effective RowHammer attacks, as hot data in the cache cannot interfere with each other. 2) It provides a simple yet effective mitigation measure by isolating hot data from cold data. 3) It caches frequently accessed hot data, improving average access latency. DIVIDE employs a two-level protection structure: the first level mitigates RowHammer in cache arrays with high efficiency, while the second level addresses the remaining threats in normal arrays to ensure complete protection. Owing to the high in-DRAM cache hit rate, DIVIDE efficiently mitigates RowHammer while preserving both the performance and energy efficiency of the in-DRAM cache. At a RowHammer threshold of 128, DIVIDE with probabilistic mitigation achieves an average performance improvement of 19.6% and energy savings of 20.4% over DDR4 DRAM for fourcore workloads. Compared to an unprotected in-DRAM cache DRAM, DIVIDE incurs only a 2.1% performance overhead while requiring just a modest 1KB per-channel CAM in the memory controller, with no modification to the DRAM chip.},
  archive      = {J_TC},
  author       = {Haitao Du and Yuxuan Yang and Song Chen and Yi Kang},
  doi          = {10.1109/TC.2025.3603729},
  journal      = {IEEE Transactions on Computers},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Comput.},
  title        = {DIVIDE: Efficient RowHammer defense via in-DRAM cache-based hot data isolation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Practical signature-free multivalued validated byzantine agreement and asynchronous common subset in constant time. <em>TC</em>, 1-14. (<a href='https://doi.org/10.1109/TC.2025.3607476'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract—Asynchronous common subset (ACS) is a powerful paradigm enabling applications such as Byzantine fault-tolerance (BFT) and multi-party computation (MPC). The most efficient ACS framework in the information-theoretic setting is due to Ben-Or, Kelmer, and Rabin (BKR, 1994). The BKR ACS protocol has been both theoretically and practically impactful. BKR ACS has an O(log $n$) running time (where $n$ is the number of replicas) due to the usage of $n$ parallel asynchronous binary agreement (ABA) instances, impacting both performance and scalability. Indeed, for a network of 16∼64 replicas, the parallel ABA phase occupies about 95%∼97% of the total runtime. A long-standing open problem is whether we can build an ACS framework with O(1) time while not increasing the message or communication complexity of the BKR protocol. We resolve the open problem, presenting the first constant-time ACS protocol with O($n$3) messages in the information-theoretic and signature-free settings. Our key ingredient is the first information-theoretic and constant-time multivalued validated Byzantine agreement (MVBA) protocol. Our results can improveߞasymptotically and concretelyߞvarious applications using ACS and MVBA. As an example, we implement FIN, a BFT protocol instantiated using our framework. Via a 121-server deployment on Amazon EC2, we show FIN reduces the overhead of the ABA phase to as low as 1.23% of the total runtime.},
  archive      = {J_TC},
  author       = {Xin Wang and Xiao Sui and Sisi Duan and Haibin Zhang},
  doi          = {10.1109/TC.2025.3607476},
  journal      = {IEEE Transactions on Computers},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Comput.},
  title        = {Practical signature-free multivalued validated byzantine agreement and asynchronous common subset in constant time},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fluid kernels: Seamlessly conquering the embedded computing continuum. <em>TC</em>, 1-14. (<a href='https://doi.org/10.1109/TC.2025.3605745'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To achieve seamless portability across the embedded computing continuum, we introduce a new kernel architecture: fluid kernels. Fluid kernels can be thought of as the intersection between embedded unikernels and general purpose monolithic kernels, allowing to seamlessly develop applications both in kernel space and user space in a unified way. This scalable kernel architecture can manage the trade-off between performance, code size, isolation and security. We compare our fluid kernel implementation, Miosix, to Linux and FreeRTOS on the same hardware with standard benchmarks. Compared to Linux, we achieve an average speedup of 3.5× and a maximum of up to 15.4×. We also achieve an average code size reduction of 84% and a maximum of up to 90%. By moving application code from user space to kernel space, an additional code size reduction up to 56% and a speedup up to 1.3× can be achieved. Compared to FreeRTOS, the use of Miosix only costs a moderate amount of code size (at most 47KB) for significant advantages in application performance with speedups averaging at 1.5× and up to 5×.},
  archive      = {J_TC},
  author       = {Federico Terraneo and Daniele Cattaneo},
  doi          = {10.1109/TC.2025.3605745},
  journal      = {IEEE Transactions on Computers},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Comput.},
  title        = {Fluid kernels: Seamlessly conquering the embedded computing continuum},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightweight graph partitioning enhanced by implicit knowledge. <em>TC</em>, 1-14. (<a href='https://doi.org/10.1109/TC.2025.3612730'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph partitioning as a classic NP-complete problem, is the most fundamental procedure that needs to be performed before parallel computations. Partitioners can be divided into vertex- and edge-based approaches. Recently, both approaches are employing a streaming heuristic to find approximate solutions. It is lightweight in space and time complexities, but suffers from suboptimal partitioning quality, especially for directed graphs where the explicit knowledge provided for heuristic is limited. This paper thereby proposes new heuristics for not only vertex-based but also edge-based partitioning. They improve quality by additionally utilizing implicit knowledge, which is embedded in the local streaming view and the global graph view. Memory reduction techniques are presented to extract this knowledge with negligible space costs. That preserves the lightweight advantages of streaming partitioning. Besides, we study parallel acceleration and restreaming, to further boost the partitioning efficiency and quality. Extensive experiments validate that our proposals outperform the state-of-the-art competitors.},
  archive      = {J_TC},
  author       = {Zhigang Wang and Gongtai Sun and Ning Wang and Lixin Gao and Chuanfei Xu and Yu Gu and Ge Yu and Zhihong Tian},
  doi          = {10.1109/TC.2025.3612730},
  journal      = {IEEE Transactions on Computers},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Comput.},
  title        = {Lightweight graph partitioning enhanced by implicit knowledge},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ElasticEC: Achieving fast and elastic redundancy transitioning in erasure-coded clusters. <em>TC</em>, 1-13. (<a href='https://doi.org/10.1109/TC.2025.3614839'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Erasure coding has been extensively deployed in today’s commodity HPC systems against unexpected failures. To adapt to the varying access characteristics and reliability demands, storage clusters have to perform redundancy transitioning via tuning the coding parameters, which unfortunately gives rise to substantial transitioning traffic. We present ElasticEC, a fast and elastic redundancy transitioning approach for erasure-coded clusters. ElasticEC first minimizes the transitioning traffic via proposing a relocation-aware stripe reorganization mechanism and a collecting-and-encoding algorithm. It further heuristically balances the transitioning traffic across nodes. We implement ElasticEC in Hadoop HDFS and conduct extensive experiments on a real-world cloud storage cluster, showing that ElasticEC can reduce 71.1-92.6% of the transitioning traffic and shorten 65.9-90.7% of the transitioning time.},
  archive      = {J_TC},
  author       = {Yuhui Cai and Guowen Gong and Zhirong Shen and Jiahui Yang and Jiwu Shu},
  doi          = {10.1109/TC.2025.3614839},
  journal      = {IEEE Transactions on Computers},
  month        = {9},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Comput.},
  title        = {ElasticEC: Achieving fast and elastic redundancy transitioning in erasure-coded clusters},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
