<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TKDE</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tkde">TKDE - 20</h2>
<ul>
<li><details>
<summary>
(2025). Approximately unimodal likelihood models for ordinal regression. <em>TKDE</em>, 1-11. (<a href='https://doi.org/10.1109/TKDE.2025.3617386'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ordinal regression (OR, also called ordinal classification) is classification of ordinal data, in which the underlying target variable is categorical and considered to have a natural ordinal relation for the underlying explanatory variable. A key to successful OR models is to find a data structure ‘natural ordinal relation’ common to many ordinal data and reflect that structure into the design of those models. A recent OR study found that many real-world ordinal data show a tendency that the conditional probability distribution (CPD) of the target variable given a value of the explanatory variable will often be unimodal. Several previous studies thus developed unimodal likelihood models, in which a predicted CPD is guaranteed to become unimodal. However, it was also observed experimentally that many real-world ordinal data partly have values of the explanatory variable where the underlying CPD will be non-unimodal, and hence unimodal likelihood models may suffer from a bias for such a CPD. Therefore, motivated to mitigate such a bias, we propose approximately unimodal likelihood models, which can represent up to a unimodal CPD and a CPD that is close to be unimodal. We also verify experimentally that a proposed model can be effective for statistical modeling of ordinal data and OR tasks.},
  archive      = {J_TKDE},
  author       = {Ryoya Yamasaki},
  doi          = {10.1109/TKDE.2025.3617386},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Approximately unimodal likelihood models for ordinal regression},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ASSM: Adaptive subject-focused modeling for multimodal summarization via semantic matching. <em>TKDE</em>, 1-15. (<a href='https://doi.org/10.1109/TKDE.2025.3610544'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal Summarization aims to use multimodal data to generate accurate and concise summaries for long sentences. While previous work has achieved promising success, they have overlooked the mismatching among multimodal semantics and lacked subject information guidance for adaptive referential images. Motivated by this observation, we propose ASSM, an Adaptive Subject-focused modeling for multimodal summarization via Semantic Matching. The novelty of ASSM lies in two aspects. First, we propose a multimodal semantic matching module that projects multimodal inputs into a shared joint embedding semantic space to determine whether the semantics between multimodalities are mismatching. Second, we propose an adaptive subject-focused guide module, which adaptively references images to learn subject tokens based on the multimodal semantic matching results. With these subject tokens, we are able to focus on the subject information, providing precise guidance for summary generation. We conduct extensive experiments on two standard benchmarks and compare ASSM with 17 existing models. The experimental results regarding ROUGE, BERTScore, and MoverScore show that the proposed ASSM model outperforms all competitors, achieving state-of-the-art performance and suggesting the effectiveness of our proposal. In addition, we provide a case study to further demonstrate the usability of ASSM.},
  archive      = {J_TKDE},
  author       = {Xujian Zhao and Chuanpeng Deng and Peiquan Jin},
  doi          = {10.1109/TKDE.2025.3610544},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {ASSM: Adaptive subject-focused modeling for multimodal summarization via semantic matching},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey of large language models on generative graph analytics: Query, learning, and applications. <em>TKDE</em>, 1-20. (<a href='https://doi.org/10.1109/TKDE.2025.3609877'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A graph is a fundamental data model to represent various entities and their complex relationships in society and nature, such as social networks, transportation networks, financial networks, and biomedical systems. Recently, large language models (LLMs) have showcased a strong generalization ability to handle various natural language processing tasks to answer users' arbitrary questions and generate specific-domain content. Compared with graph learning models, LLMs enjoy superior advantages in addressing the challenges of generalizing graph tasks by eliminating the need for training graph learning models and reducing the cost of manual annotation. However, LLMs are sequential models for textual data, but graphs are non-sequential topological data. It is challenging to adapt LLMs to tackle graph analytics tasks. In this survey, we conduct a comprehensive investigation of existing LLM studies on graph data, which summarizes the relevant graph analytics tasks solved by advanced LLM models and points out the existing challenges and future directions. Specifically, we study the key problems of LLM-based generative graph analytics (LLM-GGA) in terms of three categories: LLM-based graph query processing (LLM-GQP), LLM-based graph inference and learning (LLM-GIL), and graph-LLM-based applications. LLM-GQP focuses on an integration of graph analytics techniques and LLM prompts, including graph understanding and knowledge graphs and LLMs, while LLM-GIL focuses on learning and reasoning over graphs, including graph learning, graph-formed reasoning, and graph representation. We summarize the useful prompts incorporated into LLM to handle different graph downstream tasks. Moreover, we give a summary of LLM model evaluation, benchmark datasets/tasks, and a deep pro and cons analysis of the discussed LLM-GGA models. We also explore open problems and future directions in this exciting interdisciplinary research area of LLMs and graph analytics.},
  archive      = {J_TKDE},
  author       = {Wenbo Shang and Xin Huang},
  doi          = {10.1109/TKDE.2025.3609877},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  pages        = {1-20},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A survey of large language models on generative graph analytics: Query, learning, and applications},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive hyper-box granulation with justifiable granularity for feature selection. <em>TKDE</em>, 1-15. (<a href='https://doi.org/10.1109/TKDE.2025.3617583'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering as a fundamental technique in data mining and machine learning, aims to partition data into meaningful groups based on the inherent relationships among data. However, traditional clustering algorithms typically assume convex hyperspherical geometry of data, where the clusters have clearly defined boundaries and do not overlap. In contrast, real-world data often exhibits complex and non-convex geometries, which makes these assumptions ineffective and lead to inaccurate clustering results that fail to capture the intrinsic structure. To address this challenge, the paper proposes a novel granular clustering based on an enhanced granularity representation, which further refines the principle of justifiable granularity. By introducing a more precise and flexible hyper-box granulation mechanism, the method dynamically adapts to the topology of data, thereby improving clustering accuracy. By defining the degree of aggregation and discreteness between data points, the importance of attributes in the feature space is quantified, leading to the design of a novel hyper-box feature selection (HBFS) algorithm. This algorithm integrates the granular clustering principle to optimize the feature selection process, reducing the impact of redundant features and noise, thus improving clustering efficiency and interpretability. To validate the superiority and effectiveness of the proposed method, extensive experiments were conducted on fifteen publicly available datasets, comparing the performance of HBFS algorithm with classical and state-of-art feature selection methods. The results and the statistical significance tests show that HBFS significantly outperforms existing feature selection methods across various evaluation metrics.},
  archive      = {J_TKDE},
  author       = {Wentao Li and Bowen Yang and Witold Pedrycz and Chao Zhang and Tao Zhan},
  doi          = {10.1109/TKDE.2025.3617583},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Adaptive hyper-box granulation with justifiable granularity for feature selection},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph2Region: Efficient graph similarity learning with structure and scale restoration. <em>TKDE</em>, 1-13. (<a href='https://doi.org/10.1109/TKDE.2025.3617461'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph similarity is critical in graph-related tasks such as graph retrieval, where metrics like maximum common subgraph (MCS) and graph edit distance (GED) are commonly used. However, exact computations of these metrics are known to be NP-Hard. Recent neural network-based approaches approximate the similarity score in embedding spaces to alleviate the computational burden, but they either involve expensive pairwise node comparisons or fail to effectively utilize structural and scale information of graphs. To tackle these issues, we propose a novel geometric-based graph embedding method called Graph2Region (G2R). G2R represents nodes as closed regions and recovers their adjacency patterns within graphs in the embedding space. By incorporating the node features and adjacency patterns of graphs, G2R summarizes graph regions, i.e., graph embeddings, where the shape captures the underlying graph structures and the volume reflects the graph size. Consequently, the overlap between graph regions can serve as an approximation of MCS, signifying similar node regions and adjacency patterns. We further analyze the relationship between MCS and GED and propose using disjoint parts as a proxy for GED similarity. This analysis enables concurrent computation of MCS and GED, incorporating local and global structural information. Experimental evaluation highlights G2R's competitive performance in graph similarity computation. It achieves up to a 60.0% relative accuracy improvement over state-of-the-art methods in MCS similarity learning, while maintaining efficiency in both training and inference. Moreover, G2R showcases remarkable capability in predicting both MCS and GED similarities simultaneously, providing a holistic assessment of graph similarity.},
  archive      = {J_TKDE},
  author       = {Zhouyang Liu and Yixin Chen and Ning Liu and Jiezhong He and Dongsheng Li},
  doi          = {10.1109/TKDE.2025.3617461},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Graph2Region: Efficient graph similarity learning with structure and scale restoration},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning accurate representation to nonstandard tensors via a mode-aware tucker network. <em>TKDE</em>, 1-14. (<a href='https://doi.org/10.1109/TKDE.2025.3617894'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A nonstandard tensor is frequently adopted to model a large-sale complex dynamic network. A Tensor Representation Learning (TRL) model enables extracting valuable knowledge form a dynamic network via learning low-dimensional representation of a target nonstandard tensor. Nevertheless, the representation learning ability of existing TRL models are limited for a nonstandard tensor due to its inability to accurately represent the specific nature of the nonstandard tensor, i.e., mode imbalance, high-dimension, and incompleteness. To address this issue, this study innovatively proposes a Mode-Aware Tucker Networkbased Tensor Representation Learning (MTN-TRL) model with three-fold ideas: a) designing a mode-aware Tucker network to accurately represent the imbalanced mode of a nonstandard tensor, b) building an MTN-based high-efficient TRL model that fuses both data density-oriented modeling principle and adaptive parameters learning scheme, and c) theoretically proving the MTN-TRL model's convergence. Extensive experiments on eight nonstandard tensors generating from real-world dynamic networks demonstrate that MTN-TRL significantly outperforms state-of-the-art models in terms of representation accuracy.},
  archive      = {J_TKDE},
  author       = {Hao Wu and Qu Wang and Xin Luo and Zidong Wang},
  doi          = {10.1109/TKDE.2025.3617894},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Learning accurate representation to nonstandard tensors via a mode-aware tucker network},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A geometric approach to $k$-means clustering. <em>TKDE</em>, 1-13. (<a href='https://doi.org/10.1109/TKDE.2025.3616858'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {$k$-meansclustering is a fundamental problem in many scientific and engineering domains. The optimization problem associated with $k$-means clustering is nonconvex, for which standard algorithms are only guaranteed to find a local optimum. Leveraging the hidden structure of local solutions, we propose a general algorithmic framework for escaping undesirable local solutions and recovering the global solution or the ground truth clustering. This framework consists of iteratively alternating between two steps: (i) detect mis-specified clusters in a local solution, and (ii) improve the local solution by non-local operations. We discuss specific implementation of these steps, and elucidate how the proposed framework unifies many existing variants of $k$-means algorithms through a geometric perspective. We also present two natural variants of the proposed framework, where the initial number of clusters may be over- or under-specified. We provide theoretical justifications and extensive experiments to demonstrate the efficacy of the proposed approach.},
  archive      = {J_TKDE},
  author       = {Jiazhen Hong and Wei Qian and Yudong Chen and Yuqian Zhang},
  doi          = {10.1109/TKDE.2025.3616858},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A geometric approach to $k$-means clustering},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning from graph-graph relationship: A new perspective on graph-level anomaly detection. <em>TKDE</em>, 1-14. (<a href='https://doi.org/10.1109/TKDE.2025.3618929'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph-level anomaly detection (GLAD) aims to distinguish anomalous graphs that exhibit significant deviations from others. The graph-graph relationship, revealing the deviation and similarity between graphs, offers global insights into the entire graph level for highlighting the anomalies' divergence from normal graph patterns. Thus, understanding graph-graph relationships is critical to boosting models on GLAD tasks. However, existing deep GLAD algorithms heavily rely on Graph Neural Networks that primarily focus on analyzing individual graphs. These methods overlook the significance of graph-graph relationships in telling anomalies from normal graphs. In this paper, we propose a novel model for Graph-level Anomaly Detection using the Transformer technique, namely GADTrans. Specifically, GADTrans build the transformer upon crucial subgraphs mined by a parametrized extractor, for modeling precise graph-graph relationships. The learned graph-graph relationships put effort into distinguishing normal and anomalous graphs. In addition, a specific loss is introduced to guide GADTrans in highlighting the deviation between anomalous and normal graphs while underlining the similarities among normal graphs. GADTrans achieves model interpretability by delivering human-interpretable results, which are learned graph-graph relationships and crucial subgraphs. Extensive experiments on six real-world datasets verify the effectiveness and superiority of GADTrans for GLAD tasks.},
  archive      = {J_TKDE},
  author       = {Zhenyu Yang and Ge Zhang and Jia Wu and Jian Yang and Hao Peng and Pietro Liò},
  doi          = {10.1109/TKDE.2025.3618929},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Learning from graph-graph relationship: A new perspective on graph-level anomaly detection},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A universal physics-informed neural network framework for predicting network dynamics: From lower-order to higher-order. <em>TKDE</em>, 1-14. (<a href='https://doi.org/10.1109/TKDE.2025.3618834'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately predicting the complex networks dynamics is a challenging task. Many studies have shown that data-driven frameworks offer promising solutions to this issue. However, existing approaches still face significant limitations, particularly when network structures evolve from lower-order to higher-order networks, or when the dynamical equation of the network is governed by multiple dynamical terms, such as local self-dynamics, lower-order and higher-order coupling dynamics. To this end, we propose a universal physics-informed neural network framework capable of predicting various types of dynamics on both lower- and higher-order networks. First, the framework captures and integrates more nonlinear features through the higher-order term expansion module. Second, we design a hybrid neural network module to differentially learn each dynamical term to comprehensively capture network dynamics. Finally, a physics-informed loss function construction module is introduced to integrate differential loss with prediction loss, improving the accuracy of network dynamical prediction. Experimental results indicate that our method outperforms the state-of-the-art approaches in predicting network dynamics on both lower- and higher-order networks. Ablation studies confirm the critical role of each module. In addition, our method also performs well on real-world dynamical processes, which shows that it remains robust to real complex scenarios.},
  archive      = {J_TKDE},
  author       = {Xiao Ding and Xingyi Zhang and Hai-Feng Zhang},
  doi          = {10.1109/TKDE.2025.3618834},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A universal physics-informed neural network framework for predicting network dynamics: From lower-order to higher-order},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Breaking information granularity heterogeneity: A mutual information-inspired causal discovery framework for multi-rate time series. <em>TKDE</em>, 1-14. (<a href='https://doi.org/10.1109/TKDE.2025.3618763'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal discovery in multi-rate time series encounters greater challenges compared to regular time series. This stems from a potential problem that has not been noticed and explored in existing studies: information granularity heterogeneity, which refers to the natural difference in information granularity between fast sampling rate data (high information granularity) and slow sampling rate data (low information granularity). Such an imbalance in information granularity can hinder forecasting relationships modeling and induce biased causal learning. Therefore, we propose a Mutual Information-iNspired causal Discovery framework (MIND), aiming to derive rate-agnostic features with consistent information granularity to alleviate information granularity heterogeneity problem. Technically, MIND comprises Stage 1 (pre-training) and Stage 2 (fine-tuning and causal discovery). In Stage 1, empowered by pseudo-slow sampling rate data (generated through the interleaved down sampling strategy) and mutual information, we can eliminate the influence of sampling rates and drive rate-aware encoders (RAEs) to sense key information (i.e., rate-agnostic) that remains unchanged across varying sampling rates. In Stage 2, the well-trained RAEs can extract rate-agnostic features from real multi-rate time series, thus facilitating effective forecasting relationships modeling and yield accurate causal discovery. Empirically, MIND realizes superior performance on various multi-rate scenarios, including four simulation datasets and one real-world dataset.},
  archive      = {J_TKDE},
  author       = {Kun Zhu and Chunhui Zhao and Biao Huang},
  doi          = {10.1109/TKDE.2025.3618763},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Breaking information granularity heterogeneity: A mutual information-inspired causal discovery framework for multi-rate time series},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DBCGM: A granular model for big data classification based on data bisection and cascade weighted clustering. <em>TKDE</em>, 1-15. (<a href='https://doi.org/10.1109/TKDE.2025.3618784'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Researchers confront significant challenges when classifying and modeling data due to the growing system complexity, data volume, and requirement for accurate and reliable models. Information granules, a fundamental component of Granular Computing (GrC), play a crucial role in human cognition. In this study, we develop a granular classifier called DBCGM, which facilitates delivering models with improved accuracy and efficiency in big data classification. In particular, DBCGM achieves the goal through the following four steps. First, we construct a 1-D index for each point and then utilize a context-based data bisection method to obtain non-overlapping subsets. These disjoint subsets enhance both the quality and efficiency of big data clustering and make it possible to process the entire dataset simultaneously. Next, we propose a cascade weighted clustering (CWC) algorithm to generate numeric prototypes from the obtained subsets. Then, following the principle of justification granularity (PJG), the numeric prototypes are refined into information granules. Finally, the classifier can be regarded as the weighted sum of all the values of the spatial relationship between the input instance and the information granules. We evaluate the performance of DBCGM in terms of accuracy, V-measure, and execution time. We compare DBCGM with benchmark classifiers and three big data granulating methods. Experimental results on both synthetic and public datasets show that DBCGM outperforms the existing methods. In particular, compared with the state-of-the-art method, DBCGM reduces the running time by an average of 2.55%, and improves the V-measure and accuracy by an average of 5.71% and 2.32%, respectively.},
  archive      = {J_TKDE},
  author       = {Jiande Huang and Yuhui Deng and Yi Zhou and Shujie Pang and Qifen Yang and Geyong Min},
  doi          = {10.1109/TKDE.2025.3618784},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {DBCGM: A granular model for big data classification based on data bisection and cascade weighted clustering},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An event-centric framework for predicting crime hotspots with flexible time intervals. <em>TKDE</em>, 1-14. (<a href='https://doi.org/10.1109/TKDE.2025.3618389'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting crime hotspots in a city is a complex and critical task with significant societal implications. Numerous spatiotemporal correlations and irregularities pose substantial challenges to this endeavor. Existing methods commonly employ fixed-time granularities and sequence prediction models. However, determining appropriate time granularities is difficult, leading to inaccurate predictions for specific time windows. For example, users might ask: What are the crime hotspots during [12:00-20:00]? To address this issue, we introduce ${\sf FlexiCrime}$, a novel event-centric framework for predicting crime hotspots with flexible time intervals. ${\sf FlexiCrime}$ incorporates a continuous-time attention network to capture correlations between crime events, which learns crime context features, representing general crime patterns across time points and locations. Furthermore, we introduce a type-aware spatiotemporal point process that learns crime-evolving features, measuring the risk of specific crime types at a given time and location by considering the frequency of past crime events. Together, the crime context and evolving features allow us to predict whether an urban area is a crime hotspot given a future time interval. To evaluate ${\sf FlexiCrime}$'s effectiveness, we conducted experiments using real-world datasets from two cities, covering twelve crime types. The results show that our model outperforms baseline techniques in predicting crime hotspots over flexible time intervals.},
  archive      = {J_TKDE},
  author       = {Jiahui Jin and Yi Hong and Guandong Xu and Jinghui Zhang and Jun Tang and Hancheng Wang},
  doi          = {10.1109/TKDE.2025.3618389},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {An event-centric framework for predicting crime hotspots with flexible time intervals},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Behavior merging graph convolution network for multi-behavior recommendation. <em>TKDE</em>, 1-14. (<a href='https://doi.org/10.1109/TKDE.2025.3618466'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Encoding multi-behavior information into a single graph collaborative filtering vector is an emerging challenge, as different behaviors generate distinct graphs, each with its own embedding vector. To address this problem, recent approaches typically designate the embedding of some behaviors as primary embeddings and use the embeddings of other behaviors to enhance the primary behavior recommendation. However, these models may excel in recommending primary behaviors at the expense of degrading the performance of auxiliary behaviors. As a result, modern recommender systems often need to maintain multiple sets of collaborative filtering embeddings to achieve satisfactory recommendation performance across all behaviors. To alleviate this issue, we introduce the Behavior Merging Graphs. Instead of modeling each behavior separately, BMG uses a joint graph to capture potential behavior merging sets between nodes and applies the partial order theory to model the intricate structures and relational order among behavior merging sets. Based on BMG, we introduce the Behavior Merging Graphs Convolutional Networks (BMGCN), which aggregates neighbor information by integrating convolutional weights that account for the rank transformation of Behavior Merging Order across various behavior merging sets. Furthermore, BMGCN employs behavior merging-based sampling to guide the traditional BPR sampling process, enhancing embedding training. Experiments on three widely used datasets demonstrate that BMGCN achieves superior multi-behavior recommendation performance compared to state-of-the-art baselines.},
  archive      = {J_TKDE},
  author       = {Hao Chen and Zhiqing Li and Yuanchen Bei and Kai Xu and Yijie Zhang and Feiran Huang and Yu Yang and Huan Gong and Fakhri Karray},
  doi          = {10.1109/TKDE.2025.3618466},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Behavior merging graph convolution network for multi-behavior recommendation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Private-set-intersection-based medical data sharing scheme with integrity auditing for IoMT cloud storage systems. <em>TKDE</em>, 1-12. (<a href='https://doi.org/10.1109/TKDE.2025.3619426'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the medical industry is generating a large amount of data. How to securely store and reliably share these medical data has been a hot research topic. Cloud storage technology can be applied to the medical industry to adapt to the rapid growth of medical data. However, cloud-based data storage and sharing systems face a series of security issues: whether the integrity of outsourced medical data can be guaranteed, and malicious access between different medical institutions may leak user's privacy. This article proposes a system that simultaneously solves the integrity auditing of medical data and securely data sharing between different medical institutions under the terminal-edge-cloud framework. Specifically, patients/doctors are treated as terminal users, medical institutions are viewed as edge nodes, and medical clouds form the central storage layer. In the process of data auditing, third-party auditor can achieve integrity auditing of medical cloud storage data. Moreover, different medical institutions use private-set-intersection technology to share the common user's electronic medical data, while for other users not in intersection set, their data does not need to be shared. Finally, security and performance analyses show that our proposed system is provable secure and has high computational and communication efficiency.},
  archive      = {J_TKDE},
  author       = {Zekun Li and Jinyong Chang and Bei Liang and Kaijing Ling and Yifan Dong and Yanyan Ji and Maozhi Xu},
  doi          = {10.1109/TKDE.2025.3619426},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Private-set-intersection-based medical data sharing scheme with integrity auditing for IoMT cloud storage systems},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). OMCR: An online multivariate forecaster for cloud resource management. <em>TKDE</em>, 1-14. (<a href='https://doi.org/10.1109/TKDE.2025.3619097'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A precise workload forecaster is the key to effective resource management, system scalability, and overall operational efficiency in cloud environments. However, real-world cloud systems frequently operate in dynamic and unpredictable settings, causing workloads that exhibit significant diversity and fluctuations. To address these problems, we introduce OMCR, a novel online multivariate forecaster for cloud resource management, that overcomes the limitations of existing static forecasting methods through online learning. OMCR integrates long-term memory with a rapid response mechanism to short-term changes in cloud systems, while also considering the impact of multivariate relationships on workload prediction. OMCR minimizes its reliance on historical data, thereby reducing training difficulty and maintaining lower prediction loss in the long run. OMCR also offers an adaptive approach to forecasting peak workloads in a certain time span, which helps cloud resource management. Experimental results demonstrate the superior performance of our proposed framework compared to state-of-the-art methods in MAE and MSE metrics when forecasting cloud workloads.},
  archive      = {J_TKDE},
  author       = {Xu Gao and Xiu Tang and Chang Yao and Sai Wu and Gongsheng Yuan and Wenchao Zhou and Feifei Li and Gang Chen},
  doi          = {10.1109/TKDE.2025.3619097},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {OMCR: An online multivariate forecaster for cloud resource management},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attentive continuous-time generative adversarial networks for irregular time series imputation. <em>TKDE</em>, 1-14. (<a href='https://doi.org/10.1109/TKDE.2025.3617659'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series are widely used in many classification and regression tasks. However, numerous time series contain unavoidable missing data, making it challenging to model the temporal dynamics of sequential data. Various data imputation methods have been proposed to infer missing values in time series. Although sequences recorded at fixed time intervals are presented in discrete form, they possess an inherent temporal continuity, which is ignored in most existing approaches. In this paper, we propose an end-to-end Attentive Continuous-Time Generative Adversarial Network (ACGANet) to estimate unobserved values in irregular sequences. ACGANet captures the temporal dynamics by transforming the discrete sequence into the continuous-time flow, thereby modeling the underlying distribution of the real data. Furthermore, ACGANet employs an adversarial learning strategy to alleviate the error introduced by imputed values, with the discriminator distinguishing between real and generated samples. Additionally, ACGANet introduces the log-density of hidden temporal states as an auxiliary loss to further optimize the generator. This allows the model to simultaneously focus on the overall temporal dynamics of the time series and the underlying distribution of the missing data. Extensive experiments on three publicly available real-world datasets demonstrate that ACGANet achieves state-of-the-art performance in imputing incomplete time series. Moreover, both qualitative and quantitative analyses validate the effectiveness of the proposed model.},
  archive      = {J_TKDE},
  author       = {Yakun Wang and Yisheng Zou and Songlin He and Linfu Sun and Gang Wang},
  doi          = {10.1109/TKDE.2025.3617659},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Attentive continuous-time generative adversarial networks for irregular time series imputation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EIGA: A novel genetic algorithm based on edge information for community detection in weighted social networks. <em>TKDE</em>, 1-14. (<a href='https://doi.org/10.1109/TKDE.2025.3619494'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community Detection (CD) in weighted social networks is a highly active research field, celebrated for its profound practical implications across a multitude of disciplines. Genetic algorithms (GAs) are frequently explored to tackle CD problems, leveraging their capability to navigate the extensive discrete search space effectively. Throughout the evolutionary process, genetic operators such as crossover and mutation assume pivotal roles in effectively exploring the vast solution space. Nonetheless, prevailing GA-based approaches often ignore crucial topology information, particularly information regarding edge weights, resulting in compromised algorithm performance. In light of this, this paper introduces Edge Information-based GA (EIGA) to effectively solve CD problems in weighted networks. This is achieved specifically through the innovative designs of edgeweight-aware crossover and mutation operators. These novel edge-weight-aware operators improve the extraction of meaningful community structures, advancing knowledge discovery from social networks. Empirical findings demonstrate the superior performance of EIGA over numerous state-of-the-art algorithms across various real-world and synthetic benchmark networks.},
  archive      = {J_TKDE},
  author       = {Anjali de Silva and Gang Chen and Hui Ma and Seyed Mohammad Nekooei},
  doi          = {10.1109/TKDE.2025.3619494},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {EIGA: A novel genetic algorithm based on edge information for community detection in weighted social networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BPL: Bias-adaptive preference distillation learning for recommender system. <em>TKDE</em>, 1-12. (<a href='https://doi.org/10.1109/TKDE.2025.3619575'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems suffer from biases that cause the collected feedback to incompletely reveal user preference. While debiasing learning has been extensively studied, they mostly focused on the specialized (called counterfactual) test environment simulated by random exposure of items, significantly degrading accuracy in the typical (called factual) test environment based on actual user-item interactions. In fact, each test environment highlights the benefit of a different aspect: the counterfactual test emphasizes user satisfaction in the long-terms, while the factual test focuses on predicting subsequent user behaviors on platforms. Therefore, it is desirable to have a model that performs well on both tests rather than only one. In this work, we introduce a new learning framework, called Bias-adaptive Preference distillation Learning (BPL), to gradually uncover user preferences with dual distillation strategies. These distillation strategies are designed to drive high performance in both factual and counterfactual test environments. Employing a specialized form of teacher-student distillation from a biased model, BPL retains accurate preference knowledge aligned with the collected feedback, leading to high performance in the factual test. Furthermore, through self-distillation with reliability filtering, BPL iteratively refines its knowledge throughout the training process. This enables the model to produce more accurate predictions across a broader range of user-item combinations, thereby improving performance in the counterfactual test. Comprehensive experiments validate the effectiveness of BPL in both factual and counterfactual tests.},
  archive      = {J_TKDE},
  author       = {SeongKu Kang and Jianxun Lian and Dongha Lee and Wonbin Kweon and Sanghwan Jang and Jaehyun Lee and Jindong Wang and Xing Xie and Hwanjo Yu},
  doi          = {10.1109/TKDE.2025.3619575},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {BPL: Bias-adaptive preference distillation learning for recommender system},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A data-driven scale-adaptive time-frequency convolutional network for long sequence time-series forecasting. <em>TKDE</em>, 1-14. (<a href='https://doi.org/10.1109/TKDE.2025.3619521'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Models based on Transformer variants have consistently demonstrated leading performance in long sequence time series forecasting. However, in some complex application scenarios, Transformers tend to capture low-frequency information in the data while overlooking high-frequency information, which often contains rich non-stationary features. This unbalanced feature extraction approach limits the model's ability to effectively handle real-world time series data. To address this issue, we explicitly represent both low-frequency and high-frequency information and propose a model called STCNet, a data-driven scale-adaptive convolutional network that aims to extract diverse features and patterns from the data by learning features across different frequency bands in a balanced manner. Specifically, we propose an entropy-based adaptive wavelet basis selection algorithm, which can adaptively select appropriate wavelet bases based on the data distribution to achieve effective multi-frequency decomposition of complex time series. In addition, we designed a hierarchical scale-adaptive factor that allows for dynamic adjustment of feature weights according to different time scales through refined layered weight adjustment, significantly enhancing the model's capability in handling non-stationary time series features. To further optimize the output features of the model, we introduce a test-time training mechanism, combined with a fast weight update strategy and a weight-sharing strategy to reduce the number of model parameters, effectively mitigating the risk of overfitting. Experimental results on nine datasets demonstrate that STCNet outperforms the current state-of-the-art models in both effectiveness and efficiency.},
  archive      = {J_TKDE},
  author       = {Zhiqiang Zhang and Weiqing Wang and Xin Zhou and Yu Bai and Hongzhi Yin},
  doi          = {10.1109/TKDE.2025.3619521},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A data-driven scale-adaptive time-frequency convolutional network for long sequence time-series forecasting},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Few-shot knowledge graph completion with adaptive negative sampling mechanism. <em>TKDE</em>, 1-16. (<a href='https://doi.org/10.1109/TKDE.2025.3614171'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot knowledge graph completion (few-shot KGC) mines unseen knowledge by leveraging meta-learning and contrastive learning to achieve accurate predictions with limited triples. Recent studies have focused on designing distance or similarity metrics to provide better knowledge representation between entities and relations. However, three issues with negative sampling remain unexplored: 1) the construction of negative queries heavily relies on manual experience in selecting candidate tail entities, 2) the constructed negative queries may mislabel potential true facts, and 3) the varying difficulties of negative queries are ignored. To solve the above issues, in this paper, we introduce curriculum learning into few-shot KGC and propose a novel few-shot KGC framework empowered by an adaptive negative sampling mechanism, which can eliminate the dependence on any additional manual experience, reduce mislabeling, and generate negative queries with appropriate difficulty. Specifically, the proposed framework includes two alternating phases. In the negative sampling phase, we first design a novel positive-unlabeled learning based scoring function with a type-related candidates encoder and then build a variable-speed sliding window based pacing function to select negative queries with appropriate learning difficulty under current training step. In the meta-training phase, we develop an adapted triple-oriented knowledge encoder to provide accurate representation for queries. Experimental results demonstrate that the proposed framework outperforms the state-of-the-art baselines and provides negative queries with appropriate difficulty in few-shot KGC.},
  archive      = {J_TKDE},
  author       = {Jiaao Yu and Lanlan Rui and Yijing Lin and Zhipeng Gao and Xuesong Qiu and Shaoyong Guo},
  doi          = {10.1109/TKDE.2025.3614171},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {10},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Few-shot knowledge graph completion with adaptive negative sampling mechanism},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
