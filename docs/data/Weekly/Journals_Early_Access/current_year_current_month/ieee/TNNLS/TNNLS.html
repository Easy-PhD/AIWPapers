<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TNNLS</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tnnls">TNNLS - 27</h2>
<ul>
<li><details>
<summary>
(2025). Learning counterfactual fair representation under covariate shift via reflux. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3613549'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in counterfactual fairness have shifted focus from flawed group fairness metrics to ensuring individual-level fairness through counterfactual reasoning. However, most existing approaches remain limited to in-processing strategies—injecting fairness constraints into predictive models—while largely overlooking the potential of data preprocessing to mitigate inherent biases. Moreover, few methods address the critical challenge of real-world distribution shift, which can compromise the generalizability of fair models across domains. In this article, we propose the counterfactual reflux variational autoencoder (CRVAE), a novel framework for generating counterfactual samples and learning fair representations. To the best of our knowledge, this is the first work to explicitly consider counterfactual fair representation learning under covariate shift, enabling both single-domain and covariate shift prediction tasks. For fairness, we introduce a Reflux technique that enforces consistency between factual and counterfactual representations. For transferability, we incorporate a domain discriminator to align fair representations across domains. Experimental results show that our approach improves fairness with minimal performance loss and maintains generalization across domains. Furthermore, CRVAE can be flexibly combined with existing in-processing fairness methods. Future work may explore extending this framework to settings with limited causal graph knowledge.},
  archive      = {J_TNNLS},
  author       = {Yiliang Xia and Xiaohang Zhang and Zhengren Li},
  doi          = {10.1109/TNNLS.2025.3613549},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Learning counterfactual fair representation under covariate shift via reflux},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unbiased semantic decoding with vision foundation models for few-shot segmentation. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3611497'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot segmentation (FSS) has garnered significant attention. Many recent approaches attempt to introduce the segment anything model (SAM) to handle this task. With the strong generalization ability and rich object-specific extraction ability of the SAM model, such a solution shows great potential in FSS. However, the decoding process of SAM highly relies on accurate and explicit prompts, making previous approaches mainly focus on extracting prompts from the support set, which is insufficient to activate the generalization ability of SAM, and this design is easy to result in a biased decoding process when adapting to the unknown classes. In this work, we propose an unbiased semantic decoding (USD) strategy integrated with SAM, which extracts target information from both the support and query set simultaneously to perform consistent predictions guided by the semantics of the contrastive language-image pretraining (CLIP) model. Specifically, to enhance the unbiased semantic discrimination of SAM, we design two feature enhancement strategies that leverage the semantic alignment capability of CLIP to enrich the original SAM features, mainly including a global supplement at the image level to provide a generalize category indicate with support image and a local guidance at the pixel level to provide a useful target location with query image. Besides, to generate target-focused prompt embeddings, a learnable visual–text target prompt generator (VTPG) is proposed by interacting target text embeddings and clip visual features. Without requiring retraining of the vision foundation models, the features with semantic discrimination draw attention to the target region through the guidance of prompt with rich target information. Experiments on both the PASCAL- $5^{i}$ and COCO- $20^{i}$ show that our proposed method outperforms the existing approaches by a clear margin and achieves new state-of-the-art performances.},
  archive      = {J_TNNLS},
  author       = {Jin Wang and Bingfeng Zhang and Jian Pang and Weifeng Liu and Baodi Liu and Honglong Chen},
  doi          = {10.1109/TNNLS.2025.3611497},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Unbiased semantic decoding with vision foundation models for few-shot segmentation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Three-dimensional multiobject tracking based on voxel masking encoder and deep hashing paradigm. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3613354'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In autonomous driving, accurate 3-D multiobject tracking (MOT) plays a key role in ensuring vehicle safety. However, due to the complexity of the environment, existing methods still face many challenges when dealing with long-distance objects, partial occlusions, and interference from similar categories. To tackle these challenges, we propose a 3-D MOT framework based on a voxel masking encoder (VME) and a deep hashing paradigm (DHP). We introduce a masking strategy that processes voxel features from near to far while maintaining feature sparsity, effectively capturing global contextual information between spatial features. Simultaneously, DHP is utilized to generate image hash codes and compute their hamming distance from the category hash codes. This process effectively distinguishes between object categories and thus avoids cross-category object dissociation. In addition, we propose a distance optimization matching (DOM) method that uses geometric dimensions and spatial distances to build a cost matrix, achieving more efficient and precise object associations. Results from experiments conducted on the KITTI dataset reveal that our framework delivers outstanding tracking performance, surpassing other advanced methods in tracking accuracy. The code is released at https://github.com/lsy-collab/VD-MOT},
  archive      = {J_TNNLS},
  author       = {Saiyu Li and Zhong Chen and Hui Li and Ye Tao and Ying Gao and Jun Yan},
  doi          = {10.1109/TNNLS.2025.3613354},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Three-dimensional multiobject tracking based on voxel masking encoder and deep hashing paradigm},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optical-cue-guided diffusion probabilistic model for reflection removal. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3612402'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a novel reflection removal algorithm that integrates a flash-based optical cue into a diffusion model to control the recovery of the transmission image. The algorithm accepts a pair of ambient and flash images as inputs, and a flash-only image, which corresponds to the one captured with flash as the sole illumination source, is derived from the inputs. In light of the reflection-free nature of the flash-only image, we use it to guide the diffusion model to reconstruct the structures of the transmission image. A feature distillation scheme is designed to infer the chromatic attributes of the transmission image from the ambient image, and the features are used to modulate the generative priors learned by the diffusion model. We use time-aware strategies to ensure the synchronization between feature distillation and the dynamic image generation process of the diffusion model. The performance of the proposed algorithm is sequentially optimized in latent and pixel spaces. We also develop a plug-and-play fidelity-enhancing module (FEM) and integrate it into the proposed model to enable the faithful reconstruction of fine-granular visual characteristics of the target scene and reduce artifacts. Comparative experiments demonstrate that the proposed algorithm shows superior quantitative and qualitative performance over state-of-the-art methods in real-world scenarios. By leveraging the optical cue and the generative capability of the diffusion model, the algorithm can accurately restore the visual details of the transmission image even in the presence of strong reflections, and it also exhibits satisfactory robustness against nonlinear image representation and misalignment.},
  archive      = {J_TNNLS},
  author       = {Feiyang Zhang and Yuenan Li and Xiaoliang Chang},
  doi          = {10.1109/TNNLS.2025.3612402},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Optical-cue-guided diffusion probabilistic model for reflection removal},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hard sample mining: A new paradigm of efficient and robust model training. <em>TNNLS</em>, 1-21. (<a href='https://doi.org/10.1109/TNNLS.2025.3610948'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past two decades, deep learning (DL) has achieved unprecedented breakthroughs across diverse application domains spanning computer vision (CV) to natural language processing (NLP). However, despite significant advances in computational resources and algorithmic frameworks, the training of deep neural networks continues to present formidable challenges due to persistent issues of training inefficiency and inherent data distribution biases. Recent years have witnessed the emergence of hard sample mining (HSM) as a promising paradigm to mitigate training inefficiencies and enhance model robustness through representative sample selection. Although HSM is reshaping contemporary AI research, its critical role in enabling efficient and robust model training has not yet been systematically explored. This article presents a comprehensive survey of HSM methodologies by: 1) establishing unified definitions of hard samples through rigorous sample complexity quantification criteria; 2) proposing a systematic taxonomy of HSM approaches with in-depth technical analysis; and 3) identifying pivotal research frontiers in this evolving field. This survey not only consolidates the foundations of HSM but also provides a roadmap for advancing efficient, robust, and generalizable deep learning models.},
  archive      = {J_TNNLS},
  author       = {Lei Liu and Yunji Liang and Xiaokai Yan and Luwen Huangfu and Sagar Samtani and Zhiwen Yu and Yanyong Zhang and Daniel D. Zeng},
  doi          = {10.1109/TNNLS.2025.3610948},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-21},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Hard sample mining: A new paradigm of efficient and robust model training},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modal detection informed classification evaluation via ensemble networks for expensive constrained multimodal optimization. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3612490'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The evaluation of objective and constraint involving expensive simulations or physical experiments with multiple optimal solutions is referred to as expensive constrained multimodal optimization problems (ECMMOPs). Under limited real function evaluations (FEs), it is challenging to find multiple optimal solutions accurately while satisfying constraints. To address these issues, this article studies a self-clustering particle swarm optimization algorithm with modal detection informed classification evaluation (MDICE) to solve ECMMOPs. To deal with multimodality, a surrogate-assisted self-clustering update mechanism is first designed to update individuals in each modality. Following that, a novel modal detection strategy is proposed based on the awareness of fitness landscapes to identify all potential modal seeds. For better utilization of FEs, a modality-guided classification evaluation strategy is designed to efficiently generate infilling samples for each constraint and modality. Moreover, to address the complex constraints, a surrogate-assisted feasibility search strategy is developed to quickly search for feasible solutions at a lower evaluation cost. Experimental results on 33 benchmark functions with various characteristics indicate that MDICE outperforms four state-of-the-art surrogate-assisted evolutionary algorithms.},
  archive      = {J_TNNLS},
  author       = {Kunjie Yu and Fan Chen and Mingyuan Yu and Jing Liang and Ke Chen},
  doi          = {10.1109/TNNLS.2025.3612490},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Modal detection informed classification evaluation via ensemble networks for expensive constrained multimodal optimization},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing the output of long short-term memory cell for high-frequency forecasting in financial markets. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3611887'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-frequency trading (HFT) requires fast data processing without information lags for precise stock price forecasting. This high-paced stock price forecasting is usually based on vectors that need to be treated as sequential and time-independent signals due to the time irregularities that are inherent in HFT. A well-documented and tested method that considers these time irregularities is a type of recurrent neural network (NN), named long short-term memory (LSTM) NN. This type of NN is formed based on cells that perform sequential and stale calculations via gates and states without knowing whether their order, within the cell, is optimal. In this article, we propose a revised and real-time adjusted LSTM cell that selects the best gate or state as its final output. Our cell is running under a shallow topology, has a minimal look-back period, and is trained online. This revised cell achieves lower forecasting error compared to other recurrent NNs (RNNs) for online HFT forecasting tasks such as the limit order book (LOB) mid-price (MP) prediction as it has been tested on two high-liquid U.S. and two less-liquid Nordic stocks.},
  archive      = {J_TNNLS},
  author       = {Adamantios Ntakaris and Moncef Gabbouj and Juho Kanniainen},
  doi          = {10.1109/TNNLS.2025.3611887},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Optimizing the output of long short-term memory cell for high-frequency forecasting in financial markets},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). All-to-all connected oscillator ising machines and their application as associative memory. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3609571'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic behaviors of the classical Kuramoto models have been widely studied. The dynamics of the all-to-all connected oscillator Ising machines (OIMs) is similar to that of the classical Kuramoto models, with the main difference being that there is an additional term in OIMs, called the second harmonic term. However, the dynamic behavior of an all-to-all connected OIM is significantly different and its intricate properties are largely unexplored. In this article, we study in detail the properties of the all-to-all connected OIMs and explore their application as associative memory. The number of patterns such an OIM can store increases exponentially with respect to the number of oscillators. To improve the performance of the OIMs for associative memory, we propose a new harmonic term so that the resulting OIM achieves pattern retrieval with high accuracy in the presence of a high level of noise.},
  archive      = {J_TNNLS},
  author       = {Yi Cheng and Zongli Lin},
  doi          = {10.1109/TNNLS.2025.3609571},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {All-to-all connected oscillator ising machines and their application as associative memory},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedMPS: Federated learning in a synergy of multi-level prototype-based contrastive learning and soft label generation. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3611832'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) facilitates collaborative training among multiple clients while preserving data privacy by eliminating raw data transmission. However, the inherent data heterogeneity among participants induces bias during collaborative learning, significantly degrading the performance of local models. Existing FL solutions face critical challenges in achieving efficient knowledge transmission, particularly with respect to insufficient information extraction or excessive communication costs, which result in slow convergence and inferior performance. To address these limitations, we propose a novel FL framework in a synergy of multi-level prototype-based contrastive learning (CL) and soft label generation, named FedMPS. The proposed method first constructs multi-level prototypes from different layers of the model to capture semantic information in high-level features and detailed information in low-level features. These prototypes are then utilized through CL to enhance intra-class discriminability and intra-class consistency in the feature space. In addition, a prototype-guided soft label generation module is introduced to model latent interclass relationships in the output space. Instead of exchanging model parameters, FedMPS transmits only prototypes and soft labels, effectively reducing global knowledge shift and communication costs. Extensive experimental studies on six publicly available datasets validate the effectiveness of the proposed method when compared to the current state-of-the-art FL approaches. The code is available at github.com/wenxinyang1026/FedMPS},
  archive      = {J_TNNLS},
  author       = {Wenxin Yang and Xingchen Hu and Xiubin Zhu and Rouwan Wu and Witold Pedrycz and Xinwang Liu and Jincai Huang},
  doi          = {10.1109/TNNLS.2025.3611832},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {FedMPS: Federated learning in a synergy of multi-level prototype-based contrastive learning and soft label generation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Syntax-oriented shortcut: A syntax level perturbing algorithm for preventing text data from being learned. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3609842'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The vast availability of free data has been critical to the success of large language models (LLMs). With the widespread use of LLMs, more and more concerns have been raised about the unauthorized use of publicly available data. To protect data from unauthorized use for training models, researchers have proposed adding imperceptible perturbations into image data so that models would be misled by the generated shortcut features and cannot mine information from these images. However, due to the inherent discrete property and semantic complexity of texts, directly applying these methods to text will cause semantic changes, resulting in meaningless shortcut features being constructed. To tackle this problem, in this article, we design a novel Unlearnable text examples generation algorithm via syntax-oriented shortcut (UTE-SS) by incorporating the syntactic structure of texts. Specifically, we propose a syntax template generator (STG) to generate the optimal perturbing syntax for a given category, which will realize imperceptible perturbations. Then, a perturbing text generator (PTG) is designed to perturb the in-class texts with the selected syntax template to stably deviate from the original texts. Along this line, models will be misled to learn the shortcut between the syntax template and the category, so as to keep text examples unlearnable. Extensive experiments over eight advanced Transformer-based pretrained language models (PLMs) on four different natural language processing (NLP) tasks demonstrate the effectiveness and flexibility of our proposed algorithm. Our method is easy to implement, and the code is publicly available at https://github.com/libolb/UTE-SS.},
  archive      = {J_TNNLS},
  author       = {Bo Li and Kun Zhang and Xi Chen and Richang Hong},
  doi          = {10.1109/TNNLS.2025.3609842},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Syntax-oriented shortcut: A syntax level perturbing algorithm for preventing text data from being learned},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedNK-RF: Federated kernel learning with heterogeneous data and optimal rates. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3612728'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) has become a mainstream decentralized learning paradigm due to its privacy-preserving features. However, the heterogeneity of data in FL can reduce predictive accuracy and complicate the analysis of the generalization properties of FL methods. In this article, we propose efficient federated kernel learning (FedK) algorithms and study their generalization properties. We first devise FedK with random features (FedK-RF), which acquires global information through sharing RF of local data subsets, enhancing predictive capability while protecting privacy. We then propose federated Nyström approximation with RF (FedNK-RF) that reduces errors resulted from RF. Furthermore, using integral operator theory, we derive the excess risk bounds with minimax optimal rates, which illustrate the impacts from data heterogeneity and shared information. Finally, we conduct several experiments that demonstrate the superiority of the proposed FedNK-RF.},
  archive      = {J_TNNLS},
  author       = {Xuning Zhang and Jian Li and Rong Yin and Weiping Wang},
  doi          = {10.1109/TNNLS.2025.3612728},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {FedNK-RF: Federated kernel learning with heterogeneous data and optimal rates},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PID: A parameter-efficient isolation domain-incremental learning framework for signal modulation classification. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3615307'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks have achieved promising progress in signal modulation classification (SMC), playing an essential role in a variety of applications such as cognitive radio networks, cyber defense, and electronic surveillance. However, most existing SMC methods still follow the traditional machine learning paradigm that trains on static closed datasets, lacking the ability to cope with the challenge of continuous data distribution shifts in real communication scenarios. Directly applying the model to a new environment may lead to severe degradation of classification performance on previous scenarios, i.e., catastrophic forgetting. To address this, this article proposes the first domain-incremental learning (DIL) paradigm for SMC and designs a parameter-efficient isolation DIL (PID) method, which enables SMC models to rapidly adjust to new scenarios by extending only a few parameters, while significantly retaining classification capabilities on previous scenarios. Specifically, we first propose a parameter space decomposition-based classifier (PSD), separating the model parameters into a set of bases and corresponding coefficients. By freezing the bases and fine-tuning the low-dimensional coefficients, the catastrophic forgetting problem can be efficiently eliminated. Furthermore, we design a scene-aware domain controller (SDC) to select the most suitable domain-specific coefficients for each sample, thereby maintaining the SMC model’s classification capabilities across all domains. The extensive experimental results show the superiority of the proposed PID, which achieves state-of-the-art (SOTA) overall performance. The code will be available at: https://github.com/SMC-IL/PID},
  archive      = {J_TNNLS},
  author       = {Guanchun Wang and Ziyi Liu and Xiangrong Zhang and Yifan Chen and Yifang Zhang and Jin Zhu and Licheng Jiao},
  doi          = {10.1109/TNNLS.2025.3615307},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {PID: A parameter-efficient isolation domain-incremental learning framework for signal modulation classification},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DMutDE: Dual-view mutual distillation framework for knowledge graph embeddings. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3608503'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs (KGs) have caught more and more attention in recent years. Currently, in some practical scenarios, KG embedding (KGE) models are expected to reduce their spatial complexity without losing much performance to address the challenges of storage limitations and knowledge reasoning efficiency. To achieve this, existing works use one or more large and high-performance teacher models to improve the performance of a lightweight student model via knowledge distillation (KD), thus meeting the requirements of some practical complicated applications. However, in resource-constrained scenarios, obtaining high-performance teacher models is challenging due to high training costs and significant storage requirements. Thus, enhancing the student model’s performance without large teacher models is crucial. To address this issue, we propose Dual-View Mutual Distillation Framework for Knowledge Graph Embeddings (DMutDE), a distillation framework leveraging mutual learning for peer-to-peer distillation between two KGE models with different architectures. In KGE models, we notice that the way of modeling relational directed edges determines the model view of KGE model for learning KG data. Thus, integrating the model views from two different KGE models by KD into a student KGE model can improve its generalization, so as to increase its performance. To identify an effective dual-view fusion method, we design two modules in the DMutDE framework. Specifically, we design a novel soft-label fusion (SLF) module for noise filtering and response knowledge transfer. Then, we propose an entity embedding distillation (EED) module to distill structural features from each other. Finally, we conduct several comprehensive experiments on the standard open-source benchmarks to demonstrate that our framework achieves the state-of-the-art results. The code is available at https://github.com/RuizhouLiu/DMutDE},
  archive      = {J_TNNLS},
  author       = {Ruizhou Liu and Zhe Wu and Yiling Wu and Zongsheng Cao and Qianqian Xu and Qingming Huang},
  doi          = {10.1109/TNNLS.2025.3608503},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {DMutDE: Dual-view mutual distillation framework for knowledge graph embeddings},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multigranularity deep graph convolutional neural network node clustering leveraging spatial information. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3615830'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of information explosion, clustering analysis of graph-structured data and empty graph-structured data is of great significance for extracting the intrinsic value of data. From the perspective of spatial information, empty graph-structured data and graph-structured data are essentially the same type of data, both containing rich spatial information. However, there is currently no general clustering method that can handle both types of data, and the clustering methods applicable to empty graph-structured data pay little attention to the spatial information they contain. Meanwhile, graph convolutional neural networks (GCN) have made significant progress in processing graph-structured data, but applying them to empty graph-structured data still faces challenges because the latter lacks an explicit topological structure. To address these problems, this study proposes a multigranularity deep GCN node clustering method leveraging spatial information (CMDGCN). It converts empty graph-structured data into graph-structured data using the $k$ -nearest neighbor (k-nn) algorithm and constructs multigranularity graph structures based on feature segmentation to extend the network depth to deep layers, thereby addressing the issue of shallow network layers in traditional GCN models. In addition, this study improves the self-expressiveness principle, ensuring that the learned similarity matrix not only depends on the node embedding representation but also incorporates the original structural information of the graph, resulting in a high-quality and interpretable similarity matrix. Furthermore, through experimental verification on multiple graph-structured datasets and empty graph-structured datasets, our method outperforms existing methods in several key indicators, proving its effectiveness and robustness. This achievement not only provides new methods and perspectives for graph node clustering but also offers new effective tools for processing empty graph-structured data.},
  archive      = {J_TNNLS},
  author       = {Bin Yu and Haibo Yang},
  doi          = {10.1109/TNNLS.2025.3615830},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Multigranularity deep graph convolutional neural network node clustering leveraging spatial information},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Theoretical convergence analysis and initialization comparisons of deep soft-thresholding networks. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3614196'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft-thresholding (ST) has been widely used in deep neural networks. Its fundamental network structure is a deep soft-thresholding fully connected network (ST-FCN). However, training deep ST-FCN to achieve convergence remains time-consuming or even encounters gradient explosion, in part because the convergence behavior is not fully understood. To address this issue, this article proves the relationship between the convergence of deep ST-FCN and the values of network weights and biases. Theoretical analysis shows that, as the number of network layers approaches infinity, deep ST-FCN converges when the network weights tend to an identity matrix, while the biases tend to zero. Following this guidance, we initialize the network weights as the identity matrix, compare it with other representative initialization methods (Gaussian, He, LeCun, Xavier, and Uniform), and quantify their effects on network convergence. Extensive results on a synthetic spectrum dataset and real-world datasets (MNIST and CIFAR-10) demonstrate that initializing the weights to the identity matrix and the bias to zero leads to fast and stable convergence. These conclusions are further supported by additional experiments and statistical analysis on deeper ST networks (with more than ten layers) and other representative architectures (DenseNet-161, ResNet-152, and VGG-19), and more challenging benchmarks (CIFAR-100, STL-10, and Tiny ImageNet). This work provides a theoretical foundation for understanding the convergence of ST neural networks. Furthermore, convergence theory analysis for deep recurrent neural networks (RNNs) with ST is deduced.},
  archive      = {J_TNNLS},
  author       = {Chunyan Xiong and Mengxue Zhang and Tong Wei and Yihui Huang and Jian Cao and Qingrui Cai and Zhong Chen and Xiaobo Qu},
  doi          = {10.1109/TNNLS.2025.3614196},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Theoretical convergence analysis and initialization comparisons of deep soft-thresholding networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MDSF-YOLO: Advancing object detection with a multiscale dilated sequence fusion network. <em>TNNLS</em>, 1-12. (<a href='https://doi.org/10.1109/TNNLS.2025.3617122'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and fast detection of traffic signs is critical for autonomous driving, particularly in complex environments with diverse sign scales and varying detection distances. Existing approaches, incorporating attention modules or modifying detection heads, frequently encounter high rates of false positives and omissions due to the increased sampling depth. To address these limitations, we propose MDSF-you only look once (YOLO), a novel detection framework that integrates multiscale sequence fusion (MSF) for synergistic feature integration across granularities, enhancing the precision of both localization and semantic information fusion. Additionally, our dilated-wise residual (DWR) module leverages dilated convolutions and channel-wise reparameterization to improve fine-grained feature extraction. The architecture further introduces a $P_{2}$ detection head for shallow features and fully decouples all detection heads, optimizing target localization and category identification. Extensive experiments on the TT100K and CCTSDB2021 datasets demonstrate the superiority of MDSF-YOLO over benchmark models, including YOLOv11s, with significant improvements in mAP by 8.8% and 2.4% on respective datasets while substantially reducing false positives and leakage rate. Besides, the marked improvement of MDSF-YOLO on the VisDrone2019 dataset verifies its enhanced capability to address drone-based object detection. These advances underscore the efficiency and robustness of the proposed model, providing a promising solution for autonomous driving and similar object detection scenarios.},
  archive      = {J_TNNLS},
  author       = {Yu Sun and Chong Zhang and Xian Li and Xuyang Jing and Hui Kong and Qing-Guo Wang},
  doi          = {10.1109/TNNLS.2025.3617122},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {MDSF-YOLO: Advancing object detection with a multiscale dilated sequence fusion network},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FGPLFA: Fine-grained pseudo-labeling and feature alignment for source-free unsupervised domain adaptation. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3616236'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Source-free unsupervised domain adaptation (SFUDA) aims to improve performance in unlabeled target domain data without accessing source domain data. This is crucial in scenarios with data-sharing restrictions due to privacy or compliance constraints. Existing SFUDA approaches often rely on pseudo-labeling techniques based on entropy or confidence metrics. These often overlook fine-grained data features, resulting in noisy pseudo-labels that degrade model performance. To overcome this limitation, we develop a new method called fine-grained pseudo-labeling and feature alignment (FGPLFA) to enhance SFUDA’s performance. FGPLFA starts with a gradient-based metric that integrates insights from both model knowledge and data features, creating a more reliable sample metric. To enhance fine granularity, the fine-grained pseudo-labeling (FGPL) module was introduced. This module clusters data based on the magnitude and direction of gradients, allowing for dataset partitioning into subsets at the sample level. The subsets are pseudo-labeled with category-specificity and domain specificity, establishing a multilevel granularity structure that reduces noisy pseudo-labels. Subsequently, the mean-covariance adjustment feature alignment (MCAFA) method was introduced. Features from the subsets are aligned in a specified sequence, enhancing model adaptability in the target domain. Extensive experiments conducted across multiple datasets validate the superiority of FGPLFA.},
  archive      = {J_TNNLS},
  author       = {Zhongyi Wen and Qiang Li and Yatong Wang and Huaizong Shao and Guoming Sun},
  doi          = {10.1109/TNNLS.2025.3616236},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {FGPLFA: Fine-grained pseudo-labeling and feature alignment for source-free unsupervised domain adaptation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel pattern learning framework with enhanced scalability for continuous optimization. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3610993'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiobjective optimization problems (MOPs) arise in numerous real-world scenarios, yet finding their solutions with optimal trade-offs can be a formidable challenge. This article studies the continuous optimization problem involving large-scale variables, many objectives, and intricate constraints, which is rarely comprehensively discussed in existing works, due to the coexisting difficulties posed by the curse of dimensionality, selection pressure, and feasibility restrictions. To address these problems, this work pioneers a novel optimization framework, optimization pattern learning, embedded with machine learning (ML) techniques. Within this framework, the concept of measurable order and its corresponding learning mechanism are proposed to extract valuable knowledge from solutions. This measurable order is a general form of those orders used explicitly or implicitly in the existing studies, providing a more flexible means to evaluate solutions for efficient optimization adaptively. By substituting original solutions with their measurable orders, this framework effectively avoids the selection pressure from many objectives and the feasibility restrictions from intricate constraints. Furthermore, two novel ML models based on measurable orders are developed to progressively learn effective optimization patterns from iterative data in high-dimensional search spaces. Leveraging these learned patterns, this framework successfully addresses the curse of dimensionality from large-scale variables and thus achieves efficient optimization. Owing to the strong adaptability and search capabilities of this framework, it also demonstrates excellent scalability as the number of variables, objectives, and constraints increases. Extensive simulations validate the effectiveness of the framework and underscore its competitiveness relative to state-of-the-art algorithms in this field.},
  archive      = {J_TNNLS},
  author       = {Jian Qin and Yuanqiu Mo and Hongzhe Liu and Zhi-Hui Zhan and Wenwu Yu},
  doi          = {10.1109/TNNLS.2025.3610993},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A novel pattern learning framework with enhanced scalability for continuous optimization},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Boosting few-shot hyperspectral image classification through dynamic fusion and hierarchical enhancement. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3615950'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot learning has garnered increasing attention in hyperspectral image classification (HSIC) due to its potential to reduce dependency on labor-intensive and costly labeled data. However, most existing methods are constrained to feature extraction using a single image patch of fixed size, and typically neglect the pivotal role of the central pixel in feature fusion, leading to inefficient information utilization. In addition, the correlations among sample features have not been fully explored, thereby weakening feature expressiveness and hindering cross-domain knowledge transfer. To address these issues, we propose a novel few-shot HSIC framework incorporating dynamic fusion and hierarchical enhancement. Specifically, we first introduce a robust feature extraction module, which effectively combines the content concentration of small patches with the noise robustness of large patches, and further captures local spatial correlations through a central-pixel-guided dynamic pooling strategy. Such patch-to-pixel dynamic fusion enables a more comprehensive and robust extraction of ground object information. Then, we develop a support–query hierarchical enhancement module that integrates intraclass self-attention and interclass cross-attention mechanisms. This process not only enhances support-level and query-level feature representation but also facilitates the learning of more informative prior knowledge from the abundantly labeled source domain. Moreover, to further increase feature discriminability, we design an intraclass consistency loss and an interclass orthogonality loss, which collaboratively encourage intraclass samples to be closer together and interclass samples to be more separable in the metric space. Experimental results on four benchmark datasets demonstrate that our method substantially improves classification accuracy and consistently outperforms competing approaches. Code is available at https://github.com/guoying918/DFHE2025},
  archive      = {J_TNNLS},
  author       = {Ying Guo and Bin Fan and Yuchao Dai and Yan Feng and Mingyi He},
  doi          = {10.1109/TNNLS.2025.3615950},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Boosting few-shot hyperspectral image classification through dynamic fusion and hierarchical enhancement},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedMKD: Hybrid feature guided multilayer fusion knowledge distillation in heterogeneous federated learning. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3615230'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, federated learning (FL) has received widespread attention for its ability to enable collaborative training across multiple clients while protecting user privacy, especially demonstrating significant value in scenarios such as medical data analysis, where strict privacy protection is required. However, most existing FL frameworks mainly focus on data heterogeneity without fully addressing the challenge of heterogeneous model aggregation among clients. To address this problem, this article proposes a novel FL framework called FedMKD. This framework introduces proxy models as a medium for knowledge sharing between clients, ensuring efficient and secure interactions while effectively utilizing the knowledge in each client’s data. In order to improve the efficiency of asymmetric knowledge transfer between proxy models and private models, a hybrid feature-guided multilayer fusion knowledge distillation (MKD) learning method is proposed, which eliminates the dependence on public data. Extensive experiments were conducted using a combination of multiple heterogeneous models under diverse data distributions. The results demonstrate that FedMKD efficiently aggregates model knowledge.},
  archive      = {J_TNNLS},
  author       = {Peng Han and Han Xiao and Shenhai Zheng and Yuanyuan Li and Guanqiu Qi and Zhiqin Zhu},
  doi          = {10.1109/TNNLS.2025.3615230},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {FedMKD: Hybrid feature guided multilayer fusion knowledge distillation in heterogeneous federated learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HKANLP: Link prediction with hyperspherical embeddings and Kolmogorov–Arnold networks. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3614341'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Link prediction (LP) is fundamental to graph-based applications, yet existing graph autoencoders (GAEs) and variational GAEs (VGAEs) often struggle with intrinsic graph properties, particularly the presence of negative eigenvalues in adjacency matrices, which limits their adaptability and predictive performance. To address this limitation, we propose Hyperspherical Kolmogorov–Arnold Networks for LP (HKANLP), a novel framework that combines multiple graph neural network (GNN)-based representation learning strategies with Kolmogorov–Arnold networks (KANs) in a hyperspherical embedding space. Specifically, our model leverages the von Mises–Fisher (vMF) distribution to impose geometric consistency in the latent space and employs KANs as universal function approximators to reconstruct adjacency matrices, thereby mitigating the impact of negative eigenvalues and enhancing spectral diversity. Extensive experiments on homophilous, heterophilous, and large-scale graph datasets demonstrate that HKANLP achieves superior LP performance and robustness compared to state-of-the-art baselines. Furthermore, visualization analyses illustrate the model’s effectiveness in capturing complex structural patterns. The source code of our model is publicly available at https://github.com/zxj8806/HKANLP/},
  archive      = {J_TNNLS},
  author       = {Wenchuan Zhang and Wentao Fan and Weifeng Su and Nizar Bouguila},
  doi          = {10.1109/TNNLS.2025.3614341},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {HKANLP: Link prediction with hyperspherical embeddings and Kolmogorov–Arnold networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IML-spikeformer: Input-aware multilevel spiking transformer for speech processing. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3615971'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural networks (SNNs), inspired by biological neural mechanisms, represent a promising neuromorphic computing paradigm that offers energy-efficient alternatives to traditional artificial neural networks (ANNs). Despite proven effectiveness, SNN architectures have struggled to achieve competitive performance on large-scale speech processing tasks. Two key challenges hinder progress: 1) the high computational overhead during training caused by multitimestep spike firing and 2) the absence of large-scale SNN architectures tailored to speech processing tasks. To overcome the issues, we introduce the input-aware multilevel spikeformer (IML-Spikeformer), a spiking transformer architecture specifically designed for large-scale speech processing. Central to our design is the input-aware multilevel spike (IMLS) mechanism, which simulates multitimestep spike firing within a single timestep using an adaptive, input-aware thresholding scheme. IML-Spikeformer further integrates a reparameterized spiking self-attention (RepSSA) module with a hierarchical decay mask (HDM), forming the HD-RepSSA module. This module enhances the precision of attention maps and enables modeling of multiscale temporal dependencies in speech signals. Experiments demonstrate that IML-Spikeformer achieves word error rates (WERs) of 6.0% on AiShell-1 and 3.4% on Librispeech-960, comparable to conventional ANN transformers while reducing theoretical inference energy consumption by $4.64\times $ and $4.32\times $ , respectively. IML-Spikeformer marks an advance of scalable SNN architectures for large-scale speech processing in both task performance and energy efficiency. Our source code and model checkpoints are publicly available at github.com/Pooookeman/IML-Spikeformer},
  archive      = {J_TNNLS},
  author       = {Zeyang Song and Shimin Zhang and Yuhong Chou and Jibin Wu and Haizhou Li},
  doi          = {10.1109/TNNLS.2025.3615971},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {IML-spikeformer: Input-aware multilevel spiking transformer for speech processing},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inhibiting error exacerbation in offline reinforcement learning with data sparsity. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3615982'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Offline reinforcement learning (RL) aims to learn effective agents from previously collected datasets, facilitating the safety and efficiency of RL by avoiding real-time interaction. However, in practical applications, the approximation error of the out-of-distribution (OOD) state–actions can cause considerable overestimation due to error exacerbation during training, finally degrading the performance. In contrast to prior works that merely addressed the OOD state–actions, we discover that all data introduces estimation error whose magnitude is directly related to data sparsity. Consequently, the impact of data sparsity is inevitable and vital when inhibiting the error exacerbation. In this article, we propose an offline RL approach to inhibit error exacerbation with data sparsity (IEEDS), which includes a novel value estimation method to consider the impact of data sparsity on the training of agents. Specifically, the value estimation phase includes two innovations: 1) replace Q-net with V-net, a smaller and denser state space makes data more concentrated, contributing to more accurate value estimation and 2) introduce state sparsity to the training by design state-aware-sparsity Markov decision process (MDP), further lessening the impact of sparse states. We theoretically prove the convergence of IEEDS under state-aware-sparsity MDP. Extensive experiments on offline RL benchmarks reveal that IEEDS’s superior performance.},
  archive      = {J_TNNLS},
  author       = {Fan Zhang and Malu Zhang and Wenyu Chen and Siying Wang and Xin Zhang and Jiayin Li and Yang Yang},
  doi          = {10.1109/TNNLS.2025.3615982},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Inhibiting error exacerbation in offline reinforcement learning with data sparsity},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semi-supervised breast lesion segmentation using confidence-ranked features and bi-level prototypes. <em>TNNLS</em>, 1-12. (<a href='https://doi.org/10.1109/TNNLS.2025.3616332'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated lesion segmentation through breast ultrasound (BUS) images is an essential prerequisite in computer-aided diagnosis. However, the task of breast segmentation remains challenging, due to the time-consuming and labor-intensive process of acquiring precise labeled data, as well as severely ambiguous lesion boundaries and low contrast in BUS images. In this article, we propose a novel semi-supervised breast segmentation framework based on confidence-ranked features and bi-level prototypes (CoBiNet) to alleviate these issues. Our outputs are derived from two branches: classifier and projector. In the projector branch, we first rank the features by multilevel sampling to obtain multiple feature sets with different confidence levels. Then, these sets are progressed in two directions. One is to acquire local prototypes at each level by local sampling and perform trans-confidence level (TCL) contrastive learning. This encourages the low-confidence features to converge to the high-confidence features, which enhances the model’s ability to recognize ambiguous regions. The other process is to generate more representative global prototypes by global sampling, followed by generating more reliable predictions and performing cross-guidance (CG) consistency learning with the classifier output predictions, facilitating knowledge transfer between the structure-aware projector and the category-discriminative classifier branches. Extensive experiments on two well-known public datasets, BUSI and UDIAT, demonstrate the superiority of our method over state-of-the-art approaches. Codes will be released upon publication.},
  archive      = {J_TNNLS},
  author       = {Siyao Jiang and Huisi Wu and Yu Zhou and Junyang Chen and Jing Qin},
  doi          = {10.1109/TNNLS.2025.3616332},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Semi-supervised breast lesion segmentation using confidence-ranked features and bi-level prototypes},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal cross-city semantic segmentation based on similarity-inspired fusion and invertible transformation learning network. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3617345'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal cross-city semantic segmentation aims to adapt a network trained on multiple labeled source domains (MSDs) from one city to multiple unlabeled target domains (MTDs) in another city, where the multiple domains refer to different sensor modalities. However, remote sensing data from different sensors increases the extent of domain shift in the fused domain space, making feature alignment more challenging. Meanwhile, traditional fusion methods only consider complementarity within MSDs (or MTDs), which wastes cross-domain relevant information and neglects control over domain shift. To address the above issues, we propose a similarity-inspired fusion and invertible transformation learning network (SFITNet) for multimodal cross-city semantic segmentation. To alleviate the increasing alignment difficulty in multimodal fused domains, an invertible transformation learning strategy (ITLS) is proposed, which adopts a topological perspective on unsupervised domain adaptation. This strategy aims to simulate the potential distribution transformation function between the MSD and the MTD based on invertible neural networks (INNs) after feature fusion, thereby performing distribution alignment independently within the two feature spaces. A cross-domain similarity-inspired information interaction module (CDSiM) is also designed, which considers the correspondence between the MSD and the MTD in the fusion stage, effectively utilizes multimodal complementary information and promotes the subsequent alignment of fused domain shifts. The semantic segmentation tests are completed on the public C2Seg-AB dataset and a new multimodal cross-city Su-Wu dataset. Compared with some state-of-the-art techniques, the experimental results demonstrated the superiority of the proposed SFITNet.},
  archive      = {J_TNNLS},
  author       = {Lijia Dong and Wen Jiang and Zhengyi Xu and Jie Geng},
  doi          = {10.1109/TNNLS.2025.3617345},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Multimodal cross-city semantic segmentation based on similarity-inspired fusion and invertible transformation learning network},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature enhancement module based on class-centric loss for fine-grained visual classification. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3613791'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel feature enhancement module designed for fine-grained visual classification tasks, which can be seamlessly integrated into various backbone architectures, including both convolutional neural network (CNN)-based and Transformer-based networks. The plug-and-play module outputs pixel-level feature maps and performs a weighted fusion of filtered features to enhance fine-grained feature representation. We introduce a class-centric loss function that optimizes the alignment of samples with their target class centers by pulling them toward the center of the target class while simultaneously pushing them away from the center of the most visually similar nontarget classes. Soft labels are employed to mitigate overfitting, ensuring the model generalizes well to unseen examples. Our approach consistently delivers significant improvements in accuracy across various mainstream backbone architectures, underscoring its versatility and robustness. Furthermore, we achieved the highest accuracy on the NABirds (NAB) and our proprietary lock cylinder datasets. We have released our source code and pretrained model on GitHub: https://github.com/Richard5413/FEM-CC.git},
  archive      = {J_TNNLS},
  author       = {Daohui Wang and He Xinyu and Shujing Lyu and Wei Tian and Yue Lu},
  doi          = {10.1109/TNNLS.2025.3613791},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Feature enhancement module based on class-centric loss for fine-grained visual classification},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distill to delete: Unlearning in graph networks with knowledge distillation. <em>TNNLS</em>, 1-11. (<a href='https://doi.org/10.1109/TNNLS.2025.3607995'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph unlearning has emerged as a pivotal method to delete information from an already trained graph neural network (GNN). One may delete nodes, a class of nodes, edges, or a class of edges. An unlearning method enables the GNN model to comply with data protection regulations (i.e., the right to be forgotten), adapt to evolving data distributions, and reduce the GPU-hours carbon footprint by avoiding repetitive retraining. Removing specific graph elements from graph data is challenging due to the inherent intricate relationships and neighborhood dependencies. Existing partitioning and aggregation-based methods have limitations due to their poor handling of local graph dependencies and additional overhead costs. Our work takes a novel approach to address these challenges in graph unlearning through knowledge distillation, as it distills to delete in GNN (D2DGN). It is an efficient model-agnostic distillation framework where the complete graph knowledge is divided and marked for retention and deletion. It performs distillation with response-based soft targets and feature-based node embedding while minimizing KL-divergence. The unlearned model effectively removes the influence of the deleted graph elements while preserving knowledge about the retained graph elements. D2DGN surpasses the performance of existing methods when evaluated on various real-world graph datasets by up to $\mathbf {43.1\%}$ (AUC) in edge and node unlearning tasks. Other notable advantages include better efficiency, better performance in removing target elements, preservation of performance for the retained elements, and zero overhead costs. Source code: https://github.com/MachineUnlearn/D2DGN},
  archive      = {J_TNNLS},
  author       = {Yash Sinha and Murari Mandal and Mohan Kankanhalli},
  doi          = {10.1109/TNNLS.2025.3607995},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Distill to delete: Unlearning in graph networks with knowledge distillation},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
