<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TNNLS</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tnnls">TNNLS - 5</h2>
<ul>
<li><details>
<summary>
(2025). Optical-cue-guided diffusion probabilistic model for reflection removal. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3612402'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a novel reflection removal algorithm that integrates a flash-based optical cue into a diffusion model to control the recovery of the transmission image. The algorithm accepts a pair of ambient and flash images as inputs, and a flash-only image, which corresponds to the one captured with flash as the sole illumination source, is derived from the inputs. In light of the reflection-free nature of the flash-only image, we use it to guide the diffusion model to reconstruct the structures of the transmission image. A feature distillation scheme is designed to infer the chromatic attributes of the transmission image from the ambient image, and the features are used to modulate the generative priors learned by the diffusion model. We use time-aware strategies to ensure the synchronization between feature distillation and the dynamic image generation process of the diffusion model. The performance of the proposed algorithm is sequentially optimized in latent and pixel spaces. We also develop a plug-and-play fidelity-enhancing module (FEM) and integrate it into the proposed model to enable the faithful reconstruction of fine-granular visual characteristics of the target scene and reduce artifacts. Comparative experiments demonstrate that the proposed algorithm shows superior quantitative and qualitative performance over state-of-the-art methods in real-world scenarios. By leveraging the optical cue and the generative capability of the diffusion model, the algorithm can accurately restore the visual details of the transmission image even in the presence of strong reflections, and it also exhibits satisfactory robustness against nonlinear image representation and misalignment.},
  archive      = {J_TNNLS},
  author       = {Feiyang Zhang and Yuenan Li and Xiaoliang Chang},
  doi          = {10.1109/TNNLS.2025.3612402},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Optical-cue-guided diffusion probabilistic model for reflection removal},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modal detection informed classification evaluation via ensemble networks for expensive constrained multimodal optimization. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3612490'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The evaluation of objective and constraint involving expensive simulations or physical experiments with multiple optimal solutions is referred to as expensive constrained multimodal optimization problems (ECMMOPs). Under limited real function evaluations (FEs), it is challenging to find multiple optimal solutions accurately while satisfying constraints. To address these issues, this article studies a self-clustering particle swarm optimization algorithm with modal detection informed classification evaluation (MDICE) to solve ECMMOPs. To deal with multimodality, a surrogate-assisted self-clustering update mechanism is first designed to update individuals in each modality. Following that, a novel modal detection strategy is proposed based on the awareness of fitness landscapes to identify all potential modal seeds. For better utilization of FEs, a modality-guided classification evaluation strategy is designed to efficiently generate infilling samples for each constraint and modality. Moreover, to address the complex constraints, a surrogate-assisted feasibility search strategy is developed to quickly search for feasible solutions at a lower evaluation cost. Experimental results on 33 benchmark functions with various characteristics indicate that MDICE outperforms four state-of-the-art surrogate-assisted evolutionary algorithms.},
  archive      = {J_TNNLS},
  author       = {Kunjie Yu and Fan Chen and Mingyuan Yu and Jing Liang and Ke Chen},
  doi          = {10.1109/TNNLS.2025.3612490},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Modal detection informed classification evaluation via ensemble networks for expensive constrained multimodal optimization},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing the output of long short-term memory cell for high-frequency forecasting in financial markets. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3611887'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-frequency trading (HFT) requires fast data processing without information lags for precise stock price forecasting. This high-paced stock price forecasting is usually based on vectors that need to be treated as sequential and time-independent signals due to the time irregularities that are inherent in HFT. A well-documented and tested method that considers these time irregularities is a type of recurrent neural network (NN), named long short-term memory (LSTM) NN. This type of NN is formed based on cells that perform sequential and stale calculations via gates and states without knowing whether their order, within the cell, is optimal. In this article, we propose a revised and real-time adjusted LSTM cell that selects the best gate or state as its final output. Our cell is running under a shallow topology, has a minimal look-back period, and is trained online. This revised cell achieves lower forecasting error compared to other recurrent NNs (RNNs) for online HFT forecasting tasks such as the limit order book (LOB) mid-price (MP) prediction as it has been tested on two high-liquid U.S. and two less-liquid Nordic stocks.},
  archive      = {J_TNNLS},
  author       = {Adamantios Ntakaris and Moncef Gabbouj and Juho Kanniainen},
  doi          = {10.1109/TNNLS.2025.3611887},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Optimizing the output of long short-term memory cell for high-frequency forecasting in financial markets},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). All-to-all connected oscillator ising machines and their application as associative memory. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3609571'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic behaviors of the classical Kuramoto models have been widely studied. The dynamics of the all-to-all connected oscillator Ising machines (OIMs) is similar to that of the classical Kuramoto models, with the main difference being that there is an additional term in OIMs, called the second harmonic term. However, the dynamic behavior of an all-to-all connected OIM is significantly different and its intricate properties are largely unexplored. In this article, we study in detail the properties of the all-to-all connected OIMs and explore their application as associative memory. The number of patterns such an OIM can store increases exponentially with respect to the number of oscillators. To improve the performance of the OIMs for associative memory, we propose a new harmonic term so that the resulting OIM achieves pattern retrieval with high accuracy in the presence of a high level of noise.},
  archive      = {J_TNNLS},
  author       = {Yi Cheng and Zongli Lin},
  doi          = {10.1109/TNNLS.2025.3609571},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {All-to-all connected oscillator ising machines and their application as associative memory},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedNK-RF: Federated kernel learning with heterogeneous data and optimal rates. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3612728'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) has become a mainstream decentralized learning paradigm due to its privacy-preserving features. However, the heterogeneity of data in FL can reduce predictive accuracy and complicate the analysis of the generalization properties of FL methods. In this article, we propose efficient federated kernel learning (FedK) algorithms and study their generalization properties. We first devise FedK with random features (FedK-RF), which acquires global information through sharing RF of local data subsets, enhancing predictive capability while protecting privacy. We then propose federated Nystr√∂m approximation with RF (FedNK-RF) that reduces errors resulted from RF. Furthermore, using integral operator theory, we derive the excess risk bounds with minimax optimal rates, which illustrate the impacts from data heterogeneity and shared information. Finally, we conduct several experiments that demonstrate the superiority of the proposed FedNK-RF.},
  archive      = {J_TNNLS},
  author       = {Xuning Zhang and Jian Li and Rong Yin and Weiping Wang},
  doi          = {10.1109/TNNLS.2025.3612728},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {FedNK-RF: Federated kernel learning with heterogeneous data and optimal rates},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
