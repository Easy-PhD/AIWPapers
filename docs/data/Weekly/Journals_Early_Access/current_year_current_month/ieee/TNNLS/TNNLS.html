<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TNNLS</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tnnls">TNNLS - 34</h2>
<ul>
<li><details>
<summary>
(2025). Unveiling group-specific distributed concept drift: A fairness imperative in federated learning. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3601834'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the evolving field of machine learning, ensuring group fairness has become a critical concern, prompting the development of algorithms designed to mitigate bias in decision-making processes. Group fairness refers to the principle that a model’s decisions should be equitable across different groups defined by sensitive attributes such as gender or race, ensuring that individuals from privileged groups and unprivileged groups are treated fairly and receive similar outcomes. However, achieving fairness in the presence of group-specific concept drift remains an unexplored frontier, and our research represents pioneering efforts in this regard. Group-specific concept drift refers to situations where one group experiences concept drift over time, while another does not, leading to a decrease in fairness even if accuracy (ACC) remains fairly stable. Within the framework of federated learning (FL), where clients collaboratively train models, its distributed nature further amplifies these challenges since each client can experience group-specific concept drift independently while still sharing the same underlying concept, creating a complex and dynamic environment for maintaining fairness. The most significant contribution of our research is the formalization and introduction of the problem of group-specific concept drift and its distributed counterpart, shedding light on its critical importance in the field of fairness. In addition, leveraging insights from prior research, we adapt an existing distributed concept drift adaptation algorithm to tackle group-specific distributed concept drift, which uses a multimodel approach, a local group-specific drift detection mechanism, and continuous clustering of models over time. The findings from our experiments highlight the importance of addressing group-specific concept drift and its distributed counterpart to advance fairness in machine learning.},
  archive      = {J_TNNLS},
  author       = {Teresa Salazar and João Gama and Helder Araújo and Pedro Henriques Abreu},
  doi          = {10.1109/TNNLS.2025.3601834},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Unveiling group-specific distributed concept drift: A fairness imperative in federated learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A decomposition optimization-based multiobjective reinforcement learning algorithm for obtaining nonconvex pareto fronts. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3603165'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiobjective reinforcement learning (MORL) aims to seek a complete Pareto front (PF) with different compromise policies in multiobjective Markov decision processes (MOMDPs). However, most MORL algorithms currently have a limitation in handling the MOMDPs with nonconvex PFs. In this article, we propose a nonlinear MORL algorithm based on decomposition and variance reduction (MORL/D-VR) to overcome this limitation. MORL/D-VR adopts the Tchebycheff approach to transform a given MOMDP into a set of single-objective Markov decision processes (MDPs) and subsequently applies an improved policy gradient algorithm, called expected utility policy gradient (EUPG), to solve each single-objective MDP efficiently. We analyze the Pareto optimality of employing the Tchebycheff approach and policy gradient methods that use the full return to update policy for solving MOMDPs. The analysis shows that such a case can identify any Pareto optimal policy regardless of the shape of PFs theoretically. This can provide a theoretical guarantee for applying the Tchebycheff approach and EUPG in MORL/D-VR to obtain the policies within the nonconvex PFs. Moreover, we devise a new baseline for EUPG to reduce the variance of gradient updates and adopt a weight vector adaptation method to improve diversity. The experimental results show that MORL/D-VR achieves a desirable performance in handling problems with different convex and nonconvex PFs and outperforms current state-of-the-art MORL algorithms.},
  archive      = {J_TNNLS},
  author       = {Tianyang Li and Ying Meng and Lixin Tang},
  doi          = {10.1109/TNNLS.2025.3603165},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A decomposition optimization-based multiobjective reinforcement learning algorithm for obtaining nonconvex pareto fronts},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DA-PFL: Dynamic affinity aggregation in personalized federated learning under class imbalance. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3598818'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized federated learning (PFL) has become a hot research topic that can learn a personalized learning model for each client. Existing PFL models prefer to aggregate similar clients with similar data distribution to improve the performance of learning models. However, similarity-based PFL methods may exacerbate the class imbalance problem. In this article, we propose a novel dynamic affinity-based PFL (DA-PFL) model to alleviate the class imbalanced problem during federated learning. Specifically, we build an affinity metric from a complementary perspective to guide which clients should be aggregated. We then design a dynamic aggregation strategy that adjusts client aggregation based on the affinity metric in each round, thereby reducing the risk of class imbalance. Extensive experiments demonstrate that the proposed DA-PFL model can significantly improve the accuracy of each client in four real-world datasets with state-of-the-art comparison methods.},
  archive      = {J_TNNLS},
  author       = {Xu Yang and Jiyuan Feng and Yongxin Tong and Lingzhi Wang and Songyue Guo and Binxing Fang and Qing Liao},
  doi          = {10.1109/TNNLS.2025.3598818},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {DA-PFL: Dynamic affinity aggregation in personalized federated learning under class imbalance},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust PID-type iterative learning control for nonlinear square and nonsquare systems. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3601656'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, a novel PID-type adaptive iterative learning control (AILC) method is proposed for a class of nonlinear systems with unspecified control gain matrices and bounded iterative-varying uncertainties. Unlike the existing iterative learning method with accumulation of control information, the new PID-type AILC avoids control information accumulation in traditional iterative learning control (ILC), maintaining convergence based on error information and confining iteration to parameter estimation, suitable for amplitude- or frequency-limited controllers. Different from the existing approaches of P-type AILC, this work extends ILC advances to PID-type AILC for nonlinear square or nonsquare systems with unknown control gain matrices, enhancing robustness through simultaneous convergence of integral and proportional error terms over a larger range. This analysis method diverges from traditional approaches relying on contraction mappings or asymptotic stability theorems; error convergence is analyzed using inequalities of a composite energy function (CEF). The effectiveness of this work has been validated through two illustrated examples. The results show that compared with P-type AILC, the convergence speed can be increased by approximately two to three times.},
  archive      = {J_TNNLS},
  author       = {Kechao Xu and Bo Meng and Zhen Wang and Xia Huang},
  doi          = {10.1109/TNNLS.2025.3601656},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Robust PID-type iterative learning control for nonlinear square and nonsquare systems},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Privacy-preserving video anomaly detection: A survey. <em>TNNLS</em>, 1-22. (<a href='https://doi.org/10.1109/TNNLS.2025.3600252'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The video anomaly detection (VAD) aims to automatically analyze spatiotemporal patterns in surveillance videos collected from open spaces to detect anomalous events that may cause harm, such as fighting, stealing, and car accidents. However, vision-based surveillance systems such as closed-circuit television (CCTV) often capture personally identifiable information. The lack of transparency and interpretability in video transmission and usage raises public concerns about privacy and ethics, limiting the real-world application of VAD. Recently, researchers have focused on privacy concerns in VAD by conducting systematic studies from various perspectives, including data, features, and systems, making privacy-preserving VAD (P2VAD) a hotspot in the AI community. However, the current research in P2VAD is fragmented, and prior reviews have mostly focused on methods using RGB sequences, overlooking privacy leakage and appearance bias considerations. To address this gap, this article is the first to systematically review the progress of P2VAD, defining its scope and providing an intuitive taxonomy. We outline the basic assumptions, learning frameworks, and optimization objectives of various approaches, analyzing their strengths, weaknesses, and potential correlations. In addition, we provide open access to research resources such as benchmark datasets and available code. Finally, we discuss key challenges and future opportunities from the perspectives of AI development and P2VAD deployment, aiming to the guide future work in the field.},
  archive      = {J_TNNLS},
  author       = {Yang Liu and Siao Liu and Xiaoguang Zhu and Hao Yang and Jielin Li and Juncen Guo and Liangyu Teng and Dingkang Yang and Yan Wang and Jing Liu},
  doi          = {10.1109/TNNLS.2025.3600252},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-22},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Privacy-preserving video anomaly detection: A survey},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nesterov accelerated gradient tracking with adam for distributed online optimization. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3604059'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents an accelerated distributed optimization algorithm for online optimization problems over large-scale networks. The proposed algorithm’s iteration only relies on local computation and communication. To effectively adapt to dynamic changes and achieve a fast convergence rate while maintaining good convergence performance, we design a new algorithm called NGTAdam. This algorithm combines the Nesterov acceleration technique with an adaptive moment estimation method. The convergence of NGTAdam is evaluated by evaluating its dynamic regret through the use of linear system inequality. For online convex optimization problems, we provide an upper bound on the dynamic regret of NGTAdam, which depends on the initial conditions and the time-varying nature of the optimization problem. Moreover, we show that if the time-varying part of this upper bound is sublinear with time, the dynamic regret is also sublinear. Through a variety of numerical experiments, we demonstrate that NGTAdam outperforms state-of-the-art distributed online optimization algorithms.},
  archive      = {J_TNNLS},
  author       = {Yanxu Su and Qingyang Sheng and Xiasheng Shi and Chaoxu Mu and Changyin Sun},
  doi          = {10.1109/TNNLS.2025.3604059},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Nesterov accelerated gradient tracking with adam for distributed online optimization},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fine-grained Audio–Visual event localization. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3600878'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Audio–visual event localization (AVEL) aims to recognize events in videos by associating audio–visual information. However, events involved in existing AVEL tasks are usually coarse-grained events. Actually, finer-grained events are sometimes necessary to be distinguished, especially in certain expert-level applications or rich-content-generation studies. However, this is challenging because they are more difficult to detect or distinguish compared with coarse-grained events. To better address this problem, we discuss a new setting of fine-grained AVEL from dataset to method. First, we constructed the first fine-grained audio–visual event dataset, which is called IT-AVE, relying on videos of playing musical instruments, containing 13k video clips and over 52k audio–visual events. All events are labeled from professional music practitioners, and the event categories are all derived from playing techniques, which are fine-grained with little interclass variation. Next, we designed a new fine-grained event localization method, spatial–temporal video event detector (SVED), which focuses on the challenges that fine-grained events are more imperceptible and prone to be disturbed. Finally, we conduct extensive experiments based on the proposed IT-AVE dataset versus fine-grained versions of two existing related datasets, including UnAV-22 derived from UnAV-100 and FineAction-AV derived from FineAction. Experimental results demonstrate the effectiveness of our method. We hope that this work will contribute to the exploration of an integrated understanding of audio–visual videos.},
  archive      = {J_TNNLS},
  author       = {Baoyu Fan and Lu Liu and Xiaochuan Li and Runze Zhang and Liang Jin and Jin Zhang},
  doi          = {10.1109/TNNLS.2025.3600878},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Fine-grained Audio–Visual event localization},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrating clinical knowledge graphs and gradient-based neural systems for enhanced melanoma diagnosis via the seven-point checklist. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3600443'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The seven-point checklist (7PCL) is a widely used diagnostic tool in dermoscopy for identifying malignant melanoma by assigning point values to seven specific attributes. However, the traditional 7PCL is limited to distinguishing between malignant melanoma and melanocytic nevi (MN) and falls short in scenarios where multiple skin diseases with appearances similar to melanoma coexist. To address this limitation, we propose a novel diagnostic framework that integrates a clinical knowledge-based topological graph (CKTG) with a gradient diagnostic strategy featuring a data-driven weighting (GD-DDW) system. The CKTG captures both the internal and external relationships among the 7PCL attributes, while the GD-DDW emulates dermatologists’ diagnostic processes, prioritizing visual observation before making predictions. Additionally, we introduce a multimodal feature extraction approach leveraging a dual-attention mechanism to enhance feature extraction through cross-modal interaction and unimodal collaboration. This method incorporates meta-information to uncover interactions between clinical data and image features, ensuring more accurate and robust predictions. Our approach, evaluated on the EDRA dataset, achieved an average AUC of 88.6%, demonstrating superior performance in melanoma detection and feature prediction. This integrated system provides data-driven benchmarks for clinicians, significantly enhancing the precision of melanoma diagnosis.},
  archive      = {J_TNNLS},
  author       = {Yuheng Wang and Tianze Yu and Jiayue Cai and Sunil Kalia and Harvey Lui and Z. Jane Wang and Tim K. Lee},
  doi          = {10.1109/TNNLS.2025.3600443},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Integrating clinical knowledge graphs and gradient-based neural systems for enhanced melanoma diagnosis via the seven-point checklist},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Surfer: A world model-based framework for vision-language robot manipulation. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3594117'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considering how to make the model accurately understand and follow natural language instructions and perform actions consistent with world knowledge is a key challenge in robot manipulation. This mainly includes human fuzzy instruction reasoning and the following of physical knowledge. Therefore, the embodied intelligence agent must have the ability to model world knowledge from training data. However, most existing vision and language robot manipulation methods mainly operate in less realistic simulators and language settings and lack explicit modeling of world knowledge. To bridge this gap, we introduce a novel and simple robot manipulation framework, called Surfer. It is based on the world model, treats robot manipulation as a state transfer of the visual scene, and decouples it into two parts: action and scene. Then, the generalization ability of the model on new instructions and new scenes is enhanced by explicit modeling of the action and scene prediction in multimodal information. In addition, we built a robot manipulation simulation platform that supports physics execution based on the MuJoCo physics engine. It can automatically generate demonstration training data and test data, effectively reducing labor costs. To conduct a comprehensive and systematic evaluation of the visual-language understanding and physical execution of the manipulation model, we also created a robotic manipulation benchmark with different difficulty levels, called SeaWave. It contains four visual-language manipulation tasks of different difficulty levels and can provide a standardized testing platform for embedded AI agents in multimodal environments. Overall, we hope Surfer can freely surf in the robot’s SeaWave benchmark. Extensive experiments show that Surfer consistently outperforms all baselines significantly in all manipulation tasks. On average, Surfer achieved a success rate of 54.74% on the defined four levels of manipulation tasks, exceeding the best baseline performance of 51.07%. The simulator, code, and benchmarks are released at https://pzhren.github.io/Surfer.},
  archive      = {J_TNNLS},
  author       = {Pengzhen Ren and Kaidong Zhang and Hetao Zheng and Zixuan Li and Yuhang Wen and Fengda Zhu and Shikui Ma and Xiaodan Liang},
  doi          = {10.1109/TNNLS.2025.3594117},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Surfer: A world model-based framework for vision-language robot manipulation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dual-discriminator generative adversarial network for anomaly detection. <em>TNNLS</em>, 1-12. (<a href='https://doi.org/10.1109/TNNLS.2025.3585978'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series anomaly detection has shown potential in various fields, such as finance, aerospace, and security. The fuzzy definition of data anomalies, the complexity of data patterns, and the scarcity of abnormal data samples pose significant challenges to anomaly detection. Researchers have extensively employed autoencoders (AEs) and generative adversarial networks (GANs) in studying time series anomaly detection methods. However, relying on reconstruction error, the AE-based anomaly detection algorithm needs more effective regularization methods, rendering it susceptible to the problem of overfitting. Meanwhile, GAN-based anomaly detection algorithms require high-quality training data, significantly impacting their practical deployment. We propose a novel GAN based on a dual-discriminator structure to address these issues. The model first processes the data with the generator to obtain the reconstruction error and then calculates pseudo-labels to divide the data into two categories. One data category is input into the first discriminator, where a minor loss between the data and its reconstructed counterpart is better. The other data category is input into the second discriminator, where a larger loss between the data and its reconstructed counterpart is better. Through this process, the model can effectively constrain the generator, retaining information on normal data during data reconstruction while discarding information on abnormal data. After conducting experiments on multiple benchmark datasets, the proposed GAN based on a dual-discriminator structure achieved good results in anomaly detection, outperforming several advanced methods. Additionally, the model also performed well in practical transformer data.},
  archive      = {J_TNNLS},
  author       = {Da Ding and Youquan Wang and Haicheng Tao and Jia Wu and Jie Cao},
  doi          = {10.1109/TNNLS.2025.3585978},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A dual-discriminator generative adversarial network for anomaly detection},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Koopman-driven linearized model-based offline planning with application to freeway ramp metering. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3605015'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a novel model-based planning framework for freeway ramp metering (RM), denoted as Koopman-driven linearized model-based offline planning (KLMOP). This framework integrates the model predictive control (MPC) and offline reinforcement learning (RL) under assumptions of a linear Markov decision process (MDP) with the Koopman operator. KLMOP introduces a fully linearized control framework by learning and modeling the dynamics, reward function, and value function in a latent space through a Koopman-based latent dynamical model (KLDM) and a pessimistic value iteration (PEVI) algorithm. This formulation builds upon the connection between Koopman operator theory and linear MDP. Contrastive learning is employed to ensure the expressiveness and structural conditions of the latent representation in linear MDP, enabling accurate reward prediction and efficient policy optimization. The MPC-based planning policy, then, leverages these components to solve a linear MPC problem efficiently in the latent space. Extensive simulation studies demonstrate that KLMOP significantly improves computational efficiency and control performance as compared with existing baseline methods for RM control. This framework provides a theoretically grounded and computationally efficient approach to linearizing nonlinear control problems, and its learning-based design makes it adaptable to broader applications.},
  archive      = {J_TNNLS},
  author       = {Tao Zhou and Chuanye Gu and Chee Peng Lim and Jinlong Yuan},
  doi          = {10.1109/TNNLS.2025.3605015},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Koopman-driven linearized model-based offline planning with application to freeway ramp metering},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Expandable residual approximation for knowledge distillation. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3602118'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation (KD) aims to transfer knowledge from a large-scale teacher model to a lightweight one, significantly reducing computational and storage requirements. However, the inherent learning capacity gap between the teacher and student often hinders the sufficient transfer of knowledge, motivating numerous studies to address this challenge. Inspired by the progressive approximation principle in the Stone–Weierstrass theorem, we propose expandable residual approximation (ERA), a novel KD method that decomposes the approximation of residual knowledge into multiple steps, reducing the difficulty of mimicking the teacher’s representation through a divide-and-conquer approach. Specifically, ERA employs a multibranched residual network (MBRNet) to implement this residual knowledge decomposition. Additionally, a teacher weight integration (TWI) strategy is introduced to mitigate the capacity disparity by reusing the teacher’s head weights. Extensive experiments show that ERA improves the Top-1 accuracy on ImageNet classification benchmark by 1.41% and the AP on the MS COCO object detection benchmark by 1.40, as well as achieving leading performance across computer vision tasks.},
  archive      = {J_TNNLS},
  author       = {Zhaoyi Yan and Binghui Chen and Yunfan Liu and Qixiang Ye},
  doi          = {10.1109/TNNLS.2025.3602118},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Expandable residual approximation for knowledge distillation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Long-tail class incremental learning via bias calibration with application to continuous fault diagnosis. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3602182'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class incremental learning (CIL) offers a promising framework for continuous fault diagnosis (CFD), allowing networks to accumulate knowledge from streaming industrial data and recognize new fault classes. However, current CIL methods assume a balanced data stream, which does not align with the long-tail distribution of fault classes in real industrial scenarios. To fill this gap, this article investigates the impact of long-tail bias in the data stream on the CIL training process through the experimental analysis. Observations show that long-tail bias in the data stream has a cascading effect, affecting the retention of old task knowledge and learning new tasks. Concurrently, the incremental model encounters challenges in identifying samples that conflict with its biases. Accordingly, we propose a CFD method called long-tail CIL via bias calibration (LTCIL-BC), which aims to improve the learning of bias-conflicting samples through bias exploration and debiasing. Specifically, LTCIL-BC simultaneously trains a primary debiased network and an auxiliary biased network. Then, a bias-indicating score is developed to provide insight into model bias and data bias based on the prediction error of the primary and auxiliary models, respectively. LTCIL-BC subsequently adjusts the logits of the debiased network using the bias-indicating score to guide optimization, thereby better utilizing the role of old class exemplars and reducing catastrophic forgetting. Experiments on power system (PS) and secure water treatment (SWaT) datasets demonstrate the superior performance of LTCIL-BC in CFD, achieving up to 9% improvement over state-of-the-art baselines in multiple long-tailed CIL setting. Comprehensive results demonstrate the effectiveness of LTCIL-BC in jointly addressing data and model bias during calibration and prioritizing bias-conflicting samples.},
  archive      = {J_TNNLS},
  author       = {Dongyue Chen and Zongxia Xie and Wenlong Yu and Qinghua Hu},
  doi          = {10.1109/TNNLS.2025.3602182},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Long-tail class incremental learning via bias calibration with application to continuous fault diagnosis},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evidential graph contrastive alignment for source-free blending-target domain adaptation. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3603224'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we first tackle a more realistic domain adaptation (DA) setting: source-free blending-target DA (SF-BTDA), where we cannot access to source-domain data while facing mixed multiple target domains without any domain labels in prior. Compared to existing DA scenarios, SF-BTDA generally faces the coexistence of different label shifts in different targets, along with noisy target pseudolabels generated from the source model. In this article, we propose a new method called evidential graph contrastive alignment (EGCA) to decouple the blending-target domain and alleviate the effect of noisy target pseudolabels. First, to improve the quality of pseudo target labels, we propose a calibrated evidential learning (CEL) module to iteratively improve both the accuracy and certainty of the resulting model and adaptively generate high-quality pseudo target labels. Second, we design a graph contrastive learning with the domain distance matrix and confidence-uncertainty criterion, to minimize the distribution gap of samples of the same class in the blending-target domain, which alleviates the coexistence of different label shifts in blended targets. We conduct a new benchmark based on three standard DA datasets, and EGCA outperforms other methods with considerable gains and achieves comparable results compared with those that have domain labels or source data in prior.},
  archive      = {J_TNNLS},
  author       = {Juepeng Zheng and Guowen Li and Yibin Wen and Jinxiao Zhang and Runmin Dong and Haohuan Fu},
  doi          = {10.1109/TNNLS.2025.3603224},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Evidential graph contrastive alignment for source-free blending-target domain adaptation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Incremental learning for defect segmentation with efficient transformer semantic complement. <em>TNNLS</em>, 1-10. (<a href='https://doi.org/10.1109/TNNLS.2025.3604956'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In industrial scenarios, semantic segmentation of surface defects is vital for identifying, localizing, and delineating defects. However, new defect types constantly emerge with product iterations or process updates. Existing defect segmentation models lack incremental learning capabilities, and direct fine-tuning (FT) often leads to catastrophic forgetting. Furthermore, low contrast between defects and background, as well as among defect classes, exacerbates this issue. To address these challenges, we introduce a plug-and-play Transformer-based semantic complement module (TSCM). With only a few added parameters, it injects global contextual features from multi-head self-attention into shallow convolutional neural network (CNN) feature maps, compensating for convolutional receptive-field limits and fusing global and local information for better segmentation. For incremental updates, we propose multi-scale spatial pooling distillation (MSPD), which uses pseudo-labeling and multi-scale pooling to preserve both short- and long-range spatial relations and provides smooth feature alignment between teacher and student. Additionally, we adopt an adaptive weight fusion (AWF) strategy with a dynamic threshold that assigns higher weights to parameters with larger updates, achieving an optimal balance between stability and plasticity. The experimental results on two industrial surface defect datasets demonstrate that our method outperforms existing approaches in various incremental segmentation scenarios.},
  archive      = {J_TNNLS},
  author       = {Xiqi Li and Zhifu Huang and Ge Ma and Yu Liu},
  doi          = {10.1109/TNNLS.2025.3604956},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Incremental learning for defect segmentation with efficient transformer semantic complement},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Temporal modeling with frozen Vision–Language foundation models for parameter-efficient Text–Video retrieval. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3605657'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal modeling plays an important role in the effective adaption of the powerful pretrained text–image foundation model into text–video retrieval. However, existing methods often rely on additional heavy trainable modules, such as transformer or BiLSTM, which are inefficient. In contrast, we avoid introducing such heavy components by leveraging frozen foundation models. To this end, we propose temporal modeling with frozen vision–language foundation models (TFVL) to model the temporal dynamics with fixed encoders. Specifically, text encoder temporal modeling (TextTemp) and image encoder temporal modeling (ImageTemp) apply frozen text and image encoders within the video head and video backbone, respectively. TextTemp uses a frozen text encoder to interpret frame representations as “visual words” within a temporal “sentence,” capturing temporal dependencies. On the other hand, ImageTemp uses a frozen image encoder to treat all frame tokens as a unified visual entity, learning spatiotemporal information. The total trainable parameters of our method, comprising a lightweight projection and several prompt tokens, are significantly fewer than those in other existing methods. We evaluate the effectiveness of our method on MSR-VTT, DiDeMo, ActivityNet, and LSMDC. Compared with full fine-tuning on MSR-VTT, our TFVL achieves an average 3.25% gain in R@1 with merely 0.35% of the parameters. Extensive experiments demonstrate that the proposed TFVL outperforms state-of-the-art methods with significantly fewer parameters.},
  archive      = {J_TNNLS},
  author       = {Leqi Shen and Tianxiang Hao and Tao He and Yifeng Zhang and Pengzhang Liu and Sicheng Zhao and Jungong Han and Guiguang Ding},
  doi          = {10.1109/TNNLS.2025.3605657},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Temporal modeling with frozen Vision–Language foundation models for parameter-efficient Text–Video retrieval},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust missing value imputation with proximal optimal transport for low-quality IIoT data. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3601130'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate imputation of missing data is crucial in the Industrial Internet-of-Things (IIoT), where operations are often compromised by noisy samples from harsh environments. Traditional imputation methods struggle with such noise due to their black-box nature or lack of adaptability. To address this issue, we recast data imputation as a distribution alignment challenge, utilizing the flexibility of optimal transport (OT) to handle noisy samples. Specifically, we first introduce the Proximal Optimal Transport (POT) problem, where the transportation cost is obtained by the network simplex approach with a selective matching mechanism, which renders it capable of matching distributions with noisy samples. Subsequently, we propose the POT-I framework, where the objective is to minimize the transport cost of POT. The produced gradient is used to refine the imputation value, which achieves missing data imputation (MDI) while getting robustness to noisy samples. Experiments on real-world IIoT datasets demonstrate the superiority of POT-I over state-of-the-art imputation methods.},
  archive      = {J_TNNLS},
  author       = {Hao Wang and Zhichao Chen and Yuan Shen and Hui Zheng and Degui Yang and Dangjun Zhao and Buge Liang},
  doi          = {10.1109/TNNLS.2025.3601130},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Robust missing value imputation with proximal optimal transport for low-quality IIoT data},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiagent inductive policy optimization. <em>TNNLS</em>, 1-12. (<a href='https://doi.org/10.1109/TNNLS.2025.3601360'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Policy optimization methods are promising to tackle high-complexity reinforcement learning (RL) tasks with multiple agents. In this article, we derive a general trust region for policy optimization methods by considering the effect of subpolicy combinations among agents in multiagent environments. Based on this trust region, we propose an inductive objective to train the policy function, which can ensure agents learn monotonically improving policies. Furthermore, we observe that the policy always updates very weakly before falling into a local optimum. To address this, we introduce a cost regarding policy distance in the inductive objective to strengthen the motivation of agents to explore new policies. This approach strikes a balance during training, where the policy update step size remains within the constraints of the trust region, preventing excessive updates while avoiding getting stuck in local optima. Simulations on wind farm (WF) control tasks and two multiagent benchmarks demonstrate the high performance of the proposed multiagent inductive policy optimization (MAIPO) method.},
  archive      = {J_TNNLS},
  author       = {Yubo Huang and Xiaowei Zhao},
  doi          = {10.1109/TNNLS.2025.3601360},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Multiagent inductive policy optimization},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bicriteria policy optimization for high-accuracy reinforcement learning. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3605362'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In essence, reinforcement learning (RL) solves optimal control problem (OCP) by employing a neural network (NN) to fit the optimal policy from state to action. The accuracy of policy approximation is often very low in complex control tasks, leading to unsatisfactory control performance compared with online optimal controllers. A primary reason is that the landscape of value function is always not only rugged in most areas but also flat on the bottom, which damages the convergence to the minimum point. To address this issue, we develop a bicriteria policy optimization (BPO) algorithm, which leverages a few optimal demonstration trajectories to guide the policy search at the gradient level. Different from conventional problem definition, BPO seeks to solve a bicriteria OCP, which has two homomorphic objectives: one is from the standard reward signals and the other is to align the demonstration trajectories. We introduce two co-state variables, one for each objectives, and formulate two Hamiltonians for this bicriteria OCP. The resulting new optimality condition preserves the minimum values of both Hamiltonians. Furthermore, we find that gradient conflict is a key obstacle to simultaneously descending both Hamiltonians, and its impact is negatively proportional to the inner product between the ideal and actual gradients. A minimax optimization problem is built at each RL iteration to minimize conflicts between two homomorphic objectives, whose solution for policy updating is referred to as harmonic gradient. By converting its inner optimization loop into a linear programming with convex trust region constraint, we simplify this problem into a single-loop maximization problem with much increased computational efficiency. Experiment tests on both linear and nonlinear control tasks validate the effectiveness of our BPO algorithm on the accuracy improvement of policy network.},
  archive      = {J_TNNLS},
  author       = {Guojian Zhan and Xiangteng Zhang and Feihong Zhang and Letian Tao and Shengbo Eben Li},
  doi          = {10.1109/TNNLS.2025.3605362},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Bicriteria policy optimization for high-accuracy reinforcement learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised Visible–Infrared ReID via pseudo-label correction and modality-level alignment. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3591641'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised visible–infrared person reidentification (UVI-ReID) has recently gained great attention due to its potential for enhancing human detection in diverse environments without labeling. Previous methods utilize intramodality clustering and cross-modality feature matching to achieve UVI-ReID. However, there exist two challenges: 1) noisy pseudo-labels might be generated in the clustering process and 2) the cross-modality feature alignment via matching the marginal distribution of visible and infrared modalities may misalign the different identities from the two modalities. In this article, we first conduct a theoretical analysis where an interpretable generalization upper bound is introduced. Based on the analysis, we then propose a novel unsupervised cross-modality person reidentification framework (PRAISE). Specifically, to address the first challenge, we propose a pseudo-label correction (PLC) strategy that utilizes a beta mixture model (BMM) to predict the probability of misclustering-based network’s memory effect and rectifies the correspondence by adding a perceptual term to contrastive learning. Next, we introduce a modality-level alignment (MLA) strategy that generates paired visible–infrared latent features and reduces the modality gap by aligning the labeling function of visible and infrared features to learn identity-discriminative and modality-invariant features. Experimental results on two benchmark datasets demonstrate that our method achieves a state-of-the-art (SOTA) performance than the unsupervised visible-ReID methods.},
  archive      = {J_TNNLS},
  author       = {Yexin Liu and Weiming Zhang and Athanasios V. Vasilakos and Lin Wang},
  doi          = {10.1109/TNNLS.2025.3591641},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Unsupervised Visible–Infrared ReID via pseudo-label correction and modality-level alignment},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). When to align: Dynamic behavior consistency for multiagent systems via intrinsic rewards. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3598301'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multiagent systems, learning optimal behavior policies for individual agents remains a challenging yet crucial task. While recent research has made strides in this area, the issue of when agents should maintain consistent behaviors with one another is still not adequately addressed. This article proposes a novel approach to enable agents to autonomously decide whether their behaviors should align with those of their peers by leveraging intrinsic rewards to optimize their policies. We define behavior consistency as the divergence between the actions taken by two agents given the same observations. To encourage agents to be aware of each other’s behaviors, we propose dynamic consistency-based intrinsic reward (DCIR), which guides agents in determining when to synchronize their behaviors. In addition, we introduce a dynamic scaling network (DSN) that provides learnable scaling factors at each time step, enabling agents to dynamically decide the extent of rewarding consistent behavior. Our method is evaluated on environments including Multiagent Particle, Google Research Football, and StarCraft II Micromanagement. Experimental results demonstrate its effectiveness in learning optimal policies.},
  archive      = {J_TNNLS},
  author       = {Kunyang Lin and Yufeng Wang and Peihao Chen and Runhao Zeng and Yinjie Lei and Siyuan Zhou and Qing Du and Mingkui Tan and Chuang Gan},
  doi          = {10.1109/TNNLS.2025.3598301},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {When to align: Dynamic behavior consistency for multiagent systems via intrinsic rewards},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conv4Rec: A 1-by-1 convolutional autoencoder for user profiling through joint analysis of implicit and explicit feedback. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3597051'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a new convolutional autoencoder architecture for user modeling and recommendation tasks with several improvements over the state of the art. First, our model has the flexibility to learn a set of associations and combinations between different interaction types in a way that carries over to each user and item. Second, our model is able to learn jointly from both the explicit ratings and the implicit information in the sampling pattern (which we refer to as ”implicit feedback”). It can also make separate predictions for the probability of consuming content and the likelihood of granting it a high rating if observed. This not only allows the model to make predictions for both the implicit and explicit feedback, but also increases the informativeness of the predictions: in particular, our model can identify items that users would not have been likely to consume naturally, but would be likely to enjoy if exposed to them. Finally, we provide several generalization bounds for our model, which, to the best of our knowledge, are among the first generalization bounds for autoencoders in a Recommender systems setting; we also show that optimizing our loss function guarantees the recovery of the exact sampling distribution over interactions up to a small error in total variation. In experiments on several real-life datasets, we achieve state-of-the-art performance on both the implicit and explicit feedback prediction tasks despite relying on a single model for both, and benefiting from additional interpretability in the form of individual predictions for the probabilities of each possible rating.},
  archive      = {J_TNNLS},
  author       = {Antoine Ledent and Petr Kasalický and Rodrigo Alves and Hady W. Lauw},
  doi          = {10.1109/TNNLS.2025.3597051},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Conv4Rec: A 1-by-1 convolutional autoencoder for user profiling through joint analysis of implicit and explicit feedback},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Channelwise regional integrate and multiple firing neuron: Improving the spatiotemporal learning of spiking neural networks. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3606849'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural networks (SNNs) can be operated in an event-driven manner to save energy consumption of artificial neural networks (ANNs), which has attracted enormous research interests for their high biological plausibility and powerful spatiotemporal information processing. However, representative studies only evaluated SNNs on static temporal tasks or short sequence tasks, which could not fully demonstrate the advantages of SNNs in spatiotemporal learning. In addition, we point out that the existing directly trained SNNs to face the problems of long-term memory, network degeneration, gradient saturation, and heterogeneity learning, these limit the performance of SNNs. In this article, we propose channelwise regional integrate and multiple firing (CRIMF) neuron to improve the spatiotemporal learning of SNNs. First, CRIMF neuron contains a new internal state of regional current that enhances the memory of spiking neurons and facilitates the learning of temporal information over long time steps. Second, CRIMF neuron is implemented with the multiple firing mechanisms; it is able to adjust the distribution of membrane potential and membrane potential gradient in the single firing mechanism, thus mitigating the underactivation and gradient saturation. Third, CRIMF neuron is trained with the channelwise learning strategy for the targeted learning of different types of temporal features, and an index of differentiation degree is proposed to visualize the effectiveness of the channelwise learning strategy. We also introduce the regional current reset equation and normalize the input of postsynaptic neurons in spatiotemporal dimension to avoid network degeneration. Finally, we select two emotion electroencephalogram (EEG) datasets and perform the evaluations based on manual features and raw signals. Experimental results show that CRIMF-based SNNs outperform the state-of-the-art methods in static temporal task, and CRIMF neurons are superior to the advanced spiking neurons and recurrent units of ANNs in dynamic temporal task, using low energy consumption.},
  archive      = {J_TNNLS},
  author       = {Mincheng Cai and Quan Liu and Kun Chen and Li Ma},
  doi          = {10.1109/TNNLS.2025.3606849},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Channelwise regional integrate and multiple firing neuron: Improving the spatiotemporal learning of spiking neural networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive modality balanced online knowledge distillation for Brain–Eye–Computer-based dim object detection. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3605710'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advanced cognition can be measured from the human brain using brain–computer interfaces (BCIs). Integrating these interfaces with computer vision techniques, which possess efficient feature extraction capabilities, can achieve more robust and accurate detection of dim targets in aerial images. However, existing target detection methods primarily concentrate on homogeneous data, lacking efficient and versatile processing capabilities for heterogeneous multimodal data. In this article, we first build a brain–eye–computer-based object detection system for aerial images under few-shot conditions. This system detects suspicious targets using region proposal networks (RPNs), evokes the event-related potential (ERP) signal in electroencephalogram (EEG) through the eye-tracking-based slow serial visual presentation (ESSVP) paradigm, and constructs the EEG–image data pairs with eye movement data. Then, an adaptive modality balanced online knowledge distillation (AMBOKD) method is proposed to recognize dim objects with the EEG–image data. AMBOKD fuses EEG and image features using a multihead attention module, establishing a new modality with comprehensive features. To enhance the performance and robust capability of the fusion modality, simultaneous training and mutual learning between modalities are enabled by end-to-end online KD (OKD). During the learning process, an adaptive modality balancing module is proposed to ensure multimodal equilibrium by dynamically adjusting the weights of the importance and the training gradients across various modalities. The effectiveness and superiority of our method are demonstrated by comparing it with existing state-of-the-art methods. Additionally, experiments conducted on public datasets and real-world scenarios demonstrate the reliability and practicality of the proposed system and the designed method. The dataset and the source code can be found at: https://github.com/lizixing23/AMBOKD},
  archive      = {J_TNNLS},
  author       = {Zixing Li and Chao Yan and Zhen Lan and Xiaojia Xiang and Han Zhou and Jun Lai and Dengqing Tang},
  doi          = {10.1109/TNNLS.2025.3605710},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Adaptive modality balanced online knowledge distillation for Brain–Eye–Computer-based dim object detection},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AMAP: Automatic multihead attention pruning by similarity-based pruning indicator. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3606750'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the strong performance of transformers, quadratic computation complexity of self-attention presents challenges in applying them to vision tasks. Linear attention reduces this complexity from quadratic to linear, offering a strong computation–performance tradeoff. To further optimize this, automatic pruning is an effective method to find a structure that maximizes performance within a target resource through training without any heuristic approaches. However, directly applying it to multihead attention is not straightforward due to channel mismatch. In this article, we propose an automatic pruning method to deal with this problem. Different from existing methods that rely solely on training without any prior knowledge, we integrate channel similarity-based weights into the pruning indicator to preserve the more informative channels within each head. Then, we adjust the pruning indicator to enforce that channels are removed evenly across all heads, thereby avoiding any channel mismatch. We incorporate a reweight module to mitigate information loss due to channel removal and introduce an effective pruning indicator initialization for linear attention, based on the attention differences between the original structure and each channel. By applying our pruning method to the FLattenTransformer on ImageNet-1K, which incorporates original and linear attention mechanisms, we achieve a 30% reduction of FLOPs in a near lossless manner. It also has 1.96% of accuracy gain over the DeiT-B model while reducing FLOPs by 37%, and 1.05% accuracy increase over the Swin-B model with a 10% reduction in FLOPs as well. The proposed method outperforms previous state-of-the-art efficient models and the recent pruning methods.},
  archive      = {J_TNNLS},
  author       = {Eunho Lee and Youngbae Hwang},
  doi          = {10.1109/TNNLS.2025.3606750},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {AMAP: Automatic multihead attention pruning by similarity-based pruning indicator},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unified framework for matrix backpropagation. <em>TNNLS</em>, 1-7. (<a href='https://doi.org/10.1109/TNNLS.2025.3607405'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computing matrix gradient has become a key aspect in modern signal processing/machine learning, with the recent use of matrix neural networks requiring matrix backpropagation. In this field, two main methods exist to calculate the gradient of matrix functions for symmetric positive definite (SPD) matrices, namely, the Daleckiǐ–Kreǐn/Bhatia formula and the Ionescu method. However, there appear to be a few errors. This brief aims to demonstrate each of these formulas in a self-contained and unified framework, to prove theoretically their equivalence, and to clarify inaccurate results of the literature. A numerical comparison of both methods is also provided in terms of computational speed and numerical stability to show the superiority of the Daleckiǐ–Kreǐn/Bhatia approach. We also extend the matrix gradient to the general case of diagonalizable matrices. Convincing results with the two backpropagation methods are shown on the EEG-based BCI competition dataset with the implementation of an SPDNet, yielding around 80% accuracy for one subject. Daleckiǐ–Kreǐn/Bhatia formula achieves an 8% time gain during training and handles degenerate cases.},
  archive      = {J_TNNLS},
  author       = {Gatien Darley and Stéphane Bonnet},
  doi          = {10.1109/TNNLS.2025.3607405},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-7},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A unified framework for matrix backpropagation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Theoretical advances on stochastic configuration networks. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3608555'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article advances the theoretical foundations of stochastic configuration networks (SCNs) by rigorously analyzing their convergence properties, approximation guarantees, and the limitations of nonadaptive randomized methods. We introduce a principled objective function that aligns incremental training with orthogonal projection, ensuring maximal residual reduction at each iteration without recomputing output weights. Under this formulation, we derive a novel necessary and sufficient condition for strong convergence in Hilbert spaces and establish sufficient conditions for uniform geometric convergence, offering the first theoretical justification of the SCN residual constraint. To assess the feasibility of unguided random initialization, we present a probabilistic analysis showing that even small support shifts markedly reduce the likelihood of sampling effective nodes in high-dimensional settings, thereby highlighting the necessity of adaptive refinement in the sampling distribution. Motivated by these insights, we propose greedy SCNs (GSCNs) and two optimized variants—Newton–Raphson GSCN (NR-GSCN) and particle swarm optimization GSCN (PSO-GSCN)—that incorporate Newton–Raphson refinement and particle swarm-based exploration to improve node selection. Empirical results on synthetic and real-world datasets demonstrate that the proposed methods achieve faster convergence, better approximation accuracy, and more compact architectures compared to existing SCN training schemes. Collectively, this work establishes a rigorous theoretical and algorithmic framework for SCNs, laying out a principled foundation for subsequent developments in the field of randomized neural network (NN) training.},
  archive      = {J_TNNLS},
  author       = {Xiufeng Yan and Dianhui Wang and Ivan Y. Tyukin},
  doi          = {10.1109/TNNLS.2025.3608555},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Theoretical advances on stochastic configuration networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatial–Temporal diffusion model for matrix factorization. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3605215'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Matrix factorization (MF) is a fundamental problem in machine learning, which is usually used as a feature learning method in various fields. For complex data involving spatiotemporal interactions, MF that only handles 2-D data will disrupt spatial dependence or temporal dynamics, failing to effectively couple spatial information with temporal factors. According to Markov chain principle, the spatial information of the present time is related to the spatial state of the previous time. We propose a spatial–temporal diffusion model for MF (STDMF), which uses graph diffusion to couple spatial–temporal information. Then, MF is used to learn the joint feature of data and spatial–temporal diffusion graph. Specifically, STDMF utilizes the graph diffusion with physical laws to generate spatial–temporal structure information. It obtains the underlying core structure of complex systems from a global perspective, which enhances the generalization ability of MF in noisy time-series data. To learn the lowest rank subspace of MF in time-series data, STDMF uses structural learning to constrain the rank of the learned features. Finally, STDMF is applied to clustering and anomaly detection of dynamic graph. The effectiveness of this method is verified by sufficient experiments, especially for noisy data.},
  archive      = {J_TNNLS},
  author       = {Chenxi Tian and Wenming Wu and Lingling Li and Xu Liu and Fang Liu and Wenping Ma and Licheng Jiao and Shuyuan Yang},
  doi          = {10.1109/TNNLS.2025.3605215},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Spatial–Temporal diffusion model for matrix factorization},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Continual diffuser (CoD): Mastering continual offline RL with experience rehearsal. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3598928'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial neural networks, especially recent diffusion-based models, have shown remarkable superiority in gaming, control, and QA systems, where the training tasks’ datasets are usually static. However, in real-world applications, such as robotic control of reinforcement learning (RL), the tasks are changing, and new tasks arise in a sequential order. This situation poses the new challenge of plasticity–stability tradeoff for training an agent who can adapt to task changes and retain acquired knowledge. In view of this, we propose a rehearsal-based continual diffusion model, called continual diffuser (CoD), to endow the diffuser with the capabilities of quick adaptation (plasticity) and lasting retention (stability). Specifically, we first construct an offline benchmark that contains 90 tasks from multiple domains. Then, we train the CoD on each task with sequential modeling and conditional generation for making decisions. Next, we preserve a small portion of previous datasets as the rehearsal buffer and replay it to retain the acquired knowledge. Extensive experiments on a series of tasks show that CoD can achieve a promising plasticity–stability tradeoff and outperform existing diffusion-based methods and other representative baselines on most tasks. The source code is available at https://github.com/JF-Hu/Continual_Diffuser.},
  archive      = {J_TNNLS},
  author       = {Jifeng Hu and Li Shen and Sili Huang and Zhejian Yang and Hechang Chen and Lichao Sun and Yi Chang and Dacheng Tao},
  doi          = {10.1109/TNNLS.2025.3598928},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Continual diffuser (CoD): Mastering continual offline RL with experience rehearsal},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FEU-diff: A diffusion model with fuzzy evidence-driven dynamic uncertainty fusion for medical image segmentation. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3609085'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffusion models, as a class of generative frameworks based on step-wise denoising, have recently attracted significant attention in the field of medical image segmentation. However, existing diffusion-based methods typically rely on static fusion strategies to integrate conditional priors with denoised features, making them difficult to adaptively balance their respective contributions at different denoising stages. Moreover, these methods often lack explicit modeling of pixel-level uncertainty in ambiguous regions, which may lead to the loss of structural details during the iterative denoising process, ultimately compromising the accuracy (Acc) and completeness of the final segmentation results. To this end, we propose FEU-Diff, a diffusion-based segmentation framework that integrates fuzzy evidence modeling and uncertainty fusion (UF) mechanisms. Specifically, a fuzzy semantic enhancement (FSE) module is designed to model pixel-level uncertainty through Gaussian membership functions and fuzzy logic rules, enhancing the model’s ability to identify and represent ambiguous boundaries. An evidence dynamic fusion (EDF) module estimates feature confidence via a Dirichlet-based distribution and adaptively guides the fusion of conditional information and denoised features across different denoising stages. Furthermore, the UF module quantifies discrepancies among multisource predictions to compensate for structural detail loss during the iterative denoising process. Extensive experiments on four public datasets show that FEU-Diff consistently outperforms state-of-the-art (SOTA) methods, achieving an average gain of 1.42% in the Dice similarity coefficient (DSC), 1.47% in intersection over union (IoU), and a 2.26 mm reduction in the 95th percentile Hausdorff distance (HD95). In addition, our method generates uncertainty maps that enhance clinical interpretability.},
  archive      = {J_TNNLS},
  author       = {Sheng Geng and Shu Jiang and Tao Hou and Hongcheng Yao and Jiashuang Huang and Weiping Ding},
  doi          = {10.1109/TNNLS.2025.3609085},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {FEU-diff: A diffusion model with fuzzy evidence-driven dynamic uncertainty fusion for medical image segmentation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Restoring noisy demonstration for imitation learning with diffusion models. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3607111'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imitation learning (IL) aims to learn a policy from expert demonstrations and has been applied to various applications. By learning from the expert policy, IL methods do not require environmental interactions or reward signals. However, most existing IL algorithms assume perfect expert demonstrations, but expert demonstrations often contain imperfections caused by errors from human experts or sensor/control system inaccuracies. To address the above problems, this work proposes a filter-and-restore framework to best leverage expert demonstrations with inherent noise. Our proposed method first filters clean samples from the demonstrations and then learns conditional diffusion models to recover the noisy ones. We evaluate our proposed framework and existing methods in various domains, including robot arm manipulation, dexterous manipulation, and locomotion. The experiment results show that our proposed framework consistently outperforms existing methods across all the tasks. Ablation studies further validate the effectiveness of each component and demonstrate the framework’s robustness to different noise types and levels. These results confirm the practical applicability of our framework to noisy offline demonstration data.},
  archive      = {J_TNNLS},
  author       = {Shang-Fu Chen and Co Yong and Shao-Hua Sun},
  doi          = {10.1109/TNNLS.2025.3607111},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Restoring noisy demonstration for imitation learning with diffusion models},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Peak-padding: Clustering by padding density peaks with the minimum padding cost. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3606527'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering complex-shaped clusters is still chal lenging for most existing clustering algorithms. Herein, the peak-padding clustering algorithm (PeakPad)—clustering by padding density peaks with the minimum padding cost—is proposed. PeakPad executes clustering on the density surface and views complex-shaped clusters as combinations of highly associated single-peak clusters. The minimum padding cost that fully considers the surrounding context of a density peak is proposed to reflect a density peak’s center potential, enabling PeakPad to have robust center detection performance. Unlike mean-shift (MSC), which detects centers based on their attributes in a complex-shaped density surface embedded in the high-dimensional space of density and features, PeakPad detects centers in a standard-shaped surface embedded in the 2-D density-change (DC) density space (composed of density and DC feature). Such standardization allows PeakPad to have fast and robust cluster center detection performance on complex-shaped clusters based on the minimum padding cost. Besides, PeakPad can provide a reasonable evaluation of the association between single-peak clusters by using the minimum padding cost. As a result, PeakPad can fast capture complex-shaped clusters, achieve robust center detection performance, and be suitable for large datasets. Benchmark test results on both synthetic and real datasets demonstrate the effectiveness of PeakPad.},
  archive      = {J_TNNLS},
  author       = {Junyi Guan and Bingbing Jiang and Weiguo Sheng and Yangyang Zhao and Sheng Li and Xiongxiong He},
  doi          = {10.1109/TNNLS.2025.3606527},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Peak-padding: Clustering by padding density peaks with the minimum padding cost},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging semi-supervised learning and meta-learning for re-identification in few-shot spatiotemporal anomaly detection. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3578642'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting spatiotemporal anomalies is imperative for addressing critical societal and engineering challenges, including public safety assurance, environmental hazard identification, epidemic surveillance, and transportation system optimization. Existing methodologies, however, face persistent limitations due to sparse labeled datasets and the inherent complexity of dynamic spatiotemporal systems. In order to bridge this gap, we present unsupervised-semi-supervised stacking (USemiS), a novel framework that synergizes semi-supervised learning with ensemble meta-learning. USemiS introduces three core innovations: 1) unsupervised component learners that extract low-level representations of heterogeneous anomalies, 2) a consensus-based tuning mechanism that dynamically weights robust learners via stability metrics, and 3) spatiotemporal MixUp (ST-MixUp), a tailored augmentation strategy that interpolates anomalies across spatial and temporal dimensions to enhance decision boundaries. By integrating these components, USemiS effectively disentangles latent anomaly patterns while mitigating label scarcity. Evaluated on large-scale traffic anomaly and crowd fall detection datasets, USemiS achieves state-of-the-art performance, outperforming existing methods by 1.3% and 2.1% in AUC under extreme low-label regimes (0.4% and 0.8% labeled data, respectively). These results underscore USemiS’s capacity to generalize across diverse spatiotemporal contexts, offering a scalable and robust solution for real-world applications where labeled anomalies are scarce yet critical.},
  archive      = {J_TNNLS},
  author       = {Zhen Zhou and Ziyuan Gu and Pan Liu and Wenwu Yu and Zhiyuan Liu},
  doi          = {10.1109/TNNLS.2025.3578642},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Leveraging semi-supervised learning and meta-learning for re-identification in few-shot spatiotemporal anomaly detection},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward an effective action-region tracking framework for fine-grained video action recognition. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3602089'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained action recognition (FGAR) aims to identify subtle and distinctive differences among fine-grained action categories. However, current recognition methods often capture coarse-grained motion patterns but struggle to identify subtle details in local regions evolving over time. In this work, we introduce the action-region tracking (ART) framework, a novel solution leveraging a query-response mechanism to discover and track the dynamics of distinctive local details, enabling distinguishing similar actions effectively. Specifically, we propose a region-specific semantic activation module that employs discriminative and text-constrained semantics serve as queries to capture the most action-related region responses in each video frame, facilitating interaction among spatial and temporal dimensions with corresponding video features. The captured region responses are then organized into action tracklets, which characterize the region-based action dynamics by linking related responses across different video frames in a coherent sequence. The text-constrained queries are designed to expressly encode nuanced semantic representations derived from the textual descriptions of action labels, as extracted by the language branches within visual language models. To optimize generated action tracklets, we design a multilevel tracklet contrastive constraint among multiple region responses at spatial and temporal levels, which can effectively distinguish individual region responses in each video frame (spatial level) and establish the correlation of similar region responses between adjacent video frames (temporal level). In addition, we implement a task-specific fine-tuning mechanism to refine textual semantics during training. This ensures that the semantic representations encoded by vision language models (VLMs) are not only preserved but also optimized for specific task preferences. Comprehensive experiments on several widely used action recognition benchmarks, i.e., FineGym, Diving48, NTURGB-D, Kinetics, and Something-Something, clearly demonstrate the superiority to previous state-of-the-art baselines.},
  archive      = {J_TNNLS},
  author       = {Baoli Sun and Yihan Wang and Xinzhu Ma and Zhihui Wang and Kun Lu and Zhiyong Wang},
  doi          = {10.1109/TNNLS.2025.3602089},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Toward an effective action-region tracking framework for fine-grained video action recognition},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
