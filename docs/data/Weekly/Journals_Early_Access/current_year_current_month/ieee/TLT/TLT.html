<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TLT</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tlt">TLT - 2</h2>
<ul>
<li><details>
<summary>
(2025). RCKTE: Towards global optimal causal explanations for deep knowledge tracing. <em>TLT</em>, 1-14. (<a href='https://doi.org/10.1109/TLT.2025.3616515'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning-based knowledge tracing (DLKT) models have achieved high predictive accuracy, but their opaque “black-box” nature limits practical value: educators cannot trace why predictions are made and learners cannot obtain transparent feedback. Existing explainability techniques, which aim to explain why a model makes a particular prediction and provide the evidence for it, predominantly rely on correlational analyses, often yielding unfaithful or suboptimal explanations. To address this, we propose RCKTE, a post hoc reinforcement learning-based causal deep knowledge tracing explainer. RCKTE operates through a structured workflow: First, it formulates the explanation task as a globally optimal subsequence screening problem, aiming to identify the most causally influential historical interactions from a student's learning sequence. Then, a reinforcement learning agent, guided by a causal attribution reward and a dual optimizer scheme, iteratively constructs the optimal subsequences by assessing the causal impact of each interaction. This process results in more faithful and concise explainable subsequences than those produced by correlation-based methods, achieving this within about one second to support real-time use. Finally, these explainable subsequences directly support actionable educational applications, including identifying a learner's weak knowledge for targeted review, constructing personalized knowledge structure graphs for intervention tracking, and deriving group-level knowledge structures to guide curriculum design. Extensive experiments across multiple DLKT models and datasets confirm that RCKTE consistently outperforms existing post hoc methods in both the faithfulness and readability of explanations. By integrating causal attribution with reinforcement learning, RCKTE provides accurate, efficient, and educationally meaningful explanations that enhance the usability of DLKT in real learning environments. The implementation code and related resources are available at https://github.com/codeset-XKT/RCKTE.},
  archive      = {J_TLT},
  author       = {Qing Li and Xin Yuan and Jianwen Sun and Xinrui Li and Sijing Chen and Xiaoxuan Shen and Sannyuya Liu},
  doi          = {10.1109/TLT.2025.3616515},
  journal      = {IEEE Transactions on Learning Technologies},
  month        = {10},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Learn. Technol.},
  title        = {RCKTE: Towards global optimal causal explanations for deep knowledge tracing},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comprehensive survey on large language model based agents for education. <em>TLT</em>, 1-17. (<a href='https://doi.org/10.1109/TLT.2025.3617909'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern education aims at providing students with more personalized learning services and more engaging learning experiences. One promising approach is to develop educational agents to facilitate high-quality completion of various educational tasks. In recent years, the advent of large language models (LLMs) has breathed new life into educational agents and pushed them into a new stage of intelligence. This survey tries to conduct a comprehensive and thorough investigation of LLM-based agents in education. First, the developments of educational agents are presented as background information. Subsequently, we propose a unified architecture for LLM-based educational agents, including perception, profiling, memory, reasoning, and action modules, and summarize two primary methods (i.e., fine-tuning and prompt engineering) for equipping them with abilities. Next, we categorize the potential applications of LLM-based educational agents across the “teaching-learning-assessment-research” chain, and discover that LLM-based educational agent can play significant roles in various educational tasks. Furthermore, we reveal that when assessing the effectiveness of LLM-based educational agents, subjective evaluation remains dominant, supplemented by objective evaluation. Finally, the open issues and future research directions in this field are discussed from multiple perspectives. We hope that this survey can provide valuable insights and inspirations for researchers and practitioners to enhance the further development of educational agents in the future.},
  archive      = {J_TLT},
  author       = {Juan Yang and Minjuan Wang and Xu Du and Rina Na},
  doi          = {10.1109/TLT.2025.3617909},
  journal      = {IEEE Transactions on Learning Technologies},
  month        = {10},
  pages        = {1-17},
  shortjournal = {IEEE Trans. Learn. Technol.},
  title        = {A comprehensive survey on large language model based agents for education},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
