<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TMC</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tmc">TMC - 25</h2>
<ul>
<li><details>
<summary>
(2025). Aerial shepherds: Enabling hierarchical localization in heterogeneous MAV swarms. <em>TMC</em>, 1-18. (<a href='https://doi.org/10.1109/TMC.2025.3616380'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A heterogeneous micro aerial vehicles (MAV) swarm consists of resource-intensive but expensive advanced MAVs (AMAVs) and resource-limited but cost-effective basic MAVs (BMAVs), offering opportunities in diverse fields. Accurate and real-time localization is crucial for MAV swarms, but current practices lack a low-cost, high-precision, and real-time solution, especially for lightweight BMAVs. We find an opportunity to accomplish the task by transforming AMAVs into mobile localization infrastructures for BMAVs. However, translating this insight into a practical system is challenging due to issues in estimating locations with diverse and unknown localization errors of BMAVs, and allocating resources of AMAVs considering interconnected influential factors. This work introduces TransformLoc, a new framework that transforms AMAVs into mobile localization infrastructures, specifically designed for low-cost and resource-constrained BMAVs. We design an error-aware joint location estimation model to perform intermittent joint estimation for BMAVs and introduce a similarity-instructed adaptive grouping-scheduling strategy to allocate resources of AMAVs dynamically. TransformLoc achieves a collaborative, adaptive, and cost-effective localization system suitable for large-scale heterogeneous MAV swarms. We implement and validate TransformLoc on industrial drones. Results show it outperforms all baselines by up to 68% in localization performance, improving navigation success rates by 60%. Extensive robustness and ablation experiments further highlight superiority of its design.},
  archive      = {J_TMC},
  author       = {Haoyang Wang and Jingao Xu and Chenyu Zhao and Yuhan Cheng and Xuecheng Chen and Chaopeng Hong and Xiao-Ping Zhang and Yunhao Liu and Xinlei Chen},
  doi          = {10.1109/TMC.2025.3616380},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  pages        = {1-18},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Aerial shepherds: Enabling hierarchical localization in heterogeneous MAV swarms},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MagPrint++: Continuous user fingerprinting on mobile devices using electromagnetic signals. <em>TMC</em>, 1-12. (<a href='https://doi.org/10.1109/TMC.2025.3616308'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the nature of user-device interactions (e.g., who is using the device and what he/she is doing with it) is critical for many applications including time management, user profiles, and privacy protection. However, in scenarios where mobile devices are shared among family members or multiple employees in a company, conventional account-based statistics are not meaningful. This poses an even bigger problem when dealing with sensitive data. Moreover, fingerprint readers and front-facing cameras were not designed to continuously identify users. In this study, we developed MagPrint++ , a novel approach to fingerprint users based on unique patterns in the electromagnetic (EM) signals associated with the specific use patterns of users. Initial experiments showed that time-varying EM patterns are unique to individual users. They are also temporally and spatially consistent, which makes them suitable for fingerprinting. MagPrint++ has a number of advantages over existing schemes: i) Non-intrusive fingerprinting, ii) implementation both on COTS mobile phones and a small and easy-to-deploy device, and iii) high accuracy thanks to the proposed classification algorithm. In experiments involving 30 users, MagPrint++ achieves $94.3\%$ accuracy in classifying users from these traces, which represents a $10.9\%$ improvement over the state-of-the-art classification method.},
  archive      = {J_TMC},
  author       = {Lanqing Yang and Xinqi Chen and Hao Pan and Yi-Chao Chen and Guangtao Xue and Zechen Li and Yiheng Bian and Dian Ding and Linghe Kong and Jiadi Yu and Feng Lyu and Minglu Li and Ziyu Shen and Bo Zhang},
  doi          = {10.1109/TMC.2025.3616308},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {MagPrint++: Continuous user fingerprinting on mobile devices using electromagnetic signals},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Target wake time scheduling for time-sensitive and energy-efficient wi-fi networks. <em>TMC</em>, 1-18. (<a href='https://doi.org/10.1109/TMC.2025.3617324'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time Sensitive Networking (TSN) is fundamental for the reliable, low-latency networks that will enable the Industrial Internet of Things (IIoT). Wi-Fi has historically been considered unfit for TSN, as channel contention and collisions prevent deterministic transmission delays. However, this issue can be overcome by using Target Wake Time (TWT), which enables the access point to instruct Wi-Fi stations to wake up and transmit in non-overlapping TWT Service Periods (SPs), and sleep in the remaining time. In this paper, we first formulate the TWT Acceptance and Scheduling Problem (TASP), with the objective to schedule TWT SPs that maximize traffic throughput and energy efficiency while respecting Age of Information (AoI) constraints. Then, due to TASP being NP-hard, we propose the TASP Efficient Resolver (TASPER), a heuristic strategy to find near-optimal solutions efficiently. Using a TWT simulator based on ns-3, we compare TASPER to several baselines, including HSA, a state-of-the-art solution originally designed for WirelessHART networks. We demonstrate that TASPER obtains up to 24.97% lower mean transmission rejection cost and saves up to 14.86% more energy compared to the leading baseline, ShortestFirst, in a challenging, large-scale scenario. Additionally, when compared to HSA, TASPER also reduces the energy consumption by 34% and reduces the mean rejection cost by 26%. Furthermore, we validate TASPER on our IIoT testbed, which comprises 10 commercial TWT-compatible stations, observing that our solution admits more transmissions than the best baseline strategy, without violating any AoI deadline.},
  archive      = {J_TMC},
  author       = {Fabio Busacca and Corrado Puligheddu and Francesco Raviglione and Riccardo Rusca and Claudio Casetti and Carla Fabiana Chiasserini and Sergio Palazzo},
  doi          = {10.1109/TMC.2025.3617324},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  pages        = {1-18},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Target wake time scheduling for time-sensitive and energy-efficient wi-fi networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced velocity-adaptive scheme: Joint fair access and age of information optimization in vehicular networks. <em>TMC</em>, 1-18. (<a href='https://doi.org/10.1109/TMC.2025.3617145'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the fair access problem and the Age of Information (AoI) under 5G New Radio (NR) Vehicle-to-Infrastructure (V2I) Mode 2 in vehicular networks. Specifically, vehicles follow Mode 2 to communicate with Roadside Units (RSUs) to obtain accurate data for driving assistance. Nevertheless, vehicles often have different velocity when they are moving in adjacent lanes, leading to difference in RSU dwell time and communication duration. This results in unfair access to network resources, potentially influencing driving safety. To ensure the freshness of received data, the AoI should be analyzed. Mode 2 introduces a novel preemption mechanism, necessitating simultaneous optimization of fair access and AoI to guarantee timely and relevant data delivery. We propose a joint optimization framework for vehicular network, defining a fairness index and employing Stochastic Hybrid Systems (SHS) to model AoI under preemption mechanism. By adaptively adjusting the selection window of Semi-Persistent Scheduling (SPS) in Mode 2, we address the optimization of fairness and AoI. We apply a large language model (LLM)-Based Multi-objective Evolutionary Algorithm Based on Decomposition (MOEA/D) to solve this problem. Simulation results demonstrate the effectiveness of our scheme in balancing fair access and minimizing AoI.},
  archive      = {J_TMC},
  author       = {Xiao Xu and Qiong Wu and Pingyi Fan and Kezhi Wang and Nan Cheng and Wen Chen and Khaled B. Letaief},
  doi          = {10.1109/TMC.2025.3617145},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  pages        = {1-18},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Enhanced velocity-adaptive scheme: Joint fair access and age of information optimization in vehicular networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Secrecy energy efficiency of hybrid wireless body area networks. <em>TMC</em>, 1-14. (<a href='https://doi.org/10.1109/TMC.2025.3618098'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hybrid Wireless Body Area Networks (HyWBANs) are revolutionizing healthcare by integrating joint sensing and communication capabilities. However, this advancement introduces critical security challenges, as attackers can exploit sensing channels to intercept sensitive medical data. This paper introduces Secrecy Energy Efficiency (SEE) as a new performance metric for hybrid radio-optical wireless networks, enabling a quantitative assessment of secure communication under power-constrained conditions. We formulate and solve optimization problems to maximize the optical secrecy rate and SEE. We extend this analysis to a joint allocation framework for Ultra Wideband (UWB) and Near-Infrared (NIR) channels. Our approach leverages Sequential Fractional Programming (SFP), which enables to tackle the non-convex SEE maximization problem by a sequence of convex problems, addressing secure transmissions' inherent non-convexity and fractional nature with intentional jamming. Based on lab-based in-body measurements through porcine tissue and on radio and optical average synthetic phantoms, numerical evaluations demonstrate that the NIR link can achieve approximately 3 bit/Hz/Joule in SEE. Further, we show that optimal power allocation significantly outperforms random allocation methods, highlighting the potential of this approach for mission-critical healthcare applications. These findings provide a robust foundation for designing next-generation, low-power medical communication systems that balance security requirements with stringent energy constraints.},
  archive      = {J_TMC},
  author       = {Simone Soderi and Alessio Zappone},
  doi          = {10.1109/TMC.2025.3618098},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Secrecy energy efficiency of hybrid wireless body area networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Privacy-preserving rényi layer-wise budget allocation against gradient leakage for federated learning. <em>TMC</em>, 1-15. (<a href='https://doi.org/10.1109/TMC.2025.3618185'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is vulnerable to gradient-based privacy attacks, where malicious attackers reconstruct training data from exchanged gradients. While existing differential privacy (DP) defenses mitigate this, they often cause excessive additive noise due to the inequality scaling in the theoretical analyses, which degrades the model's utility or fail under adaptive attacks. To address this issue, we propose FedMSBA, a layer-wise privacy-preservation method that adaptively allocates privacy budgets via Rényi DP (RDP) and modified sensitivity. FedMSBA dynamically scales noise to model intricacies and adaptively choose the better applied DP mechanisms, which provides a tighter mathematical bound and finally prevents non-convergence while resisting reconstruction attacks. Experiments demonstrate superior privacy-utility trade-offs compared to state-of-the-art defenses. FedMSBA achieves an approximately 2% improvement in accuracy and a 5% enhancement in privacy preservation. Furthermore, FedMSBA's performance remains nearly unaffected by variations in the privacy budget $\epsilon$ and failure rate $\delta$.},
  archive      = {J_TMC},
  author       = {Leyu Shi and Ying Gao and Chong Chen and Siquan Huang and Jiafeng Zhao and Xiping Hu},
  doi          = {10.1109/TMC.2025.3618185},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Privacy-preserving rényi layer-wise budget allocation against gradient leakage for federated learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Minimizing the AoI for pull-based target-level data collection in energy-harvesting IoTs. <em>TMC</em>, 1-16. (<a href='https://doi.org/10.1109/TMC.2025.3618092'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data collection is a crucial task of IoTs. According to the data collection scheme and the required data granularity, data collection in IoTs can be classified into pull-based/push-based data collection as well as node-level/target-level data collection. Thus, there are four scenarios for data collection: Push-based node-level data collection (Push-Node), Push-based target-level data collection (Push-Target), Pull-based node-level data collection (Pull-Node), and Pull-based target-level data collection (Pull-Target). Energy-Harvesting IoT (EH-IoT) is an important component of IoTs and the Age of Information (AoI) minimization problem has been studied extensively for data collection in EH-IoTs. However, existing works only studied the problem under the scenario of Push-Node, Push-Target and Pull-Node. Therefore, this paper investigates the AoI minimization problem for Pull-based Target-level data collection in EH-IoTs (AoI-Pull-Target) for the first time. AoI-Pull-Target is formally defined and proved to be NP-hard. A two-stage dynamic programming-based node scheduling algorithm and a real-time schedule adjustment scheme are proposed to solve the problem. The proposed algorithm is analyzed theoretically. Extensive simulations and real-world testbed experiments verify the high performance of our algorithm.},
  archive      = {J_TMC},
  author       = {Bingkun Yao and Hong Gao and Yang Zhang and Dongjing Miao and Quan Chen and Jianzhong Li},
  doi          = {10.1109/TMC.2025.3618092},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Minimizing the AoI for pull-based target-level data collection in energy-harvesting IoTs},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). User-centric communication service provision for edge-assisted mobile augmented reality. <em>TMC</em>, 1-15. (<a href='https://doi.org/10.1109/TMC.2025.3618147'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Future 6G networks are envisioned to facilitate edge-assisted mobile augmented reality (MAR) via strengthening the collaboration between MAR devices and edge servers. In order to provide immersive user experiences, MAR devices must timely upload camera frames to an edge server for simultaneous localization and mapping (SLAM)-based device pose tracking. In this paper, to cope with user-specific and non-stationary uplink data traffic, we develop a digital twin (DT)-based approach for user-centric communication service provision for MAR. Specifically, to establish DTs for individual MAR devices, we first construct a data model customized for MAR that captures the intricate impact of the SLAM-based frame uploading mechanism on the user-specific data traffic pattern. We then define two DT operation functions that cooperatively enable adaptive switching between different data-driven models for capturing non-stationary data traffic. Leveraging the user-oriented data management introduced by DTs, we propose an algorithm for network resource management that ensures the timeliness of frame uploading and the robustness against inherent inaccuracies in data traffic modeling for individual MAR devices. Trace-driven simulation results demonstrate that the user-centric communication service provision achieves a 14.2% increase in meeting the camera frame uploading delay requirement in comparison with the slicing-based communication service provision widely used for 5G.},
  archive      = {J_TMC},
  author       = {Conghao Zhou and Jie Gao and Shisheng Hu and Nan Cheng and Weihua Zhuang and Xuemin Shen},
  doi          = {10.1109/TMC.2025.3618147},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {User-centric communication service provision for edge-assisted mobile augmented reality},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Service migration strategies based on partially observable and multi-objective optimization. <em>TMC</em>, 1-15. (<a href='https://doi.org/10.1109/TMC.2025.3618278'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-access Edge Computing (MEC) extends cloud computing to the network edge, supporting resource-intensive mobile applications. Service migration ensures seamless continuity and high-quality service (QoS) when users move between MEC servers. In the Internet of Vehicles (IoV), the high mobility of vehicles causes network instability, complicating the collection of system information. In addition, vehicles impose strict latency and green energy requirements, and the search for the Pareto front among conflicting objectives increases the complexity of migration. Existing service migration methods rely on centralized decision making using complete system information, which is not suitable for the user-centric IoV environment. Current multi-objective reinforcement learning approaches lack sufficient exploration randomness, leading to suboptimal performance. We propose the Adversarial Variational State Inference with Maximum Entropy Multi-Objective Policy Optimization (AVSIMEMPO) algorithm to address the partially observable and multi-objective optimization problem, optimizing migration node selection. The service migration problem is modeled as a partially observable Markov decision process (POMDP). To solve this, we design an encoding network, AVSI, integrating Long ShortTerm Memory (LSTM), Variational Autoencoders (VAE), and adversarial learning to extract hidden state. We also introduce the Maximum Entropy Multi-Objective Policy Optimization (MEMPO) algorithm, which enhances exploration randomness through maximum entropy and dynamic weight design. Extensive experiments based on real mobility trajectories show that our method outperforms baseline algorithms and achieves nearoptimal results in various MEC scenarios.},
  archive      = {J_TMC},
  author       = {Yingzhen Hou and Lei Yang and Yu Dai},
  doi          = {10.1109/TMC.2025.3618278},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Service migration strategies based on partially observable and multi-objective optimization},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Personalized federated learning via gradient-fusion and gradient-decoupling for heterogeneous data. <em>TMC</em>, 1-17. (<a href='https://doi.org/10.1109/TMC.2025.3618262'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) enables devices to collaboratively train a global model without centralizing raw data. However, heterogeneous data distributions often hinder a single global model from performing optimally across diverse clients. In this paper, we introduce two personalized federated learning methods to address the aforementioned challenge. First, we introduce a gradient-fusion approach that merges global gradients aggregated via a learnable collaboration matrix with local gradients tailored to each client's data. This fusion harmonizes collective intelligence with device-specific knowledge, thereby improving personalization under data heterogeneity. Second, we propose a gradient-decoupling method that mitigates the limitations of relying solely on a collaboration matrix for balancing knowledge sharing and personalization. By decoupling the tasks and regularizing local updates through the incorporation of extracted collective intelligence, we introduce an inductive bias that significantly improves generalization. Extensive evaluations on four computed tomography and pathology imaging datasets covering a wide range of heterogeneity show that our frameworks substantially outperform existing baselines. We also provide theoretical analyses that establish performance bounds and convergence guarantees under mild assumptions.},
  archive      = {J_TMC},
  author       = {Zaobo He and Yusen Li and Zhipeng Cai},
  doi          = {10.1109/TMC.2025.3618262},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  pages        = {1-17},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Personalized federated learning via gradient-fusion and gradient-decoupling for heterogeneous data},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent omni-surface-aided multi-objective ISAC: A meta hybrid deep reinforcement learning approach. <em>TMC</em>, 1-16. (<a href='https://doi.org/10.1109/TMC.2025.3618256'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies an intelligent omni-surface (IOS)-aided integrated sensing and communication (ISAC) system, where a base station (BS) provides simultaneous target sensing and communication services with an IOS under outdated and imperfect channel state information (CSI). Both the communication sum-rate and sensing signal-to-noise ratio are maximized through joint optimization of BS beamforming and IOS configuration. To address this problem, we propose an intelligent joint optimization scheme called meta multi-objective hybrid deep reinforcement learning (meta-MHDRL). Specifically, the meta-MHDRL framework first introduces a hybrid deep reinforcement learning (DRL) approach that integrates double-critic-based deep deterministic policy gradient with deep double Q-network algorithms, enabling parallel optimization of both continuous-domain variables (i.e., BS beamforming, IOS reflecting phase shift, and IOS reflecting/refracting amplitudes) and the discrete-domain variable (i.e., IOS refracting phase shift). Thereafter, an objective-preference weight is incorporated into the hybrid DRL framework, such that meta-MHDRL can capture the trade-off between communication and sensing performance. To address the complex coupling relationships among different optimization variables, we further put forth a synchronized experience replay mechanism for meta-MHDRL, which maintains training synchronization among different neural networks. In addition, a meta-learning approach is developed to enhance the generalization ability of meta-MHDRL across different objective-preference weights. Simulation results show that meta-MHDRL attains more Pareto-efficient solutions than other schemes under outdated and imperfect CSI while maintaining stronger robustness across various simulation setups. Besides, we demonstrate the generalization ability of meta-MHDRL for unseen tasks},
  archive      = {J_TMC},
  author       = {Xiaowen Ye and Xianxin Song and Yi Wu and Liqun Fu},
  doi          = {10.1109/TMC.2025.3618256},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Intelligent omni-surface-aided multi-objective ISAC: A meta hybrid deep reinforcement learning approach},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PAAP: A graph-based VNF deployment framework for embedding bidirectional SFC in mobile edge networks. <em>TMC</em>, 1-18. (<a href='https://doi.org/10.1109/TMC.2025.3617016'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the realm of Mobile Edge Computing (MEC) networks, mobile interactive applications, such as multiplayer online games, federated learning, and interactive multi-view video, are becoming increasingly popular. The embedding of Bidirectional Service Function Chains (BSFCs) for these applications has been studied. However, existing BSFC embedding research only considers static users, and the prevailing Virtual Network Functions (VNFs) placement methods do not account for the impact of individual node resources on the path, thus failing to maximize node resource utilization at the network level. Considering the aforementioned issues, we introduce a framework for BSFC embedding tailored for mobile users, named Path as a Point (PAAP). This framework integrates the resources of the paths and then globally considers the impact of the computing resources of edge nodes on the paths connecting them, maximizing edge node resource utilization across the entire network. We propose a three-phase algorithm within the PAAP framework. In the first phase, we introduce a singleuser algorithm for VNFs deployment during BSFC embedding. In the second phase, this optimization is extended to multiple users by establishing inter-user association rules. In the third phase, candidate application placement positions are evaluated across the entire network, culminating in the determination of optimal placement strategies. Empirical evaluations confirm the effectiveness of the proposed algorithm, demonstrating significant performance improvements over baseline methods.},
  archive      = {J_TMC},
  author       = {Yuhao Xie and Dehui Ou and Zhen Zhang and Yuhui Deng and Geyong Min and Lin Cui and Zhijie Wang},
  doi          = {10.1109/TMC.2025.3617016},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  pages        = {1-18},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {PAAP: A graph-based VNF deployment framework for embedding bidirectional SFC in mobile edge networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated continual learning with bounded forgetting via diffusion-based generative replay in edge computing. <em>TMC</em>, 1-17. (<a href='https://doi.org/10.1109/TMC.2025.3618275'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated continual learning (FCL) aims to train a shared model incrementally on evolving tasks while respecting data privacy across distributed edge devices. In edge settings, historical task data for replay is often unavailable; moreover, as the model is continuously updated, features of newly introduced classes encroach on the feature space of older classes, distorting decision boundaries and exacerbating catastrophic forgetting. We propose DGR-FCL, an FCL framework that bounds forgetting via server-side, diffusion-based generative replay. The generator is trained with margin constraints and batch-normalization alignment to faithfully recover previously learned distributions. On each client, we introduce supervised contrastive learning with synthetic negatives to separate old and new classes, and an importance-weighted feature-distillation strategy to constrain representation drift along feature directions critical for old tasks. Theoretically, an integral probability metric (IPM) analysis shows that margin preservation on replay data ensures bounded forgetting. Empirically, DGR-FCL achieves consistent 4–5% accuracy gains over state-of-the-art baselines on both independent and identically distributed (IID) and non-IID benchmarks, offering a robust solution to the stability–plasticity trade-off in decentralized, continuously evolving environments.},
  archive      = {J_TMC},
  author       = {Zaobo He and Yunkun Wang and Zhipeng Cai},
  doi          = {10.1109/TMC.2025.3618275},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  pages        = {1-17},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Federated continual learning with bounded forgetting via diffusion-based generative replay in edge computing},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TruChord: A secure communication framework for hybrid SDIoT architecture based on chord overlay. <em>TMC</em>, 1-13. (<a href='https://doi.org/10.1109/TMC.2025.3618876'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a highly integrated and comprehensive application of the new generation of information technology, IoT inevitably comes with security issues. The communication security of IoT devices is the foundation for their large-scale development. To address the problems of missing cross-domain identity authentication, low routing efficiency, and frequent malicious attacks in hybrid SDIoT, we propose a secure and trusted communication framework for IoT based on overlay networks, namely TruChord. This framework introduces DICE technology to generate device firmware identifiers, constructs a trust chain, and realizes hardware binding of device identities and firmware integrity measurement. Meanwhile, it designs a domain-specific identifier mapping mechanism, which integrates SDN domain DPID, IP domain prefix, and firmware identifiers to make physically adjacent nodes logically adjacent on the ring. Finally, it proposes a hierarchical trust aggregation protocol, which ensures secure communication between nodes through intra-domain local verification and cross-domain global aggregation with the help of a trust mechanism. Through formal proof, TruChord can resist Sybil attacks and collusion attacks. Simulation experiments show that TruChord outperforms the comparison frameworks in core indicators such as end-to-end delay, network traffic, and convergence time, providing an efficient solution for cross-domain secure communication of IoT devices.},
  archive      = {J_TMC},
  author       = {Yu Zhang and Bei Gong and Zahid Halim and Hisham Alasmary and Muhammad Waqas and Iftekhar Ahmad},
  doi          = {10.1109/TMC.2025.3618876},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {TruChord: A secure communication framework for hybrid SDIoT architecture based on chord overlay},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Age-optimal rate control transport protocol for cohesive clustered satellite systems. <em>TMC</em>, 1-15. (<a href='https://doi.org/10.1109/TMC.2025.3618276'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cohesive clustered satellite (CCS) system integrates diverse payloads from multiple formation-flying low Earth orbit (LEO) satellites to provide pervasive intelligent services to ground user equipment (UE), which is regarded as the critical component of satellite-integrated Internet. Considering the CCS system aggregates information at a backbone satellite and connect to the ground station via the satellite-integrated Internet, achieving timely transmission within this bottleneck link becomes crucial. In this paper, we propose an age-optimal rate control (ARC) protocol in transport layer, where each satellite in the CCS system independently and iteratively adjusts its transmit rate (TR) according to the feedback queuing delay at the backbone satellite to approach its age-optimal rate (AR), aimed at minimizing the average age of information (AAoI) of CCS system. Specifically, we derive the upper bound AAoI by modeling an $M/M/1$ queue at backbone satellite, and formulate an AAoI minimization problem by utilizing the upper bound AAoI and solve it to obtain the AR. Then, each satellite can calculate its expected rate (ER) by calculating the queuing delay via the timestamp of Acknowledgements (ACK) from backbone satellite, which is significantly larger than AR. Further, we design an Exponential then Additive Increase Additive Decrease (EAIAD) algorithm to control the convergence position and oscillation of TR, thereby avoiding the significantly increase in AAoI resulting from TR exceeds AR. Finally, we conduct extensive simulations to demonstrate that our ARC protocol achieves minimum AAoI compared to the state-of-the-art transport protocols.},
  archive      = {J_TMC},
  author       = {Hao Liu and Jian Jiao and Jianhao Huang and Weizhi Wang and Ye Wang and Qinyu Zhang},
  doi          = {10.1109/TMC.2025.3618276},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Age-optimal rate control transport protocol for cohesive clustered satellite systems},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mitigating catastrophic forgetting in personalized federated learning for edge devices using state-space models. <em>TMC</em>, 1-14. (<a href='https://doi.org/10.1109/TMC.2025.3618886'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge computing involves distributed devices operating in dynamic environments with diverse resource constraints and highly heterogeneous data distributions. In these settings, personalized federated learning (PFL) provides a collaborative learning framework that preserves the unique data characteristics of each device. However, PFL models often encounter bidirectional catastrophic forgetting. During consecutive training rounds, the personalized characteristics learned by local models are readily overwritten by updates from the global model, while the global model's shared representations are degraded by distribution shifts arising from heterogeneous local data. This challenge is further amplified in edge computing settings, where devices must adapt to fast-changing heterogeneous data. To address this issue, we propose FedSSM, a novel framework that leverages state-space models to mitigate forgetting in PFL. By capturing the temporal evolution of local model parameters through hidden states, the framework enhances the retention of critical knowledge throughout training rounds. Extensive experiments on multiple benchmark datasets demonstrate that FedSSM outperforms various state-of-the-art PFL algorithms, particularly with high data heterogeneity. The code can be found at: https://github.com/wei-d-zhang/FedSSM.},
  archive      = {J_TMC},
  author       = {Weidong Zhang and Dongshang Deng and Xuangou Wu and Tao Zhang and Xiao Zheng and Dusit Niyato and Dong In Kim},
  doi          = {10.1109/TMC.2025.3618886},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Mitigating catastrophic forgetting in personalized federated learning for edge devices using state-space models},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Post-quantum secure authenticated key agreement scheme for vehicular digital twin. <em>TMC</em>, 1-16. (<a href='https://doi.org/10.1109/TMC.2025.3618752'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advent of digital twins, which leverage the server's robust data-processing and storage capacities to manage vehicular tasks, effectively addresses the limitations of traditional Internet of Vehicles (IoV). However, the communication link between a vehicle and its digital twin remains open and insecure, necessitating the development of an Authenticated Key Agreement (AKA) scheme to secure this channel. Existing AKA schemes for Vehicular Digital Twin (VDT) fail to achieve post-quantum security, and the progression of quantum computing has intensified the urgency to establish post-quantum secure solutions. To address these shortcomings, we propose a lightweight, quantum-resistant three-party AKA scheme for VDT networks based on the Ring Learning With Errors (RLWE) computational problem. Our scheme enables one-round interaction with privacy preservation while ensuring the efficiency of the AKA protocol through its RLWE-based design. Additionally, our approach mitigates the risk of temporary key reuse during Gaussian sampling, thereby resisting newly discovered key reuse attacks targeting lattice-based key agreement schemes. Security proofs and analyses prove that the proposed scheme meets the fundamental security and privacy requirements of IoV. Furthermore, performance evaluations indicate that our scheme achieves post-quantum security with low computational overhead and energy consumption, making it compatible with quantum-resistant VDT communications.},
  archive      = {J_TMC},
  author       = {Jie Cui and Jiyu Liu and Lu Wei and Irina Bolodurina and Jiaxin Li and Hong Zhong},
  doi          = {10.1109/TMC.2025.3618752},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Post-quantum secure authenticated key agreement scheme for vehicular digital twin},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pao-ding: Accelerating cross-edge video analytics via automated CNN model partitioning. <em>TMC</em>, 1-15. (<a href='https://doi.org/10.1109/TMC.2025.3618296'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-edge video analytics is a technology that involves collaborative processing of video data among multiple edge devices. To handle increasingly complex video analytics tasks on edge devices with higher frame rates or improved accuracy, cross-edge video analytics leverages model partitioning techniques to divide Convolutional Neural Network (CNN) models into multiple sub-models deployed across different computing nodes. This approach enables the efficient utilization of heterogeneous edge computing resources for compute-intensive CNN inference. Nonetheless, several challenges persist in cross-edge video analytics. These include the partitionability of CNN models requiring a lot of manual work, excessive transmission of intermediate features leading to performance degradation, and high computational complexity in partitioning decision-making. To tackle these challenges, this paper proposes Pao-Ding, a framework to accelerate cross-edge video analytics. Pao-Ding employs gradient information to automatically parse the structure of CNN models, thereby enabling partitionability for chain, simple Directed Acyclic Graph (DAG), and complex DAG models. By incorporating a skip-layer design, Pao-Ding is able to compress redundant intermediate features more accurately. Additionally, a layer-pruning-based algorithm is proposed in Pao-Ding which effectively reduces the computational overhead associated with partitioning decision-making. Experimental results on real hardware show that Pao-Ding supports automated model partitionability for 67 CNN models with a model coverage rate of 94.37%. Compared to state-of-the-art, Pao-Ding reduces total prediction error by 47.43%, lowers the partitioning decision time by 37.5%–58.35%, and decreases the average video frame processing time by 5.75%–22.18%. Furthermore, a cross-edge video analytics simulation platform developed using Docker and Pumba verifies the robustness of Pao-Ding under various conditions involving different number of nodes, computing capacities, and network environments.},
  archive      = {J_TMC},
  author       = {Guanping Liang and Biao Han and Ruidong Li and Xueqiang Han and Zhigang Sun},
  doi          = {10.1109/TMC.2025.3618296},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Pao-ding: Accelerating cross-edge video analytics via automated CNN model partitioning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Joint task offloading and resource allocation in ultra-dense multi-access edge computing: A mean field learning approach. <em>TMC</em>, 1-18. (<a href='https://doi.org/10.1109/TMC.2025.3619077'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In ultra-dense multi-access edge computing (MEC), efficient task offloading and resource allocation are critical to meeting stringent delay and energy constraints. However, the rapid growth in terminal devices poses a significant challenge to traditional deep reinforcement learning (DRL)-based methods, which struggle to maintain efficient task offloading and resource allocation due to increased computational complexity and decision latency. To address this challenge, in this paper, we propose a mean field theory (MFT)-guided DRL approach which leverages the statistical characteristics of a large population of terminal devices to reduce the computational complexity of decision-making. Firstly, we formulate the joint task offloading and resource allocation problem as a mean field Markov decision process (MFMDP) with the objective of minimizing the overall system energy consumption while satisfying the task delay requirements and resource constraints. Secondly, by leveraging the inherent structure of the MFMDP, which represents the system dynamics using state and action distributions rather than joint action spaces, we achieve significant dimensionality reduction and improved scalability. Thirdly, we prove that the Q-function of MFMDP satisfies the fixed point theory, and considering the continuity of task offloading and resource allocation variables, we develop an MFT-guided deep deterministic policy gradient (MFT-DDPG) algorithm to solve the proposed problem. Experimental results show that MFT-DDPG significantly outperforms conventional DRL baselines in convergence speed and scalability. Specifically, for 50 terminal devices, the training time of proposed MFT-DDPG is reduced by up to 86.1%, 92.1%, and 94.6% compared to those of MADDPG, QMIX, and DDPG, respectively. In comparison with the Edge Server Computing Only (ECO) scheme and Device and Edge Server Collaborative Computing (DECC) scheme, the proposed method consistently yields lower energy consumption and delay across varying numbers of terminal devices, transmission power, and edge server computing resources compared to benchmark solutions, demonstrating its robustness and effectiveness in ultra-dense MEC scenarios.},
  archive      = {J_TMC},
  author       = {Huixian Gu and Liqiang Zhao and Zhu Han and Xiaoli Chu and Gan Zheng and Jiaxin Liu and Guorong Zhou},
  doi          = {10.1109/TMC.2025.3619077},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  pages        = {1-18},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Joint task offloading and resource allocation in ultra-dense multi-access edge computing: A mean field learning approach},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IAB vs. RIS: Performance-cost tradeoffs in 5G/6G systems with multicast and unicast traffic in roadside deployments. <em>TMC</em>, 1-18. (<a href='https://doi.org/10.1109/TMC.2025.3619418'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The introduction of millimeter wave (mmWave) and sub-terahertz (sub-THz) frequency bands in 5G and future 6G networks promises an unprecedented capacity enhancement at the air interface driven by highly directional transmissions. While this facilitates interference suppression and increased deployment density, it also presents challenges in multicast service delivery, particularly due to the use of directional antennas and environmental factors that can cause signal blockage. Technologies such as Integrated Access and Backhaul (IAB) and Reconfigurable Intelligent Surfaces (RISs) have emerged to address these challenges and reduce capital expenditure. This study comprehensively compares IAB- and RIS-based designs for cost-efficient densification in mmWave and sub-THz 5G/6G systems, focusing on both unicast and multicast traffic in roadside-type deployments. Two deployment scenarios with tunable parameters are analyzed, and optimization frameworks are formulated for each approach, accounting for propagation characteristics, radio properties, and antenna directionality. The evaluation metrics not only assess the performance of each technology (IAB and RIS) but also consider the deployment costs required to achieve equivalent performance levels. Numerical results show that both RIS- and IAB-based deployments can effectively support multicast and unicast traffic, with IAB systems demonstrating superior performance in terms of overall resource utilization up to 50% in sparse deployment scenarios. Instead, in highly dense deployment scenarios, RISs exhibit superior scalability and resource efficiency compared to IABs, achieving up to a 3 times improvement factor. Furthermore, unlike IAB deployments, the performance of RIS-based systems continuously improves as the number of RIS nodes increases. From a capital expenditure perspective, RIS deployments prove to be more cost-efficient than IAB systems, provided that the unit cost of RIS is lower.},
  archive      = {J_TMC},
  author       = {Olga Chukhno and Dmitri Moltchanov and Gianluca Brancati and Sara Pizzi and Antonella Molinaro and Giuseppe Araniti},
  doi          = {10.1109/TMC.2025.3619418},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  pages        = {1-18},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {IAB vs. RIS: Performance-cost tradeoffs in 5G/6G systems with multicast and unicast traffic in roadside deployments},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reconfigurable intelligent surface aided mobile fog computing: A space aggregation-based lyapunov driven reinforcement learning approach. <em>TMC</em>, 1-15. (<a href='https://doi.org/10.1109/TMC.2025.3619505'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid proliferation of mobile devices within Internet of Things (IoT) has substantially heightened the demand for mobile edge computing (MEC). Fog computing (FC) is a more advanced form of edge computing that allows computing nodes to cooperate with each other. Reconfigurable intelligent surfaces (RIS) have emerged as a critical technology for optimizing wireless communication environments, attracting considerable attention. In this paper, we develop an online optimization problem for RIS-aided mobile FC deployed across wireless networks with computing nodes at the base stations (BS). We propose a Lyapunov-drift-plus-penalty-based, space aggregation-assisted proximal policy optimization (LSAPPO) algorithm to tackle the challenges in online optimization problem in RIS-aided mobile FC system. Our technique integrates a reinforcement learning (RL) algorithm employing the proximal policy optimization (PPO) agent, further enhanced by Lyapunov drift-plus-penalty optimization. The space aggregation technique effectively consolidates excessive decision variables and channel state information (CSI) into a manageable set of parameters to streamline the computing framework. Numerical simulation result shows that our proposed algorithm surpasses the benchmarks, underscoring the effectiveness in complicated wireless networks. Furthermore, we introduce the multi-agent LSAPPO algorithm to address the distributed demands of practical scenarios. The multi-agent LSAPPO algorithm enhances convergence speed and performs better in large-scale problems.},
  archive      = {J_TMC},
  author       = {Wenhan Xu and Cunhua Pan and Yulan Yuan and Yuan Wu and Danny H.K. Tsang},
  doi          = {10.1109/TMC.2025.3619505},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Reconfigurable intelligent surface aided mobile fog computing: A space aggregation-based lyapunov driven reinforcement learning approach},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Achieving machine learning dependability through model switching and compression. <em>TMC</em>, 1-15. (<a href='https://doi.org/10.1109/TMC.2025.3619560'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning (ML) can be often distributed, owing to the need to harness more resources and/or to preserve privacy. Accordingly, distributed learning has received significant attention from the literature; however, most works focus on the expected learning quality (e.g., loss) attained and do not consider the distribution thereof. It follows that ML models are not dependable, and may fall short of the required performance in many real-world cases. In this work, we tackle this challenge and propose DepL, a framework attaining dependable learning orchestration. DepL efficiently makes joint, near-optimal decisions concerning (i) which data to use for learning, (ii) the ML models to use – chosen within a set of full-size models and compressed versions thereof – and when to switch from one model to another, and (iii) the clusters of physical nodes to use for the learning. DepL improves over previous works by guaranteeing that the learning quality target (e.g., a minimum loss) is achieved with a target probability, while minimizing the learning (e.g., energy) cost. DepL has provably low polynomial computational complexity and a constant competitive ratio. Further, experimental results using the CIFAR-10 and GTSRB datasets show that it consistently matches the optimum and outperforms state-of-theart approaches (30% faster learning and 40–80% lower cost).},
  archive      = {J_TMC},
  author       = {Francesco Malandrino and Giuseppe Di Giacomo and Marco Levorato and Carla Fabiana Chiasserini},
  doi          = {10.1109/TMC.2025.3619560},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Achieving machine learning dependability through model switching and compression},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). VMR-STAG based online SFC orchestration in space-terrestrial integrated networks. <em>TMC</em>, 1-17. (<a href='https://doi.org/10.1109/TMC.2025.3619832'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Space-Terrestrial Integrated Networks (STIN) have an important influence on Service Function Chains (SFCs), broadening their service scope and enhancing application performance. However, STIN features a dynamic terrestrial access layer and an inter-satellite layer; it's complex to orchestrate the SFC in such a dynamic network. In this paper, we provide the Virtual Multi-Resource Storage Time Aggregated Graph (VMR-STAG) model and SFC orchestration algorithms for SFC orchestration in STIN. Inspired by the Virtual Topology (VT) method, VMR-STAG aggregates the dual-layer dynamic topology and time-varying resources into a single virtual graph, thus reducing the complexity of the STIN model. Based on VMR-STAG, we propose the Offline Request Orchestration (ORO) and Online Request Orchestration (OLRO) algorithms, designed to minimize SFC migration frequency, service delay, service jitter, and enhance load balancing. Leveraging resource distribution across multiple time slots, these algorithms schedule the long-lasting, high-performance SFC within STIN. Evaluation and simulation results demonstrate that our proposed model and algorithms significantly outperform conventional solutions, achieving significant improvements in model complexity, SFC migration frequency, workload balancing, service delay, and jitter.},
  archive      = {J_TMC},
  author       = {Yepeng Liu and Ran Zhang and Jiang Liu and Ninghan Sun and Xinyuan Zhang},
  doi          = {10.1109/TMC.2025.3619832},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  pages        = {1-17},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {VMR-STAG based online SFC orchestration in space-terrestrial integrated networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust DNN partitioning and resource allocation under uncertain inference time. <em>TMC</em>, 1-17. (<a href='https://doi.org/10.1109/TMC.2025.3619509'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In edge intelligence systems, deep neural network (DNN) partitioning and data offloading can provide real-time task inference for resource-constrained mobile devices. However, the inference time of DNNs is typically uncertain and cannot be precisely determined in advance, presenting significant challenges in ensuring timely task processing within deadlines. To address the uncertain inference time, we propose a robust optimization scheme to minimize the total energy consumption of mobile devices while meeting task probabilistic deadlines. The scheme only requires the mean and variance information of the inference time, without any prediction methods or distribution functions. The problem is formulated as a mixed-integer nonlinear programming (MINLP) that involves jointly optimizing the DNN model partitioning and the allocation of local CPU/GPU frequencies and uplink bandwidth. To tackle the problem, we first decompose the original problem into two subproblems: resource allocation and DNN model partitioning. Subsequently, the two subproblems with probability constraints are equivalently transformed into deterministic optimization problems using the chance-constrained programming (CCP) method. Finally, the convex optimization technique and the penalty convex-concave procedure (PCCP) technique are employed to obtain the optimal solution of the resource allocation subproblem and a stationary point of the DNN model partitioning subproblem, respectively. The proposed algorithm leverages real-world data from popular hardware platforms and is evaluated on widely used DNN models. Extensive simulations show that our proposed algorithm effectively addresses the inference time uncertainty with probabilistic deadline guarantees while minimizing the energy consumption of mobile devices.},
  archive      = {J_TMC},
  author       = {Zhaojun Nan and Yunchu Han and Sheng Zhou and Zhisheng Niu},
  doi          = {10.1109/TMC.2025.3619509},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  pages        = {1-17},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Robust DNN partitioning and resource allocation under uncertain inference time},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MPNet: Multi-stage progressive convolutional neural networks for trajectory prediction. <em>TMC</em>, 1-15. (<a href='https://doi.org/10.1109/TMC.2025.3619573'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trajectory prediction is a continuing concern within autonomous vehicles. Psychological research shows that pedestrian traveling is a cyclic alternation. Pedestrians constantly interact with their surroundings, including social agents and physical environments, and plan paths to achieve goals. Nevertheless, most existing trajectory prediction methods are based on a single-stage design, which runs counter to traffic psychology principles. In this work, we present MPNet, a novel multi-stage progressive convolutional neural network that decomposes complicated trajectory prediction into multiple manageable components, where lightweight sub-networks handle each stage with a divide-and-conquer methodology. Specifically, our sub-networks are based on the encoder-decoder architecture, in which we capture interactive information and estimate goals to achieve trajectory prediction. The communication among sub-networks depends on a novel cross-stage fusion design. We introduce a feedback channel mutual attention mechanism and a cross-sub-network fusion unit to enable efficient information sharing across different stages. At each stage, we develop a symmetric gated supervision module to supervise future trajectory generation from coarse to fine. Extensive experiments demonstrate that MPNet achieves state-of-the-art performance, reducing Average Displacement Error (ADE) and Final Displacement Error (FDE) by 5.6%/7.4% on the ETH and UCY Datasets, 7.5%/7.7% on the Stanford Drone Dataset, and 7.1%/22.5% on the Intersection Drone Dataset, while maintaining comparable computational complexity. Additionally, our MPNet-Tiny variant reduces parameters by 90.5% and inference time by 1.83 seconds with competitive accuracy.},
  archive      = {J_TMC},
  author       = {Huihui Pan and Changzhi Yang and Jue Wang and Yuanduo Hong},
  doi          = {10.1109/TMC.2025.3619573},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {MPNet: Multi-stage progressive convolutional neural networks for trajectory prediction},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
