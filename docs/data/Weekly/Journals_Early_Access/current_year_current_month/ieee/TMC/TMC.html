<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TMC</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tmc">TMC - 84</h2>
<ul>
<li><details>
<summary>
(2025). 2FDP-BRL: A new framework of distributed task offloading for IoAV in extreme weather scenarios. <em>TMC</em>, 1-18. (<a href='https://doi.org/10.1109/TMC.2025.3604461'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the Internet of Autonomous Vehicles (IoAV), task offloading is crucial for managing tasks that require extensive computing power to guarantee vehicle safety under different weather scenarios. However, extreme weather events can lead to infrastructure damage and network disruptions, significantly increasing the computational demands of autonomous vehicles. These vehicles require additional computing resources to navigate complex road conditions and risks, all while facing a high degree of uncertainty, such as fluctuations in vehicle resource utilization and task workloads. To address these challenges, a new and lightweight task offloading decision framework, named 2FDP-BRL, has been first proposed in this paper. This framework not only considers the fast response time required for autonomous driving, but also considers the resource shortage and offloading uncertainty caused by extreme weather. Therefore, we introduce the dynamic pricing idea and the Interval Type-2 Fuzzy Inference System (IT2FIS) utilizing broad reinforcement learning to deal with various dynamic uncertainties in the IoAV under extreme weather. For the authenticity of experimental results, we utilize the VISSIM platform to collect experimental data and conduct simulations. Moreover, to accurately simulate extreme weather scenarios, we also account for the variability of infrastructure and road elements, including reduced transmission rates and decreased efficiency in executing tasks. Furthermore, to enhance the realism of the simulation, we incorporate historical weather data from NOAA for Shenyang in 2024 to model dynamic uncertainties under extreme weather conditions and conduct comparative experimental analyses focusing on task completion rates. Finally, the proposed framework was implemented on both a local setup and the Huawei Atlas 200I DK A2 device, illustrating its efficacy design.},
  archive      = {J_TMC},
  author       = {Xiting Peng and Shun Song and Xiaoyu Zhang and Mianxiong Dong and Kaoru Ota and Lexi Xu},
  doi          = {10.1109/TMC.2025.3604461},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-18},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {2FDP-BRL: A new framework of distributed task offloading for IoAV in extreme weather scenarios},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sniffing the application usage information with the leakage current of laptops. <em>TMC</em>, 1-14. (<a href='https://doi.org/10.1109/TMC.2025.3599338'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart devices are proliferating in every aspect of our lives, providing convenience but also exposing us to the risk of information leakage at any moment. Attackers can monitor the user and infer private information such as personality and preferences by stealing the behavioral information. In this paper, we investigated the potential threat of information stealing via the leakage current of laptops and electrodes in wearable devices (e.g., smart watches and bracelets). Specifically, the leakage current in the laptop adapter can flow from the metal casing into the human body and be collected by electrodes in wearable devices when the user is using a laptop with a metal casing (e.g., MacBook). We verified the correlation between leakage current and the working states of the laptop, where different operations corresponding to different CPU instructions can generate different leakage currents. Based on this, we propose LeakThief, a system that consists of three components: leakage current detection, application operation detection, and application recognition. The experiments in a real-world environment demonstrated that the proposed system can recognize 25 common applications with high accuracy, including launching-based (96.4%) and in-application operation-based recognition (81.2%).},
  archive      = {J_TMC},
  author       = {Dian Ding and Yijie Li and Yongzhao Zhang and Yi-Chao Chen and Xiaoyu Ji and Guangtao Xue},
  doi          = {10.1109/TMC.2025.3599338},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Sniffing the application usage information with the leakage current of laptops},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rising from pieces: Effective inference at the edge via robust split ML. <em>TMC</em>, 1-14. (<a href='https://doi.org/10.1109/TMC.2025.3605382'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing processing demands of today's mobile deep learning applications impose stringent requirements on edge devices. Offloading these tasks to the cloud, while being a potential solution, often results in significant data transfer overhead, as well as privacy and connectivity concerns. To address these challenges, split machine learning (split ML) has emerged as an innovative paradigm, enabling task distribution among edge devices themselves. However, split ML systems inherently exhibit instability due to the hardware and communication limitations of mobile devices, which frequently result in failures and malfunctions of client nodes. In light of these challenges, we present Axolotl, a fault-tolerant edge split ML inference system for addressing node failure with minimal performance impact. Specifically, we first design a novel curriculum dropout mechanism to enhance the model's resilience by gradually exposing it to potential server node failures. We then design inverse-proximal weight consolidation to mitigate catastrophic forgetting caused by curriculum dropout. To further tackle potential node failures, we innovate in a resource-aware substitution module that offload the functions of a failed node to neighboring ones, ensuring efficient information flow. Extensive experiments demonstrate the effectiveness and robustness of Axolotl in various deep learning networks and tasks in edge environments.},
  archive      = {J_TMC},
  author       = {Yuxuan Weng and Tianyue Zheng and Zhe Chen and Menglan Hu and Jun Luo},
  doi          = {10.1109/TMC.2025.3605382},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Rising from pieces: Effective inference at the edge via robust split ML},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uplink resource allocation for RSMA-aided digital twin-assisted user-centric cell-free massive MIMO systems. <em>TMC</em>, 1-17. (<a href='https://doi.org/10.1109/TMC.2025.3604722'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates uplink radio resource optimization of a user-centric (UC) cell-free (CF) massive multiple-input multiple-output (mMIMO) system aided by the rate splitting multiple access (RSMA) technique subject to pilot contamination. We formulate problem to maximize the minimum spectral efficiency (SE) problem by jointly addressing decoding order selection, power allocation, and access point (AP) - user equipment (UE) association assignment. The envisioned optimization exhibits two challenges. First, it requires global channel state information (CSI) for near-optimal performance, which incurs substantial overhead and data collection costs in large-scale CF networks. Second, the optimization is intractable due to its NP-hard and discrete non-linear programming nature. To address the CSI acquisition issue, we utilize a digital twin (DT) of the CF mMIMO system, leveraging its context-awareness to acquire global CSI with reduced overhead. To address computational intractiablity of the optimization problem, we decompose it into three sub-problems. The power allocation sub-problem is transformed into a second-order cone programming problem and solved by the bisection method. Additionally, we propose a computationally efficient heuristic approach for power allocation. Next, we propose an analytical method for the decoding order selection by ranking the channels in descending order of strength. Simulation results validate the ability of the proposed approach to attain the near-optimal performance. Subsequently, the AP-UE association assignment problem is solved by a heuristic approach to further improve the SE performance. Finally, we solve the original NP-hard problem in a unified manner via the block-coordinate descent algorithm. Simulation results underscore a substantial 61% improvement in the SE performance when integrating the RSMA technique into a UC CF mMIMO system.},
  archive      = {J_TMC},
  author       = {Manobendu Sarker and Md. Zoheb Hassan and Georges Kaddoum and Abraham O. Fapojuwo},
  doi          = {10.1109/TMC.2025.3604722},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-17},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Uplink resource allocation for RSMA-aided digital twin-assisted user-centric cell-free massive MIMO systems},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Secure charging scheduling in wireless rechargeable sensor networks. <em>TMC</em>, 1-15. (<a href='https://doi.org/10.1109/TMC.2025.3605390'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless Rechargeable Sensor Networks (WRSNs) promise to address the limited energy resource issue for sensor nodes through wireless power transfer technology. However, WRSNs are vulnerable to various security threats, such as compromised node attack and malicious mobile charger (MC) attack, which can disrupt the charging process and degrade charging efficiency. In this work, we investigate the eneRgy conversion Efficiency maximization problem unDer chargIng attackS (REDIS). We propose a blockchain-based framework that employs a lightweight multi-layer storage approach tailored for resource-constrained sensor nodes and features consensus algorithms that validate charging transactions. Furthermore, we introduce a validation node selection strategy that integrates consensus execution with charging scheduling, reducing energy consumption, and improving energy efficiency. Extensive simulations and experiments validate the effectiveness of our framework, improving energy efficiency by 30% and as much as 5 times in networks without attacks and those under full attacks, respectively.},
  archive      = {J_TMC},
  author       = {Wei Yang and Chi Lin and Jing Deng and Haipeng Dai and Liming Chen and Xinxin Fan and Li Zhang},
  doi          = {10.1109/TMC.2025.3605390},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Secure charging scheduling in wireless rechargeable sensor networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fully anonymous broadcast signcryption for secure health data transmission in WBANs. <em>TMC</em>, 1-15. (<a href='https://doi.org/10.1109/TMC.2025.3605205'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To support comprehensive and personalized healthcare delivery, sensitive personal health data must often be transmitted from wearable devices to multiple designated specialists via wireless body area networks. Although existing identity-based broadcast signcryption schemes provide secure one-to-many transmission, they typically fail to preserve recipient anonymity. In particular, each recipient is usually required to know the identities of all other recipients to unsigncrypt the message, which undermines privacy and enables inference attacks, especially problematic in telemedicine applications. In this paper, we propose a novel broadcast signcryption scheme that simultaneously achieves recipient anonymity, sender anonymity, and resilience to physical attacks, which are not realized in prior work. Our key innovation lies in an anonymity-preserving unsigncryption mechanism based on inner product, which enables each recipient to independently verify and decrypt the broadcast message without knowledge of others' identities. In addition, we incorporate a physical unclonable function with a fuzzy extractor to resist physical attacks in the presence of noise. Furthermore, a comprehensive security analysis demonstrates that our scheme satisfies essential security properties, including authentication, integrity, confidentiality, and full anonymity. It is resilient against common attacks such as impersonation, modification, replay, and man-in-the-middle attacks. Finally, performance evaluations confirm the practical feasibility of our scheme.},
  archive      = {J_TMC},
  author       = {Yangfan Liang and Gao Liu and Xianchao Zhang and Yiming Chen and Jingxue Chen and Yuanjun Xia and Yining Liu},
  doi          = {10.1109/TMC.2025.3605205},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Fully anonymous broadcast signcryption for secure health data transmission in WBANs},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AIGC-enhanced federated learning: Addressing data scarcity in preference-based scenarios. <em>TMC</em>, 1-16. (<a href='https://doi.org/10.1109/TMC.2025.3605397'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is a decentralized machine learning paradigm that enables collaborative model training while preserving data privacy by avoiding sensitive data exfiltration from local storage. Despite its success in various domains, current FL frameworks lack mechanisms to accommodate personalized training objectives, particularly in optimizing performance for specific data classes. Recent advancements in Artificial Intelligence Generated Content (AIGC) present opportunities to address these limitations by supplementing training data for user-preferred classes using generative models. Nonetheless, incorporating AIGC into FL introduces significant challenges, including non-compliant data quality, disorganized data distributions, limited computational resources, and slow data generation speed on edge devices. To address these challenges, we propose AIGC-enhanced Federated Preference Learning (FPL), a novel framework designed to enhance FL performance for user-specified preference classes (PCs). Our approach employs pre-training and fine-tuning of generative models across diverse datasets to improve the quality of synthetic data. Additionally, we optimize FPL efficiency through a client selection strategy that matches tasks involving generated data with suitable clients and a data distribution mechanism that allocates synthetic data to where it is most needed. To further accelerate data supplementation, data augmentation is utilized on local clients. We provide theoretical convergence guarantees for AIGC-enhanced FPL and demonstrate its effectiveness through comprehensive experiments on MNIST and CIFAR-10 datasets, including ablation studies on various data supplementation techniques.},
  archive      = {J_TMC},
  author       = {Chenyu Wang and Zhi Zhou and Zixin Xu and Zhijie Wang and Shaoquan Wang and Xu Chen},
  doi          = {10.1109/TMC.2025.3605397},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {AIGC-enhanced federated learning: Addressing data scarcity in preference-based scenarios},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Blockchain-assisted message reporting scheme with weighted threshold signature for vehicular ad-hoc networks. <em>TMC</em>, 1-18. (<a href='https://doi.org/10.1109/TMC.2025.3605858'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In vehicular ad-hoc networks (VANETs), message reporting is an effective method for improving traffic safety and efficiency. Most existing VANET message reporting schemes rely on the trust value of a single vehicle to determine message authenticity, which leads to unreliable message sources. Even multi vehicle-assisted reporting schemes are limited by the assumption that all vehicles have the same credibility, which does not reflect the actual dynamic VANET environment in which vehicles have different credibilities. To address this issue, we propose a blockchain-assisted VANET message reporting scheme with weighted threshold signatures. Through the design of weights, the credibility of different vehicles is quantified, and the impact of vehicles on the signing process is differentiated. Threshold signature generation relies on the weight sum of all signatories reaching a predetermined threshold, to enable flexible and reliable message reporting. Security analysis shows that our proposed scheme combined with blockchain can satisfy the security and privacy requirements of VANET message reporting. Performance analysis indicates that our proposed scheme outperforms the most advanced VANET message reporting schemes in terms of transmission and computation performance.},
  archive      = {J_TMC},
  author       = {Ru Li and Jie Cui and Jing Zhang and Lu Wei and Hong Zhong and Debiao He},
  doi          = {10.1109/TMC.2025.3605858},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-18},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Blockchain-assisted message reporting scheme with weighted threshold signature for vehicular ad-hoc networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AppGen: Mobility-aware app usage behavior generation for mobile users. <em>TMC</em>, 1-15. (<a href='https://doi.org/10.1109/TMC.2025.3605939'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile app usage behavior reveals human patterns and is crucial for stakeholders, but data collection is costly and raises privacy issues. Data synthesis can address this by generating artificial datasets that mirror real-world data. In this paper, we propose AppGen, an autoregressive generative model designed to generate app usage behavior based on users' mobility trajectories, improving dataset accessibility and quality. Specifically, AppGen employs a probabilistic diffusion model to simulate the stochastic nature of app usage behavior. By utilizing an autoregressive structure, AppGen effectively captures the intricate sequential relationships between different app usage events. Additionally, AppGen leverages latent encoding to extract semantic features from spatio-temporal points, guiding behavior generation. These key designs ensure the generated behaviors are contextually relevant and faithfully represent users' environments and past interactions. Experiments with two real-world datasets show that AppGen outperforms state-of-the-art baselines by over 12% in critical metrics and accurately reflects real-world spatio-temporal patterns. We also test the generated datasets in applications, demonstrating their suitability for downstream tasks by maintaining algorithm accuracy and order.},
  archive      = {J_TMC},
  author       = {Zihan Huang and Tong Li and Yong Li},
  doi          = {10.1109/TMC.2025.3605939},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {AppGen: Mobility-aware app usage behavior generation for mobile users},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EDGE360: Edge-enabled multi-agent DRL for region-aware rate adaptation solution to enhance quality of 360° video streaming. <em>TMC</em>, 1-18. (<a href='https://doi.org/10.1109/TMC.2025.3605849'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal tile-based bitrate allocation improves the Quality of Experience (QoE) for adaptive 360° video streaming across multiple clients in heterogeneous network environments; however, it is challenging as it implies accurate viewport prediction, finest tile-based bitrate reservation, and maintaining QoE fairness, particularly under constrained network conditions. This paper proposes a strategy named EDGE360, that employs an edge-driven Multi-Agent Deep Reinforcement Learning (MADRL) solution for rate adaptation to improve the joint QoE in DASH-based rich media content delivery based on adaptive viewport prediction and Video Multi-method Assessment Fusion (VMAF) corresponding tiling granularity selection. Cooperative strategies among agents in the central critic network are crucial for addressing the complexity of network instances at the edge and optimizing media streaming bitrate assignment in multiple-client scenarios. Therefore, EDGE360 aims to implement the Counterfactual Multi-Agent Policy Gradients (COMA) based on 5G network traces to train agents in policies that optimize individual client QoE and fairness among clients, resulting in an improved rich streaming experience. At the edge, a tile-based quality monitor evaluates viewport trajectories, buffer status, and network throughput, employing deep learning to forecast optimal tile bitrate allocation, which is formulated as an MDP and solved with MADRL. Based on extensive experimentation, EDGE360 surpasses state-of-the-art adaptive bitrate algorithms by achieving the highest average reward, outperforming RAPT360, 360SRL, and BOLA360 by 8.12%, 11.86%, and 18.00%, respectively, demonstrating superior convergence and refinement.},
  archive      = {J_TMC},
  author       = {Fazal E Subhan and Abid Yaqoob and Cristina Hava Muntean and Gabriel-Miro Muntean},
  doi          = {10.1109/TMC.2025.3605849},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-18},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {EDGE360: Edge-enabled multi-agent DRL for region-aware rate adaptation solution to enhance quality of 360° video streaming},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EOC-tracking: An environmental obstacles constrained adaptive wi-fi tracking framework. <em>TMC</em>, 1-18. (<a href='https://doi.org/10.1109/TMC.2025.3605936'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wi-Fi device-free tracking enables the inference of user behaviors without physical contact, which is crucial for intelligent indoor location-based services. Nevertheless, the practical implementation of current tracking systems is constrained by several critical limitations: 1) The low-quality sensing signals in complex scenarios lead to increased tracking errors; 2) Existing methods inadequately adjust to dynamic environments, necessitating additional data collection or retraining processes. To address these challenges, this paper introduces EOC-Tracking, a device-free Wi-Fi tracking system that dynamically incorporates environmental information. Our key innovation involves leveraging obstacles to correct illogical users' trajectories and facilitate adjustment to varying environments. This significantly improves the accuracy of the follow-up in complex and changing environments. The EOC-Tracking system is built upon three fundamental design principles: 1) A lightweight dual-branch neural network architecture that effectively fuses environmental data with Wi-Fi signal characteristics; 2) An autonomous map updating mechanism that facilitates real-time adaptation to environmental layout modifications without human intervention; 3) A sophisticated data-driven, phased training paradigm that optimizes the model's ability to learn and apply obstacle constraints. We implement EOC-Tracking using commercial Wi-Fi devices and deploy it on low-power embedded systems such as the MCU. Experimental results demonstrate that EOC-Tracking can reduce tracking errors by at most 49.48% compared to datadriven methods and 62.21% compared to model-based methods in various complex scenarios.},
  archive      = {J_TMC},
  author       = {Jinwei Gao and Qixuan Cai and Mengjie Yu and Xinyu Tong and Tony Xiao Han and Xiulong Liu and Xin Xie and Wenyu Qu},
  doi          = {10.1109/TMC.2025.3605936},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-18},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {EOC-tracking: An environmental obstacles constrained adaptive wi-fi tracking framework},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Service-oriented segmented trajectory design for low-altitude UAV-assisted MEC networks. <em>TMC</em>, 1-17. (<a href='https://doi.org/10.1109/TMC.2025.3605865'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the integration of Unmanned Aerial Vehicles (UAV) with Internet of Things (IoT) infrastructure to enhance Mobile Edge Computing capabilities in urban environments. While UAVs offer promising solutions for mobile edge computing, their deployment in high-rise urban areas presents significant challenges, particularly in computational resource balancing, energy-efficient trajectory planning, and dynamic IoT service provisioning. We propose a comprehensive low-altitude UAV-assisted mobile edge computing framework that jointly optimizes UAV trajectory planning, the assignment of offloaded tasks to specific UAVs, and the strategic deployment and energy management of the UAV fleet to maximize system utility. We first formulate this as a multi-objective optimization problem and prove its NP-hardness due to its non-convex and integer linear programming nature. To tackle this challenge, we develop a decomposition-based approach that systematically addresses the coupled variables. We then propose a novel Variable Strategy Reinforcement Learning-based Lin-Kernighan-Helsgaun algorithm that synergistically combines Q-learning, Sarsa, and Monte Carlo methods with the LKH algorithm. The proposed solution is further enhanced by incorporating two refined trajectory optimization mechanisms, the Trajectory Refining Algorithm and the Service-Oriented Segmented Trajectory Refining Algorithm, specifically designed to improve the robustness and reliability in solving the Computation Offloading Trajectory Optimization Problem. Extensive simulation results demonstrate that our proposed algorithms consistently outperform state-of-the-art approaches, achieving faster convergence, higher energy efficiency for UAVs, and lower computational latency for IoT devices.},
  archive      = {J_TMC},
  author       = {Pengfei Wu and Fu Xiao and Chao Sha and Haiping Huang},
  doi          = {10.1109/TMC.2025.3605865},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-17},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Service-oriented segmented trajectory design for low-altitude UAV-assisted MEC networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). P2TS: A preemptive approach for priority-aware task scheduling in computing power networks. <em>TMC</em>, 1-18. (<a href='https://doi.org/10.1109/TMC.2025.3606454'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an emerging computing paradigm, Computing Power Networks (CPNs) are dedicated to coordinating and managing network resources and computing resources to achieve interconnectivity in computing power perception. Efficient collaborative computing of massive data can be achieved through the scheduling function of CPNs. However, existing scheduling research mainly focuses on selecting network links and computing nodes, lacking consideration for task execution after scheduling, which may degrade the Quality of Service (QoS), leading to widespread failures and significant losses. To address this issue, we design a priority-aware preemptive task scheduling (P2TS) strategy for CPNs to jointly optimize task scheduling and execution in terms of success rate, average processing delay, and load balancing. Specifically, at the execution level, we propose a priority-aware preemptive mechanism (P2M) to optimize post-scheduling task execution. Then, at the scheduling level, we apply deep reinforcement learning (DRL) to optimize the scheduling process supporting the P2M in CPNs. A series of simulations are conducted to demonstrate the superiority of our strategy.},
  archive      = {J_TMC},
  author       = {Tao Huang and Haoxiang Qiu and Qinqin Tang and Li Feng and Renchao Xie and Tianjiao Chen and Zehui Xiong},
  doi          = {10.1109/TMC.2025.3606454},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-18},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {P2TS: A preemptive approach for priority-aware task scheduling in computing power networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cooperative highly-maneuvering target tracking using multi-AUV networks: A bearing-only approach. <em>TMC</em>, 1-16. (<a href='https://doi.org/10.1109/TMC.2025.3606690'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater target tracking is a fundamental technology for marine development, providing real-time position estimates of the interested targets. However, due to the harsh underwater environment and the noncooperativity of targets, improving tracking accuracy remains a challenge, especially for highly-maneuvering targets. To address this problem, based on multi-autonomous underwater vehicle (multi-AUV) networks, this paper extends the idea of interacting multiple models (IMM) and designs a bearing-only cooperative tracking algorithm in the consideration of the harsh underwater acoustic channels. Specifically, in position prediction, the combination of historical information and the concept of IMM reduces the severe time-lagged effect in traditional prediction methods and the model reliance in standard IMM filters. Then, during position update, a rigidity-assisted relative position representation is designed based solely on bearing measurements, which alleviates the impact of information loss due to communication interruptions, significantly enhancing the continuity of target tracking. Moreover, the algorithm design also considers various uncertainties that may concurrently occur underwater (e.g., error accumulation and model mismatches), and robust optimization strategies with the principle of maximum entropy are designed to enhance the environmental adaptability. Through various simulations and field experiments, the advantages of the proposed method have been validated.},
  archive      = {J_TMC},
  author       = {Yichen Li and Yang Yang and Wenbin Yu and Xinping Guan},
  doi          = {10.1109/TMC.2025.3606690},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Cooperative highly-maneuvering target tracking using multi-AUV networks: A bearing-only approach},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic multi-modal UAV control for optimized coverage and backhaul connectivity in spatially unstructured and dispersed user environments. <em>TMC</em>, 1-15. (<a href='https://doi.org/10.1109/TMC.2025.3606778'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned aerial vehicles (UAVs) have emerged as a promising solution for establishing wireless communications in regions lacking terrestrial network infrastructure, such as remote or emergency areas. Deploying UAV networks effectively in these scenarios poses significant challenges due to the unknown and potentially complex locations of users. In scenarios where users are dispersed in intricate spatial patterns, achieving high coverage and resilient network connectivity among the UAV networks is challenging. The irregular and arbitrary distribution of users can lead to gaps in coverage, as traditional UAV placement optimization approaches are often unable to adapt to such dynamic environments. This complexity necessitates advanced strategies to ensure reliable and continuous network service to users. In this paper, we propose a distributed approach that leverages flocking dynamics and distributed consensus algorithms for dynamic UAV positioning. By enabling a multi-modal UAV operation policy, we develop a framework which enables the network to dynamically respond to complex user locations and establish backhaul connectivity between dispersed user clusters. Simulation results demonstrate that our approach successfully establishes a robust and adaptable UAV network capable of providing seamless coverage for complex user configurations and also ensuring comprehensive inter-cluster connectivity among dispersed user clusters. Additionally, the network exhibits strong resilience against random failures, swiftly recovering from disruptions to ensure stable and reliable communication even when UAVs are compromised.},
  archive      = {J_TMC},
  author       = {Yuhui Wang and Junaid Farooq and Juntao Chen},
  doi          = {10.1109/TMC.2025.3606778},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Dynamic multi-modal UAV control for optimized coverage and backhaul connectivity in spatially unstructured and dispersed user environments},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MaestroBot: Generalized gesture-driven hierarchical coordination for robotic formations. <em>TMC</em>, 1-17. (<a href='https://doi.org/10.1109/TMC.2025.3606847'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic swarm coordination holds transformative potential for applications such as warehouse automation, search & rescue, and entertainment. However, approaches relying on wearable devices or vision-based systems are often constrained by hardware-intensive, high computational requirements, reliance on line-of-sight, and privacy concerns. Wireless sensing, particularly using Channel State Information (CSI), offers a promising alternative by translating environmental perturbations into CSI variation data. Nevertheless, existing CSI-based systems face significant challenges in domain adaptation, resource limitation, and scalability issues. This paper introduces MaestroBot, a hierarchical motion coordination system that combines distributed CSI-based wireless sensing with domain-adaptive learning to address these limitations. For leader robots, the system features a lightweight hand gesture recognition model, built on a “Hybrid-Single” knowledge distillation framework, achieving up to 95.87% accuracy while maintaining adaptability across diverse domains. For follower robots, the hierarchical motion propagation model leverages localized CSI analysis and dual-layer error correction mechanisms to deliver 97.2% accuracy with a low latency of 0.085 seconds, even in multi-row formations. Additionally, its cost-effective hardware design ensures practical scalability and real-world deployability. These results position MaestroBot as an efficient, robust, and privacy-preserving solution for large-scale robotic swarm coordination in dynamic environments.},
  archive      = {J_TMC},
  author       = {Yutong Liu and Zhiye Wang and Yuhan Xu and Yang Yue and Haiming Jin and Linghe Kong and Rui Li and Xi Chen and Qiao Xiang and Jun Zhang and Guihai Chen},
  doi          = {10.1109/TMC.2025.3606847},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-17},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {MaestroBot: Generalized gesture-driven hierarchical coordination for robotic formations},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mobility resilient vehicular federated learning: Enhancing training efficiency in dynamic environments. <em>TMC</em>, 1-17. (<a href='https://doi.org/10.1109/TMC.2025.3607138'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The vehicular environment presents unique challenges, including massive data generation, stringent latency requirements for safety-critical applications, bandwidth limitations, and intermittent connectivity, which make centralized learning approaches impractical. Vehicular Federated Learning (VFL) enables distributed model training by leveraging local data from connected vehicles, while preserving data privacy and reducing network overhead. However, the dynamic nature of VFL presents several additional challenges. High vehicle mobility and unstable channels lead to inconsistent client participation, while heterogeneous vehicle capabilities result in unbalanced training workloads and competitive resource allocation. These challenges significantly degrade VFL model performance and prolong training periods. In this paper, we propose a Mobility Resilient Vehicular Federated Learning (MR-VFL) scheme, which comprises two key components: an amplification-based adaptive vehicular FL (AVFL) training scheme and a dual-timescale FL scheduler. Specifically, AVFL adapts local training epochs to vehicle capabilities to improve scheduling flexibility and alleviate the impact of insufficient local epochs on model updates, which enhances training efficiency and reduces communication competition. The dual-timescale FL scheduler includes a macro scheduling strategy that optimizes long-term VFL performance based on the correlation between convergence speed and model accuracy, and a Mamba-based real-time scheduler that enhances training efficiency and reduces decision latency in massive vehicles scenarios. Extensive simulations show that MR-VFL effectively mitigates performance degradation due to complex vehicle mobility and heterogeneity, and improves training efficiency.},
  archive      = {J_TMC},
  author       = {Tianao Xiang and Yuanguo Bi and Lin Cai and Mingjian Zhi},
  doi          = {10.1109/TMC.2025.3607138},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-17},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Mobility resilient vehicular federated learning: Enhancing training efficiency in dynamic environments},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Resilient topological control for dynamic underwater optical wireless networks. <em>TMC</em>, 1-18. (<a href='https://doi.org/10.1109/TMC.2025.3607035'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater Wireless Optical Networks (UWONs) play a critical role in tasks such as ocean monitoring and resource exploration, which require high connectivity and reliability. However, water turbidity, ocean currents, and ambient light noise significantly affect communication stability, creating serious deployment challenges. To address this, we propose a network topology optimization method based on resilience evaluation. First, a resilience evaluation method is designed to quantify the network's ability to adapt to disturbances. Then, an improved predecessor-based evolutionary algorithm (Pred-EA) is used for resilience-guided topology optimization. To improve algorithmic efficiency and search quality, the prim algorithm is introduced to ensure chromosome feasibility, enhancing both the diversity of the initial population and computational efficiency. Experimental results show that our method achieves better recovery performance than three comparison methods in all scenarios. The average number of recovered edges improves by up to 18.30% over the second-best method. Under non-recoverable conditions, resilience improves by up to 20.52%. These results confirm the strong topological robustness and practical value of the proposed method in dynamic underwater environments.},
  archive      = {J_TMC},
  author       = {Qing Zhang and Youling Huang and Lin Lin and Chi Lin},
  doi          = {10.1109/TMC.2025.3607035},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-18},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Resilient topological control for dynamic underwater optical wireless networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quick-pass continuous authentication with real-time biometrics extraction on COTS earphones using out-ear microphones. <em>TMC</em>, 1-18. (<a href='https://doi.org/10.1109/TMC.2025.3606846'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continuous authentication is increasingly critical for cyber security. However, existing approaches are time-consuming due to their simplistic signal modulation and low efficiency in feature extraction. In this paper, we propose a continuous authentication technique, OnePiece. OnePiece is free from the requirement of in-ear microphones, which are necessary for existing earphone authentication systems. It exploits out-ear microphones for biometrics extraction, which are ubiquitous on off-the-shelf earphones. We analyze the acoustic response model of ears towards out-ear microphones via the air, which is different from that towards in-ear microphones. A frequency-varying ultrasonic modulation scheme is proposed to characterize in-depth ear biometrics in user-friendly, error-free, and time-efficient ways. Therefore, OnePiece enables quick-pass authentication once users wear the earphones, followed by continuous authentication covering the whole course. Moreover, we propose a wake-up mechanism to reduce the consumed power, which addresses the key power consumption issue in ultrasonic sensing techniques. Particularly, OnePiece can be smoothly deployed on off-the-shelf wired and wireless earphones. It performs good cross-device performance in which users just register only once. Extensive evaluations are conducted to validate its effectiveness under real-world scenarios.},
  archive      = {J_TMC},
  author       = {Ming Gao and Jiatong Chen and Xin Tong and Ruitong Ye and Yike Chen and Fu Xiao and Jinsong Han},
  doi          = {10.1109/TMC.2025.3606846},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-18},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Quick-pass continuous authentication with real-time biometrics extraction on COTS earphones using out-ear microphones},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient iTreeKEM-based group key agreement protocol for flying ad-hoc networks. <em>TMC</em>, 1-17. (<a href='https://doi.org/10.1109/TMC.2025.3607316'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As Flying Ad-hoc Network (FANET) evolves toward larger scales and higher levels of autonomy, the importance of secure and efficient group communication continues to grow. However, resource-constrained unmanned aerial vehicles (UAVs) face dual challenges: limited computational power struggles to meet the high demands of complex cryptographic algorithms, while bandwidth constraints exacerbate communication overhead caused by multi-round interaction mechanisms. Moreover, existing solutions find it hard to support dynamic group environments and are prone to single point of failure (SPoF) in centralized architectures, which significantly compromises system reliability and scalability. To address these issues, this paper proposes a novel key agreement protocol for FANET. The protocol employs an improved tree-based key encapsulation mechanism (iTreeKEM) to support rapid key updates in highly dynamic environments. It reduces the computational cost for each group member by 90.08% even when the group size reaches 128. To further enhance system robustness, the protocol introduces a smart contract-based distributed leader election mechanism, effectively eliminating SPoF. The security of the proposed protocol is guaranteed by the CDH problem under the generalized selective decryption (GSD) model. Finally, we implement the protocol in NS-3 simulations, and the results demonstrate its effective applicability to FANET.},
  archive      = {J_TMC},
  author       = {Tianqi Zhou and Shijia Hong and Jian Shen and Md Zakirul Alam Bhuiyan and Pandi Vijayakumar and Debiao He},
  doi          = {10.1109/TMC.2025.3607316},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-17},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {An efficient iTreeKEM-based group key agreement protocol for flying ad-hoc networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Microservice deployment in space computing power networks via robust reinforcement learning. <em>TMC</em>, 1-17. (<a href='https://doi.org/10.1109/TMC.2025.3607488'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growing demand for Earth observation, it is important to provide reliable real-time remote sensing inference services to meet the low-latency requirements. The Space Computing Power Network (Space-CPN) offers a promising solution by providing onboard computing and extensive coverage capabilities for real-time inference. This paper presents a remote sensing artificial intelligence applications deployment framework designed for Low Earth Orbit satellite constellations to achieve real-time inference performance. The framework employs the microservice architecture, decomposing monolithic inference tasks into reusable, independent modules to address high latency and resource heterogeneity. This distributed approach enables optimized microservice deployment, minimizing resource utilization while meeting quality of service and functional requirements. We introduce Robust Optimization to the deployment problem to address data uncertainty. Additionally, we model the Robust Optimization problem as a Partially Observable Markov Decision Process and propose a robust reinforcement learning algorithm to handle the semi-infinite Quality of Service constraints. Our approach yields sub-optimal solutions that minimize accuracy loss while maintaining acceptable computational costs. Simulation results demonstrate the effectiveness of our framework.},
  archive      = {J_TMC},
  author       = {Zhiyong Yu and Yuning Jiang and Xin Liu and Yuanming Shi and Chunxiao Jiang and Linling Kuang},
  doi          = {10.1109/TMC.2025.3607488},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-17},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Microservice deployment in space computing power networks via robust reinforcement learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CI-HDA: Heterogeneous deniable authentication based on CLC and IBC for location privacy in edge computing. <em>TMC</em>, 1-15. (<a href='https://doi.org/10.1109/TMC.2025.3607414'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge computing improves the performance of Internet of Things (IoT) devices by moving cloud services closer to where these devices operate, thereby reducing delays and saving bandwidth. However, the IoT devices communicate wirelessly with edge servers, which creates a significant challenge in keeping the devices' locations private, especially when they use different methods. To address this, researchers have proposed various methods. However, these methods require a lot of computational power and storage, which makes them unsuitable for edge computing environments. To address these challenges, we propose a certificateless cryptography (CLC) and identity-based cryptography (IBC) based heterogeneous deniable authentication (CI-HDA) scheme. It enables an IoT device operating CLC to securely communicate with an edge server using IBC. The server verifies the devices authenticity without proving its participation to third parties, which ensures location privacy in edge computing environments. Additionally, our scheme supports batch verification, which enables the server to efficiently validate multiple authenticators simultaneously. The security of CI-HDA scheme is formally proven in the random oracle model, and performance evaluations demonstrate reduced computational and communication/storage overheads compared to existing methods. We also explored its application in military surveillance, which highlights its practicality in privacy-sensitive edge computing environments.},
  archive      = {J_TMC},
  author       = {Ikram Ali and Jianqiang Li and Jie Chen and Yong Chen and Shamsher Ullah and Abdul Wakeel},
  doi          = {10.1109/TMC.2025.3607414},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {CI-HDA: Heterogeneous deniable authentication based on CLC and IBC for location privacy in edge computing},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Through-wall cross-domain user identification via lip movement micro-doppler and MIMO radar: An unsupervised domain adaptation approach. <em>TMC</em>, 1-18. (<a href='https://doi.org/10.1109/TMC.2025.3607413'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lip movement-based user identification holds significant promise for public security and intelligent surveillance due to its dynamic patterns, forgery resistance, and individual distinctiveness. Recently, millimeter-wave radar has been employed for contactless identification, offering advantages such as light insensitivity, privacy preservation, and sensitivity to fine motion. However, its limited wall penetration and vulnerability to occlusion present ongoing challenges. Moreover, existing recognition approaches rely heavily on supervised learning, demanding large labeled datasets and exhibiting poor generalization across domains. To overcome these limitations, we propose Lip-TWCDID, a lip movement-based cross-domain user identification system using 1–2 GHz MIMO radar. The use of low-frequency signals enhances penetration, while the MIMO architecture improves spatial resolution, enabling stable detection of fine-grained micro-Doppler signatures of lip movements through a 22 cm brick wall. To reduce dependence on labeled data and improve domain generalization, we introduce a novel unsupervised domain adaptation (UDA) framework, consistency-adversarial-contrastive learning (CACL), which integrates pseudo-label consistency learning, domain adversarial training, and pseudo-supervised contrastive learning. Specifically, pseudo-label consistency enforces prediction consistency under input perturbations, improving robustness; domain adversarial training introduces a domain discriminator to encourage domaininvariant feature learning and align feature distributions; pseudosupervised contrastive learning leverages high-confidence pseudolabels to perform contrastive learning in the feature space, enhancing inter-class separability and intra-class compactness. By jointly optimizing these components, CACL effectively adapts to unlabeled target domains while minimizing annotation costs. Extensive experiments demonstrate that CACL outperforms state-of-the-art UDA methods and significantly improves the generalization and robustness of through-wall user identification.},
  archive      = {J_TMC},
  author       = {Kai Yang and Dongsheng Zhu and Yujie Xu and Chong Han and Jian Guo and Lijuan Sun},
  doi          = {10.1109/TMC.2025.3607413},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-18},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Through-wall cross-domain user identification via lip movement micro-doppler and MIMO radar: An unsupervised domain adaptation approach},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mobility-aware multi-task decentralized federated learning for vehicular networks: Modeling, analysis, and optimization. <em>TMC</em>, 1-17. (<a href='https://doi.org/10.1109/TMC.2025.3607496'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is a promising paradigm that can enable collaborative model training between vehicles while protecting data privacy, thereby significantly improving the performance of intelligent transportation systems (ITSs). In vehicular networks, due to mobility, resource constraints, and the concurrent execution of multiple training tasks, how to allocate limited resources effectively to achieve optimal model training of multiple tasks is an extremely challenging issue. In this paper, we propose a mobility-aware multi-task decentralized federated learning (MMFL) framework for vehicular networks. By this framework, we address task scheduling, subcarrier allocation, and leader selection, as a joint optimization problem, termed TSLP. For the case with a single FL task, we derive the convergence bound of model training. For general cases, we first model TSLP as a resource allocation game, and prove the existence of a Nash equilibrium (NE). Then, based on this proof, we reformulate the game as a decentralized partially observable Markov decision process (DEC-POMDP), and develop an algorithm based on heterogeneous-agent proximal policy optimization (HAPPO) to solve DEC-POMDP. Finally, numerical results are used to demonstrate the effectiveness of the proposed algorithm.},
  archive      = {J_TMC},
  author       = {Dongyu Chen and Tao Deng and He Huang and Juncheng Jia and Mianxiong Dong and Di Yuan and Keqin Li},
  doi          = {10.1109/TMC.2025.3607496},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-17},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Mobility-aware multi-task decentralized federated learning for vehicular networks: Modeling, analysis, and optimization},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-layer design for dynamic routing and MAC protocols in terahertz nanonetworks. <em>TMC</em>, 1-14. (<a href='https://doi.org/10.1109/TMC.2025.3607434'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advancement of nanotechnology has enabled the deployment of medical nanonetworks within the human body, further accelerated by progress in terahertz communication technologies and nanonetwork routing protocols. However, nanonodes may move in dynamic environments due to environmental influences or self-propulsion mechanisms, posing significant challenges to routing protocol design. To address this, we propose a dynamic routing protocol for nanonetworks that integrates real-time velocity vectors to account for time-varying node positions. During relay node selection, key factors such as candidate nodes' velocity vectors are comprehensively evaluated to determine the optimal relay for next-hop transmission. To ensure efficient data exchange among multiple nodes, we design a time-division multiple access (TDMA)-based media access control (MAC) protocol to prevent packet collisions and losses. The protocol assigns distinct transmission and reception time slots to different node types and implements a countdown mechanism to manage channel access and eliminate conflicts. Numerical and simulation results demonstrate that the proposed protocol significantly outperforms benchmark protocols, achieving notable improvements in both time and energy efficiency.},
  archive      = {J_TMC},
  author       = {Duyu Dai and Yu Huang and Mingyue Cheng and Miaowen Wen and Nan Yang and Chan-Byoung Chae},
  doi          = {10.1109/TMC.2025.3607434},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Cross-layer design for dynamic routing and MAC protocols in terahertz nanonetworks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive sacrifice for QoS-aware routing: A graph reinforcement learning approach. <em>TMC</em>, 1-18. (<a href='https://doi.org/10.1109/TMC.2025.3607388'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet today hosts a multitude of communication sessions from diverse vertical industries, each with distinct and increasingly stringent quality-of-service (QoS) requirements across multiple performance metrics. However, QoS-aware routing remains a significant challenge in traffic engineering, as existing solutions struggle to adapt to dynamic network conditions and meet these rigorous QoS demands. To address this issue, this paper proposes a multi-agent graph reinforcement learning-based routing algorithm that provides differentiated treatment for multiple services. First, we explore both nodebased and link-based graph reinforcement learning paradigms for performance comparison. Second, two key mechanisms, i.e., a packet sacrifice mechanism and a Tchebycheff-based reward function, are designed to realize adaptive sacrifice behavior patterns, aiming to optimize the lower bound of service satisfaction rates and enhance fairness across services. Furthermore, to ensure practical applicability, we devise a distributed computing architecture featuring neighborhood-restricted data acquisition and asynchronous historical information retrieval. Extensive simulation results demonstrate that our proposed algorithms significantly outperform benchmark methods regarding the minimum service satisfaction rate, even under unseen networks. Besides, the distributed computing architecture is proven to incur no performance penalty, which can be generalized to other resource-constrained applications.},
  archive      = {J_TMC},
  author       = {Yuqian Song and Jingli Zhou and Shudan Yu and Jun Liu},
  doi          = {10.1109/TMC.2025.3607388},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-18},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Adaptive sacrifice for QoS-aware routing: A graph reinforcement learning approach},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PrivGuardInfer: Channel-level end-edge collaborative inference strategy protecting original inputs and sensitive attributes. <em>TMC</em>, 1-18. (<a href='https://doi.org/10.1109/TMC.2025.3607483'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {End-edge collaborative inference improves computational efficiency by dividing a deep neural network into two parts, executed across the end device and the edge node in parallel. However, adversaries like malicious edge nodes can exploit transmitted data to reconstruct original inputs or infer sensitive attributes. Existing collaborative inference strategies upload the majority of input features to the edge node, significantly increasing the risk of privacy leakage, even without input reconstruction. Therefore, we propose PrivGuardInfer, a channel-level DNN end-edge collaborative inference strategy that optimizes intra-layer partition to simultaneously protect original inputs and sensitive attributes while ensuring latency constraints, supported by three key designs. First, the privacy measurements oriented both layer depth and channel count, jointly quantify the difficulty of reconstructing original inputs using varying numbers of feature maps across different layers. After assessing each channel's contribution, the information offset further measures the difficulty of inferring sensitive attributes. Finally, PrivGuardInfer models the privacy-optimal intra-layer partition under latency constraints as a grouped knapsack problem, mapping attack difficulty to item values and inference latency to item weights. Experimental results reveal that PrivGuardInfer achieves an average improvement of 80.54% in defending against model inversion attacks and 63.34% against attribute inference attacks compared to existing end-edge partition strategies. Moreover, it outperforms current privacy protection methods by an average of 69.37% and 49.75% in mitigating these two types of attacks.},
  archive      = {J_TMC},
  author       = {Yunhao Yao and Zhiqiang Wang and Puhan Luo and Yihang Cheng and Jiahui Hou and Xiang-Yang Li},
  doi          = {10.1109/TMC.2025.3607483},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-18},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {PrivGuardInfer: Channel-level end-edge collaborative inference strategy protecting original inputs and sensitive attributes},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Is FISHER all you need in the multi-AUV underwater target tracking task?. <em>TMC</em>, 1-15. (<a href='https://doi.org/10.1109/TMC.2025.3607882'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is significant to employ multiple autonomous underwater vehicles (AUVs) to execute the underwater target tracking task collaboratively. However, it's pretty challenging to meet various prerequisites utilizing traditional control methods. Therefore, we propose an effective two-stage learning from demonstrations training framework, FISHER, to highlight the adaptability of reinforcement learning (RL) methods in the multi-AUV underwater target tracking task, while addressing its limitations such as extensive requirements for environmental interactions and the challenges in designing reward functions. The first stage utilizes imitation learning (IL) to realize policy improvement and generate offline datasets. To be specific, we introduce multi-agent discriminator-actor-critic based on improvements of the generative adversarial IL algorithm and multi-agent IL optimization objective derived from the Nash equilibrium condition. Then in the second stage, we develop multi-agent independent generalized decision transformer, which analyzes the latent representation to match the future states of high-quality samples rather than reward function, attaining further enhanced policies capable of handling various scenarios. Besides, we propose a simulation to simulation demonstration generation procedure to facilitate the generation of expert demonstrations in underwater environments, which capitalizes on traditional control methods and can easily accomplish the domain transfer to obtain demonstrations. Extensive simulation experiments from multiple scenarios showcase that FISHER possesses strong stability, multi-task performance and capability of generalization.},
  archive      = {J_TMC},
  author       = {Guanwen Xie and Jingzehua Xu and Ziqi Zhang and Xiangwang Hou and Dongfang Ma and Shuai Zhang and Yong Ren and Dusit Niyato},
  doi          = {10.1109/TMC.2025.3607882},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Is FISHER all you need in the multi-AUV underwater target tracking task?},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The survey hole inpainting problem: A machine learning approach. <em>TMC</em>, 1-12. (<a href='https://doi.org/10.1109/TMC.2025.3607935'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work considers the inpainting of missing data in an indoor field, such as geomagnetism and WiFi fingerprints. As opposed to typical image/video inpainting problems, this problem poses several new challenges. First, unlike images with rectangular shapes and fixed RGB channels, indoor geographic data are multi-channeled and highly influenced by building structures. Second, unlike natural objects with fixed shapes, each geographic field is distinct and geographic data are environmentsensitive, following complex physical laws. Consequently, learning from data in other fields is difficult. Third, such data may be obtained from manual surveys and crowdsourcing, which often results in weakly-labeled and noisy datasets. We model our field data as (i) manually surveyed labeled data with holes and (ii) crowdsourced weakly-labeled data without holes. We propose a two-level adversarial regularization inpainting model to conquer these challenges and validate our results with real field data.},
  archive      = {J_TMC},
  author       = {Wei-Zhi Lin and Jen-Jee Chen and Yu-Chee Tseng},
  doi          = {10.1109/TMC.2025.3607935},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {The survey hole inpainting problem: A machine learning approach},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Group-based federated learning with cost-efficient sampling mechanism in mobile edge computing networks. <em>TMC</em>, 1-18. (<a href='https://doi.org/10.1109/TMC.2025.3608024'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) that preserves privacy has appeared as a prospective paradigm in mobile edge computing networks. However, due to the system and data heterogeneity of mobile clients (MCs), group-based FL with a sampling mechanism is crucial for minimizing model training costs. To address these challenges, we investigate and formulate the problem of group-based FL with a sampling mechanism for reducing model training cost (i.e., latency and energy consumption), and propose a group-based FL with a cost-efficient sampling mechanism (GFLCSM) framework to address it. More precisely, before training, each MC locally pre-trains a model, estimates its data distribution from the classifier's gradient norms, and uploads it to the central server (CS) instead of raw data to preserve privacy. Using this information, the CS transforms vanilla FL into a group-based FL. During training, GFLCSM replaces the random sampling mechanism with a cost-efficient one. Moreover, to enhance robustness against network dynamics, we extend GFLCSM with a backup resampling mechanism, termed GFLCSM-E. Experimental results indicate that GFLCSM surpasses the baseline frameworks, reducing latency by 24.63% and energy consumption by 11.47% on average across two datasets, while GFLCSM-E maintains high performance even under client dropout. The source code address is https://github.com/kt4ngw/GFLCSM.},
  archive      = {J_TMC},
  author       = {Jian Tang and Xiuhua Li and Guozeng Xu and Penghua Li and Xiaofei Wang and Victor C. M. Leung},
  doi          = {10.1109/TMC.2025.3608024},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-18},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Group-based federated learning with cost-efficient sampling mechanism in mobile edge computing networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). VR-PCT: Enhanced VR semantic performance via edge-client collaborative multi-modal point cloud transformers. <em>TMC</em>, 1-16. (<a href='https://doi.org/10.1109/TMC.2025.3607791'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time semantic recognition is crucial for virtual reality (VR) applications, but the efficient fusion of multi-modal data poses significant challenges under resource-constrained VR scenarios. While integrating millimeter-wave (mmWave) radar point clouds with vision data offers a promising solution, existing methods often suffer from excessive data overhead and degraded accuracy due to redundant and noisy information. To address this limitation, this paper presents VR-PCT, a multi-modal transformer for edge-client collaborative VR semantic recognition that fuses mmWave radar point cloud and vision data for VR applications. VR-PCT introduces a novel collaborative design where VR clients perform lightweight semantic region detection while VR edge processes multi-modal VR semantic recognition. Through efficient edge-client collaboration, VR-PCT optimizes the transmission of mmWave point cloud and vision data by transmitting only the VR semantic region of vision data instead of the entire video. Additionally, it incorporates adaptive cross-modal data selection and fusion strategies to achieve real-time semantic recognition while significantly reducing data redundancy. Across 22 participants engaged in four experimental scenes utilizing VR devices from three different manufacturers, our evaluation demonstrates that VR-PCT achieves 97.6% recognition accuracy while reducing transmission overhead by 81.5% compared to existing approaches. These results highlight the effectiveness of VR-PCT in enabling efficient and accurate multi-modal VR semantic recognition for VR applications. The code and data of VR-PCT are released on https://github.com/luoyumei1-a/VR-PCT.},
  archive      = {J_TMC},
  author       = {Luoyu Mei and Shuai Wang and Ruofeng Liu and Yun Cheng and Shuai Wang and Wenchao Jiang and Zhimeng Yin and Tian He},
  doi          = {10.1109/TMC.2025.3607791},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {VR-PCT: Enhanced VR semantic performance via edge-client collaborative multi-modal point cloud transformers},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semantic communication based on large language model for underwater image transmission. <em>TMC</em>, 1-15. (<a href='https://doi.org/10.1109/TMC.2025.3607717'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater communication is essential for environmental monitoring, marine biology research, and underwater exploration. Traditional underwater communication faces limitations like low bandwidth, high latency, and susceptibility to noise, while semantic communication (SC) offers a promising solution by focusing on the exchange of semantics rather than symbols or bits. However, SC encounters challenges in underwater environments, including semantic information mismatch and difficulties in accurately identifying and transmitting critical information that aligns with the diverse requirements of underwater applications. To address these challenges, we propose a novel SC framework based on Large Language Models (LLMs). Our framework leverages visual LLMs to perform semantic compression and prioritization of underwater image data according to the query from users. By identifying and encoding key semantic elements within the images, the system selectively transmits high-priority information while applying higher compression rates to less critical regions. On the receiver side, an LLM-based recovery mechanism, along with Global Vision ControlNet and Key Region ControlNet networks, aids in reconstructing the images, thereby enhancing communication efficiency and robustness. Our framework reduces the overall data size to 0.8% of the original. Experimental results demonstrate that our method significantly outperforms existing approaches, ensuring high-quality, semantically accurate image reconstruction.},
  archive      = {J_TMC},
  author       = {Weilong Chen and Wenxuan Xu and Haoran Chen and Xinran Zhang and Zhijin Qin and Yanru Zhang and Zhu Han},
  doi          = {10.1109/TMC.2025.3607717},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Semantic communication based on large language model for underwater image transmission},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reliable intelligent reflecting surface-assisted mobile edge computing systems: A physical layer security and encryption design. <em>TMC</em>, 1-15. (<a href='https://doi.org/10.1109/TMC.2025.3607599'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile edge computing (MEC) has emerged as a promising technology to extend the functionality of end-users' wireless devices while prolonging their battery life by offloading computationally intensive tasks to remote edge servers. However, the inherent broadcast nature of wireless transmission during offloading introduces notable security challenges. To address this issue, we propose leveraging intelligent reflecting surface (IRS) technology to enhance physical layer security (PLS). Nevertheless, attaining high PLS for all users in dense networks with multiple malicious terminals is challenging. In this paper, we investigate the physical layer encryption (PLE) to complement the PLS in enabling secure wireless transmission. Since such encryption and decryption processes require computation resources, we aim to optimize the encryption decision, offloading decision, as well as wireless and computing resource allocations. Our objective is to minimize the maximum weighted energy consumption while satisfying practical constraints, including limited computing and wireless resources, fulfilling minimum user rate requirements, and complying with IRS conditions. To tackle the non-convex objective and constraints, we explore the utilization of bisection search and successive convex approximation (SCA) methods. Our numerical results confirm the efficiency of the proposed design in terms of energy consumption and network capacity within a secure MEC network.},
  archive      = {J_TMC},
  author       = {Ti Ti Nguyen and Vu Nguyen Ha and Thanh-Dung Le and Duc-Dung Tran and Symeon Chatzinotas and Kim-Khoa Nguyen},
  doi          = {10.1109/TMC.2025.3607599},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Reliable intelligent reflecting surface-assisted mobile edge computing systems: A physical layer security and encryption design},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring cellular user re-identification risks with networking behaviors analysis and modeling. <em>TMC</em>, 1-16. (<a href='https://doi.org/10.1109/TMC.2025.3607772'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile network operators (e.g., China Mobile, Verizon) are significant for providing communication services and collecting massive amounts of data. However, operators are increasingly concerned about customer data breaches involving third-party application providers (e.g., Tencent, Apple, Netflix). This concern is particularly aggravated when anonymous datasets shared with third-party providers or publicly released can be linked to user data compromised in breaches, leading to severe re-identification attacks and privacy threats. However, comprehensive methods for identifying such privacy risks on a large scale are lacking due to limited networking behavioral data. To address this, we aim to measure the re-identification privacy risk associated with sharing or releasing cellular traces amidst data breaches. Based on the analysis of key privacyimpacting features in traffic usage and base station association data, we propose a novel re-identification method, SURE, which learns similarities between cellular traces to classify if traces belong to the same user. Extensive experiments on a largescale dataset of 10,000 users over four months demonstrate SURE's superior performance, with AUC scores exceeding 0.9. Our findings reveal significant re-identification risks in data sharing/release, influenced by data scale and user attributes, corroborated by a public dataset.},
  archive      = {J_TMC},
  author       = {Sijing Duan and Feng Lyu and Shanshan Wang and Yi Ding and Xiaohao He and Yaoxue Zhang},
  doi          = {10.1109/TMC.2025.3607772},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Exploring cellular user re-identification risks with networking behaviors analysis and modeling},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sleep scheduling algorithm for the $k$-coverage problem in 3D heterogenous BF-WSNs. <em>TMC</em>, 1-16. (<a href='https://doi.org/10.1109/TMC.2025.3607841'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Battery-free Wireless Sensor Networks (BF-WSNs) have emerged as an essential part of Internet of Things (IoT) systems. Although two-dimensional (2D) BF-WSNs have been researched, three-dimensional (3D) ones are more indicative of real-world applications. Achieving $k$-coverage in this scenario is a greater challenge and has yet to be investigated. This paper presents an optimization problem in heterogeneous 3D BF-WSNs to maximize $k$-coverage quality while considering the recharging and sampling rates. We prove the problem is NP-Hard and decouple it into two subproblems. The first optimizes $k$-coverage quality for each time slot without energy constraints. The second ensures that nodes scheduled for operation in each time slot can be immediately replenished with sufficient energy. We prove the near-optimal and optimal solutions to the two subproblems composes the near-optimal solution to the original problem. Following the development of Distributed Iterative Grouping (DIG) algorithm and Adaptive Sampling (AS) method to address two subproblems each, we propose a sleep scheduling algorithm to integrate them and solve the original problem. Simulation results verify the effectiveness and efficiency of the proposed algorithm.},
  archive      = {J_TMC},
  author       = {Yanlei Chen and Haoyang Zhou and Jingjing Li and Na Tang and Ping Li},
  doi          = {10.1109/TMC.2025.3607841},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Sleep scheduling algorithm for the $k$-coverage problem in 3D heterogenous BF-WSNs},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A superposition code-based semantic communication approach with quantifiable and controllable security. <em>TMC</em>, 1-18. (<a href='https://doi.org/10.1109/TMC.2025.3608054'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the challenge of achieving security in semantic communication (SemCom) over a wiretap channel, where a legitimate receiver coexists with an eavesdropper experiencing a poorer channel condition. Despite previous efforts to secure SemCom against eavesdroppers, guarantee of approximately zero information leakage remains an open issue. In this work, we propose a secure SemCom approach based on superposition code, aiming to provide quantifiable and controllable security for digital SemCom systems. The proposed method employs a double-layered constellation map, where semantic information is associated with satellite constellation points and cloud center constellation points are randomly selected. By carefully allocating power between these two layers of constellation, we ensure that the symbol error probability (SEP) of the eavesdropper when decoding satellite constellation points is nearly equivalent to random guessing, while maintaining a low SEP for the legitimate receiver to successfully decode the semantic information. Simulation results demonstrate that the peak signal-to-noise ratio (PSNR) and mean squared error (MSE) of the eavesdropper's reconstructed data, under the proposed method, can range from decoding Gaussian-distributed random noise to approaching the variance of the data. This validates the effectiveness of our method in nearly achieving the experimental upper bound of security for digital SemCom systems when both eavesdroppers and legitimate users utilize identical decoding schemes. Furthermore, the proposed method consistently outperforms benchmark techniques, showcasing superior data security and robustness against eavesdropping. The implementation code is publicly available at: https://github.com/1weixuanchen/A-Superposition-Code-Based-Semantic-Communication.},
  archive      = {J_TMC},
  author       = {Weixuan Chen and Shuo Shao and Qianqian Yang and Zhaoyang Zhang and Ping Zhang},
  doi          = {10.1109/TMC.2025.3608054},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-18},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A superposition code-based semantic communication approach with quantifiable and controllable security},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online location planning for AI-defined vehicles: Optimizing joint tasks of order serving and spatio-temporal heterogeneous model fine-tuning. <em>TMC</em>, 1-18. (<a href='https://doi.org/10.1109/TMC.2025.3608179'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advances in artificial intelligence (AI) including foundation models (FMs), are increasingly transforming human society, with smart city driving the evolution of urban living. Meanwhile, vehicle crowdsensing (VCS) has emerged as a key enabler, leveraging vehicles' mobility and sensor-equipped capabilities. In particular, ride-hailing vehicles can effectively facilitate flexible data collection and contribute towards urban intelligence, despite resource limitations. Therefore, this work explores a promising scenario, where edge-assisted vehicles perform joint tasks of order serving and the emerging foundation model finetuning using various urban data. However, integrating the VCS AI task with the conventional order serving task is challenging, due to their inconsistent spatio-temporal characteristics: (i) The distributions of ride orders and data point-of-interests (PoIs) may not coincide in geography, both following a priori unknown patterns; (ii) they have distinct forms of temporal effects, i.e., prolonged waiting makes orders become instantly invalid while data with increased staleness gradually reduces its utility for model fine-tuning. To overcome these obstacles, we propose an online framework based on multi-agent reinforcement learning (MARL) with careful augmentation. A new quality-of-service (QoS) metric is designed to characterize and balance the utility of the two joint tasks, under the effects of varying data volumes and staleness. We also integrate graph neural networks (GNNs) with MARL to enhance state representations, capturing graph-structured, time-varying dependencies among vehicles and across locations. Extensive experiments on our testbed simulator, utilizing various real-world foundation model fine-tuning tasks and the New York City Taxi ride order dataset, demonstrate the advantage of our proposed method.},
  archive      = {J_TMC},
  author       = {Bokeng Zheng and Bo Rao and Tianxiang Zhu and Chee Wei Tan and Jingpu Duan and Zhi Zhou and Xu Chen and Xiaoxi Zhang},
  doi          = {10.1109/TMC.2025.3608179},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-18},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Online location planning for AI-defined vehicles: Optimizing joint tasks of order serving and spatio-temporal heterogeneous model fine-tuning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WarmGait: Thermal array-based gait recognition for privacy-preserving person re-ID. <em>TMC</em>, 1-14. (<a href='https://doi.org/10.1109/TMC.2025.3608447'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person re-identification (Re-ID) can recognize users based on their clothing, body shape, and other information without the need for clear facial images, and is widely applied in the field of intelligent security. Traditional Re-ID systems mainly rely on high-definition RGB cameras, but the deployment of large-scale high-definition RGB cameras indoors has caused serious privacy and ethical concerns. Recently, wireless-based Re-ID systems (Wi-Fi, RFID, millimeter-wave radar, etc.) have shown promising prospects, but the limited sensing resolution hinders their practical deployment. In this paper, we propose WarmGait, a Re-ID system based on thermal array sensors, which can achieve high-precision Re-ID at low cost and minimize the invasion of user privacy. However, using thermal arrays for Re-ID still faces two major challenges. The first is the low and unclear texture resolution of images caused by low-cost infrared devices. The second is that existing gait recognition methods require maintaining the sequential constraint of gait images, which reduces the flexibility of gait recognition or Re-ID. To address these two challenges, we first designed an edge module inspired by Taylor Finite Difference (TFD) to aggregate image edge information to help improve the resolution of infrared devices. Then, we considered gait as a collection of gait profiles and extracted features from the frame level and collection level for recognition, breaking through the limitations of the number and order of input images. After extensive experimental evaluation, our model can achieve an average recognition accuracy of 87.3% in various scenarios, demonstrating the potential of WarmGait in Re-ID.},
  archive      = {J_TMC},
  author       = {Hongbo Jiang and Lei Ye and Jingyang Hu and Xiaotian Chen and Siyu Chen and Wei Zhang and Kehua Yang},
  doi          = {10.1109/TMC.2025.3608447},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {WarmGait: Thermal array-based gait recognition for privacy-preserving person re-ID},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Joint inference offloading and model caching for small and large language model collaboration. <em>TMC</em>, 1-16. (<a href='https://doi.org/10.1109/TMC.2025.3608303'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs), with advanced content creation and inference capabilities, can provide immersive intelligent services to users in mobile edge networks. However, the increasing demand for real-time artificial intelligence (AI) applications aggravates the limitations of cloud-based LLMs due to the long response time. Meanwhile, Small Language Models (SLMs), which are cost-effective and locally deployable for terminal devices, can serve as an efficient supplement to LLMs for performing latency-sensitive tasks with lower generalization capability. Due to the resource constraints of edge networks and the diverse requirements of user tasks, it is critical to design an inference framework that effectively coordinates the deployment and collaboration of LLMs and SLMs. In this paper, we propose an LLM-SLM collaborative inference (LSCI) scheme under a mobile edge computing (MEC) architecture, which jointly decides where to cache models and how to offload inference tasks to balance latency, accuracy, and resource costs. To optimize inference performance subject to resource constraints, we jointly solve the inference task offloading and model caching problem in LSCI scheme. Specifically, we employ deep reinforcement learning (DRL) to select highly popular SLMs to be cached on the edge server, and distributed belief propagation technique to solve the associated inference task offloading issue. Numerical results show that the proposed LSCI scheme can achieve significant performance gain in terms of inference performance when compared with a number of baseline solutions.},
  archive      = {J_TMC},
  author       = {Xinyi Xu and Gang Feng and Yijing Liu and Shuang Qin and Jian Wang and Yunxiang Wang},
  doi          = {10.1109/TMC.2025.3608303},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Joint inference offloading and model caching for small and large language model collaboration},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Denoising and adaptive online vertical federated learning for sequential multi-sensor data in IIoT. <em>TMC</em>, 1-15. (<a href='https://doi.org/10.1109/TMC.2025.3608244'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advancement of computational capabilities in edge devices such as intelligent sensors in the Industrial Internet of Things (IIoT), these sensors evolving beyond simple data collection to support complex computational tasks. This advancement provides new opportunities for adopting distributed learning approaches in IIoT. In this study, we focus on enhancing learning performance in an industrial assembly line scenario where multiple distributed sensors sequentially collect real-time data with distinct feature spaces. However, existing research lacks an online distributed learning framework tailored for such IIoT settings. To address this gap, we propose the Denoising and Adaptive Online Vertical Federated Learning (DAO-VFL) algorithm, a novel algorithm that leverages the computing potential of edge sensors while addressing key challenges such as communication overhead and data privacy. DAO-VFL effectively manages continuous data streams and adapts to shifting learning objectives. Furthermore, it can address critical challenges prevalent in industrial environment, such as communication noise and heterogeneity of sensor capabilities. To support the proposed algorithm, we provide a comprehensive theoretical analysis, highlighting the effects of noise reduction and adaptive local iteration decisions on the regret bound. Experimental results on two real-world datasets further demonstrate the superior performance of DAO-VFL compared to benchmarks.},
  archive      = {J_TMC},
  author       = {Heqiang Wang and Xiaoxiong Zhong and Kang Liu and Fangming Liu and Weizhe Zhang},
  doi          = {10.1109/TMC.2025.3608244},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Denoising and adaptive online vertical federated learning for sequential multi-sensor data in IIoT},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hierarchical MAFDRL-based resource allocation and incentive mechanism for TN-NTN in 6G networks. <em>TMC</em>, 1-18. (<a href='https://doi.org/10.1109/TMC.2025.3608291'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the limitations of existing wireless networks for demanding applications like brain-computer interfaces and intelligent transportation systems, we propose an advanced framework for joint resource allocation and task offloading across integrated terrestrial and non-terrestrial networks (TN-NTN). This framework utilizes multiple layers, including ground users, UAVs, HAPs, and satellites, to improve service quality and immersive experiences, particularly in scenarios like Metaverse applications. Ground users request resources, while UAVs and HAPs serve as resource providers, and satellites ensure reliable communication during emergencies. A double auction-based incentive scheme is employed in which operators control UAV and HAP resources to maximize utility, and users aim to minimize computation costs and protect data privacy. To handle the complexity of the operator-user interaction, which results in an NP-hard optimization problem, we applied a hierarchical multi-agent federated deep reinforcement learning (FeDRL) approach. Our simulation results demonstrate that the FeDRL algorithm significantly improves social welfare by 6.38%, 17.43%, and 28.73% over modified MADDPG, FRL, and DDPG algorithms, respectively.},
  archive      = {J_TMC},
  author       = {Abegaz Mohammed Seid and Aiman Erbad and Hayla Nahom Abishu and Gordon Owusu Boateng and Latif U. Khan and Carla Fabiana Chiasserini and Mohsen Guizani},
  doi          = {10.1109/TMC.2025.3608291},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-18},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A hierarchical MAFDRL-based resource allocation and incentive mechanism for TN-NTN in 6G networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data divergence-aware client selection via knowledge graph for federated LLM fine-tuning. <em>TMC</em>, 1-14. (<a href='https://doi.org/10.1109/TMC.2025.3608172'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of edge devices and growing awareness of privacy protection, recent developers have transformed to fine-tune LLMs via federated learning instead of centralized training. Federated fine-tuning can leverage distributed data sources and computation power, but it also suffers from system and statistical heterogeneity. Client selection is an effective tool to solve the system and statistical heterogeneity in FL, but existing client selection schemes that involve online measurement will not be as effective in LLM fine-tuning as in conventional FL due to the huge LLM size and fewer fine-tuning rounds. In this paper, to the best of our knowledge, we are the first to consider both system and statistical heterogeneity in federated LLM fine-tuning, and we formulate a new latency minimization problem. We propose to measure client data overlap via knowledge graph offline to assist client selection in federated LLM fine-tuning. Our client selection scheme excels in both model accuracy and fine-tuning latency. We evaluate our scheme via two LLMs and two applications via four datasets. The experiment results illustrate that our scheme achieves the highest accuracy while 2.05x faster than the baselines.},
  archive      = {J_TMC},
  author       = {Bihai Zhang and Dan Wang and Yifei Zhu and Zhu Han},
  doi          = {10.1109/TMC.2025.3608172},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Data divergence-aware client selection via knowledge graph for federated LLM fine-tuning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FreeEnv: Enabling zero-effort RF-based micro-environment changes monitoring. <em>TMC</em>, 1-16. (<a href='https://doi.org/10.1109/TMC.2025.3608245'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, a major issue of WiFi-based sensing technologies is how to adapt to changes in the surrounding environment. The extreme sensitivity of Channel State Information (CSI) makes many WiFi sensing arts frustrated when applied to the complex and unknown real world. To solve this problem, in this paper, we propose freeEnv designed to automatically identify the micro-environmental changes (even tiny movements of the laptop) using WiFi devices, which can coexist with other WiFi sensing tasks with zero effort. To achieve automatic identification of micro-environmental changes, we quantify micro-environmental changes based on the physical propagation laws of WiFi signals and the main factors that affect CSI measurements. Then, we design a micro-environmental changes identification method, which determines whether the environment has changed by calculating the Earth Mover's Distance (EMD) of the Probability Density Function (PDF) of continuous CSI, without requiring training data. To remove the influence of dynamic human behaviors, we design a human dynamic detection scheme, which is achieved by obtaining the average inter-cluster distance of performing Gaussian Mixture Model (GMM) clustering on CSI. We evaluate freeEnv in real-world scenarios with six different hardware, four different scenarios, and twenty-four ways of micro-environmental changes. The results show that our method is robust to different devices and scenarios, and can achieve the average precision of 96.1% and 93.2% for micro-environmental changes identification and human dynamic behavior detection. By testing on a case study of threshold-based human presence detection, freeEnv can effectively improve the detection performance.},
  archive      = {J_TMC},
  author       = {Dawei Yan and Feiyu Han and Mingzhu Yang and Shanyue Wang and Panlong Yang and Yubo Yan},
  doi          = {10.1109/TMC.2025.3608245},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {FreeEnv: Enabling zero-effort RF-based micro-environment changes monitoring},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tiered spatio-temporal difficulty: Curriculum scheduler for multi-sensor traffic flow prediction. <em>TMC</em>, 1-15. (<a href='https://doi.org/10.1109/TMC.2025.3608620'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of the Internet of Things (IoT) has enhanced smart city services for traffic monitoring, leading to numerous schemes for accurate flow prediction based on traffic sensors. However, existing approaches primarily capture spatio-temporal (ST) dependencies from traffic graphs and train their models using randomly ordered data. This overlooks the fact that the modeling difficulty of each sensor/node in the ST traffic graph can vary significantly due to its spatial dependencies and temporal trends, resulting in unreliable and unstable predictions in IoT scenarios. In this context, we argue that a well-designed curriculum with an easy-to-difficult order can improve the training of ST models. Therefore, this paper introduces an ST difficulty measurer to score the node-level difficulty of traffic graph from both spatial and temporal aspects, and then implements a curriculum in the ST model training process. More specifically, based on the tiered ST difficulty score, the ST model training begins with a subgraph consisting of “easy” nodes characterized by relatively consistent spatial relationships and regular temporal patterns. Gradually, more difficult nodes are incorporated into the subgraph and participate in subsequent training stages. Comprehensive experiments and analysis on two real-world traffic flow datasets confirm the effectiveness of our proposed approach.},
  archive      = {J_TMC},
  author       = {Zhiwen Zhang and Hongjun Wang and Zipei Fan and Renhe Jiang and Wei Yuan and Xuan Song and Ryosuke Shibasaki},
  doi          = {10.1109/TMC.2025.3608620},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Tiered spatio-temporal difficulty: Curriculum scheduler for multi-sensor traffic flow prediction},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deterministic backoff approach for wi-fi and NR-U coexistence in shared bands. <em>TMC</em>, 1-15. (<a href='https://doi.org/10.1109/TMC.2025.3608270'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In unlicensed (shared) bands, wireless technologies typically operate without central coordination, which can lead to unwanted transmission interruptions, collisions, and resource wastage. We focus on Wi-Fi and NR-U coexistence in shared bands and solve the aforementioned problem with a deterministic backoff approach. The proposed scheme allows active transmitters to learn the number of nearby interferers in a distributed manner and, as a result, implement an ordered round-robin transmission schedule to minimize collisions. We show analytically that the scheme converges not only in equilibrium (when collisions are negligible), but also in a general case (when collisions are frequent at the beginning or in the middle of the proposed scheme's operation). Furthermore, extensive simulations prove that the proposed scheme guarantees fairness between contenting cells and technologies (both in terms of throughput and delay) as well as optimizes channel efficiency. We also study the impact of imperfect readings of the number of contending nodes (which may be the result of, e.g., asymmetric channel conditions) on the performance of the proposed scheme. In most cases, the deterministic backoff approach outperforms legacy channel access schemes. Additionally, our proposal does not add additional signaling overhead and is backward compatible with standard Wi-Fi and NR-U operation.},
  archive      = {J_TMC},
  author       = {Ilenia Tinnirello and Menzo Wentink and Alice Lo Valvo and Szymon Szott and Katarzyna Kosek-Szott},
  doi          = {10.1109/TMC.2025.3608270},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A deterministic backoff approach for wi-fi and NR-U coexistence in shared bands},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SwinULoc: Pre-trained swin transformer U-net with ToF offset correction for resource-efficient WiFi indoor localization. <em>TMC</em>, 1-15. (<a href='https://doi.org/10.1109/TMC.2025.3608157'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ubiquity of WiFi infrastructure has motivated significant research into WiFi-based indoor positioning systems as practical alternatives to GNSS. While deep learning approaches show promise, existing models face three critical limitations: (1) inadequate modeling of long-range feature dependencies, (2) difficulty in correcting time-of-flight (ToF) offsets induced by device clock asynchrony, and (3) prohibitive computational costs for environmental adaptation through model retraining. This paper introduces SwinULoc, a novel U-shaped indoor positioning framework that synergizes Swin Transformer blocks with 2D CSI heatmap processing. Our architecture uniquely addresses these challenges through three key innovations: First, the integration of shifted window attention mechanisms enables effective learning of long-range signal correlations. Second, a multi-access-point fusion strategy enhanced with skip connections achieves precise ToF offset correction through cross-device pattern analysis and multi-scale feature integration. Third, a transfer learning paradigm reduces retraining costs by 75% compared to conventional approaches. Extensive evaluations demonstrate SwinULoc's superiority, achieving 70% higher positioning accuracy than state-of-the-art baselines while requiring only 1/4 of the training resources for new environments.},
  archive      = {J_TMC},
  author       = {Wenhao Zhang and Xingfa Shen and Sicong Xia and Zhibo Wang},
  doi          = {10.1109/TMC.2025.3608157},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {SwinULoc: Pre-trained swin transformer U-net with ToF offset correction for resource-efficient WiFi indoor localization},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A semi-supervised indoor localization algorithm based on probabilistic distribution modeling. <em>TMC</em>, 1-16. (<a href='https://doi.org/10.1109/TMC.2025.3608276'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in wireless technology have spurred the growth of indoor localization applications based on wireless signals. Most existing methods model the relationship between input data and the target's location using the $l_{2}$ loss function, which assumes that the residual between the predicted location and the ground truth follows a Gaussian distribution with a fixed standard deviation. Nevertheless, this approach may not conform to the actual distribution and lacks confidence measures for individual predictions, potentially compromising accuracy. Furthermore, in the realm of regression, Semi-Supervised Learning (SSL) remains relatively unexplored due to the absence of a reliable method to quantify prediction uncertainty, especially when labeled data is scarce. To address these challenges, we developed a novel indoor localization algorithm that employs probabilistic distribution modeling. Our approach focuses on indoor localization with Channel Impulse Response (CIR) as the input. Crucially, it leverages Maximum Likelihood Estimation (MLE) to model the localization error as a Gaussian distribution, and utilizes Residual Log-likelihood Estimation (RLE) to capture arbitrary error distributions. This enables us to extract the confidence of each prediction and utilize the most reliable ones as pseudo-labels for the unlabeled data. By employing probabilistic distribution modeling, we observed a significant improvement in localization accuracy over the $l_{2}$ loss function. Additionally, by integrating pseudo-labeled data for model retraining, our algorithm achieves superior performance compared to existing state-of-the-art machine learning-based and SSL-based methods. This is demonstrated by our evaluation on two public datasets, showcasing the efficiency of the proposed method.},
  archive      = {J_TMC},
  author       = {Ruofei Gao and Xiaotao Li and Wai Chen},
  doi          = {10.1109/TMC.2025.3608276},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A semi-supervised indoor localization algorithm based on probabilistic distribution modeling},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AEDS: An affinity-driven efficient DRL-based task scheduling framework for edge computing. <em>TMC</em>, 1-16. (<a href='https://doi.org/10.1109/TMC.2025.3608263'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge computing is a promising paradigm that deploys computing resources at the network edge to provide services. Many existing solutions leverage deep reinforcement learning (DRL) to optimize task scheduling, yet they often rely on global scheduling approaches. However, such solutions result in an excessively large decision search space, reducing task scheduling efficiency in complex environments. Additionally, the cold start problem impedes the generation of optimal scheduling strategies. To address these challenges, we propose AEDS, a DRL-based task scheduling framework designed to enhance scheduling efficiency. AEDS optimizes the decision-making process from three aspects: (1) Decision Space Reduction. AEDS incorporates a novel affinity matching mechanism that identifies the most suitable edge cluster based on task characteristics, thereby significantly narrowing the decision search space. (2) Decision Process Optimization. AEDS adopts a hybrid strategy combining offline pre-training and online fine-tuning to address the cold start problem. Offline pre-training with historical task data ensures effective initial scheduling, while online fine-tuning periodically updates the DRL model to enhance long-term adaptability to dynamic system changes. (3) Decision Strategy Calibration. AEDS proposes a task migration solution to adapt to real-time workload variations dynamically. It utilizes triple queues to assess server overload and dynamically calibrates the scheduling strategy through task migration within interconnected clusters. Comprehensive experimental results validate the efficacy of AEDS. Compared with existing frameworks, AEDS reduces task latency by $28.23\%$ and enhances task completion rate by $10.28\%$. Furthermore, by effectively narrowing the decision scope, AEDS accelerates the decision-making process by a remarkable $88.06\%$},
  archive      = {J_TMC},
  author       = {Xu Liu and Zhaolong Jian and Xueshuo Xie and Qiankun Dong and Mulin Li and Xiaoyu Zhang and Tao Li},
  doi          = {10.1109/TMC.2025.3608263},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {AEDS: An affinity-driven efficient DRL-based task scheduling framework for edge computing},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal online federated learning with modality missing in internet of things. <em>TMC</em>, 1-13. (<a href='https://doi.org/10.1109/TMC.2025.3608269'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) ecosystem generates vast amounts of multimodal data from heterogeneous sources such as sensors, cameras, and microphones. As edge intelligence continues to evolve, IoT devices have progressed from simple data collection units to nodes capable of executing complex computational tasks. This evolution necessitates the adoption of distributed learning strategies to effectively handle multimodal data in an IoT environment. Furthermore, the real-time nature of data collection and limited local storage on edge devices in IoT call for an online learning paradigm. To address these challenges, we introduce the concept of Multimodal Online Federated Learning (MMO-FL), a novel framework designed for dynamic and decentralized multimodal learning in IoT environments. Building on this framework, we further account for the inherent instability of edge devices, which frequently results in missing modalities during the learning process. We conduct a comprehensive theoretical analysis under both complete and missing modality scenarios, providing insights into the performance degradation caused by missing modalities. To mitigate the impact of modality missing, we propose the Prototypical Modality Mitigation (PMM) algorithm, which leverages prototype learning to effectively compensate for missing modalities. Experimental results on two multimodal datasets further demonstrate the superior performance of PMM compared to benchmarks.},
  archive      = {J_TMC},
  author       = {Heqiang Wang and Xiang Liu and Xiaoxiong Zhong and Lixing Chen and Fangming Liu and Weizhe Zhang},
  doi          = {10.1109/TMC.2025.3608269},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Multimodal online federated learning with modality missing in internet of things},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sym-FEC: Enhancing error correction in LoRa PHY with a symbol-level FEC decoder. <em>TMC</em>, 1-15. (<a href='https://doi.org/10.1109/TMC.2025.3608893'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {LoRa, a leading wireless technology for Low Power Wide Area Networks (LPWAN), is well-known for its long transmission range and low power consumption. The extended range is primarily attributed to the Chirp Spread Spectrum technique. However, the LoRa physical layer (LoRa PHY) contributes only marginally to this advantage, as it employs an inefficient Forward Error Correction (FEC) strategy for error recovery. In this paper, we introduce Sym-FEC, a symbol-level FEC decoder designed to link the received signals' spectrum with the coding correlations inherent in LoRa PHY, thereby enhancing error recovery. The key enabler of Sym-FEC is signal copy retrieval. We begin by facilitating signal copy conversion between two symbols and extend this to the general case, where signal copy conversions can be performed between any symbols in a coding block. Approaches are also introduced to assess the validity of the block-wide decoding results. Extensive hardware evaluations demonstrate that Sym-FEC provides Signal-to-Noise-Ratio (SNR) improvement of 2.3dB to 3dB compared to the traditional decoder in LoRa PHY. Sym-FEC requires no modifications at the transmitter while incurs low storage and computational complexity at the gateway, thus can be easily integrated into gateway nodes.},
  archive      = {J_TMC},
  author       = {Weiwei Chen and Xianjin Xia and Shuai Wang and Xianjun Deng and Jiehong Wu and Caishi Huang},
  doi          = {10.1109/TMC.2025.3608893},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Sym-FEC: Enhancing error correction in LoRa PHY with a symbol-level FEC decoder},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A privacy-preserving auction for task offloading and resource allocation in UAV-assisted MEC. <em>TMC</em>, 1-16. (<a href='https://doi.org/10.1109/TMC.2025.3609202'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a complementary solution for Mobile Edge Computing (MEC), Unmanned Aerial Vehicles (UAVs) can temporarily provide reliable and flexible offloading services when edge servers are damaged or unavailable. However, existing UAV-assisted MEC systems suffer from issues such as uneven resource allocation, low utilization efficiency, load imbalance, and poor dynamic adaptability, affecting service quality. Moreover, sensitive user equipment (UE) information faces leakage during the computational process of UAVs. How to jointly optimize the scheduling of servers and UAVs for task offloading and resource allocation without compromising UEs' privacy remains a significant challenge. Thus, this paper proposed a privacy-preserving auction framework (namely Prizty) by considering the trajectory of UAVs, their constrained energy and computational capabilities, and the variability in UE distribution. Prizty employs a combinatorial obfuscation method to protect UEs' privacy and links bidding prices to computational resources and energy characteristics. It calls the sub-algorithm WPA to determine the winners by balancing social costs and utility. Theoretical analysis demonstrates that Prizty satisfies truthfulness and individual rationality while maintaining scalability for large-scale resource allocation problems. Extensive experiments on real-world datasets validate Prizty's effectiveness in critical metrics, including offload rate, average service latency, energy consumption, and social cost.},
  archive      = {J_TMC},
  author       = {Jiajie Xu and Xiaolong Xu and Guangming Cui and Muhammad Bilal and Rong Gu and Wanchun Dou and Arumugam Nallanathan},
  doi          = {10.1109/TMC.2025.3609202},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A privacy-preserving auction for task offloading and resource allocation in UAV-assisted MEC},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the timeliness of radio channel access: Random access or scheduled access?. <em>TMC</em>, 1-16. (<a href='https://doi.org/10.1109/TMC.2025.3609285'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the role of channel access schemes in enhancing the timeliness of status updates in sensor networks. Specifically, we model the large-scale sensor network as a Poisson cellular network and derive the network average age of information (AoI) under five different channel access schemes: slotted ALOHA, frame slotted ALOHA, random scheduling, round robin, and channel-aware. These schemes are categorized based on random vs. scheduled access and non-channel-aware vs. channel-aware. Our goal is to investigate when the additional overhead and complexity introduced by scheduling and channel state information (CSI) are beneficial, enabling better decisions in network design. Our findings reveal that the effectiveness of these schemes is influenced by the signal-to-interference ratio (SIR) decoding threshold, which often reflects the length of communication data. For short-packet communications, the performance differences among various channel access strategies are minimal, and the gains from scheduling are limited. Additionally, the inclusion of extra CSI does not yield performance improvements; in fact, some simple scheduling strategies, along with channelaware strategy that leverage CSI, may not outperform basic random access methods. Among the protocols we examined, the round robin scheme achieves the best performance. In contrast, scheduled access schemes exhibit a clear performance advantage in long-packet communications. Furthermore, the channel-aware scheme significantly enhances the network AoI performance, particularly in networks with higher transmitter competition.},
  archive      = {J_TMC},
  author       = {Zhiling Yue and Yuting Tang and Nikolaos Pappas and Yaru Fu and Tony Q. S. Quek and Howard H. Yang},
  doi          = {10.1109/TMC.2025.3609285},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {On the timeliness of radio channel access: Random access or scheduled access?},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Collaborative access with waiting window: Enhancing age-of-information in CSMA networks. <em>TMC</em>, 1-13. (<a href='https://doi.org/10.1109/TMC.2025.3609393'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The next generation of industrial Internet-of-Things systems demands timely delivery of fresh data, quantified by the Age-of-Information (AoI) metric, from a vast number of sensors. In such systems, sensors usually adopt random access where the back-off mechanism is mostly crucial. This paper studies the back-off mechanism for Carrier Sense Multiple Access (CSMA) systems in collision-prone scenarios. Considering the fact that transmitting immediately after a prior successful transmission yields limited AoI reduction, we propose an enhanced waiting CSMA scheme by introducing a waiting window to the existing contention window. In the proposed scheme, each source waits after each successful transmission. It enables a collaborative channel access strategy, such that sources have recently transmitted grant greater opportunities for others to access the channel. To optimize the window sizes, we analyze the Normalized Average Peak AoI (NPAoI) and Normalized Average AoI (NAoI), which are normalized by the packet transmission duration. Our findings indicate that minimizing these metrics is feasible through maintaining a nearly constant collision probability. Specifically, NPAoI reaches its minimum by adjusting either the contention or the waiting window, while NAoI requires a larger waiting window combined with a smaller contention window. Given the network scale, we derive optimal window sizes in closed form. When the network scale is unknown or dynamic, we propose a data-driven approach to adjust window sizes based solely on the real-time measured collision probability. Simulation results confirm that the proposed waiting CSMA scheme significantly outperforms existing methods for both NPAoI and NAoI, particularly in large-scale networks.},
  archive      = {J_TMC},
  author       = {Yifan Gu and Suzhi Bi and Zhaoxu Wang and Zhi Quan},
  doi          = {10.1109/TMC.2025.3609393},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Collaborative access with waiting window: Enhancing age-of-information in CSMA networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Flow prioritization in asynchronous TSN with multiple ATS instances. <em>TMC</em>, 1-15. (<a href='https://doi.org/10.1109/TMC.2025.3609519'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time-sensitive networking (TSN) is an essential technology for the development of deterministic networks as it can offer deterministic quality of service (QoS) in terms of transmission delay. In addition, it is more scalable, more affordable, and simplifies the management of current industrial networks. This paper focuses on asynchronous traffic shaping (ATS) in TSN and proposes a novel solution to prioritize the flows being transmitted in a TSN with multiple ATS instances to meet their delay requirements. To this end, we formally formulate the flow prioritization assignment problem in an ATS-TSN network, demonstrate the correctness of the proposed algorithm, and study the solution's scalability. The results show that our solution is optimal, obtaining a shorter execution time than an exhaustive search with the same prioritization result. Furthermore, our solution scales correctly as a function of the number of flows with a considerably low execution time. Compared to another ATS prioritization method, our solution finds feasible solutions four orders of magnitude larger with reduced execution time. Moreover, the results show that per-flow prioritization has higher utilization than per-Priority Code Point (PCP) prioritization. Finally, an increase in the percentage of traffic with strict delay requirements harms the maximum achievable utilization.},
  archive      = {J_TMC},
  author       = {Julia Caleya-Sanchez and Jonathan Prados-Garzon and Pablo Muñoz and Juan M. Lopez-Soler and Pablo Ameigeiras},
  doi          = {10.1109/TMC.2025.3609519},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Flow prioritization in asynchronous TSN with multiple ATS instances},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). E2E hybrid computation offloading for complex MEC system. <em>TMC</em>, 1-16. (<a href='https://doi.org/10.1109/TMC.2025.3609546'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile Edge Computing (MEC) places computational resources at the network edge, thereby enabling compute-intensive applications through task offloading. However, in dynamic multi-user, multi-server environments, user mobility induces time-varying channel conditions, and the spatiotemporal heterogeneity of server loads further complicates system behavior. Consequently, the system must jointly optimize discrete offloading decisions and continuous resource-allocation parameters, forming a hybrid action space whose integrated decision-making mechanism is central to breaking the long-standing trade-off between latency and energy consumption. Traditional deep reinforcement learning (DRL) approaches that rely on a single policy network often suffer from strong strategy coupling and Q-value estimation bias, leading to policy oscillations and the curse of dimensionality in highly dynamic scenarios and thus impeding stable convergence. To address this problem, this paper proposes an innovative End-to-End Hybrid Computation Offloading (E2EHCO) framework based on an enhanced Twin Delayed Deep Deterministic Policy Gradient (TD3) algorithm. By employing dual critic networks together with a delayed-update mechanism, the method effectively suppresses Q-value overestimation, while the integration of Softmax and Tanh activations in the actor network allows simultaneous handling of discrete and continuous actions, thereby achieving efficient and robust joint decision optimization under dynamically changing conditions. Experiments on real-world mobility traces show that, relative to benchmark methods, E2EHCO reduces total latency by at least 20% and energy consumption by approximately 16% in high-density user scenarios, providing an adaptive offloading solution with real-time responsiveness for large-scale, dynamic MEC systems.},
  archive      = {J_TMC},
  author       = {Jingjing Zhang and Xiaoheng Deng and Jian Yin and Xianjun Deng and Xuechen Chen and Jinsong Gui and Shichao Zhang},
  doi          = {10.1109/TMC.2025.3609546},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {E2E hybrid computation offloading for complex MEC system},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Resolving inter-logical channel interference for large-scale LoRa deployments. <em>TMC</em>, 1-14. (<a href='https://doi.org/10.1109/TMC.2025.3609316'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {LoRaWANs are envisioned to connect billions of IoT devices through thousands of physically overlapping yet logically orthogonal channels (termed logical channels). These logical channels hold significant potential for enabling highly concurrent scalable IoT connectivity. Large-scale deployments however face strong interference between logical channels. This practical issue has been largely overlooked by existing works but becomes increasingly prominent as LoRaWAN scales up. To address this issue, we introduce Canas, an innovative gateway design that is poised to orthogonalize the logical channels by eliminating mutual interference. To this end, Canas develops a series of novel solutions to accurately extract the meta-information of individual ultra-weak LoRa signals from the received overlapping channels. The meta-information is then leveraged to accurately reconstruct and subtract the LoRa signals over thousands of logical channels iteratively. Real-world evaluations demonstrate that Canas can enhance concurrent transmissions across overlapping logical channels by 2.3× compared to the best known related works.},
  archive      = {J_TMC},
  author       = {Shiming Yu and Ziyue Zhang and Xianjin Xia and Yuanqing Zheng and Jiliang Wang},
  doi          = {10.1109/TMC.2025.3609316},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Resolving inter-logical channel interference for large-scale LoRa deployments},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing learning to communicate with reward-shaped curriculum and network awareness. <em>TMC</em>, 1-12. (<a href='https://doi.org/10.1109/TMC.2025.3608813'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Communication enhances collaboration among artificial intelligence agents, for example, by sharing observations that contribute to safer driving. Given the conflicts between limited communication resources and communication needs, learning effective communication strategies is essential. We observe that incorporating learning to communicate can complicate mastering primary tasks, like vehicle control, the original focus in autonomous driving. This is due to the uncertainty in information acquisition during the learning process, which can lead to an unstable environment for primary tasks. In this paper, we introduce ReSCOM, an efficient joint learning framework that combines learning-to-communicate with primary tasks. ReSCOM progressively adjusts the learning emphasis through rewardshaped curriculum, allowing agents to shift their focus from primary tasks and basic communication tasks (e.g., how to encode) to advanced communication strategies (e.g., determining when it is worthwhile to communicate). This approach minimizes the impact on the learning efficiency of primary tasks while simultaneously facilitating communication learning. Besides, we explore the extent to which communication channel states (i.e., delays and packet loss) and protocols impact agent cooperation and learning. We evaluate ReSCOM against state-of-the-art methods in various tasks, demonstrating its strong performance. Furthermore, we verify that current modern wireless channels, includingWi-Fi, 4G, and 5G, provide low enough delays that their impact can be ignored. When packet loss occurs, we find that the UDP protocol performs better than TCP because, for agent cooperation, timely information is more valuable than reliability.},
  archive      = {J_TMC},
  author       = {Xinghai Wei and Jie Yuan and Tingting Yuan and Xiang Liu and Xiaoming Fu},
  doi          = {10.1109/TMC.2025.3608813},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Enhancing learning to communicate with reward-shaped curriculum and network awareness},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design and security analysis of SDN-based IoT-oriented blockchain protected E-voting system. <em>TMC</em>, 1-14. (<a href='https://doi.org/10.1109/TMC.2025.3609480'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The electoral system is one of the fundamental pillars of democracy, but the traditional voting system suffers from several limitations such as fraud voting, vote tampering, impersonation, and inefficiencies. To overcome these limitations, several research works have been initiated to design a blockchain-based e-voting system. These designs addressed the loopholes of the existing ones to a limited extent. Here, a novel multi-level blockchain-secured SDN-based IoT enabled e-voting system has been proposed. The proposed system consists of booth, district, state, and country level systems. Here, a voter needs to be authenticated at the booth-level and then this valid vote data can be propagated to the upper hierarchical levels and stored there after signing and encrypting it using ECDSA and ECC respectively. Man-in-the-middle attacks, DoS/DDoS, unauthorized access, and impersonation attacks are avoided using flow rules in SDN controllers and firewalls installed in the servers. Furthermore, blockchain technology provides security for voting data stored at all levels. The security strengths were tested at different levels (e.g., programming, operating system, and network level) using open-source tools (i.e. scyther, nmap, metasploit, etc.). The performance of the proposed architecture was evaluated satisfactorily in a testbed. It also performed satisfactorily under both normal and stressed conditions in a scaled-up environment.},
  archive      = {J_TMC},
  author       = {Ngangbam Indrason and Kalyan Baital and Goutam Saha},
  doi          = {10.1109/TMC.2025.3609480},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Design and security analysis of SDN-based IoT-oriented blockchain protected E-voting system},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards efficient and scalable asynchronous federated learning via stragglers version control. <em>TMC</em>, 1-17. (<a href='https://doi.org/10.1109/TMC.2025.3609568'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Asynchronous Federated Learning (AFL) has emerged as a promising paradigm to address the challenges posed by heterogeneous device environments in federated learning systems. However, the problem of low accuracy and slow convergence due to inconsistent updates from stragglers and normal clients remains severe in AFL. Previous works either discard or penalize the updates from stragglers, which can lead to the loss of valuable data or introduce bias into the model. Furthermore, existing AFL frameworks integrating synchronous optimization algorithms face the challenges of weak compatibility and scalability, limiting large-scale training. In this paper, we propose DVAFL1 an efficient and scalable AFL framework that significantly improves the performance of AFL in terms of model accuracy and convergence speed by effectively utilizing and compensating for the updates from stragglers, while naturally integrating synchronous optimization algorithms. Specifically, DVAFL introduces a dynamic window protocol for adaptive aggregation to balance the contribution of stragglers and ensure faster and more stable convergence. Further, the version control mechanism corrects stale gradients by compensating for the missed model updates of stragglers, thereby improving model performance. Extensive experiments on three public datasets demonstrate that DVAFL achieves an average convergence speed 2.3× faster and an accuracy improvement of 5.5% compared to state-of-the-art AFL methods.},
  archive      = {J_TMC},
  author       = {Chuyi Chen and Yanchao Zhao and Zhe Zhang and Wenzhong Li and Jie Wu},
  doi          = {10.1109/TMC.2025.3609568},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-17},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Towards efficient and scalable asynchronous federated learning via stragglers version control},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Computation resource management in mobile edge computing for healthcare using lyapunov-deep deterministic policy gradient. <em>TMC</em>, 1-14. (<a href='https://doi.org/10.1109/TMC.2025.3608771'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the mobile edge computing healthcare (MECH) system, the integration of MECH servers and wearable medical sensors can achieve real-time monitoring and analysis of user health. However, the system still faces key challenges such as network security risks and high energy consumption. To address these issues, this paper proposes a dual pronged solution. First, a new mechanism integrating smart contracts and asymmetric encryption is designed to achieve secure and efficient user authentication. Then, a method called Lyapunov Deep Deterministic Policy Gradient (L-DDPG) has been proposed to solve the resource optimization of the system. L-DDPG utilizes the Lyapunov optimization framework to transform the original long-term average constraint optimization problem into an instant optimization problem for each time slot, and solves the system optimization variables using the Deep Deterministic Policy Gradient algorithm. Through this design, L-DDPG effectively combines the advantages of Lyapunov optimization in ensuring system stability, as well as the decision modeling ability of deep reinforcement learning in complex state spaces, thereby simultaneously improving the resource utilization efficiency and safety of the system. The experimental results show that compared with existing baseline methods, L-DDPG significantly reduces the average energy consumption of equipment while effectively reducing task response delay, demonstrating better overall performance.},
  archive      = {J_TMC},
  author       = {Qiang He and Yang Xia and Zheng Feng and Lianbo Ma and Yingjie Lv and Keping Yu and Ammar Hawbani and Kaifa Zheng and Li Xu},
  doi          = {10.1109/TMC.2025.3608771},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Computation resource management in mobile edge computing for healthcare using lyapunov-deep deterministic policy gradient},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-layer position-pose fusion framework for joint magnetoquasistatic field and IMU positioning. <em>TMC</em>, 1-17. (<a href='https://doi.org/10.1109/TMC.2025.3608822'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetoquasistatic (MQS) field positioning has demonstrated significant potential for emergency rescue applications due to its strong penetration and non-reliance on pre-deployment. However, its accuracy is notably impaired by metal interference and distance attenuation. Inertial Measurement Units (IMUs) can reliably provide motion data even in environments affected by metal and electromagnetic interference, but they suffer from cumulative drift over time. Effectively, combining MQS field and IMU positioning to harness their respective advantages presents a crucial challenge. To address this, we propose a Multi-Layer Position-Pose Fusion (MP2F) framework that integrates MQS field with IMU data to enhance position and pose estimation. The MP2F framework comprises three layers: a Quaternion-based Pose Fusion Layer (QPFL), a Kalman Filter-based Position Fusion Layer (KFFL), and a Global Position-Pose Fusion Layer (GP2FL). Specifically, QPFL utilizes the Extended Kalman Filter (EKF) to effectively mitigate magnetic field distortion and IMU drift, thereby significantly enhancing pose estimation precision. Next, KFFL incorporates the fused pose estimation from QPFL into an inertial navigation motion model, and leverages MQS field observations to further improve positional accuracy. Finally, GP2FL formulates a nonlinear least squares optimization problem by marginalizing prior factors, inertial sensor factors, and Kalman fusion outputs, enabling globally optimized state estimation. Comprehensive simulation results and analyses prove that the proposed MP2F framework achieves high-precision position and pose estimation in complex emergency scenarios, with strong robustness. Experimental results in real-world environments show that the proposed MP2F achieves improvements in positioning accuracy of 61.1%, 58.7%, 48.4%, and 50.2% over EKF, iMag+, GWO-PF, and MagLoc, respectively.},
  archive      = {J_TMC},
  author       = {Bocheng Qian and Lei Huang and Xiansheng Guo and Gordon Owusu Boateng and Rui Ma and Nirwan Ansari},
  doi          = {10.1109/TMC.2025.3608822},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-17},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A multi-layer position-pose fusion framework for joint magnetoquasistatic field and IMU positioning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing dynamic task assignment in spatial crowdsourcing: Bilateral preference-aware approaches. <em>TMC</em>, 1-14. (<a href='https://doi.org/10.1109/TMC.2025.3603833'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Task assignment is a crucial challenge in spatial crowdsourcing (SC). Most existing studies have two limitations: Firstly, only one-sided preferences of workers or tasks are taken into account, and the satisfaction of workers or tasks could be improved; Secondly, tasks are always assigned based on the current locations of workers, which is not suitable for many real-life applications, such as carpooling, where the trajectories of workers require to be taken into account. To this end, we investigate a new problem of Bilateral Preference-aware Dynamic Task Assignment (BDTA), which is proven to be NP-hard, to maximize overall satisfaction by incorporating worker-task bilateral preferences and assigns tasks using the trajectories of workers. For the BDTA problem, we first propose a hybrid batch processing framework to address uneven data distribution. After that, a task-initiated bidirectional select algorithm is proposed to mitigates the impact of task order on the matching results. Furthermore, we propose an $\alpha$-approximate task-initiated generalized deferred-acceptance algorithm and a reverse generalized deferred-acceptance algorithm to enhance the stability and overall satisfaction of task assignment results. Extensive experiments are conducted on both real and synthetic datasets to validate the effectiveness and efficiency of the proposed algorithms.},
  archive      = {J_TMC},
  author       = {Yang Huang and Yumeng Liu and Xu Zhou and Tianyue Ren and Zhibang Yang and Keqin Li and Kenli Li},
  doi          = {10.1109/TMC.2025.3603833},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Optimizing dynamic task assignment in spatial crowdsourcing: Bilateral preference-aware approaches},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Time-efficient identifying key tag distribution in large-scale RFID systems. <em>TMC</em>, 1-17. (<a href='https://doi.org/10.1109/TMC.2025.3609967'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the proliferation of RFID-enabled applications, large-scale RFID systems often require multiple readers to ensure full coverage of numerous tags. In such systems, we sometimes pay more attention to a subset of tags instead of all, which are called key tags. This paper studies an under-investigated problem key tag distribution identification, which aims to identify which key tags are beneath which readers. This is crucial for efficiently managing specific items of interest, which can quickly pinpoint key tags and help RFID readers covering these tags collaborate to improve the tag inventory efficiency. We propose a protocol called Kadept that identifies the key tag distribution by designing a sophisticated Cuckoo filter that teases out key tags as well as assigns each of them a singleton slot for response. With this design, a great number of trivial (non-key) tags will keep silent and free up bandwidth resources for key tags, and each key tag is sorted in a collision-free way and can be identified with only 1-bit response, which significantly improves the time efficiency. To enhance the scalability and efficiency of Kadept for high key tag proportions, we propose E-Kadept protocol, which accelerates the identification process by designing an incremental Cuckoo filter that reduces false positives and improves space efficiency. We theoretically analyze how to optimize protocol parameters of Kadept and E-Kadept, and conduct extensive simulations under different tag distribution scenarios. Compared with the state-of-the-art, E-Kadept can improve the time efficiency by a factor of 1.75×, when the ratio of key tags to all tags is 0.3.},
  archive      = {J_TMC},
  author       = {Yanyan Wang and Jia Liu and Zhihao Qu and Shen-Huan Lyu and Bin Tang and Baoliu Ye},
  doi          = {10.1109/TMC.2025.3609967},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-17},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Time-efficient identifying key tag distribution in large-scale RFID systems},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). QoE maximization for laser-powered multi-UAV communication networks. <em>TMC</em>, 1-15. (<a href='https://doi.org/10.1109/TMC.2025.3610026'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned aerial vehicle (UAV) communication is expected to play an important role in many applications, including emergency services, remote surveillance and even daily logistics, thanks to its great advantages such as flexible deployment and mobility support. In this paper, we propose a multi-UAV-aided communication scheme supported by laser power transfer (LPT), where the quality-of-experience (QoE) requirements of user equipment (UE) is considered. Specifically, to improve the sum QoE, we first maximize the sum of average data rates (ADRs) of all UEs through an alternating optimization of UAVs' positions, UE-network association and LPT station (LPTS)-network association. Then, we devise an advanced Gale-Shapley rematching (GSRM) scheme to address the intractable 0-1 programming problem in UE/LPTS-network association. Moreover, an L2-norm polynomial (L2NP) programming method is designed to transform the L2NP of the LPT-based UAV positioning problem into a convex form. Finally, a redundant resource reallocation (RRR) algorithm is designed to recycle and reallocate the excessive transmit power and backhaul capacity of both the base station (BS) and the UAVs, to further maximize the number of UEs satisfying the QoE requirements. Simulation results show that the proposed UAV-aided communication scheme can help more UEs achieve their QoE requirements at a reduced power consumption compared with existing solutions.},
  archive      = {J_TMC},
  author       = {Jianchao Chen and Ming Jiang},
  doi          = {10.1109/TMC.2025.3610026},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {QoE maximization for laser-powered multi-UAV communication networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards the age of semantic information: A deep learning-enabled generalized deduplication-based semantic transmission mechanism. <em>TMC</em>, 1-18. (<a href='https://doi.org/10.1109/TMC.2025.3609792'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the upcoming global-coverage 6G networks, high packet loss and long latency in long-distance transmissions exacerbate the trade-off between data timeliness and integrity, particularly in time-sensitive applications involving time-series data with stringent integrity requirements. This challenge exposes the limitations of existing transmission systems, such as source-channel coding and semantic communication, which fail to jointly address both dimensions. In this paper, we propose a deep learning (DL)-enabled generalized deduplication (GD)-based semantic transmission (DLGD-ST) mechanism for time-series data. By leveraging GD to address the impact of semantic ambiguity on data integrity, DLGD-ST exploits the semantic recovery and temporal discreteness of the data to effectively mitigate the conflict between integrity and timeliness. In particular, a well-designed long-short-term memory (LSTM)-based GD algorithm is developed to separate shallow semantic components and supplementary components, ensuring the integrity of semantic transmission. A deep semantic encoding process is then performed using a double-layer progressive dimension reduction (DPDR) and adaptive quantization (AQ) scheme, which capitalizes on the channel robustness of semantics to reduce transmission rounds and improve timeliness. Furthermore, an incremental dimension hybrid automatic repeat request (ID-HARQ) mechanism is introduced to improve semantic reliability by retransmitting high-dimensional semantics, thereby further minimizing end-to-end transmission rounds. To accurately evaluate performance, we introduce the Age of Semantic Information (AoSI), which incorporates integrity constraints into the generalized Age of Information (AoI) to jointly assess integrity and timeliness. Simulation results demonstrate that the proposed DLGD-ST mechanism, enabled by accurate data recovery and reduced transmission rounds, achieves better AoSI performance compared to existing communication systems under both high and low signal-to-noise ratio (SNR) conditions.},
  archive      = {J_TMC},
  author       = {Yunlai Xu and Ronghao Gao and Qinyu Zhang and Zhihua Yang},
  doi          = {10.1109/TMC.2025.3609792},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-18},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Towards the age of semantic information: A deep learning-enabled generalized deduplication-based semantic transmission mechanism},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Phase-proof: Robust mobile two-factor authentication via phase fingerprinting. <em>TMC</em>, 1-15. (<a href='https://doi.org/10.1109/TMC.2025.3610154'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The two-factor authentication (2FA) has been widely applied with the proliferation of mobile devices. Currently, many existing 2FA solutions propose to use acoustic fingerprints as the second factor. However, these schemes mainly consider using the magnitude or non-linearity information of the acoustic signal for authentication and ignore the fingerprint variations caused by the change of transmission distance between devices, which could threaten the accuracy of the system. To address these vulnerabilities, we propose Phase-Proof, a secure and robust 2FA that utilizes the phase distortions incurred by the acoustic elements of mobile devices as the second proof. Given the received acoustic signal, our system first extracts phase information from the signal and designs a new distance effect elimination scheme to remove the impact of transmission distances for robust fingerprint extraction. Moreover, our device authentication component then adopts a transfer learning-based method to capture the subtle differences in devices' fingerprints for accurate device authentication. Moreover, to further withstand the co-located attacks, our proximity detection component collects certain environmental randomness from the enrolled phone, and then matches it with the environmental randomness collected from the login device to verify the proximity of two devices. Our experimental results show that our system is accurate in providing 2FA and robust to various attacks across different scenarios.},
  archive      = {J_TMC},
  author       = {Tingyuan Yang and Shuyu Liu and Yanzhi Ren and Haitao Jia and Ziyu Shao and Hongbo Liu and Jiadi Yu and Hongwei Li},
  doi          = {10.1109/TMC.2025.3610154},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Phase-proof: Robust mobile two-factor authentication via phase fingerprinting},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed rate limiting under decentralized cloud networks. <em>TMC</em>, 1-18. (<a href='https://doi.org/10.1109/TMC.2025.3610314'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid expansion of cloud applications has led to unprecedented increases in network traffic volume, diversity, and complexity. As Cloud Service Providers (CSPs) adopt decentralized, geographically distributed data centers, effective traffic management across these environments has become critical. Distributed Rate Limiting (DRL) has emerged as an essential tool to manage the complex traffic dynamics of decentralized networks, yet traditional centralized rate limiting methods fall short, facing limitations in scalability, adaptability to bursty traffic, and efficiency. This paper presents C3PDAR (Cloud Control with Constant Probabilities and Dynamic Adjustment Range), a novel DRL algorithm tailored for decentralized cloud infrastructures. C3PDAR introduces three key innovations: (1) CPS-BPS DualPoint Rate Limiting and Parent-Child Token Bucket mechanisms, which effectively mitigate burst traffic and short-lived connections while improving bandwidth fairness and inter-tenant isolation; (2) A vSwitch-CGW Cascade Rate Limiting architecture, which reduces CPU overhead in CGW clusters and accelerates convergence by 42%–78%; (3) Virtual Extensible Local Area Network (VXLAN) Padding scheme, which embeds rate-limiting information in existing traffic instead of transmitting new data packets, reducing the communication overhead of the C3PDAR algorithm by over 40%. By integrating these advancements, C3PDAR delivers a scalable, robust solution that outperforms traditional DRL approaches in performance, fault tolerance, and resource efficiency. C3PDAR uniquely empowers CSPs to manage complex, high-volume traffic dynamics in decentralized cloud environments, offering both theoretical insights and practical optimizations for next-generation network control.},
  archive      = {J_TMC},
  author       = {Xiang Hu and Tianyu Xu and Lilong Chen and Xiaochong Jiang and Ye Yang and Liming Ye and Xu Wang and Yilong Lv and Chenhao Jia and Yongwang Wu and Zhigang Zong and Xing Li and Bingqian Lu and Shunmin Zhu and Chengkun Wei and Wenzhi Chen},
  doi          = {10.1109/TMC.2025.3610314},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-18},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Distributed rate limiting under decentralized cloud networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Incentivizing throughput enhancement in blockchain-based energy trading system. <em>TMC</em>, 1-18. (<a href='https://doi.org/10.1109/TMC.2025.3610648'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain-based energy trading (BBET) systems depend on prosumers to allocate energy between trading activities and blockchain mining operations. However, inadequate incentive structures lead prosumers to under-contribute to mining, creating throughput bottlenecks and system performance degradation. This paper introduces the Fee and Two-Piece Compensation (FTPC) mechanism to optimize energy allocation and enhance system throughput. We formulate the interaction between the system designer and prosumers as a three-stage Stackelberg game where the system designer establishes the incentive framework in Stage I, while prosumers determine energy allocation in Stage II and set transaction fees in Stage III. Our analysis demonstrates that prosumers' failure to internalize mining's positive externality results in suboptimal throughput investment. Counterintuitively, we show that impatient prosumers may exploit others' mining contributions as free riders. The FTPC mechanism resolves these issues by jointly optimizing transaction fees and compensation structures to align individual incentives with social welfare. We prove that FTPC achieves socially optimal outcomes through fully decentralized decision-making. Numerical evaluation shows FTPC improves social welfare and prosumer payoffs by 88.1% and 87.8%, respectively. Ethereum testbed implementation validates equilibrium convergence through iterative best-response dynamics.},
  archive      = {J_TMC},
  author       = {Yunshu Liu and Man Hon Cheung and Jianwei Huang},
  doi          = {10.1109/TMC.2025.3610648},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-18},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Incentivizing throughput enhancement in blockchain-based energy trading system},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic searchable symmetric encryption with efficient and complete access control for multi-user cloud computing. <em>TMC</em>, 1-17. (<a href='https://doi.org/10.1109/TMC.2025.3609829'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Searchable symmetric encryption (SSE) enables the storage and retrieval of encrypted data on untrusted cloud servers, while dynamic searchable symmetric encryption (DSSE) further supports updating encrypted data. To date, in multi-user environments, most DSSE schemes cannot achieve simultaneous access control for both keyword retrieval and data updates. To address this issue, we propose a new DSSE scheme with efficient and complete (keyword retrieval and update) access control for multi-user environments, named EFCAM. Our work has simultaneously achieved efficient, flexible, and fine-grained access control for keyword retrieval and updating, this is extremely rare in existing research. For update operations, we combine file index encoding and homomorphic encryption (HE) technology, so that EFCAM optimizes the calculation; to achieve flexible access control, we adopt an equality test scheme that can supports three types of update authorization. For retrieval operations, users do not need to share keys. By executing a single query, the users can effectively retrieve all the data that they have permission to access. To enhance system security and operational efficiency, we have extended EFCAM with a dynamic policy update mechanism for flexible and real-time adjustment of access control policies. We formally analyze the security of EFCAM to prove that our scheme has forward security (FS) and backward security (BS). Experimental results show that, EFCAM maintains outstanding efficiency in encrypted data retrieval and update operations within multi-user environments, while also exhibiting strong scalability.},
  archive      = {J_TMC},
  author       = {Liqun Yang and Yuze Yang and Dusit Niyato and Zhoujun Li and Wanxu Xia and Liang Sun},
  doi          = {10.1109/TMC.2025.3609829},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-17},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Dynamic searchable symmetric encryption with efficient and complete access control for multi-user cloud computing},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Octopus: Optimizing interactive video QoE via loosely coupled codec-transport adaptation. <em>TMC</em>, 1-18. (<a href='https://doi.org/10.1109/TMC.2025.3610501'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Enhancing the quality of experience (QoE) in interactive video streaming (IVS) remains a persistent challenge due to the need for ultra-low latency and rising bandwidth demands. Conventional algorithms, whether rule-based or learning-based, are obsessed with achieving tight coupling between encoding and sending bitrate adaptations for low-latency guarantee. However, our measurement studies reveal alarming harms of tight coupling in suppressing throughput, encoding bitrates and smoothness, as application- and transport-layer bitrate adaptations inherently have different mechanisms and goals. To tackle this problem, we propose Octopus, the first loosely coupled cross-layer bitrate adaptation algorithm for IVS to maximize QoE. Instead of blind synchronization, Octopus promotes mutual cooperation and independence between encoding and sending bitrate adaptations by integrating a multi-head network with shortcut connections and auto-regressive action modules. Additionally, based on meta-imitation reinforcement learning, we design a network condition-aware online adaptation scheme that enables the loosely coupled policy to swiftly adapt to diverse and dynamic wireless networks. We implement Octopus on a testbed, a microcosm of real-world deployment, with transceiver pairs running WebRTC on the WeChat for Business dataset. Results show that Octopus outperforms state-of-the-art algorithms, either improving bitrates by 37.1%, or optimizing stalling rate and smoothness by 54.1% and 9.2%, or achieving all-around improvements.},
  archive      = {J_TMC},
  author       = {Xuedou Xiao and Mingxuan Yan and Yingying Zuo and Boxi Liu and Paul Ruan and Yang Cao and Yue Cao and Wei Wang},
  doi          = {10.1109/TMC.2025.3610501},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-18},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Octopus: Optimizing interactive video QoE via loosely coupled codec-transport adaptation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ERA: A QoE-aware collaborative inference algorithm for NOMA-based edge intelligence. <em>TMC</em>, 1-16. (<a href='https://doi.org/10.1109/TMC.2025.3610699'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although AI has been extensively adopted and has profoundly transformed our lives, it is not feasible to directly deploy large AI models on edge devices with limited resources. To enhance the performance of Edge Intelligence (EI), model split inference has been proposed. In this approach, an AI model is segmented into sub-models, with the most resource-intensive parts offloaded wirelessly to the edge server. This reduces the resource demands and inference latency on the device. However, previous studies have primarily focused on enhancing and optimizing system Quality of Service (QoS), often overlooking Quality of Experience (QoE), which is another crucial aspect for users. Even though QoE has been extensively studied in Edge Computing (EC), the distinct differences between task offloading in EC and split inference in EI, along with specific QoE issues that remain unaddressed in both fields, render these algorithms ineffective for edge split inference scenarios. Therefore, this paper introduces an effective resource allocation algorithm, dubbed ERA, which aims to: 1) expedite split inference in EI, and 2) balance inference delay, QoE, and resource consumption. ERA incorporates resource consumption, QoE, and inference latency to determine the most optimal model split and resource allocation strategies. Given that it is impossible to simultaneously minimize inference delay and resource consumption while maximizing QoE, we employ a gradient descent-based algorithm to find the best possible compromise. Furthermore, to address the complexity arising from parameter discretization in the gradient descent algorithm, we have developed a pipeline gradient descent approach, known as PipGD. We have also examined the properties of the proposed algorithms, including their convergence, complexity, and approximation error. The experimental results clearly show that ERA outperforms previous studies significantly in terms of performance.},
  archive      = {J_TMC},
  author       = {Xin Yuan and Ning Li and Quan Chen and Wenchao Xu and Song Guo},
  doi          = {10.1109/TMC.2025.3610699},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {ERA: A QoE-aware collaborative inference algorithm for NOMA-based edge intelligence},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient privacy-preserving federated learning via homomorphic encryption-enabled over-the-air computation. <em>TMC</em>, 1-16. (<a href='https://doi.org/10.1109/TMC.2025.3610887'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) enables collaborative model training across devices, but data exchanges pose privacy risks. Homomorphic Encryption (HE) is widely used to enhances privacy in FL but incurs significant communication and computation latency. Prior work reduced this latency using compressions, but sacrificed learning accuracy and overlooked the impact of the number of participating devices on latency. Over-the-air computation (AirComp) leverages wireless channels' superposition property to achieve high spectral efficiency and efficient aggregation irrespective of device number. In this paper, we propose HEAirFed, integrating AirComp with the state-ofthe-art HE scheme CKKS for efficient privacy-preserving FL. In HEAirFed, we develop a ciphertext-oriented wireless communication module to ensure homomorphic operations leverage AirComp's superposition property, enabling correct decryption. We further build a rigorous error analysis model, derive the worst-case upper bound of approximation error, and characterize this bound's impact on the convergence guarantee of HEAirFed, measured by the optimality gap with bounded approximation error. Then, we minimize this gap and derive a near-optimal solution in semi-closed form. Extensive experimental results on real-world datasets validate the ciphertext-oriented design's necessity, the error analysis's correctness, and demonstrate that HEAirFed achieves a substantial reduction in communication and aggregation latency compared to baseline, with minimal learning accuracy loss.},
  archive      = {J_TMC},
  author       = {Yehui Wang and Baoxian Zhang and Jinkai Zhang and Cheng Li},
  doi          = {10.1109/TMC.2025.3610887},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Efficient privacy-preserving federated learning via homomorphic encryption-enabled over-the-air computation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Singular value decomposition based indoor localization using small scale crowd sensing data. <em>TMC</em>, 1-18. (<a href='https://doi.org/10.1109/TMC.2025.3610882'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional crowd sensing based indoor localization methods rely on large scale pre-collected fingerprint data to construct a radio map with cumbersome prior preparation. However, when they lack floor plan information or only have a little of data is willing to share, the tracking accuracy degrades significantly. In this paper, we propose a singular value decomposition (SVD) track matching scheme to obtain an effective radio map based on small scale crowd sensing data, which is a non-learning based system (SVD-CSP). SVD-CSP fuses received signal strength indicator (RSSI), inertial measurement unit (IMU), and magnetic field strength to label surrounding WiFi access points as marker points. The proposed scheme uses SVD method to directly compute the rotation matrix and displacement vector among the crowd sensing trajectories and attain the reliable tracks. The radio map is constructed and users are tracked according to our developed bidirectional Bayesian filter, which contains forward filter and reverse filter. The density-based spatial clustering of applications with noise (DBSCAN) is embedded within the forward filter to improve the radio map quality. Meanwhile, the reverse filter fuses pedestrian dead reckoning (PDR) and radio map-based localization to track users. Experimental results demonstrate that SVD-CSP can achieve robust localization using extremely sparse crowd trajectories (e.g., 4 trajectories in a 648 m2 scenario, 30 trajectories in a 2856 m2 scenario) without deep learning training or infrastructure knowledge.},
  archive      = {J_TMC},
  author       = {Xiaohao Liu and Yubin Zhao and Xiaofan Li and Huaming Wu and Cheng-Zhong Xu},
  doi          = {10.1109/TMC.2025.3610882},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-18},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Singular value decomposition based indoor localization using small scale crowd sensing data},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Accelerating stable matching between workers and spatial-temporal tasks for dynamic MCS: A stagewise service trading approach. <em>TMC</em>, 1-16. (<a href='https://doi.org/10.1109/TMC.2025.3610915'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designing effective incentive mechanisms in mobile crowdsensing (MCS) networks is crucial for engaging distributed mobile users (workers) to contribute heterogeneous data for various applications (tasks). In this paper, we propose a novel stagewise trading framework to achieve efficient and stable task-worker matching, explicitly accounting for task diversity (e.g., spatio-temporal limitations) and network dynamics inherent in MCS environments. This framework integrates both futures and spot trading stages. In the former, we introduce the futures trading-driven stable matching and pre-path-planning mechanism (FT-SMP3), which enables long-term taskworker assignment and pre-planning of workers' trajectories based on historical statistics and risk-aware analysis. In the latter, we develop the spot trading-driven DQN-based path planning and onsite worker recruitment mechanism (ST-DP2WR), which dynamically improves the practical utilities of tasks and workers by supporting real-time recruitment and path adjustment. We rigorously prove that the proposed mechanisms satisfy key economic and algorithmic properties, including stability, individual rationality, competitive equilibrium, and weak Pareto optimality. Extensive experiements further validate the effectiveness of our framework in realistic network settings, demonstrating superior performance in terms of service quality, computational efficiency, and decision-making overhead.},
  archive      = {J_TMC},
  author       = {Houyi Qi and Minghui Liwang and Xianbin Wang and Liqun Fu and Yiguang Hong and Li Li and Zhipeng Cheng},
  doi          = {10.1109/TMC.2025.3610915},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Accelerating stable matching between workers and spatial-temporal tasks for dynamic MCS: A stagewise service trading approach},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive decentralized federated learning in energy and latency constrained wireless networks. <em>TMC</em>, 1-18. (<a href='https://doi.org/10.1109/TMC.2025.3611075'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Federated Learning (FL), with parameter aggregated by a central node, the communication overhead is a substantial concern. To circumvent this limitation and alleviate the single point of failure within the FL framework, recent studies have introduced Decentralized Federated Learning (DFL) as a viable alternative. Considering the device heterogeneity, and energy cost associated with parameter aggregation, in this paper, the problem on how to efficiently leverage the limited resources available to enhance the model performance is investigated. Specifically, we formulate a problem that minimizes the loss function of DFL while considering energy and latency constraints. The proposed solution involves optimizing the number of local training rounds across diverse devices with varying resource budgets. To make this problem tractable, we first analyze the convergence of DFL with edge devices with different rounds of local training. The derived convergence bound reveals the impact of the rounds of local training on the model performance. Then, based on the derived bound, the closed-form solutions of rounds of local training in different devices are obtained. Meanwhile, since the solutions require the energy cost of aggregation as low as possible, we modify different graph-based aggregation schemes to solve this energy consumption minimization problem, which can be applied to different communication scenarios. Finally, a DFL framework which jointly considers the optimized rounds of local training and the energy-saving aggregation scheme is proposed. Simulation results show that, the proposed algorithm achieves a better performance than the conventional schemes with fixed rounds of local training, and consumes less energy than other traditional aggregation schemes.},
  archive      = {J_TMC},
  author       = {Zhigang Yan and Dong Li and Qiang Sun and Dusit Niyato and Tony Q. S. Quek},
  doi          = {10.1109/TMC.2025.3611075},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-18},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Adaptive decentralized federated learning in energy and latency constrained wireless networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mitigating interference for automotive millimeter-wave radar perception in dense traffic scenarios. <em>TMC</em>, 1-14. (<a href='https://doi.org/10.1109/TMC.2025.3610963'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automotive Millimeter-wave (mmWave) radar is becoming an essential modality for autonomous vehicles to enable all-weather perception, especially when LiDAR and camera fail in foggy, rainy, or snowy conditions. It is expected that the mutual interference among multiple radars becomes a critical issue in dense traffic scenarios, which can severely degrade the radar performance and lead to accidents. Despite extensive interference mitigation techniques, none can meet the less valid signal distortion while high robustness requirements for automotive radar perception in dense traffic scenarios. To overcome this predicament, we propose mmMic, a novel multiple mutual interference mitigation system that can accurately separate interference and recover valid signals to maintain the reliability of the radar measurements. The key insight is to design an interference estimator that can accurately localize the interference signal according to its linear frequency modulation features in the time-frequency (TF) domain. In addition, mmMic also fully exploits undisturbed valid signal information within an extended time-frequency domain to reconstruct the damaged signal. Our experiments on a real testbed show that mmMic can improve SINR to interference-free levels from multiple radars, achieving an average SINR improvement of 17% compared to the best-performing baseline.},
  archive      = {J_TMC},
  author       = {Wei Wang and Chunshen Li and Bixin Zeng and Lieke Chen and Liang Sun and Kai Luo and Da Chen},
  doi          = {10.1109/TMC.2025.3610963},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Mitigating interference for automotive millimeter-wave radar perception in dense traffic scenarios},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedBRB: A solution to the small-to-large scenario in device-heterogeneity federated learning. <em>TMC</em>, 1-14. (<a href='https://doi.org/10.1109/TMC.2025.3610985'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the success of large models has demonstrated the importance of scaling up model sizes. However, it is difficult to directly train large models locally on multiple mobile devices due to their intrinsic computational constraints. To address this challenge, it becomes a crucial need to train larger global models by training small local models on devices. As a distributed learning approach, federated learning (FL) allows multiple devices to train models locally and aggregate them to form the global model by sharing the updated parameters with the server, thus enabling the co-training of models. This promising feature has spurred an increasing interest in exploring the collaborative training of large models. Despite the advent of existing device-heterogeneity FL approaches, they still have limitations in fully covering the parameter space of the global model. To fill this gap, we propose a novel approach called FedBRB (Block- wise Rolling and weighted Broadcast). The core idea of FedBRB is to utilize local models of small devices to train all modules of a large global model and broadcast the trained parameters to the entire space, thereby enabling faster information sharing. This approach not only improves training efficiency but also fully utilizes limited computational resources. Experiments demonstrate that FedBRB can produce significant performance gains, achieving state-of-the-art results. Additionally, this paper provides theoretical and experimental analyses of FedBRB convergence, thereby paving a theoretical ground and providing practical guidance for further research and application of the FedBRB method.},
  archive      = {J_TMC},
  author       = {Tianchi Liao and Ziyue Xu and Qing Hu and Hong-Ning Dai and Huaiwei Huang and Zibin Zheng and Chuan Chen},
  doi          = {10.1109/TMC.2025.3610985},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {FedBRB: A solution to the small-to-large scenario in device-heterogeneity federated learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid model with bayesian nonparametric inference for RF fingerprint identification. <em>TMC</em>, 1-15. (<a href='https://doi.org/10.1109/TMC.2025.3611135'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radio frequency fingerprint identification (RFFI) aims to identify subtle impairments in hardware devices, which play an important role in the mobile environment security community. To identify various mobile devices in the complex electromagnetic environment, deep learning methods such as convolutional neural networks (CNN) and recurrent neural networks (RNN) have been adopted to extract device hardware-related features. However, the single network structure has difficulty in comprehensive feature extraction, as many factors can introduce hardware impairments. In this paper, we propose a hybrid model termed switching dynamical deep network (SDDN) for RFFI tasks, which can jointly extract both coarse-grained radio frequency fingerprints (RFFs) and fine-grained RFFs. Additionally, the proposed hybrid model consists of a probabilistic part and a deterministic part. Specifically, in the probabilistic part, the switching linear dynamical systems (SLDS) are incorporated to establish the correspondence between the signal slice and the feature extraction network (FEN). In the deterministic part, multiple independent FENs are established to extract the RFFs. Moreover, to automatically determine the suitable number of FENs, a Bayesian nonparametric prior distribution is placed over the probabilistic part. Finally, an end-to-end parameter optimization method that is based on variational inference and stochastic gradient descent is proposed. Experiments on a real-life Wi-Fi dataset demonstrate the superiority of the proposed method over existing methods.},
  archive      = {J_TMC},
  author       = {Jian Yang and Jiadi Bao and Luyao Zhang and Yatong Wang and Fang Yang and Shafei Wang},
  doi          = {10.1109/TMC.2025.3611135},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A hybrid model with bayesian nonparametric inference for RF fingerprint identification},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiple CPUs cooperation for CF massive MIMO with MmWave fronthaul and backhaul. <em>TMC</em>, 1-15. (<a href='https://doi.org/10.1109/TMC.2025.3611133'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cell-free massive multiple-input multiple-output (CF massive MIMO) is regarded as a promising technology for next-generation wireless communication systems. However, relying on a single central processing unit (CPU) in CF massive MIMO systems is not scalable in practical networks, requiring the introduction of multiple CPUs for more efficient and feasible transmission. In this paper, we investigate a CF massive MIMO system with multiple CPUs. To obtain flexible and cost-efficient deployment, we propose to use wireless x-haul links instead of wired ones. More specifically, we assume that both the fronthaul links from the APs to the corresponding CPU and the backhaul links between CPUs operate under millimeter wave (mmWave) networks. Taking into account a tradeoff between the degree of centralized coordination and the signal overhead on the backhaul links, we consider four levels of multiple CPUs cooperation schemes from fully centralized to fully distributed. In addition, we propose a binary search method to allocate the backhaul capacities for maximizing the sum spectral efficiency (SE). Simulation results show that mmWave backhaul amplifies the compression noise introduced by mmWave fronthaul, leading to a more pronounced impact on the SE of systems. In this case, the centralized processing scheme can generate more compression noise due to the larger data overhead on the backhaul link, making the distributed processing scheme a superior processing scheme, especially when dealing with a large number of APs or significant distances between CPUs.},
  archive      = {J_TMC},
  author       = {Feiyang Li and Qiang Sun and Jiayi Zhang and Cunhua Pan and Kai-Kit Wong},
  doi          = {10.1109/TMC.2025.3611133},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Multiple CPUs cooperation for CF massive MIMO with MmWave fronthaul and backhaul},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Active data routing based on reward backpropagation-enabled multi-agent Q-learning towards SDN-enabled wireless buoy networks. <em>TMC</em>, 1-16. (<a href='https://doi.org/10.1109/TMC.2025.3611873'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advancements in Wireless Buoy Network (WBN) have significantly accelerated the development of marine exploitation and monitoring, acting as a relay between underwater and surface networks in emerging 6G scenarios. Due to unstable maritime communication environment, it is a challenging issue to deploy the optimal data routing or collection strategies to ensure the collected data to be delivered to the target point. By employing the Software-Defined Networking (SDN) technology, this paper proposes the paradigm of Software-Defined WBN (SDWBN) to improve the network management efficiency and provide a platform to embed the Multi-Agent Reinforcement Learning (MARL) framework (for data routing intelligence), respectively. On account of the proposed SDWBN, this paper proposes a Reward Backpropagation-enabled Multi-Agent Deep Q-learning algorithm (RBMADQ)-based active routing scheme, which aims to assist buoys in making routing decisions and navigating the challenges posed by the dynamic and unstable communication environment. Further, this paper proposes a dual replay buffer-based training method, to enhance the convergence speed of the proposed RBMADQ-based routing scheme. Evaluation results demonstrate that the proposed routing scheme performs better compared with recent research products, with a higher packet delivery rate, lower network latency, and simultaneously, less communication overhead, etc.},
  archive      = {J_TMC},
  author       = {Yuan Liu and Guangjie Han and Chuan Lin and Shengchao Zhu},
  doi          = {10.1109/TMC.2025.3611873},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Active data routing based on reward backpropagation-enabled multi-agent Q-learning towards SDN-enabled wireless buoy networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Joint UAVs deployment and resource allocation for AoI-aware RIS-assisted UAV-USV MEC network. <em>TMC</em>, 1-15. (<a href='https://doi.org/10.1109/TMC.2025.3611808'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Age of information (AoI)-sensitive bidirectional computation tasks quality of service (QoS) for unmanned surface vehicles (USVs) is a critical issue in realizing ship-shore cooperative systems. In this paper, a reconfigurable intelligent surface (RIS)-assisted unmanned aerial vehicle (UAV)-USV mobile edge computing (MEC) network architecture is proposed, where one RIS-carried tethered UAV (TUAV) and rotary-wing UAVs (RUAVs) are cooperatively dispatched to serve USVs bidirectional data computation with average AoI (AAoI) constraint. The minimization of weighted sum USVs AAoI and RUAVs flight energy is formulated by jointly considering RUAVs service duration indicators, TUAV-mounted RIS phase shift, TUAV hovering altitude, and RUAVs' trajectories. A heursitic solution is proposed to address this minimized issue. In particular, a novel mixed linear quadratic Lyapunov framework is utilized to transform the original long-term stochastic problem into a list of deterministic single-slot problems. Then, each single-slot problem is divided into two subproblems. First, the subproblem of RUAVs' trajectories is tackled by an enhanced whale optimization algorithm. Second, the subproblem of RUAVs service duration indicators, TUAV-mounted RIS phase shift and TUAV hovering altitude is addressed by an enhanced alternating optimization algorithm. The results demonstrate that the proposed heuristic solution reduces long-term RUAVs flight energy consumption by approximately 50% while maintaining satisfactory USVs AAoI.},
  archive      = {J_TMC},
  author       = {Yangzhe Liao and Yuanyan Song and Dan Song},
  doi          = {10.1109/TMC.2025.3611808},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Joint UAVs deployment and resource allocation for AoI-aware RIS-assisted UAV-USV MEC network},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bi-CrowdCache: A decentralized game-theoretic model for edge content sharing over time-varying communication networks. <em>TMC</em>, 1-13. (<a href='https://doi.org/10.1109/TMC.2025.3611963'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile edge computing (MEC) is a promising solution for enhancing user experience, minimizing content delivery expenses, and reducing backhaul traffic. This paper presents a game-theoretic framework to address the edge resource crowdsourcing problem, where mobile edge devices (MEDs) provide idle storage for content caching in exchange for rewards from a content provider (CP). We model the interaction between the CP and MEDs as a Stackelberg game, with the CP as the leader setting the reward structure and the MEDs as followers competing in a non-cooperative game for these rewards. We propose a novel privacy-preserving method to derive the Stackelberg equilibrium of the game. Notably, our algorithm is designed to operate effectively in time-varying communication networks, addressing the high mobility inherent in MEC environments. This contrasts with state-of-the-art algorithms, which assume a static communication network among MEDs–an impractical condition that does not account for the mobility of MEDs during algorithm execution. Specifically, our approach employs consensus-based algorithms to compute the Nash equilibrium (NE) for MEDs, with MEDs exchanging NE profile estimates with neighbors via row-stochastic mixing matrices and performing gradient steps to optimize their utility in a fully decentralized manner. Based on the computed NE strategies, we propose a zeroth-order reward search algorithm for the CP to determine the optimal strategy for profit maximization. Our comprehensive analysis details the properties of the equilibrium and establishes the geometric convergence of the proposed algorithms to the NE. We also derive explicit bounds for the stepsizes based on the game's properties and the graphs' connectivity structure. Extensive numerical results validate the efficacy of our proposed approach.},
  archive      = {J_TMC},
  author       = {Duong Thuy Anh Nguyen and Jiaming Cheng and Ni Trieu and Duong Tung Nguyen and Angelia Nedic},
  doi          = {10.1109/TMC.2025.3611963},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Bi-CrowdCache: A decentralized game-theoretic model for edge content sharing over time-varying communication networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Energy-efficient multi-UAV navigation for cooperative data sensing and transmission. <em>TMC</em>, 1-18. (<a href='https://doi.org/10.1109/TMC.2025.3612221'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned aerial vehicles (UAVs) hold significant potential for sensing services in a large scope of area, thanks to their wide coverage and adaptable deployment. Considering the complex environment dynamics and limited sensing range, navigating multiple UAVs in a distributed way becomes challenging to implement cooperative data sensing and transmission tasks. In this paper, we optimize the trajectory design of UAVs by jointly considering the collected data volume, geographical fairness and limited energy reserve during their service period. To achieve the long-term serving objective, a memory augmented multi-agent deep reinforcement learning approach is presented to ensure energy-efficient distributed trajectory design with partial observations. Specifically, the intrinsic criterion is developed to enhance UAV spatial exploration when reaching the boundary of explored regions. Then, to address the information loss caused by incomplete observations, the spatial-temporal memory augmented actor-critic architecture is designed to extract historical contextual features for multi-UAV cooperative navigation. Furthermore, the prioritized experience replay mechanism is incorporated to enhance important experience exploitation for UAV collaboration. Extensive simulations using two real-world datasets in Shenzhen and Beijing demonstrate that the proposed method outperforms the state-of-the-art methods in terms of data collection ratio, geographical fairness, and energy consumption ratio.},
  archive      = {J_TMC},
  author       = {Hu He and Jun Peng and Lin Cai and Weirong Liu and Chenglong Wang and Xin Gu and Zhiwu Huang},
  doi          = {10.1109/TMC.2025.3612221},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-18},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Energy-efficient multi-UAV navigation for cooperative data sensing and transmission},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CrossSense: Enabling cross-technology sensing between WiFi and LoRa. <em>TMC</em>, 1-15. (<a href='https://doi.org/10.1109/TMC.2025.3612289'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the explosive increase in wireless devices, enabling sensing between incompatible radios has become critically beneficial. Integrating diverse IoT devices enhances sensing accuracy by providing richer data, while utilizing the diverse characteristics of heterogeneous signals meets sensing needs in complex environments. However, most existing wireless sensing methods primarily focus on homogeneous signals, while research on sensing with heterogeneous signals is still in its infancy. In this paper, we propose CrossSense, a novel Cross-Technology Sensing (CTS) framework that enables sensing between incompatible WiFi and LoRa device. CrossSense recovers the fine-grained trajectory of a WiFi transmitter based on its emulated LoRa signals. To decompose the motion feature components of WiFi transmitter, we develop a chirp difference vector model that utilizes the energy peak within each chirp window for sensing. We model the relationship between sampling frequency offsets and oscillation frequency offsets among heterogeneous devices to guide the extraction of motion features from the emulated signal. We also propose a greedy-based peak enhancement method to calculate the optimized LoRa phases, minimizing the impact of phase discontinuity caused by cyclic prefix (CP) errors. We implement a prototype of CrossSense on the USRP platform. The extensive experiments demonstrate that CrossSense can achieve an efficient Cross-Technology Sensing with $2.92cm$ distance accuracy and $0.26cm/s$ speed accuracy over a $120m$ sensing range.},
  archive      = {J_TMC},
  author       = {Dan Xia and Guanghui Chen and Fu Yu and Yuxuan Wang and Xiaolong Zheng and Liang Liu and Shanguo Huang and Huadong Ma},
  doi          = {10.1109/TMC.2025.3612289},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {CrossSense: Enabling cross-technology sensing between WiFi and LoRa},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
