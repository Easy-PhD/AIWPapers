<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TBD</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tbd">TBD - 69</h2>
<ul>
<li><details>
<summary>
(2025). FinMem: A performance-enhanced LLM trading agent with layered memory and character design. <em>TBD</em>, 1-18. (<a href='https://doi.org/10.1109/TBDATA.2025.3593370'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {We introduce FinMem, a novel Large Language Models (LLM)-based agent framework for financial trading, designed to address the need for automated systems that can transform real-time data into executable decisions. FinMem comprises three core modules: Profile for customizing agent characteristics, Memory for hierarchical financial data assimilation, and Decision-making for converting insights into investment choices. The Memory module, which mimics human traders' cognitive structure, offers interpretability and real-time tuning while handling the critical timing of various information types. It employs a layered approach to process and prioritize data based on its timeliness and relevance, ensuring that the most recent and impactful information is given appropriate weight in decision-making. FinMem's adjustable cognitive span allows retention of critical information beyond human limits, enabling it to balance historical patterns with current market dynamics. This framework facilitates self-evolution of professional knowledge, agile reactions to investment cues, and continuous refinement of trading decisions in financial environments. When compared against advanced algorithmic agents using a large-scale real-world financial dataset, FinMem demonstrates superior performance across classic metrics like Cumulative Return and Sharpe ratio. Further tuning of the agent's perceptual span and character setting enhances its trading performance, positioning FinMem as a cutting-edge solution for automated trading.},
  archive  = {J},
  author   = {Yangyang Yu and Haohang Li and Zhi Chen and Yuechen Jiang and Yang Li and Jordan W. Suchow and Denghui Zhang and Khaldoun Khashanah},
  doi      = {10.1109/TBDATA.2025.3593370},
  journal  = {IEEE Transactions on Big Data},
  month    = {8},
  pages    = {1-18},
  title    = {FinMem: A performance-enhanced LLM trading agent with layered memory and character design},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Document-image perceptual hashing for content authentication. <em>TBD</em>, 1-15. (<a href='https://doi.org/10.1109/TBDATA.2025.3596854'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {This paper proposes an end-to-end two-branch network for a document image perceptual hashing scheme, where the two branches focus on image visual features and text features, respectively. Existing perceptual hashing schemes cannot solve the problem of the tiny proportion of text tampering detection, while simple text detection is unable to solve the problem of background region-aware matching. To address these issues, we extract text information via optical character recognition (OCR) and then generate the text features using the bidirectional encoder representations from Transformers (BERT). Visual features of the image are extracted from the local and global features of the image using ResNet and Vision Transformer cascades, and then fused to generate the final hash sequence through the fully connected layer. The proposed network considers both image visual features and textual information to verify that the document image has not been tampered with. In our network, the OCR module enables accurate and intelligent text detection and recognition, particularly for dealing with text tampering that has only been conducted in tiny portions. It also provides more efficient and robust text recognition services. Experimental results show that the proposed hashing scheme is robust and discriminative in document images.},
  archive  = {J},
  author   = {Xiaotong Situ and Tong Liu and Heng Yao and Chuan Qin and Xinpeng Zhang},
  doi      = {10.1109/TBDATA.2025.3596854},
  journal  = {IEEE Transactions on Big Data},
  month    = {8},
  pages    = {1-15},
  title    = {Document-image perceptual hashing for content authentication},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PatchAD: A lightweight patch-based MLP-mixer for time series anomaly detection. <em>TBD</em>, 1-15. (<a href='https://doi.org/10.1109/TBDATA.2025.3596745'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Time series anomaly detection is a pivotal task in data analysis, yet it poses the challenge of discerning normal and abnormal patterns in label-deficient scenarios. While prior studies have largely employed reconstruction-based approaches, which limit the models' representational capacities. Moreover, existing deep learning-based methods are not sufficiently lightweight. Addressing these issues, we present PatchAD, our novel, highly efficient multiscale patch-based MLP-Mixer architecture that utilizes contrastive learning for representation extraction and anomaly detection. With its four distinct MLP Mixers and innovative dual project constraint module, PatchAD mitigates potential model degradation and offers a lightweight solution, requiring only 0.403M parameters. Its efficacy is demonstrated by state-of-the-art results across 8 datasets sourced from different application scenarios, outperforming over 30 comparative algorithms. PatchAD significantly improves the classical F1 score by 6.84%, the Aff-F1 score by 4.27%, and the V-ROC by 2.49%. Simultaneously, an in-depth analysis of the mechanisms underlying PatchAD has been conducted from both theoretical and experimental perspectives, validating the design motivations of the model. The code is publicly available at https://github.com/EmorZz1G/PatchAD.},
  archive  = {J},
  author   = {Zhijie Zhong and Zhiwen Yu and Yiyuan Yang and Weizheng Wang and Kaixiang Yang and C. L. Philip Chen},
  doi      = {10.1109/TBDATA.2025.3596745},
  journal  = {IEEE Transactions on Big Data},
  month    = {8},
  pages    = {1-15},
  title    = {PatchAD: A lightweight patch-based MLP-mixer for time series anomaly detection},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identifying covert channels in blockchain: A case study on bitcoin, zcash, monero and ethereum. <em>TBD</em>, 1-11. (<a href='https://doi.org/10.1109/TBDATA.2025.3594241'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Blockchain has been an attractive platform both for covert channel and covert communication. Recent years have witnessed growing researches on achieving covert communication with blockchain applications. Identifying covert channels in blockchain is necessary and important to design blockchain based covert communication schemes. However, there still lacks a systematical method to analyze all possible covert channels in blockchain applications. In the paper, we propose a layer based covert channel identification method to analyze both covert storage channels and covert timing channels in blockchain applications. 11, 15, 14 and 19 new covert channels are identified in Bitcoin, Zcash, Monero and Ethereum with the proposed method, which proves the effectiveness of the method. The method is general and can be applied to identify covert channels in other blockchain applications, which lays foundation for both practical covert communication with blockchain applications and covert communication detection research.},
  archive  = {J},
  author   = {Tao Zhang},
  doi      = {10.1109/TBDATA.2025.3594241},
  journal  = {IEEE Transactions on Big Data},
  month    = {8},
  pages    = {1-11},
  title    = {Identifying covert channels in blockchain: A case study on bitcoin, zcash, monero and ethereum},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comprehensive privacy analysis on recommendation with causal embedding against model inversion attacks. <em>TBD</em>, 1-13. (<a href='https://doi.org/10.1109/TBDATA.2025.3594291'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In recommendation systems, the interactions between users and items are influenced by two factors: the user's conformity towards popular items and the user's real interest. Training individual user embeddings and item embeddings to capture these two factors can effectively improve the accuracy of recommendations. However, recommendation systems often exchange item embeddings with third-party servers, which may expose sensitive information to malicious attackers. Specifically, attackers can infer sensitive user information based on published item embeddings and partial public user information. In this paper, we first design a model inversion attack to analyze the influence of conformity item embeddings and interest item embeddings on privacy. This analysis reveals that different item embeddings have varying resistances against inversion attack. Based on the resistance levels of the two item embeddings, we propose a novel adaptive differential privacy protection method that enhances resistance against model inversion attacks while ensuring recommendation accuracy. We conduct experiments on three real datasets, and the results demonstrate the outstanding performance of our method in terms of both recommendation accuracy and resistance to inversion attack.},
  archive  = {J},
  author   = {Hanyang Liu and Yong Wang and Zhiqiang Zhang and Jiangzhou Deng and Yongdong Wang},
  doi      = {10.1109/TBDATA.2025.3594291},
  journal  = {IEEE Transactions on Big Data},
  month    = {8},
  pages    = {1-13},
  title    = {Comprehensive privacy analysis on recommendation with causal embedding against model inversion attacks},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PB-TABL: Task incremental learning strategy via applying piggyback architecture on temporal attention-augmented bilinear networks for financial time-series classification. <em>TBD</em>, 1-13. (<a href='https://doi.org/10.1109/TBDATA.2025.3598730'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {As financial markets continue to grow and generate vast volumes of data, there is a growing need for models capable of being updated incrementally. In this paper, we present PB-TABL, a novel method for financial time-series forecasting that integrates the piggyback (PB) architecture with Temporal Attention-Augmented Bilinear Networks (TABL). The proposed PB-TABL architecture addresses the challenges of task-incremental learning, including catastrophic forgetting, concept drift, and computational efficiency. By adapting pre-trained models through binary masks, PB-TABL enables efficient reuse of models for new tasks, significantly reducing training time and computational costs. We demonstrate the effectiveness of this approach through extensive experiments on large-scale Limit Order Book (LOB) data, where PB-TABL outperforms baseline models in terms of accuracy, F1 score, and overall computational efficiency. Our contributions include formulating the problem of adapting pre-trained neural networks to new financial data, introducing the PB-TABL architecture, and showing its advantages in handling time-series data with temporal dependencies while mitigating the risks of catastrophic forgetting and model degradation. All the data and implemented code are available here: https://github.com/rezapaki1376/PB-TABL.},
  archive  = {J},
  author   = {Reza Paki and Hossein Abbasimehr},
  doi      = {10.1109/TBDATA.2025.3598730},
  journal  = {IEEE Transactions on Big Data},
  month    = {8},
  pages    = {1-13},
  title    = {PB-TABL: Task incremental learning strategy via applying piggyback architecture on temporal attention-augmented bilinear networks for financial time-series classification},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DucDiff: Dual-consistent diffusion for uncertainty-aware information diffusion prediction. <em>TBD</em>, 1-15. (<a href='https://doi.org/10.1109/TBDATA.2025.3598713'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Information diffusion prediction is a vital component for a wide range of social applications, including viral marketing identification and personal recommendation. Prior methods primarily focus on learning target user representation by modeling contextual information from the historical retweet user sequence of a single cascade, overlooking the uncertainties that exist in both historical propagation trajectory and future diffusion trends. In this work, we propose DucDiff, a novel dual-consistent diffusion model for enhancing target user representation used for information diffusion prediction. DucDiff harnesses the distribution generation capability of the diffusion model to generate target user representations from a distributional perspective rather than a fixed vector. Specifically, it captures the multi-latent aspects (i.e., uncertainties) of target user representation from historical and future user sequences, respectively, using disentangled dual denoising modules. Additionally, a shared information bottleneck is designed for the cross-distillation of knowledge between the historical and future denoising modules, eliminating the performance gap between training and inference, while ensuring that future information can be implicitly introduced during the inference phase. Extensive experiments conducted on five datasets demonstrate that DucDiff significantly outperforms state-of-the-art baselines.},
  archive  = {J},
  author   = {Ting Zhong and Wenxue Ye and Shichong Li and Yang Liu and Zhangtao Cheng and Fan Zhou and Xueqin Chen},
  doi      = {10.1109/TBDATA.2025.3598713},
  journal  = {IEEE Transactions on Big Data},
  month    = {8},
  pages    = {1-15},
  title    = {DucDiff: Dual-consistent diffusion for uncertainty-aware information diffusion prediction},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). VDDFormer: A variable dependency discrepancy-based transformer for multivariate time series anomaly detection. <em>TBD</em>, 1-14. (<a href='https://doi.org/10.1109/TBDATA.2025.3600004'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The dynamics of multivariate time series (MTS) data are jointly characterized by its nonlinear temporal dependencies and complex variable dependencies, making unsupervised time series anomaly detection a challenging task. Existing methods primarily rely on prediction or reconstruction errors, neglecting the valuable information within the variable dependencies. In this paper, we propose a variable dependency discrepancy-based Transformer (VDDFormer) for unsupervised MTS anomaly detection. VDDFormer comprises a variable correlation encoder, a temporal dependency encoder, and a reconstruction decoder. The variable correlation encoder capitalizes on a variable dependency attention mechanism, which employs self-attention to learn the global variable dependencies; meanwhile, the local variable dependencies are captured by the adaptive correlation matrix. The global and local variable dependencies are then used to compute the variable dependency discrepancy as a new intrinsic property to distinguish between normal and abnormal patterns. By integrating this new discrepancy with the reconstruction error, the model effectively enhances its anomaly differentiation capability. Extensive experiments on five real-world anomaly detection datasets demonstrate that VDDFormer effectively and robustly detects group anomaly patterns by leveraging the variable dependency discrepancy and achieves state-of-the-art performance on four out of the five datasets.},
  archive  = {J},
  author   = {Bo Liu and Lingling Tao and Xiaodan Chen and Zhijun Li},
  doi      = {10.1109/TBDATA.2025.3600004},
  journal  = {IEEE Transactions on Big Data},
  month    = {8},
  pages    = {1-14},
  title    = {VDDFormer: A variable dependency discrepancy-based transformer for multivariate time series anomaly detection},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intent-driven semantic query: An effective approach for temporal knowledge graph query. <em>TBD</em>, 1-13. (<a href='https://doi.org/10.1109/TBDATA.2025.3600035'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The temporal knowledge graph (TKG) query facilitates the retrieval of potential answers by parsing questions that incorporate temporal constraints, regarded as a vital downstream task in the broader spectrum of the TKG applications. Currently, enhancing the accuracy of the queries and the user experience has become a focal point for researchers. Existing query methods of the TKG aim to execute unambiguous standard query statements to return query results while neglecting the potential ambiguity in user input queries. To overcome this problem, in this paper, we propose a semantic query model for temporal knowledge graphs, TKGSQ-PM (Temporal Knowledge Graph Semantic Query based on Pre-trained Model). This model first identifies and extracts entity and temporal information from temporal knowledge graph queries and obtains corresponding temporal knowledge graph embedding information based on embedding methods. Then, it utilizes the pre-trained model DistilBERT to infer the true query intent from user input queries. Finally, it performs comprehensive sorting to return highquality query results. We conduct multiple experiments on three different datasets to demonstrate the efficiency and effectiveness of the proposed methods. Experimental results indicate that the TKGSQ-PM model has an overall advantage over baseline models in terms of query effectiveness and efficiency.},
  archive  = {J},
  author   = {Luyi Bai and Jixuan Dong and Lin Zhu},
  doi      = {10.1109/TBDATA.2025.3600035},
  journal  = {IEEE Transactions on Big Data},
  month    = {8},
  pages    = {1-13},
  title    = {Intent-driven semantic query: An effective approach for temporal knowledge graph query},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sentences based adversarial attack on AI-generated text detectors. <em>TBD</em>, 1-12. (<a href='https://doi.org/10.1109/TBDATA.2025.3600034'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The widespread use of AI-generated text has introduced significant security concerns, driving the need for reliable detection systems. However, recent studies reveal that neural network-based detectors are vulnerable to adversarial examples. To improve the robustness of such classifiers, a number of adversarial attack strategies have been developed, particularly in the context of text sentiment classification. Most existing adversarial attack methods focus on the semantics of individual words or sentences, often neglecting the broader contextual semantics of the entire text-particularly in the case of long AI-generated text. This limitation frequently results in adversarial examples that lack fluency and coherence. In this paper, we propose a novel method called Sentence-based Adversarial attack on AI-Generated Text detectors (SAGT), which generates linguistically fluent adversarial examples by inserting model-generated sentences into the original text. To ensure contextual semantic consistency, we extract important keywords from the original text-selected based on changes in the detector's confidence score-and incorporate them into the generated sentences. Extensive experimental results demonstrate that adversarial examples crafted by SAGT can effectively evade AI-generated text detectors.},
  archive  = {J},
  author   = {Rongxin Tu and Xiangui Kang and Chee Wei Tan and Chi-Hung Chi and Kwok-Yan Lam},
  doi      = {10.1109/TBDATA.2025.3600034},
  journal  = {IEEE Transactions on Big Data},
  month    = {8},
  pages    = {1-12},
  title    = {Sentences based adversarial attack on AI-generated text detectors},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Can GNNs learn link heuristics? a concise review and evaluation of link prediction methods. <em>TBD</em>, 1-15. (<a href='https://doi.org/10.1109/TBDATA.2025.3600031'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {This paper explores the ability of Graph Neural Networks (GNNs) in learning various forms of information for link prediction, alongside a brief review of existing link prediction methods. Our analysis reveals that GNNs cannot effectively learn structural information related to the number of common neighbors between two nodes, primarily due to the nature of set-based pooling of the neighborhood aggregation scheme. Also, our extensive experiments indicate that trainable node embeddings can improve the performance of GNN-based link prediction models. Importantly, we observe that the denser the graph, the greater such the improvement. We attribute this to the characteristics of node embeddings, where the link state of each link sample could be encoded into the embeddings of nodes that are involved in the neighborhood aggregation of the two nodes in that link sample. In denser graphs, every node could have more opportunities to attend the neighborhood aggregation of other nodes and encode states of more link samples to its embedding, thus learning better node embeddings for link prediction. Lastly, we demonstrate that the insights gained from our research carry important implications in identifying the limitations of existing link prediction methods, which could guide the future development of more robust algorithms.},
  archive  = {J},
  author   = {Shuming Liang and Yu Ding and Zhidong Li and Bin Liang and Siqi Zhang and Yang Wang and Fang Chen},
  doi      = {10.1109/TBDATA.2025.3600031},
  journal  = {IEEE Transactions on Big Data},
  month    = {8},
  pages    = {1-15},
  title    = {Can GNNs learn link heuristics? a concise review and evaluation of link prediction methods},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ST-DDGAN: A traffic data compensation model based on image restoration technology. <em>TBD</em>, 1-18. (<a href='https://doi.org/10.1109/TBDATA.2025.3600037'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In Intelligent Transportation Systems (ITS), the accuracy of compensating for missing traffic data is critical. This directly impacts the effectiveness of traffic flow prediction and road condition monitoring. Inspired by image restoration techniques, this study introduces the Generative Adversarial Network (GAN) to enhance traffic data compensation. Firstly, to address the problem of converting traffic data into the traffic flow matrix of the road network, we propose the RoadNetIMatrix algorithm to generate the traffic flow matrix of the road network. This algorithm precisely captures traffic flow dynamics in road networks and provides a holistic representation of traffic states. Secondly, given the inherent spatio-temporal correlation in traffic data, we proposed a spatio-temporal collaborative mining component (STSSM). This component integrates the hidden temporal dependencies and spatial features of the mined traffic data into the GAN generator to improve the authenticity of the generated content and ensure the consistency of data compensation. Finally, addressing the influence of external characteristics of traffic data on data compensation results, an external information module based on a multi-head attention mechanism is constructed, which can effectively mine the influence of external factors of traffic data. Furthermore, spatio-temporal and external features are fused to further improve the accuracy of data compensation. Experiments show that the model has a higher accuracy of data compensation and a better generalization of the system in the case of multiple types or a high data loss rate.},
  archive  = {J},
  author   = {Rong Wang and Na Lv and Xing Huang and Qingwang Guo and Yunpeng Xiao and Chaolong Jia and Haofei Xie},
  doi      = {10.1109/TBDATA.2025.3600037},
  journal  = {IEEE Transactions on Big Data},
  month    = {8},
  pages    = {1-18},
  title    = {ST-DDGAN: A traffic data compensation model based on image restoration technology},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TAG: Triple alignment with rationale generation for knowledge-based visual question answering. <em>TBD</em>, 1-16. (<a href='https://doi.org/10.1109/TBDATA.2025.3600012'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Knowledge-based Visual Question Answering (VQA) involves answering questions based not only on the given image, but also on external knowledge. Existing methods for knowledge-based VQA can be classified into two main categories: those that rely on external knowledge bases, and those that use Large Language Models (LLMs) as implicit knowledge engines. However, the former approach heavily relies on the quality of information retrieval, introducing additional information bias to the entire system. And the latter approach suffers from the extremely high computational cost and the loss of image information. To address these issues, we propose a novel framework called TAG that reformulates knowledge-based VQA as a contrastive learning problem. We innovatively propose a triple asymmetric paradigm, which aligns a lightweight text encoder to the image space with an extremely low training cost (0.0152B trainable parameters), and enhance its understanding ability on semantic granularity. TAG is both computation-efficient and effective, and we evaluate it on the knowledge-based VQA datasets, A-OKVQA, OK-VQA and VCR. The results show that TAG (0.387B) achieves the state-of-the-art performance when compared to methods using less than 1B parameters. Besides, TAG still shows competitive performance when compared to methods with LLM.},
  archive  = {J},
  author   = {Sihang Cai and Xuan Lin and Wenqiang Xu and Jingtong Wu and Tao Jin and Zhou Zhao and Fei Wu and Jun Yu},
  doi      = {10.1109/TBDATA.2025.3600012},
  journal  = {IEEE Transactions on Big Data},
  month    = {8},
  pages    = {1-16},
  title    = {TAG: Triple alignment with rationale generation for knowledge-based visual question answering},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-modal entity in one word: Aligning multi-level semantics for multi-modal knowledge graph completion. <em>TBD</em>, 1-14. (<a href='https://doi.org/10.1109/TBDATA.2025.3600014'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Current multi-modal knowledge graph completion often incorporates simple fusion neural networks to achieve multi-modal alignment and knowledge completion tasks, which face three major challenges: 1) Inconsistent semantics between images and texts corresponding to the same entity; 2) Discrepancies in semantic spaces resulting from the use of diverse uni-modal feature extractors;3) Inadequate evaluation of semantic alignment using only energy functions or basic contrastive learning losses. To address these challenges, we propose the Multi-modal Entity in One Word (MEOW) model. This model ensures alignment at various levels, including text-image match alignment, feature alignment and distribution alignment. Specificially, the entity image filtering module utilizes a visual-language model to exclude unrelated images by aligning their captions with corresponding text descriptions. A pre-trained CLIP-based encoder is utilized for encoding dense semantic relationships, while a graph attention network based structure encoder handles sparse semantic relationships, yielding a comprehensive semantic representation and enhancing convergence speed. Additionally, a diffusion model is integrated to enhance denoising capabilities. The proposed MEOW further includes a distribution alignment module equipped with dense alignment constraint, integrity alignment constraint, and fusion fidelity constraint to effectively align multi-modal representations. Experiments on two public multi-modal knowledge graph datasets show that MEOW significantly improves link prediction performance. The code of the proposed model is available at https://github.com/yuyuyuger/MEOW.},
  archive  = {J},
  author   = {Lan Zhao and Boyue Wang and Junbin Gao and Xiaoyan Li and Yongli Hu and Baocai Yin},
  doi      = {10.1109/TBDATA.2025.3600014},
  journal  = {IEEE Transactions on Big Data},
  month    = {8},
  pages    = {1-14},
  title    = {Multi-modal entity in one word: Aligning multi-level semantics for multi-modal knowledge graph completion},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Community-imbalanced graph sampling. <em>TBD</em>, 1-14. (<a href='https://doi.org/10.1109/TBDATA.2025.3600032'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {A community-imbalanced graph refers to a graph containing multiple communities with large differences in node and edge scales. Graph sampling is a widely used graph reduction technique to accelerate graph computations and simplify graph visualizations. However, existing graph sampling algorithms may encounter several problems, including the loss of small communities, disconnections between communities, and distortions of community scale distribution, on maintaining the community structures in a community-imbalanced graph. In this work, a new quality indicator is proposed to determine if a graph can be regarded as a community-imbalanced graph. A community-imbalanced graph sampling (CIGS) algorithm is proposed to address the community-imbalanced graph sampling problems. Three new evaluation metrics are proposed to assess the performance of community structure maintenance of graph sampling. An algorithm performance experiment and a user study are conducted to evaluate the effectiveness of the proposed CIGS.},
  archive  = {J},
  author   = {Ying Zhao and Genghuai Bai and Yusheng Qiu and Yiwen Liu and Chuhan Zhang and Chi Han and Yitao Wu and Kehua Guo and Jian Zhang and Fangfang Zhou},
  doi      = {10.1109/TBDATA.2025.3600032},
  journal  = {IEEE Transactions on Big Data},
  month    = {8},
  pages    = {1-14},
  title    = {Community-imbalanced graph sampling},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SDEC: Semantic deep embedded clustering. <em>TBD</em>, 1-16. (<a href='https://doi.org/10.1109/TBDATA.2025.3603433'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The high dimensional and semantically complex nature of textual Big data presents significant challenges for text clustering, which frequently lead to suboptimal groupings when using conventional techniques like k-means or hierarchical clustering. This work presents Semantic Deep Embedded Clustering (SDEC), an unsupervised text clustering framework that combines an improved autoencoder with transformer-based embeddings to overcome these challenges. This novel method preserves semantic relationships during data reconstruction by combining Mean Squared Error (MSE) and Cosine Similarity Loss (CSL) within an autoencoder. Furthermore, a semantic refinement stage that takes advantage of the contextual richness of transformer embeddings is used by SDEC to further improve a clustering layer with soft cluster assignments and distributional loss. The capabilities of SDEC are demonstrated by extensive testing on five benchmark datasets: AG News, Yahoo! Answers, DBPedia, Reuters 2, and Reuters 5. The framework not only outperformed existing methods with a clustering accuracy of 85.7% on AG News and set a new benchmark of 53.63% on Yahoo! Answers, but also showed robust performance across other diverse text corpora. These findings highlight the significant improvements in accuracy and semantic comprehension of text data provided by SDEC's advances in unsupervised text clustering.},
  archive  = {J},
  author   = {Mohammad Wali Ur Rahman and Ric Nevarez and Lamia Tasnim Mim and Salim Hariri},
  doi      = {10.1109/TBDATA.2025.3603433},
  journal  = {IEEE Transactions on Big Data},
  month    = {8},
  pages    = {1-16},
  title    = {SDEC: Semantic deep embedded clustering},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing deduplication parameters via a change-estimation analytical model. <em>TBD</em>, 1-12. (<a href='https://doi.org/10.1109/TBDATA.2025.3604171'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Variable-sized, content-defined deduplication is a technique to find and eliminate redundant chunks of data for efficient data backups, reduced data transfers, and reduced data-storage overheads. For big datasets, especially with incremental updates over time such as backups and gathered data, deduplication makes data management faster and more efficient. While many existing deduplication systems use default expected chunk lengths such as 4 KB or 8 KB, they are suboptimal. Poorly optimized deduplication systems can significantly increase storage costs and network usage, making large datasets prohibitively expensive to manage. We present the design, implementation, and an empirical validation of our Deduplication Change-Estimation Analytical Model (DCAM) which predicts the performance of sliding window-based deduplication parameters on any given dataset, to be used for parameter optimization. Our empirical evaluation includes workloads based on source code (Linux kernel, Kubernetes, TensorFlow), open-research datasets (CORD-19), and articles (Wikipedia). Validated using both our system and the Destor deduplication system, a DCAM-based search finds deduplication parameters that require up to 3.8× less storage relative to a common baseline. DCAM Search optimizes parameters up to 19.8× faster than previously possible, and the size of the resulting deduplicated datasets are all within 5.15% of the best results found by searching using actual deduplication.},
  archive  = {J},
  author   = {Owen Randall and Luke Schultz and Paul Lu},
  doi      = {10.1109/TBDATA.2025.3604171},
  journal  = {IEEE Transactions on Big Data},
  month    = {8},
  pages    = {1-12},
  title    = {Optimizing deduplication parameters via a change-estimation analytical model},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ScProGraph: A cell bagging strategy for cell type annotation with gene interaction-aware explainability. <em>TBD</em>, 1-12. (<a href='https://doi.org/10.1109/TBDATA.2025.3604169'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The rapid advancement of scRNA-seq has generated massive data for cell type annotation. However, current automated annotation methods remain limited: most approaches separately model either cell-cell similarities or gene-gene relationships, neglecting their synergistic effects, which leads to suboptimal accuracy and poor biological interpretability. To address this, we propose scProGraph, a prototype-guided graph neural network that jointly models cell type classification and functional gene subgraph discovery. By constructing a cell similarity graph and incorporating cell-type prototypes as prior anchors, our method simultaneously optimizes classification boundaries and the interpretability of gene subgraphs. Experiments on seven independent datasets spanning three disease categories demonstrate that scProGraph achieves over 90% accuracy on four datasets and exceeds 80% on six datasets, outperforming state-of-the-art methods. Further analysis reveals that the gene subgraphs extracted by scProGraph for Macrophage, Fibroblast, and Monocyte cover 26.92%, 26.83%, and 22.22% of a protein-protein interaction networks dataset, respectively, validating the biological relevance of the identified gene modules. This study not only provides a high-accuracy tool for single-cell annotation but also opens new avenues for discovering novel biomarkers and regulatory mechanisms through gene relationship mining.},
  archive  = {J},
  author   = {Xinyuan Li and Yue-Chao Li and Hai-Ru You and Xuequn Shang and Leon Wong and Zhi-An Huang and Zhu-Hong You and Yu-An Huang},
  doi      = {10.1109/TBDATA.2025.3604169},
  journal  = {IEEE Transactions on Big Data},
  month    = {8},
  pages    = {1-12},
  title    = {ScProGraph: A cell bagging strategy for cell type annotation with gene interaction-aware explainability},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal transport barycentric aggregation for byzantine-resilient federated learning. <em>TBD</em>, 1-12. (<a href='https://doi.org/10.1109/TBDATA.2025.3604177'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Federated learning (FL) has emerged as a promising solution to enable distributed learning without sharing sensitive data. However, FL is vulnerable to data poisoning attacks, where malicious clients inject malicious data during training to compromise the global model. Existing FL defenses suffer from the assumptions of independent and identically distributed (IID) model updates, asymptotic optimal error rate bounds, and strong convexity in the optimization problem. Hence, we propose a novel framework called Federated Learning Optimal Transport (FLOT) that leverages the Wasserstein barycentric technique to obtain a global model from a set of locally trained non-IID models on client devices. In addition, we introduce a loss function-based rejection (LFR) mechanism to suppress malicious updates and a dynamic weighting scheme to optimize the Wasserstein barycentric aggregation function. We provide the theoretical proof of the Byzantine resilience and convergence of FLOT to highlight its efficacy. We evaluate FLOT on four benchmark datasets: GTSRB, KBTS, CIFAR10, and EMNIST. The experimental results underscore the practical significance of FLOT as an effective defense mechanism against data poisoning attacks in FL while maintaining high accuracy and scalability. Also, we observe that FLOT serves as a robust client selection technique under no attack, which demonstrates its effectiveness.},
  archive  = {J},
  author   = {K Naveen Kumar and Srinivasa Rao Chalamala and Ajeet Kumar Singh and C Krishna Mohan},
  doi      = {10.1109/TBDATA.2025.3604177},
  journal  = {IEEE Transactions on Big Data},
  month    = {8},
  pages    = {1-12},
  title    = {Optimal transport barycentric aggregation for byzantine-resilient federated learning},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MuGNet-CMI: Multi-head hybrid graph neural network for predicting circRNA-miRNA interactions with global high-order and local low-order information. <em>TBD</em>, 1-15. (<a href='https://doi.org/10.1109/TBDATA.2025.3604175'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Circular RNAs (circRNAs) are non-coding RNA molecules that play a crucial role in regulating genes and contributing to disease progression. CircRNAs can function as sponges for microRNAs (miRNAs), thereby regulating gene expression and influencing disease outcomes. Identifying associations between circRNAs and miRNAs through computational methods enhances the understanding of complex disease mechanisms and offers a reliable tool for pre-selecting candidates for experimental validation. Existing models, however, are limited in their ability to capture either global or local node information, the prediction of circRNA and miRNA interactions is still challenging. In order to effectively deal with this problem, we propose a novel framework for predicting circRNA-miRNA interactions (CMIs), known as MuGNet-CMI, which leverages multi-head hybrid graph neural network and global high-order and local low-order information. The model employs the MetaPath2Vec algorithm to generate high-quality node embeddings within the circRNA-miRNA heterogeneous matrix. The multi-head dynamic attention mechanism, combined with GraphSAGE, is incorporated to efficiently capture both global high-order and local low-order node information. Additionally, we integrate neural aggregators into the multi-head dynamic attention mechanism to aggregate feature information from the captured nodes. Validation using three real datasets demonstrates that MuGNet-CMI delivers good performance in predicting CMIs, offering valuable insights to guide experimental research in gene regulation.},
  archive  = {J},
  author   = {Chen Jiang and Lei Wang and Changqing Yu and Zhuhong You and Xinfei Wang and Mengmeng Wei and Mianshuo Lu},
  doi      = {10.1109/TBDATA.2025.3604175},
  journal  = {IEEE Transactions on Big Data},
  month    = {8},
  pages    = {1-15},
  title    = {MuGNet-CMI: Multi-head hybrid graph neural network for predicting circRNA-miRNA interactions with global high-order and local low-order information},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ImAdv: Transferable implicit adversarial attack for 3D object detectors in autonomous driving. <em>TBD</em>, 1-14. (<a href='https://doi.org/10.1109/TBDATA.2025.3588083'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {3D adversarial attacks have garnered significant attention in the realm of autonomous driving security due to their high feasibility and multi-view effectiveness. However, existing 3D attacks have limited transferability, primarily due to their overfitting to surrogate models. To address this limitation, we introduce a novel 3D adversarial attack method based on implicit texture modeling, termed ImAdv, against 3D object detection models. Specifically, ImAdv utilizes a positional encoder and a MLP to map the 3D coordinates of an object's surface to the RGB color space, thereby reformulating the object's texture within an implicit framework. This method significantly reduces the parameter number for color modeling, thus mitigating overfitting and improving transferability. Furthermore, we propose two innovative techniques to enhance the transferability, Random Texture Reset (RandReset) and Texture Model Averaging. RandReset randomly restores portions of the adversarial texture, increasing the training set diversity and mitigating overfitting. Texture Model Averaging employs self-ensembling of multiple texture checkpoints during the training phase to reduce overfitting in the final texture model. Comprehensive experiments demonstrate the superiority of our methods, which outperform previous methods by 17.18% in average black-box attack success rate. Additionally, our method shows strong transferability and practicality in zero-shot cross-task attacks and physical attacks.},
  archive  = {J},
  author   = {Zijian Zhu and Xiao Yang and Hang Su and Shu Zhao and Shibao Zheng},
  doi      = {10.1109/TBDATA.2025.3588083},
  journal  = {IEEE Transactions on Big Data},
  month    = {7},
  pages    = {1-14},
  title    = {ImAdv: Transferable implicit adversarial attack for 3D object detectors in autonomous driving},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view spectral clustering on the grassmannian manifold with hypergraph representation. <em>TBD</em>, 1-12. (<a href='https://doi.org/10.1109/TBDATA.2025.3588078'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Graph-based multi-view spectral clustering methods have achieved notable progress recently, yet they often fall short in either oversimplifying pairwise relationships or struggling with inefficient spectral decompositions in high-dimensional Euclidean spaces. In this paper, we introduce a novel approach that begins to generate hypergraphs by leveraging sparse representation learning from data points. Based on the generated hypergraph, we propose an optimization function with orthogonality constraints for multi-view hypergraph spectral clustering, which incorporates spectral clustering for each view and ensures consistency across different views. In Euclidean space, solving the orthogonality-constrained optimization problem may yield local maxima and approximation errors. Innovately, we transform this problem into an unconstrained form on the Grassmannian manifold. Finally, we devise an alternating iterative Riemannian optimization algorithm to solve the problem. To validate the effectiveness of the proposed algorithm, we test it on four real-world multi-view datasets and compare its performance with six state-of-the-art multi-view clustering algorithms. The experimental results demonstrate that our method outperforms the baselines in terms of clustering performance due to its superior low-dimensional and resilient feature representation.},
  archive  = {J},
  author   = {Murong Yang and Shihui Ying and Xin-Jian Xu and Yue Gao},
  doi      = {10.1109/TBDATA.2025.3588078},
  journal  = {IEEE Transactions on Big Data},
  month    = {7},
  pages    = {1-12},
  title    = {Multi-view spectral clustering on the grassmannian manifold with hypergraph representation},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prediction of multivariate spatial-temporal series data based on adaptive spatial-temporal information. <em>TBD</em>, 1-13. (<a href='https://doi.org/10.1109/TBDATA.2025.3588086'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {This paper proposes an Prediction of Multivariate Spatial-Temporal Series Data Based on Adaptive Spatial-Temporal Information(ASTCN), which learns complex spatio-temporal information from multivariate spatio-temporal series through trainable temporal embeddings and graph adjacency matrices. A gated fusion mechanism is employed to control the proportion of different temporal embeddings to improve prediction accuracy. Visualization of the temporal embeddings reveals that weekly temporal embeddings have the greatest impact on prediction accuracy, followed by daily temporal embeddings, while monthly temporal embeddings have the least impact. Additionally, a novel method for constructing graph adjacency matrices is introduced. Ablation experiments demonstrate that the two types of graph adjacency matrices proposed in this method have varying degrees of influence on improving the prediction accuracy of the dataset. Consequently, this paper integrates the two graph adjacency matrices, enabling ASTCN to achieve superior prediction accuracy on traffic speed, traffic flow, and air quality datasets compared to when either matrix is used alone. In comparative experiments, ASTCN ultimately achieves excellent prediction performance with relatively low training costs.},
  archive  = {J},
  author   = {Chen An and Zibao Lu and Yuru Ma and Weiwei Zhao and Xinyi Chen},
  doi      = {10.1109/TBDATA.2025.3588086},
  journal  = {IEEE Transactions on Big Data},
  month    = {7},
  pages    = {1-13},
  title    = {Prediction of multivariate spatial-temporal series data based on adaptive spatial-temporal information},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Determination of the number of clusters in high-dimensional data with subspace clusters. <em>TBD</em>, 1-14. (<a href='https://doi.org/10.1109/TBDATA.2025.3588027'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Current big data clustering methods pose a challenge to efficiently estimate the number of clusters when dealing with a large number of instances and dimensions. However, determining the large number of clusters in a high-dimensional dataset is difficult due to the conflicting nature of its subspaces. In this paper, we propose a new distributed clustering ensemble method called subspace cluster ensemble (SSCE) to find the number of clusters in big high-dimensional datasets with informative subspace clusters. We represent the high-dimensional dataset as a set of random subspaces, and then in each subspace view, we investigate the number of clusters and initial cluster centers with the I-niceDP clustering scheme. To efficiently handle big data (i.e., a large number of instances with high dimensions), we use multiple random samples of a big dataset to estimate the number of clusters. With this aim, we first adopt the random sample partitioning (RSP) data model to facilitate random sample generation and then apply the subspace cluster estimation scheme. To do so, each random sample (i.e., RSP data block) is processed independently in parallel, and subspace clustering components are generated. A novel two-stage clustering ensemble, ball fusion (BF), is proposed to estimate the final result from the subspace clustering components and multiple RSP sample outcomes. Subspace and full-space clusters induce key connections within subspaces to generate the final ensemble outcome. Results from experiments on synthetic and real-world datasets demonstrated the effectiveness of the proposed method, which outperformed the state-of-the-art baselines.},
  archive  = {J},
  author   = {Mohammad Sultan Mahmud and Joshua Zhexue Huang and Germán González-Almagro and Salvador García},
  doi      = {10.1109/TBDATA.2025.3588027},
  journal  = {IEEE Transactions on Big Data},
  month    = {7},
  pages    = {1-14},
  title    = {Determination of the number of clusters in high-dimensional data with subspace clusters},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Disentangled graph contrastive learning for socially-aware next-item recommendation. <em>TBD</em>, 1-14. (<a href='https://doi.org/10.1109/TBDATA.2025.3588077'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Next-item recommendation has received considerable attention in academia and industry, which aims to predict the next desired item for each user based on his historical behaviors. It has been validated that user behaviors are driven by two key factors: social influence, which leverages social relationships to better infer user preference, and sequential influence, which captures item transition patterns to model the dynamic evolution of user interest. While previous next-item recommenders have made great progress, we argue that there still exist three critical limitations: (1) they always follow the paradigm of entangling social and sequential influences, resulting in poor interpretability; (2) they fail to explicitly capture high-order influences at social-level and sequential-level, resulting in the suboptimal performance; (3) they fail to dynamically distinguish the importance of each influence factor when predicting user preference. To settle these three defects, we contribute a novel solution for socially-aware next-item recommendation, namely Disentangled Graph Contrastive Learning (DGCL) method, which explicitly disentangles social and sequential influences on user behavior data. Specifically, we first reorganize social relationships and all users' behavior sequences as two separate graphs. Then, a disentangled graph propagation module is developed on these two graphs to independently capture high-order influences at social-level and sequential-level. Furthermore, we formalize a dual contrastive learning paradigm as an auxiliary task to supervise the thorough disentanglement. Finally, we devise a user-specific attention mechanism to adaptively differentiate the importance of each influence factor for model prediction. Empirical results on four benchmark datasets demonstrate the superiority of DGCL over recent state-of-the-art recommenders. Further analysis verifies the rationality and necessity of each part in our solution. Our implemented codes and used datasets are available at https://github.com/wubinzzu/DGCL.},
  archive  = {J},
  author   = {Bin Wu and Xun Su and Long Chen and Jing Liang and Yangdong Ye},
  doi      = {10.1109/TBDATA.2025.3588077},
  journal  = {IEEE Transactions on Big Data},
  month    = {7},
  pages    = {1-14},
  title    = {Disentangled graph contrastive learning for socially-aware next-item recommendation},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Effective and efficient conductance-based community search at billion scale. <em>TBD</em>, 1-14. (<a href='https://doi.org/10.1109/TBDATA.2025.3588028'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Community search is a widely studied semi-supervised graph clustering problem, retrieving a high-quality connected subgraph containing the user-specified query vertex. However, existing methods primarily focus on cohesiveness within the community but ignore the sparsity outside the community, obtaining sub-par results. Inspired by this, we adopt the well-known conductance metric to measure the quality of a community and introduce a novel problem of conductance-based community search (CCS). CCS aims at finding a subgraph with the smallest conductance among all connected subgraphs that contain the query vertex. We prove that the CCS problem is NP-hard. To efficiently query CCS, a four-stage subgraph-conductance-based community search algorithm, SCCS, is proposed. Specifically, we first greatly reduce the entire graph using local sampling techniques. Then, a three-stage local optimization strategy is employed to continuously refine the community quality. Namely, we first utilize a seeding strategy to obtain an initial community to enhance its internal cohesiveness. Then, we iteratively add qualified vertices in the expansion stage to guarantee the internal cohesiveness and external sparsity of the community. Finally, we gradually remove unqualified vertices during the verification stage. Extensive experiments on real-world datasets containing one billion-scale graph and synthetic datasets show the effectiveness, efficiency, and scalability of our solutions.},
  archive  = {J},
  author   = {Longlong Lin and Yue He and Wei Chen and Pingpeng Yuan and Rong-Hua Li and Tao Jia},
  doi      = {10.1109/TBDATA.2025.3588028},
  journal  = {IEEE Transactions on Big Data},
  month    = {7},
  pages    = {1-14},
  title    = {Effective and efficient conductance-based community search at billion scale},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GTPool: Graph transformer pooling with diverse sampling. <em>TBD</em>, 1-13. (<a href='https://doi.org/10.1109/TBDATA.2025.3588080'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Graph pooling techniques have emerged as powerful tools for downsampling graphs, yielding impressive results on various graph-level tasks like graph classification and generation. Node dropping pooling stands out as a significant approach in this domain, utilizing learnable scoring functions to drop nodes with relatively lower significance. However, previous node dropping methods face two critical limitations: (1) they often struggle to capture long-range dependencies effectively for each pooled node, potentially limiting the expressiveness of node representations. (2) by exclusively retaining the highest-scoring nodes, they tend to preserve similar nodes, thereby discarding valuable information residing in low-scoring nodes; To address these issues, we propose a novel Graph Transformer Pooling method termed GTPool. GTPool constructs a node dropping pooling layer based on the Transformer architecture, aiming to efficiently capture long-range pairwise interactions while promoting diverse sampling. A key component of GTPool is its scoring module, grounded in the self-attention mechanism, which assesses the relevance between node representations and the graph representation. This nuanced approach offers a more natural means of measuring node importance. Additionally, GTPool adopts Roulette Wheel Sampling (RWS), a diversified sampling method that is capable of preserving nodes across various scoring intervals, rather than solely focusing on higher-scoring nodes. Consequently, GTPool can effectively capture long-range information and identify more representative nodes, thereby outperforming existing popular graph pooling methods across 14 benchmark datasets.},
  archive  = {J},
  author   = {Gaichao Li and Jinsong Chen and Kun He},
  doi      = {10.1109/TBDATA.2025.3588080},
  journal  = {IEEE Transactions on Big Data},
  month    = {7},
  pages    = {1-13},
  title    = {GTPool: Graph transformer pooling with diverse sampling},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient FCTN decomposition with structural sparsity for noisy tensor completion. <em>TBD</em>, 1-15. (<a href='https://doi.org/10.1109/TBDATA.2025.3588029'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Recently, the fully-connected tensor network (FCTN) decomposition has shown a powerful capability of depicting intrinsic correlations between any pair of tensor modes. But there exists a challenging question in FCTN decomposition-based methods, i.e., the accurate determination of the complicated FCTN-rank, which contains ${N(N-1)}/{2}$ elements for $N$th-order tensors. In this paper, we design a structural sparsity regularization for the FCTN decomposition, which estimates the complicated FCTN-rank by adaptively pruning near-zero groups in FCTN factor. Based on this regularization, we propose a noisy tensor completion (NTC) model, aiming at the recovery of a tensor from its partial and noisy observation. Besides, we design a proximal alternating minimization (PAM)-based algorithm to solve the model. In theorem, we prove a guarantee for the global convergence of the developed algorithm. To further accelerate our method for large-scale data sets, we customize the randomized block sampling strategy for general tensor network decomposition methods by updating factors from small samples. Experiments demonstrate that our strategy can accurately estimate the FCTN-rank and achieve better reconstruction performances, and our methods outperform the state-of-the-art methods in the reconstruction of different types of real-world tensors.},
  archive  = {J},
  author   = {Wei-Jian Huang and Li Huang and Tai-Xiang Jiang and Yu-Bang Zheng and Guisong Liu},
  doi      = {10.1109/TBDATA.2025.3588029},
  journal  = {IEEE Transactions on Big Data},
  month    = {7},
  pages    = {1-15},
  title    = {Efficient FCTN decomposition with structural sparsity for noisy tensor completion},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A pluggable common sense-enhanced framework for knowledge graph completion. <em>TBD</em>, 1-18. (<a href='https://doi.org/10.1109/TBDATA.2025.3588081'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Knowledge graph completion (KGC) tasks aim to infer missing facts in a knowledge graph (KG) for many knowledgeintensive applications. However, existing embedding-based KGC approaches primarily rely on factual triples, potentially leading to outcomes inconsistent with common sense. Besides, generating explicit common sense is often impractical or costly for a KG. To address these challenges, we propose a pluggable common sense-enhanced KGC framework that incorporates both fact and common sense for KGC. This framework is adaptable to different KGs based on their entity concept richness and has the capability to automatically generate explicit or implicit common sense from factual triples. Furthermore, we introduce common senseguided negative sampling and a coarse-to-fine inference approach for KGs with rich entity concepts. For KGs without concepts, we propose a dual scoring scheme involving a relation-aware concept embedding mechanism. Importantly, our approach can be integrated as a pluggable module for many knowledge graph embedding (KGE) models, facilitating joint common sense and fact-driven training and inference. The experiments illustrate that our framework exhibits good scalability and outperforms existing models across various KGC tasks.},
  archive  = {J},
  author   = {Guanglin Niu and Bo Li and Siling Feng},
  doi      = {10.1109/TBDATA.2025.3588081},
  journal  = {IEEE Transactions on Big Data},
  month    = {7},
  pages    = {1-18},
  title    = {A pluggable common sense-enhanced framework for knowledge graph completion},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robustness benchmarking of convolutional and transformer architectures for image classification. <em>TBD</em>, 1-12. (<a href='https://doi.org/10.1109/TBDATA.2025.3593385'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Amidst the burgeoning landscape of thousands of deep convolutional neural networks (CNNs), selecting a robust architecture for image classification poses a formidable challenge. The prime reason is the broad vulnerability of these DNNs to image corruption. The literature still does not understand which network is sensitive to which kind of corruption and to what extent. Our study rigorously analyzes DNNs across the classification spectrum, from pure CNNs (without attention layers) to state-of-the-art Vision Transformers (ViTs). To reach a robust conclusion, we have performed extensive experiments using 18 DNNs, 5 diverse datasets, and 15 corruption types of varying severity. Our analysis uncovers insightful and surprising findings concerning the robustness of different DNNs across corruption types. For example, it is observed that the ViT trained on CIFAR10 is found to be highly robust in handling noise corruptions, even of considerable severity (say, severity 4), but is found vulnerable to environmental corruptions of the same severity. At the same time, while the performance of pure CNNs is lower than that of ViT, they can handle environmental factors better than noise corruption. Another interesting observation showcased that these corruptions can even fool one of the popular network explainability algorithms, Grad-CAM. The heat map highlights the same region of interest on the noisy image, similar to clean images, but the class label differs. Shedding light on the vulnerabilities of deep learning models and revealing their vulnerability against particular corruption ensures the deployment of a correct network in the real world that deals with specific corruption frequently.},
  archive  = {J},
  author   = {Vishesh Kumar and Shivam Shukla and Akshay Agarwal},
  doi      = {10.1109/TBDATA.2025.3593385},
  journal  = {IEEE Transactions on Big Data},
  month    = {7},
  pages    = {1-12},
  title    = {Robustness benchmarking of convolutional and transformer architectures for image classification},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comprehensive image protection framework based on high-capacity adversarial data hiding. <em>TBD</em>, 1-16. (<a href='https://doi.org/10.1109/TBDATA.2025.3593381'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In recent years, a large number of personal images have been uploaded to social network platforms, contributing to the formation of image Big Data. These images are vulnerable to security threats, e.g., privacy inference, copyright infringement, and malicious tampering. Many image protection methods have been proposed, e.g., privacy protection methods based on adversarial perturbations, and copyright protection methods based on data hiding. However, these methods can only deal with a single security threat causing the image to suffer from residual threats. Therefore, this paper proposes a comprehensive image protection framework, which generates adversarial examples by embedding meaningful perturbations, achieving image privacy protection while protecting copyright and integrity by data hiding. In this framework, we design a novel high-capacity adversarial data hiding model (HADH) to support adversarially embedding of adequate robust watermarking for copyright protection and fragile watermarking for integrity protection. Experimental results show that HADH achieves a high embedding rate of 3.21 Reed-Solomon bits per pixel (RS-bpp), providing sufficient capacity for copyright and identity verification information. The capacity is even higher than other pure robust steganography schemes. In addition, the privacy protection performance is better than the existing adversarial attack-based privacy protection methods.},
  archive  = {J},
  author   = {Ming Li and Wenwen Zhou and Tao Wang and Yushu Zhang and Wenying Wen},
  doi      = {10.1109/TBDATA.2025.3593381},
  journal  = {IEEE Transactions on Big Data},
  month    = {7},
  pages    = {1-16},
  title    = {A comprehensive image protection framework based on high-capacity adversarial data hiding},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neurocognitive insights: Cognitive comprehension attention in multi-organ segmentation. <em>TBD</em>, 1-15. (<a href='https://doi.org/10.1109/TBDATA.2025.3593348'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In multi-organ segmentation, attention mechanisms are frequently employed to enhance the focus on irregular organs, improving performance. However, current attention mechanisms exhibit notable limitations. On the one hand, their visual saliency-based attention bias results in incomplete region-of-interest coverage. On the other hand, their organ-specific cognitive deficiency exacerbates organ misclassification. Inspired by neurocognitive science, this paper proposes a Cognitive Comprehension Attention (CCA). Diverging from existing methods, CCA achieves refined attention allocation by decomposing visual representations into discrete visual stimuli. This fine-grained approach enables unbiased processing for each visual stimulus, preventing critical information omission and ensuring comprehensive organ region coverage. More importantly, CCA generates organ-specific attention representations by establishing distinct attention patterns across different organ regions, which empowers CCA with cognitive capacity, resolving organ misclassification. Extensive experiments across multiple datasets demonstrate that CCA significantly enhances backbone performance, achieving a max mDice improvement of 8.45% while surpassing state-of-the-art methods by 9% in Recall and 11.78% in Precision. Code is available at: https://github.com/robert1818118/CCA.},
  archive  = {J},
  author   = {Junhao Xiao and Yang Wei and Wendong Huang and Jingyu Wang and Xiuli Bi and Xuezong Yang and Yanliang Zhang and Bin Xiao},
  doi      = {10.1109/TBDATA.2025.3593348},
  journal  = {IEEE Transactions on Big Data},
  month    = {7},
  pages    = {1-15},
  title    = {Neurocognitive insights: Cognitive comprehension attention in multi-organ segmentation},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Patch based unsupervised deep learning for retrieval and part matching in large image datasets. <em>TBD</em>, 1-14. (<a href='https://doi.org/10.1109/TBDATA.2025.3594237'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In this paper, we address the dual problems of retrieval and part (Region Of Interest (ROI)) matching, especially in large-scale image datasets. At the heart of our solution lies a patch-based unsupervised deep image representational model, termed a Bag of Variational Deep Embedded Visual Words (BoVDEVW). This model has three main components. Firstly, we extract a set of informative patches based on their entropy values. Secondly, the Variational AutoEncoder (VAE) is used to represent these informative patches in a robust low-dimensional probabilistic latent space. Third, deep embedded clustering is applied to group them. We introduce a composite loss function in this connection, which consists of reconstruction, regularization, and clustering losses, and explicitly show that it is convex. The cluster centers are termed as Variational Deep Embedded Visual Words. Image retrieval is performed by computing the Euclidean distance between a query image and the database images, each being represented as a Bag of Variational Deep Embedded Visual Words (BoVDEVW). The problem of finding ROI(s) in the retrieved images corresponding to ROI(s) in a query image is modeled as a matching problem in a bipartite graph constructed in the probabilistic latent space of the VAE. Comprehensive experimentation on large image datasets, NUS-WIDE and Google Landmarks Dataset (GLD) v2, and medium image datasets, Oxford-5K and Paris-6K clearly shows the efficacy of our proposed solution.},
  archive  = {J},
  author   = {Anindita Mukherjee and Jaya Sil and Abhimanyu Sahu and Ananda S. Chowdhury},
  doi      = {10.1109/TBDATA.2025.3594237},
  journal  = {IEEE Transactions on Big Data},
  month    = {7},
  pages    = {1-14},
  title    = {Patch based unsupervised deep learning for retrieval and part matching in large image datasets},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DAG-EnseFL: DAG-based asynchronous federated learning with ensemble distillation. <em>TBD</em>, 1-14. (<a href='https://doi.org/10.1109/TBDATA.2025.3594244'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In the industrial Internet of Things (IIoT), blockchain technology has been employed to ensure the trustworthiness of federated learning (FL) services. However, the existing framework that combines blockchain and FL suffers from poor training performance and high computational overhead due to the complex consensus mechanism. Although recent studies have explored architectures that integrate Directed Acyclic Graph (DAG) with FL, the aggregation process in DAG-based multi-branch structures still faces significant challenges due to strong statistical heterogeneity across branches. To accommodate the heterogeneity, this paper proposes a DAG-based asynchronous aggregation framework for decentralized FL services. In this framework, the local models are aggregated with global models in the DAG ledger to form a new transaction block (TB). The verified TB becomes the subsequent node of the tail node in the DAG multi-branch structure. Additionally, an FL model delivery mechanism based on improved ensemble distillation is designed. This mechanism merges the models in verified TBs from multiple branches of the DAG, enhancing the accuracy of the final delivery model without compromising system training efficiency. Extensive ablation and comparative experiments demonstrate that our proposed scheme enhances the training efficiency and accuracy of DAG-FL systems while ensuring the security and trustworthiness.},
  archive  = {J},
  author   = {Jiewei Chen and Da Wu and Shaoyong Guo and Feng Qi and Xuesong Qiu},
  doi      = {10.1109/TBDATA.2025.3594244},
  journal  = {IEEE Transactions on Big Data},
  month    = {7},
  pages    = {1-14},
  title    = {DAG-EnseFL: DAG-based asynchronous federated learning with ensemble distillation},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph-based contract sensing framework for smart contract vulnerability detection. <em>TBD</em>, 1-14. (<a href='https://doi.org/10.1109/TBDATA.2025.3594303'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Smart contract vulnerabilities have led to significant economic losses, threatening blockchain security and development. Graph neural network (GNN)-based approaches, which capture the structural properties of contracts and leverage code dependencies to better understand contract behavior, have become widely used for vulnerability detection. However, these approaches face challenges in losing valuable information during graph construction and failing to capture rich semantic content, while traditional GNNs struggle with long-range dependencies and global context in complex contract graphs. To address these challenges, we propose ConSense, a GNN-based Contract Sensing Framework for Smart Contract Vulnerability Detection. ConSense comprises two core components: the smart contract graph generator, which constructs contract graphs while retaining both structural and semantic information, and ExploreFormer, which effectively integrates local and global context using advanced attention mechanisms for vulnerability detection. Comprehensive experimental evaluations were performed on the IR-ESCD and SCVHunter-SCD datasets. For instance, the IR-ESCD benchmark—which encompasses eight distinct vulnerability categories—demonstrates that ConSense attains an average detection accuracy of 97.74%, with a mean processing time of 0.648 seconds per contract. These results signify a statistically significant improvement over state-of-the-art methods in both precision and computational efficiency.},
  archive  = {J},
  author   = {Yan Pang and Xiangfu Liu and Teng Huang and Yile Hong and Jiahui Huang and Sisi Duan and Changyu Dong},
  doi      = {10.1109/TBDATA.2025.3594303},
  journal  = {IEEE Transactions on Big Data},
  month    = {7},
  pages    = {1-14},
  title    = {Graph-based contract sensing framework for smart contract vulnerability detection},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MinoRare: Handling rare minority instances in imbalanced and drifting data streams through adaptive instance weighting scheme. <em>TBD</em>, 1-18. (<a href='https://doi.org/10.1109/TBDATA.2025.3594302'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The joint occurrence of concept drifts and class imbalance poses a significant challenge to the classification tasks in data streams. Among the various challenges in imbalanced data, rare minority instances deeply embedded within the majority class space present a unique difficulty. These instances are not only few in number but are also surrounded by majority class data, making the joint problem even more complex to address. This paper proposes MinoRare, a batch-based ensemble technique, to address the joint problem with a special focus on rare minority instances. MinoRare divides the batch data into subframes and applies weight instance criteria at the subframe level. Weights are assigned to minority and majority class instances based on their difficulty level, which is calculated by analyzing the neighborhood density of each instance in a subframe coupled with the global class overlap calculated at batch-level. Additionally, the ensemble pool is kept updated with classifiers setup with new weighted instance data, whereas outdated classifiers are removed making it adaptive to recent concepts and the current state of imbalanced data. By mitigating the rarity issue, MinoRare ensures that classifiers focus on critical rare minority instances through a targeted instance-weighting strategy, enhancing their ability to learn and represent decision boundaries for the minority class effectively, and ultimately improving classification performance in evolving data streams. Experiments against 13 state-of-the-art methods on 345 data streams containing a variety of concept drift and class imbalance coupled with different data difficulty factors demonstrate the efficacy of the proposed method.},
  archive  = {J},
  author   = {Hina Farooq and Muhammad Usman and Huanhuan Chen},
  doi      = {10.1109/TBDATA.2025.3594302},
  journal  = {IEEE Transactions on Big Data},
  month    = {7},
  pages    = {1-18},
  title    = {MinoRare: Handling rare minority instances in imbalanced and drifting data streams through adaptive instance weighting scheme},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge aggregation transformer network for multivariate time series classification. <em>TBD</em>, 1-17. (<a href='https://doi.org/10.1109/TBDATA.2025.3594294'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Over the years, various sophisticated deep learning algorithms have surfaced for multivariate time series classification (MTSC), notably the dual-network-based model. This model comprises two parallel networks tailored to time series data: one for local feature extraction and the other for global relation extraction. However, effectively integrating these dual networks poses a significant challenge. To address this, we propose a knowledge aggregation transformer network (KATN) for MTSC. KATN, composed of four aggregation transformer blocks, extracts abundant regularizations and connections hidden within the data. Each block incorporates a modified residual network (MResNet) for local feature extraction and a multi-head attention network for global relation extraction. Initially, the block merges MResNet's output feature with that of the multi-head attention network through an additive operation. Subsequently, it aligns features with a fully connected (i.e., dense) layer and activates neural units using the Gaussian error linear unit function. This strategic feature aggregation allows for capturing long-range dependencies among multiple variables in multivariate time series data. Experimental results demonstrate that KATN significantly outperforms 6 state-of-the-art transformer variants, achieving a ‘win’/‘tie’/‘lose’ record of 9/6/15 and securing the lowest AVG_rank score. Furthermore, when evaluated against 18 existing MTSC algorithms across 13 UEA datasets, KATN consistently delivers superior performance, attaining the lowest AVG_rank score among all compared methods.},
  archive  = {J},
  author   = {Zhiwen Xiao and Huanlai Xing and Rong Qu and Hui Li and Huagang Tong and Shouxi Luo and Jing Song and Li Feng and Qian Wan},
  doi      = {10.1109/TBDATA.2025.3594294},
  journal  = {IEEE Transactions on Big Data},
  month    = {7},
  pages    = {1-17},
  title    = {Knowledge aggregation transformer network for multivariate time series classification},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid ensemble framework for imbalanced data streams with concept drift. <em>TBD</em>, 1-14. (<a href='https://doi.org/10.1109/TBDATA.2025.3594239'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In the field of online learning, handling imbalanced data streams with concept drift has become a substantial challenge. Research interest in the combined challenges of concept drift and class imbalance is steadily growing. When dealing with concept drift, existing methods usually adopt active detection or passive adaptation to deal with concept drift. However, a single adaptation method is relatively limited in dealing with joint concept drift. This paper introduces a novel hybrid ensemble framework (HEF-IDS) specifically designed to tackle drifting data streams while effectively accommodating class imbalance. The framework integrates an active detection module and a passive adaptation module. In the passive adaptation module, we use a hybrid sampling strategy to balance data chunks, construct a sub-ensemble classifier for each balanced chunk, and combine it with a weighted voting scheme to deal with the class imbalance and adapt to the latest concept. In the process of active detection, we design a new sample selection mechanism that stores the most informative samples in the buffer, and uses these samples for training when drift is detected to prevent catastrophic forgetting. Comparative results on artificial and real-world datasets show that the proposed HEF-IDS is superior to other advanced online classification methods.},
  archive  = {J},
  author   = {Mianfen Lin and Zhiwen Yu and Kaixiang Yang and C. L. Philip Chen},
  doi      = {10.1109/TBDATA.2025.3594239},
  journal  = {IEEE Transactions on Big Data},
  month    = {7},
  pages    = {1-14},
  title    = {Hybrid ensemble framework for imbalanced data streams with concept drift},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diffusion-based adversarial purification with feature distillation. <em>TBD</em>, 1-13. (<a href='https://doi.org/10.1109/TBDATA.2025.3594243'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Adversarial purification is a defense strategy that utilizes generative models to neutralize adversarial perturbations. Diffusion models stand out for their powerful generative ability, making them the latest choice for generative models in adversarial purification methods. It is crucial to keep the balance between robustness against attacks and the integrity of the image content. However, these diffusion models are typically trained exclusively on clean data. We experimentally demonstrate that in the adversarial purification task, the data distribution operated by the diffusion model is often contaminated by adversarial perturbations. Adjusting the diffusion length to effectively mask adversarial perturbations while preserving image label semantics proves challenging. In this paper, we propose an innovative distillation-based diffusion approach for adversarial purification, enabling the diffusion model to operate effectively on the contaminated data distribution. Our approach involves a novel training process that integrates adversarial samples into the diffusion model's training by considering adversarial perturbations as part of the diffusion noise predicted by the model. The key to resisting perturbations is to align the feature representation of the purified image more closely with that of the clean image. To accomplish this, we develop a feature distillation technique to empower the diffusion model to learn and extract clean feature representations from adversarial samples. Extensive experimentation shows that our method achieves state-of-the-art performance against various adaptive attack benchmarks.},
  archive  = {J},
  author   = {Sitong Liu and Zhichao Lian and Liang Xiao},
  doi      = {10.1109/TBDATA.2025.3594243},
  journal  = {IEEE Transactions on Big Data},
  month    = {7},
  pages    = {1-13},
  title    = {Diffusion-based adversarial purification with feature distillation},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient and tractable conflict detection in knowledge graphs via path analysis. <em>TBD</em>, 1-13. (<a href='https://doi.org/10.1109/TBDATA.2025.3575948'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Knowledge graphs (KGs), which utilize graph structures to represent real-world facts, are pivotal in information retrieval and artificial intelligence. However, heuristic knowledge graph construction methods will produce errors. Some conflicts, such as expression ambiguities, are challenging to detect at triple granularity and require semantic analysis together with other triples. In this paper, we propose an approach for conflict detection at path granularity in large-scale knowledge graphs. It is based on rules on a specific pattern. Different from previous rules, our rules are defined with a ring pattern to extend error detection from triple granularity to path granularity. We prove that indicating whether a triple brings such conflicts only requires dealing with any one of its related ring structures, which can significantly reduce the complexity. We propose ${\mathsf {{RingE}}}$, a novel Ring Embedding method, to detect ring-pattern conflicts, and ${\mathsf {{DeCon}}}$, a CONflict DEtection framework suitable for both static and incremental scenes. This framework divides the ring-pattern conflict detection task in KGs into ring discovery and conflict detection. We also design a pruning strategy for ring discovery that reduces the time complexity from the exponential level to the polynomial level. Using real-world graphs, we experimentally verify that our algorithms are effective and feasible for large graphs. Our case study also verifies that ${\mathsf {{DeCon}}}$ can detect real conflicts.},
  archive  = {J},
  author   = {Yihan Wang and Qi Song and Ling Zheng and Xiang-Yang Li},
  doi      = {10.1109/TBDATA.2025.3575948},
  journal  = {IEEE Transactions on Big Data},
  month    = {6},
  pages    = {1-13},
  title    = {Efficient and tractable conflict detection in knowledge graphs via path analysis},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bi-directional spatiotemporal gated graph convolutional network for traffic speed prediction. <em>TBD</em>, 1-13. (<a href='https://doi.org/10.1109/TBDATA.2025.3576009'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Accurate traffic speed prediction plays a key role in transportation planning. Inspired by advanced natural language processing (NLP) techniques in speech recognition, this paper proposes a bidirectional spatio-temporal gated graph convolutional network (BiSTGG) based on the attention mechanism for urban traffic speed prediction. The model analogizes the average daily traffic speed with word frequencies in speech, thus establishing a novel semantic perspective for traffic modeling. In order to comprehensively assess the similarity between traffic speed trajectories, the model introduces a dynamic temporal regularization (DTW) algorithm, which enables the construction of dynamic semantic similarity subgraphs that go beyond the traditional spatial proximity modeling approach. Meanwhile, the model applies the multi-head graph attention mechanism to ensure that the complex and diverse interactions in the road network can be captured effectively. In addition, the model introduces spatial identification vectors to enhance robustness and direct attention to focus on key features. The model also incorporates a bi-directional gated recurrent unit (Bi-GRU) structure with an attention mechanism to capture the complex forward and backward time dependencies in traffic patterns. Experiments on two large-scale real datasets show that BiSTGG performs well in terms of prediction accuracy and robustness, and significantly improves real-time traffic speed prediction.},
  archive  = {J},
  author   = {Chaolong Jia and Fu Jiang and Bingyu Huang and Zheyi Kang and Rong Wang and Yunpeng Xiao},
  doi      = {10.1109/TBDATA.2025.3576009},
  journal  = {IEEE Transactions on Big Data},
  month    = {6},
  pages    = {1-13},
  title    = {Bi-directional spatiotemporal gated graph convolutional network for traffic speed prediction},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Asymmetric dual-encoder network with clustering and mutual contrast loss for the semantic segmentation of remote-sensing images. <em>TBD</em>, 1-13. (<a href='https://doi.org/10.1109/TBDATA.2025.3575945'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In recent years, the semantic segmentation of multimodal remote-sensing images using convolutional methods has received significant attention. Owing to the localized nature of convolutional operations, existing methods use the attention method to obtain global relations. However, effectively complementing and eliminating the global and local relations between two modalities has become a major challenge. In addition, category imbalance often affects the model performance as a result of the high resolution of remote-sensing images. In this study, we propose an asymmetric dual encoder network with clustering mutual contrast loss. Specifically, we use a convolutional neural network and Transformer as the backbone to extract two modal features in parallel to learn the local and global information, respectively. Next, our proposed multimodal hierarchical interaction module and dynamic weight inspired block efficiently fuse the multimodal features to complement the local and global information. The fused features are fed into our proposed local context extraction module and global context extraction module. Furthermore, to address the challenge presented by feature class imbalances, we apply a clustering algorithm to classify each pixel, which is subsequently inter-supervised using the inter-contrast loss. Extensive experiments on benchmark datasets show that the proposed model is extremely effective in the semantic segmentation of remotely sensed images and that it outperforms current state-of-the-art networks both quantitatively and qualitatively. Our code and results can be found at https://github.com/LYZ00918/AMCNet.},
  archive  = {J},
  author   = {Wujie Zhou and Yangzhen Li and Yuanyuan Liu},
  doi      = {10.1109/TBDATA.2025.3575945},
  journal  = {IEEE Transactions on Big Data},
  month    = {6},
  pages    = {1-13},
  title    = {Asymmetric dual-encoder network with clustering and mutual contrast loss for the semantic segmentation of remote-sensing images},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using construction waste hauling trucks' GPS data to classify earthwork-related locations: A chengdu case study. <em>TBD</em>, 1-12. (<a href='https://doi.org/10.1109/TBDATA.2025.3575940'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Earthwork-related locations (ERLs), such as construction sites, earth dumping grounds, and concrete mixing stations, are major sources of urban dust pollution (particulate matter). The effective management of ERLs is crucial and requires timely and efficient tracking of these locations throughout the city. This study aims to identify and classify urban ERLs using GPS trajectory data of over 16,000 construction waste hauling trucks (CWHTs), as well as 58 urban features encompassing geographic, land cover, POI, and transport dimensions. We compare several machine learning models and examine the impact of various spatial-temporal features on classification performance using real-world data in Chengdu, China. The results demonstrate that 77.8% classification accuracy can be achieved with a limited number of features. Implemented in the Alpha MAPS system in Chengdu, this classification framework successfully identified 724 construction sites/ earth dumping grounds, 48 concrete mixing stations, and 80 truck parking locations in the city in December 2023, enabling local authorities to manage urban dust pollution at low personnel costs effectively.},
  archive  = {J},
  author   = {Lei Yu and Ke Han},
  doi      = {10.1109/TBDATA.2025.3575940},
  journal  = {IEEE Transactions on Big Data},
  month    = {6},
  pages    = {1-12},
  title    = {Using construction waste hauling trucks' GPS data to classify earthwork-related locations: A chengdu case study},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DTWformer: A DTW-based transformer for multivariate time series forecasting. <em>TBD</em>, 1-12. (<a href='https://doi.org/10.1109/TBDATA.2025.3581114'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Accurate and robust time series forecasting is critical in numerous domains but remains challenging due to issues such as temporal misalignments, noise, and complex multivariate dependencies. Transformer-based models have demonstrated strong performance in sequential tasks; however, their reliance on dot-product attention renders them sensitive to noise and less effective for misaligned time series. To address these limitations, we propose a novel dynamic time warping (DTW)-based attention mechanism, leveraging a Sakoe-Chiba-constrained softDTW framework to replace the traditional dot-product similarity. This approach enables dynamic sequence alignment, enhancing robustness to temporal misalignments. Building on this innovation, we introduce DTWformer, a multi-scale Transformer model that integrates DTW-attention with adaptive patching to capture dependencies across varying temporal resolutions. DTWformer achieves superior forecasting performance and efficiency, addressing the limitations of existing approaches in handling misaligned and noisy time series. The implementation is publicly available at https://github.com/unihe/DTWformer.},
  archive  = {J},
  author   = {Zhongyang Yu and Zhihai Wang and Jidong Yuan and Huiting Pei and Yuxuan Fan and Shijiang Li},
  doi      = {10.1109/TBDATA.2025.3581114},
  journal  = {IEEE Transactions on Big Data},
  month    = {6},
  pages    = {1-12},
  title    = {DTWformer: A DTW-based transformer for multivariate time series forecasting},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BANG: Billion-scale approximate nearest neighbour search using a single GPU. <em>TBD</em>, 1-16. (<a href='https://doi.org/10.1109/TBDATA.2025.3581085'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Approximate Nearest Neighbour Search (ANNS) is a subroutine in algorithms routinely employed in information retrieval, pattern recognition, data mining, image processing, and beyond. Recent works have established that graph-based ANNS algorithms are practically more efficient than the other methods proposed in the literature. The growing volume and dimensionality of data necessitates designing scalable techniques for ANNS. To this end, the prior art has explored parallelising graph-based ANNS on GPU, leveraging its massive parallelism. The current state-of-the-art GPU-based ANNS algorithms either (i) require both the dataset and the generated graph index to reside entirely in the GPU memory, or (ii) they partition the dataset into small independent shards, each of which can fit in GPU memory, and perform the search on these shards on the GPU. While the first approach fails to handle large datasets due to the limited memory available on the GPU, the latter delivers poor performance on large datasets due to high data traffic over the low-bandwidth PCIe interconnect. We introduce BANG, a first-of-its-kind technique for graph-based ANNS on GPU for billion-scale datasets, that cannot entirely fit in the GPU memory. BANG stands out by harnessing a compressed form of the dataset on a single GPU to perform distance computations while efficiently accessing the graph index kept on the host memory, enabling efficient ANNS on large graphs within the limited GPU memory. BANG incorporates highly optimised GPU kernels and proceeds in phases that run concurrently on the GPU and CPU, taking advantage of their architectural specificities. Furthermore, it enables overlapping communication with computation that results in efficient data transfer between the CPU and GPU. Using a single NVIDIA Ampere A100 GPU, BANG achieves throughputs 50×-400× higher than competing methods for a recall of 0.9 on three popular billion-scale datasets.},
  archive  = {J},
  author   = {Karthik V. and Saim Khan and Somesh Singh and Harsha Vardhan Simhadri and Jyothi Vedurada},
  doi      = {10.1109/TBDATA.2025.3581085},
  journal  = {IEEE Transactions on Big Data},
  month    = {6},
  pages    = {1-16},
  title    = {BANG: Billion-scale approximate nearest neighbour search using a single GPU},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing vulnerability reports with automated and augmented description summarization. <em>TBD</em>, 1-12. (<a href='https://doi.org/10.1109/TBDATA.2025.3566618'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Public vulnerability databases, such as the National Vulnerability Database (NVD), document vulnerabilities and facilitate threat information sharing. However, they often suffer from short descriptions and outdated or insufficient information. In this paper, we introduce Zad, a system designed to enrich NVD vulnerability descriptions by leveraging external resources. Zad consists of two pipelines: one collects and filters supplementary data using two encoders to build a detailed dataset, while the other fine-tunes a pre-trained model on this dataset to generate enriched descriptions. By addressing brevity and improving content quality, Zad produces more comprehensive and cohesive vulnerability descriptions. We evaluate Zad using standard summarization metrics and human assessments, demonstrating its effectiveness in enhancing vulnerability information.},
  archive  = {J},
  author   = {Hattan Althebeiti and Mohammed Alkinoon and Manar Mohaisen and Saeed Salem and DaeHun Nyang and David Mohaisen},
  doi      = {10.1109/TBDATA.2025.3566618},
  journal  = {IEEE Transactions on Big Data},
  month    = {5},
  pages    = {1-12},
  title    = {Enhancing vulnerability reports with automated and augmented description summarization},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards privacy-preserving personalized federated relation classification. <em>TBD</em>, 1-16. (<a href='https://doi.org/10.1109/TBDATA.2025.3566576'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Relation classification plays a crucial role in detecting semantic relations between annotated entities within text data, serving as a fundamental tool for knowledge structurization. In recent years, federated learning has emerged as a promising approach for training relation classification models in decentralized settings. Existing methods have focused on developing a robust server model by decoupling model training at the server from direct access to client-side text data, while taking advantage of distributed data sources. However, a significant challenge arises from the heterogeneous nature of client texts, characterized by diverse and skewed distributions of relations, which has limited the practicality of current approaches. In response to this challenge, this study introduces the concept of personalized federated relation classification, aiming to tailor strong client models to adapt to their individual data distributions. To further address the issues stemming from heterogeneous texts, a novel framework, referred to as ${\sf pFedRC}$, is proposed with several optimized designs. This framework incorporates a knowledge fusion method that leverages a relation-wise weighting mechanism, and a feature augmentation approach utilizing prototypes to adaptively enhance the representations of instances associated with long-tail relations. Although federated learning can safely ensure private data unexposed, it is important to recognize that, from an information theory standpoint, there still exists a possibility for a curious server to deduce private information by analyzing the shared knowledge uploaded by clients. To enhance the privacy guarantees of the personalized federated relation classification system, this work integrates client-level differential privacy mechanism into the federated training process. According to our theoretical analysis, ${\sf pFedRC}$ with client-level differential privacy can realize rigorous privacy guarantees. Experimental evaluations demonstrate the superiority of the proposed ${\sf pFedRC}$ framework over competing baselines in various settings, illustrating that the tailored techniques effectively mitigate the challenges posed by heterogeneous text data while preserving privacy guarantees. This research contributes to the advancement of learning privacy-preserving personalized relation classification models via taking advantages of data from multiple sources.},
  archive  = {J},
  author   = {Ning Pang and Xiang Zhao and Weixin Zeng and Zhen Tan and Weidong Xiao},
  doi      = {10.1109/TBDATA.2025.3566576},
  journal  = {IEEE Transactions on Big Data},
  month    = {5},
  pages    = {1-16},
  title    = {Towards privacy-preserving personalized federated relation classification},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-representation-based generative graph neural networks for end-to-end link prediction. <em>TBD</em>, 1-15. (<a href='https://doi.org/10.1109/TBDATA.2025.3566584'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Recently, deep neural networks have revolutionized the field of link prediction, and the state-of-the-art works are typically subgraph-based discriminative methods, which construct features of local subgraphs firstly and predicting potential links via deep learning based binary subgraph classification. However, the discriminative link prediction methods always fail to automatically learn features and perform link prediction, and the performance of them depends on the construction of enclosing subgraphs and the manually-designed features for the subgraphs. To address these issues, we leverage the idea of graph disentangling and propose a novel self-representation-based generative graph neural network framework (GraphLP) for end-to-end link prediction, which learns to extract the latent patterns, i.e., recurring subgraphs, from input graphs via self-supervised learning and reconstruct graphs for link prediction using the subgraphs as structural basis. GraphLP consists of three components: self-representation-based collaborative inference, high-order connectivity computation, and multi-scale pattern fusion. The key idea is to utilize the correlations between the extracted recurring subgraphs on different scales to effectively assist link inference. GraphLP also can effectively exploit the hierarchical organization patterns and incorporate them within the representation procedure, producing robust and accurate results. Compared with traditional methods and state-of-the-art methods, experimental results on public benchmark datasets demonstrate that GraphLP achieves promising performance. Different from the discriminative methods, GraphLP provides a new paradigm for generative neural-network-based link prediction.},
  archive  = {J},
  author   = {Xingping Xian and Tao Wu and Shaojie Qiao and Chao Wang and Lin Yuan and Yanbing Liu},
  doi      = {10.1109/TBDATA.2025.3566584},
  journal  = {IEEE Transactions on Big Data},
  month    = {5},
  pages    = {1-15},
  title    = {Self-representation-based generative graph neural networks for end-to-end link prediction},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated average clustering learning based on time-asynchronous similarity. <em>TBD</em>, 1-15. (<a href='https://doi.org/10.1109/TBDATA.2025.3566605'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {To address the challenge of non-independent and identically distributed data in federated learning, clustering federated learning extracts local model features from clients and groups clients with high local model similarity into the same cluster to optimize the global model for the corresponding data distribution. However, current federated clustering algorithms bring additional communication cost for the accuracy of cluster division, which increases the communication burden of some performance-limited edge devices. To address the communication efficiency issue of clustering federated learning, we proposed an optimized communication efficiency federated average clustering learning that uses time weights to select partial clients to participate in training randomly. At the same time, a time-asynchronous similarity calculation method is proposed to improve the accuracy of local model similarity calculation for randomly selected clients. Extensive experimental evaluations show that our federated average clustering learning can achieve or even surpass the model accuracy of existing federated clustering algorithms. In the communication evaluation experiment, we can achieve the specified model accuracy using 5% to 30% of the communication of existing federated clustering algorithms.},
  archive  = {J},
  author   = {Xiaoyao Zheng and Haonan Li and Di Wu and Tianran Bu and Peng Hu and Ji Zhang},
  doi      = {10.1109/TBDATA.2025.3566605},
  journal  = {IEEE Transactions on Big Data},
  month    = {5},
  pages    = {1-15},
  title    = {Federated average clustering learning based on time-asynchronous similarity},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph-enhanced multi-scale contrastive learning for graph anomaly detection with adaptive diffusion models. <em>TBD</em>, 1-12. (<a href='https://doi.org/10.1109/TBDATA.2025.3566619'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Graph anomaly detection has gained significant research interest across various domains. Due to the lack of labeled data, contrastive learning has been applied in detecting anomalies and various contrastive strategies have been initiated. However, these methods might force two instances (e.g., node-level and subgraph-level representations) with different category labels to be consistent during model training, which can adversely impact the model robustness. Also, they extract node-level representations only based on node attributes, which are inadequate in reflecting the information of the structural anomaly. To tackle this problem, we present a Graph-enhanced multi-scale Contrastive Learning framework for Anomaly Detection, GCLAD. In this framework, we design a diffusion probabilistic model-based graph enhancement module to adaptively manipulate neighbors to generate enhanced graphs, which can efficiently enhance subgraph-level representations and alleviate the inconsistent problem. Further, we present a multi-scale contrastive module where we introduce meta-paths to exploit a few relevant neighbors to boost node-level representations, and build the multi-scale contrastive losses to promote anomaly detection performance. Experimental results demonstrate the superiority of GCLAD compared with state-of-the-art baselines.},
  archive  = {J},
  author   = {Chunjing Xiao and Yao Tong and Jiahui Lu and Yuxia Xue and Wenxin Tai and Zhangtao Cheng and Fan Zhou},
  doi      = {10.1109/TBDATA.2025.3566619},
  journal  = {IEEE Transactions on Big Data},
  month    = {5},
  pages    = {1-12},
  title    = {Graph-enhanced multi-scale contrastive learning for graph anomaly detection with adaptive diffusion models},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unified hypergraph framework for inter and intra-session dynamics in session-based social recommendations. <em>TBD</em>, 1-16. (<a href='https://doi.org/10.1109/TBDATA.2025.3566617'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Session-based recommendations have become increasingly important in social media platforms due to the dynamic and temporal nature of user interactions. The utilization of Graph Neural Networks in these systems has grown due to their proficiency in incorporating node information and structural topology. However, current recommendation methods that use graphs focus on recommendations within a single session, neglecting the more complex dependencies between different sessions. This omission limits improvements in the accuracy of recommendations. In addition, existing GNN-based approaches generally focus on simple binary connections, neglecting to capture the intricate and heterogeneous interactions in real-world situations. Furthermore, a notable obstacle arises from the absence of node positional information for hyperedges in hypergraphs. Therefore, different item orders can lead to identical hyperedges, which limits the formation of precise session vector representations. The paper proposes a unified framework utilizing heterogeneous hypergraph neural networks for session-based social recommendations to address these limitations. This framework utilizes hypergraphs to depict complex multivariate connections among sessions, social networks, and items. It addresses the problem of hyperedge ambiguity while maintaining the sequential order of data. The methodology entails creating a linkage graph and a session-item graph, which aid in identifying similar user intentions across various sessions and potential behavior patterns within a single session. In addition, the framework utilizes a Graph Attention Network (GAT) to combine social information from users and their connections, thereby improving the representation of user interests. Empirical assessments on three datasets show that our proposed model outperforms popular recommendation models. This emphasizes its effectiveness in accurately capturing user preferences and behaviors in session-based social recommendations.},
  archive  = {J},
  author   = {Bilal Khan and Jia Wu and Jian Yang and Malik Khizar Hayat and Shan Xue},
  doi      = {10.1109/TBDATA.2025.3566617},
  journal  = {IEEE Transactions on Big Data},
  month    = {5},
  pages    = {1-16},
  title    = {A unified hypergraph framework for inter and intra-session dynamics in session-based social recommendations},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep global distance estimation hashing for image retrieval. <em>TBD</em>, 1-18. (<a href='https://doi.org/10.1109/TBDATA.2025.3566532'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Hashing technology has an excellent high dimensional visual information encoding ability. It can map distance information from high dimensional to low dimensional Hamming space, which is widely used in large-scale image nearest neighbor search tasks. Most recent studies, such as pair-wise and tripletwise, use local positional relations to construct hashing functions. These learning methods, which are only based on local information, will lead to an incoherent feature representation, especially for semantic similarity features. Therefore, we propose a global distance estimation hashing (DEH). The DEH establishes a deep hashing model by constructing global distance relations that can define a distance between every paired category. Thus the distance relations constructed by DEH include much more detailed information. In other words, DEH focuses on global distance relations and makes the division of boundaries have excellent performance, especially for those samples with subtle changes. After the mapping, the model quantization approach effectively decreases the quantization loss caused by transitioning from the real-valued space to the Hamming space. Numerous experiments show that our DEH achieves excellent results on CIFAR-10, NUS-WIDE and ImageNet. These achievements not only validate the effectiveness of DEH in general image hashing retrieval tasks but also demonstrate its significant advantages in handling the large-scale multimedia retrieval systems.},
  archive  = {J},
  author   = {Mengfei Xu and Bowen Luo and Jianfeng Xu and Feng Ding},
  doi      = {10.1109/TBDATA.2025.3566532},
  journal  = {IEEE Transactions on Big Data},
  month    = {5},
  pages    = {1-18},
  title    = {Deep global distance estimation hashing for image retrieval},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Vertical federated representation synthesis for non-aligned samples in the active party. <em>TBD</em>, 1-15. (<a href='https://doi.org/10.1109/TBDATA.2025.3566595'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In vertical federated learning (VFL) settings, all parties obtain aligned samples of common users identified through private set intersection. For these aligned samples, each party holds disjoint features, while only the active party possesses the label information. As the initiator of model training, the active party can solely benefit from limited aligned samples, overlooking the valuable information contained in its non-aligned local samples. To address the constraint of failing to incorporate the active party's non-aligned samples in practical VFL, this paper presents a Vertical Federated Representation Synthesis (VFedRS) approach for the active party. Its main idea is to transfer the knowledge of common samples to the active party's local feature space, thereby enhancing the performance of the task model trained locally within the active party. Specifically, we first propose a vertical federated principal component analysis module to extract accurate federated representations for common samples under privacy guarantees. To transfer knowledge from federated representations, we then build an input-conditional generative model to synthesize non-aligned samples' representations for the active party. Subsequently, the active party can leverage data representations to locally train any type of machine learning model suited to the downstream task. We conduct extensive experiments on two tabular datasets and two image datasets in the vertically partitioned setting, and the evaluation results validate the effectiveness of our approach.},
  archive  = {J},
  author   = {Jintao Liang and Sen Su and Zhenya Wang},
  doi      = {10.1109/TBDATA.2025.3566595},
  journal  = {IEEE Transactions on Big Data},
  month    = {5},
  pages    = {1-15},
  title    = {Vertical federated representation synthesis for non-aligned samples in the active party},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Collaborative framework for circRNA-disease associations prediction using dual variational graph. <em>TBD</em>, 1-13. (<a href='https://doi.org/10.1109/TBDATA.2025.3566581'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Many experiments have shown that circular RNA (circRNA) can act as biomarkers for complex diseases and play significant regulatory roles in multiple pathological processes. However, most circRNA-disease associations remain unknown, and discovering these associations through biological experimental approach is expensive and time-consuming. Taking into account the shortcomings of current methods, we introduce a new collaborative framework that utilizes multi-heterogeneous graphs, along with variational graph auto-encoders (VGAE) to predict associations between circRNA and diseases. First, we build multi-similarity networks using various biological attributes of circRNA and diseases, and integrate these similarity networks. Two subnetworks are constructed from association matrix and combined similarity network, which included a circRNA-based network and a disease-based network. We then employ random walk with restart and Singular Value Decomposition, for feature extraction from the similarity matrix. Finally, we use collaborative framework to predict the circRNAdisease association scores based on the two subnetworks. We integrate the two score matrices to obtain a final prediction scoring matrix. Using 5-fold cross-validation on the CircR2Disease dataset, our model achieved an AUC score of 0.9828 and an AUPR score of 0.9820. Additionally, among the top 30 highest-scoring circRNA-disease association pairs, 26 associations have already been validated. Our model shows strong performance and can accurately predict associations between circRNA and diseases, according to experimental results.},
  archive  = {J},
  author   = {Changchun Liu and Lei Wang and Bowei Zhao and Mengmeng Wei and Yang Li and Mianshuo Lu and Yu Wei and Sizhe Liang},
  doi      = {10.1109/TBDATA.2025.3566581},
  journal  = {IEEE Transactions on Big Data},
  month    = {5},
  pages    = {1-13},
  title    = {Collaborative framework for circRNA-disease associations prediction using dual variational graph},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parallel multi-scale deep supervision net for hand key point detection. <em>TBD</em>, 1-14. (<a href='https://doi.org/10.1109/TBDATA.2025.3566535'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Key point detection plays an important role in a wide range of applications. However, predicting key points of small objects such as human hands is a challenging problem. Recent works fuse feature maps of deep Convolutional Neural Networks (CNNs), either via multi-level feature integration or multi-resolution aggregation. Despite achieving some success, the feature fusion approaches increase the complexity and the opacity of CNNs. To address this issue, we propose a novel CNN model named Parallel Multi-Scale Deep Supervision Network (P-MSDSNet) that learns feature maps at different scales in parallel with deep supervisions to produce spatial attention maps for adaptive feature propagation from layer to layer. PMSDSNet has a multi-stage with a parallel structure that fuses multi-scale features from both the same and different depth levels. The deep supervision with spatial attention would enhance relevant features and help improve the transparency of the feature learning at each stage. In the experiment, we show that P-MSDSNet outperforms the state-of-the-art approaches on benchmark datasets while requiring fewer parameters. We also demonstrate the applicability of P-MSDSNet to quantifying finger-tapping hand movements in a neuroscience study.},
  archive  = {J},
  author   = {Renjie Li and Son N. Tran and Saurabh Garg and Katherine Lawler and Jane Alty and Quan Bai},
  doi      = {10.1109/TBDATA.2025.3566535},
  journal  = {IEEE Transactions on Big Data},
  month    = {5},
  pages    = {1-14},
  title    = {Parallel multi-scale deep supervision net for hand key point detection},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic modeling and analysis of bi-directional traffic flows through a deep spatio-temporal graph neural network. <em>TBD</em>, 1-13. (<a href='https://doi.org/10.1109/TBDATA.2025.3566578'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Accurate traffic flow forecasting is critical for the efficient operation of intelligent transportation systems (ITS), as it directly supports urban management and decision-making. With the increasing complexity of urban traffic, existing models often fail to fully capture the dynamic dependencies between traffic inflows and outflows. Some treat them as a unified process, while others only explore their commonalities. Inflows and outflows exhibit distinct patterns and interactions that require more refined modeling. To improve modeling performance, we propose BiSTGNN, a novel deep spatio-temporal network model which explicitly models bidirectional traffic flows as independent stochastic processes. Our approach leverages the unique temporal and spatial dependencies of each flow direction to distinguish transitions between directions, and integrates them through a composite graph convolution framework, offering a more detailed analysis of the transfer process between flows. Additionally, we introduce an innovative dynamic graph construction method that differentiates the interactions between inflows and outflows, capturing their heterogeneous relationships. Extensive experiments on five real-world traffic datasets demonstrate that our method outperforms state-of-the-art baselines, achieving superior accuracy in predicting both inflows and outflows.},
  archive  = {J},
  author   = {Jin Fan and Fu Zhu and Wenchao Weng and Xinyi Zhang and Hanyu Jiang and Hao Tian and Huifeng Wu},
  doi      = {10.1109/TBDATA.2025.3566578},
  journal  = {IEEE Transactions on Big Data},
  month    = {5},
  pages    = {1-13},
  title    = {Dynamic modeling and analysis of bi-directional traffic flows through a deep spatio-temporal graph neural network},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AB-DOM: An algorithmic framework for supporting privacy-preserving big data publishing in big data lakes. <em>TBD</em>, 1-18. (<a href='https://doi.org/10.1109/TBDATA.2025.3570081'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {With the emergence of new technologies that extend the capabilities of actual data collection methods, healthcare data are more and more amassed in the purpose of being later analyzed to serve the ultimate, well-known, goal of 4P medicine (Predictive, Preventive, Personalized, Participative). Given the sensitive nature of healthcare data, and in a matter of compliance with data protection and privacy regulations, there is a need to make data publishing more secure. This is one of the main goals of the EU H2020 QUALITOP research project, with particular regards to the issue of defining a big health data smart digital platform and the shared data lake. In this context, we design, implement and experimentally assess an innovative algorithmic framework called Advanced Privacy-Preserving Big Data Publishing in Hierarchical DOMains (AB-DOM). AB-DOM is based on state-of-the-art anonymization techniques mixed with a graph coloring algorithm and an integrated data sampling method to guarantee that sensitive data are highly secured.},
  archive  = {J},
  author   = {Alfredo Cuzzocrea and Selim Soufargi},
  doi      = {10.1109/TBDATA.2025.3570081},
  journal  = {IEEE Transactions on Big Data},
  month    = {5},
  pages    = {1-18},
  title    = {AB-DOM: An algorithmic framework for supporting privacy-preserving big data publishing in big data lakes},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generative-contrastive heterogeneous graph neural network. <em>TBD</em>, 1-12. (<a href='https://doi.org/10.1109/TBDATA.2025.3570082'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Heterogeneous Graphs (HGs) effectively model complex relationships in the real world through multi-type nodes and edges. In recent years, inspired by self-supervised learning (SSL), contrastive learning (CL)-based Heterogeneous Graphs Neural Networks (HGNNs) have shown great potential in utilizing data augmentation and contrastive discriminators for downstream tasks. However, data augmentation remains limited due to the graph data's integrity. Furthermore, the contrastive discriminators suffer from sampling bias and lack local heterogeneous information. To tackle the above limitations, we propose a novel Generative-Contrastive Heterogeneous Graph Neural Network (GC-HGNN). Specifically, we propose a heterogeneous graph generative learning method that enhances CL-based paradigm. This paradigm includes: 1) A contrastive view augmentation strategy using a masked autoencoder. 2) Position-aware and semantics-aware positive sample sampling strategy for generating hard negative samples. 3) A hierarchical contrastive learning strategy aimed at capturing local and global information. Furthermore, the hierarchical contrastive learning and sampling strategies aim to constitute an enhanced contrastive discriminator under the generative-contrastive perspective. Finally, we compare our model with seventeen baselines on eight real-world datasets. Our model outperforms the latest baselines on node classification and link prediction tasks. To reproduce our work, we have open-sourced our code at https://github.com/wangyu0627/GC-HGNN.},
  archive  = {J},
  author   = {Yu Wang and Lei Sang and Yi Zhang and Yiwen Zhang and Xindong Wu},
  doi      = {10.1109/TBDATA.2025.3570082},
  journal  = {IEEE Transactions on Big Data},
  month    = {5},
  pages    = {1-12},
  title    = {Generative-contrastive heterogeneous graph neural network},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ensemble approaches for dynamic data stream classification under label scarcity. <em>TBD</em>, 1-15. (<a href='https://doi.org/10.1109/TBDATA.2025.3570072'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {As data continues to grow exponentially, the importance of online learning across various domains has increased significantly. However, most existing studies assume that the true class label for each incoming data point is readily available, an assumption that is often impractical. To address this issue, this paper introduces a novel algorithm called Density-based Clustering and One-Class Ensemble Active Learning (DCOE-AL). This approach constructs an ensemble model by combining a clustering algorithm with the One-Class Broad Learning System (OCBLS), which represents clusters within the feature space. Furthermore, a new active learning mechanism is developed to enable DCOE-AL to effectively handle challenges associated with concept drift and label scarcity. The proposed method is evaluated on multiple synthetic data streams that exhibit diverse types of concept drift, as well as on several real-world data streams. Comparative evaluations demonstrate that DCOE-AL achieves superior performance while requiring significantly fewer labeled samples.},
  archive  = {J},
  author   = {Zhiwen Yu and Siyong Huang and Kaixiang Yang and Jianming Lv and C. L. Philip Chen},
  doi      = {10.1109/TBDATA.2025.3570072},
  journal  = {IEEE Transactions on Big Data},
  month    = {5},
  pages    = {1-15},
  title    = {Ensemble approaches for dynamic data stream classification under label scarcity},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ScholarFinder: Knowledge embedding based recommendations using a deep embedded clustering model. <em>TBD</em>, 1-17. (<a href='https://doi.org/10.1109/TBDATA.2025.3570035'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Bold scientific research tasks need multi-disciplinary knowledge and collaborations that require finding scholars from particular domains with relevant knowledge. Given the variety of scholars and diversity, finding the appropriate scholar is an important and challenging problem for scientific communities. In this paper, we propose a “ScholarFinder” framework that uses contextual information (abstracts or publications) for embedding a scholar's knowledge in an unsupervised learning manner. Specifically, we implement an unsupervised embedding technique viz., Variational AutoEncoder (VAE). For better feature representation learning, we also implement a Variational Deep Embedded Clustering (VDEC) method that further enhances downstream tasks (e.g., clustering, classification) accuracy, scalability, and performance. In addition, we incorporate a multi-task learning scheme into our VDEC model for improving the effectiveness of simultaneously learning both embedding and clustering. Subsequently, the downstream tasks can be built based on pre-trained scholars' knowledge embeddings to predict suitability of a scholar for a research task. Using a dataset involving a 20-year collection of federal grant awards, we have demonstrated how our pre-trained model improved the performance for downstream tasks. We have also investigated how our pre-trained model can be integrated into a knowledge graph to achieve better performance. Lastly, we show that our ScholarFinder model variants outperform state-of-the-art baseline models (i.e., XGBoost, GBDT, AdaBoost, DNN, GraphSAGE, DEC, VaDE) and recent LLM based models (i.e., Bert4Rec, OpenP5) by atleast 18%.},
  archive  = {J},
  author   = {Yuanxun Zhang and Xiyao Cheng and Roland Oruche and Sai Swathi Sivarathri and Prasad Calyam},
  doi      = {10.1109/TBDATA.2025.3570035},
  journal  = {IEEE Transactions on Big Data},
  month    = {5},
  pages    = {1-17},
  title    = {ScholarFinder: Knowledge embedding based recommendations using a deep embedded clustering model},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FIFA: A forest-based sliding window aggregation scheme for out-of-order data streams. <em>TBD</em>, 1-14. (<a href='https://doi.org/10.1109/TBDATA.2025.3558844'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Sliding window aggregation is a core operation in data stream analysis that extracts summaries from the most recent data stream. An evict or insert of the window can be handled in $O(1)$ for in-order data streams. However, real-world data streams are typically disordered due to network delays. To process out-of-order data streams, existing methods primarily use a tree to maintain the sliding windows. Since the complexity of the tree is related to the window size, the performance of these methods will drop sharply or become unavailable when facing a big window. To overcome the limitation of existing methods, this paper presents Finger B-Trees Forest Aggregation (FIFA). This novel forest-based sliding window aggregation scheme optimally handles out-of-order data streams. At its heart, FIFA uses aggregation forest to extend Finger B-Trees. Specifically, FIFA evenly divides a window into several chunks and constructs a separate tree to maintain each chunk. When an out-of-order item arrives, FIFA first locates the corresponding chunk of the item and then uses Finger B-Trees to insert it into the window efficiently. Chunking reduces the complexity of the tree and the coupling of aggregation results by isolating items within windows. Thus, an insert or evict takes amortized $O(c)$ in the worst case, where $c$ is the size of each chunk. Finally, extensive experiments based on real-world data demonstrate that FIFA achieves an average 2-fold throughput improvement on out-of-order data streams compared with the state-of-the-art (SOTA) aggregation schemes.},
  archive  = {J},
  author   = {Jiande Huang and Yuhui Deng and Jianjun Li and Lijuan Lu and Qifen Yang and Geyong Min},
  doi      = {10.1109/TBDATA.2025.3558844},
  journal  = {IEEE Transactions on Big Data},
  month    = {4},
  pages    = {1-14},
  title    = {FIFA: A forest-based sliding window aggregation scheme for out-of-order data streams},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A cross-domain recommendation model integrating users' long-term and short-term interests. <em>TBD</em>, 1-15. (<a href='https://doi.org/10.1109/TBDATA.2025.3558836'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Cross-domain recommendation can combine users' interests in multiple domains to achieve diversification of recommended content. To solve the problem of complex and changeable interest relationship among different domains, this paper proposes a cross-domain recommendation model integrating user's long-term and short-term interests. Firstly, to solve the problem of different data distributions in different domains, this paper proposes the graph convolutional network with maximum mean discrepancy (MMD), which gradually aligns the feature representation of shared potential space during training to reduce the influence of negative transfer. Secondly, to solve the problem of different features of items in different domains, considering the advantage of attention mechanism in distinguishing importance, a hierarchical attention mechanism focusing on item features is proposed to build users' short-term interests in source domain. Finally, aiming at the dynamic influence of users' long-term and short-term interest, a multi-type interest dynamic aggregation module based on gated network is proposed, which not only integrates users' preferences in different domains, but also takes into account the characteristics of items to be predicted. Experiments show that the model can effectively capture users' multi-type interests in source domain and target domain on real data set, so as to improve the recommendation accuracy of target domain.},
  archive  = {J},
  author   = {Wanjing Zhao and Yunpeng Xiao and Chaolong Jia and Tun Li and Rong Wang and Qian Li},
  doi      = {10.1109/TBDATA.2025.3558836},
  journal  = {IEEE Transactions on Big Data},
  month    = {4},
  pages    = {1-15},
  title    = {A cross-domain recommendation model integrating users' long-term and short-term interests},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Look closer to your enemy: Learning to attack via teacher-student mimicking. <em>TBD</em>, 1-14. (<a href='https://doi.org/10.1109/TBDATA.2025.3558832'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Deep neural networks have significantly advanced person re-identification (ReID) applications in the realm of the industrial internet, yet they remain vulnerable. Thus, it is crucial to study the robustness of ReID systems, as there are risks of adversaries using these vulnerabilities to compromise industrial surveillance systems. Current adversarial methods focus on generating attack samples using misclassification feedback from victim models (VMs), neglecting VM's cognitive processes. We seek to address this by producing authentic ReID attack instances through VM cognition decryption. This approach boasts advantages like better transferability to open-set ReID tests, easier VM misdirection, and enhanced creation of realistic and undetectable assault images. However, the task of deciphering the cognitive mechanism in VM is widely considered to be a formidable challenge. In this paper, we propose a novel inconspicuous and controllable ReID attack baseline, LCYE (Look Closer to Your Enemy), to generate adversarial query images. Specifically, LCYE first distills VM's knowledge via teacher-student memory mimicking the proxy task. This knowledge prior serves as an unambiguous cryptographic token, encapsulating elements deemed indispensable and plausible by the VM, with the intent of facilitating precise adversarial misdirection. Further, benefiting from the multiple opposing task framework of LCYE, we investigate the interpretability and generalization of ReID models from the view of the adversarial attack, including cross-domain adaption, cross-model consensus, and online learning process. Extensive experiments on four ReID benchmarks show that our method outperforms other state-of-the-art attackers with a large margin in white-box, black-box, and target attacks. The source code can be found at https://github.com/MingjieWang0606/LCYE-attack_reid.},
  archive  = {J},
  author   = {Mingjie Wang and Jianxiong Guo and Sirui Li and Dingwen Xiao and Zhiqing Tang},
  doi      = {10.1109/TBDATA.2025.3558832},
  journal  = {IEEE Transactions on Big Data},
  month    = {4},
  pages    = {1-14},
  title    = {Look closer to your enemy: Learning to attack via teacher-student mimicking},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Aligning crowd-sourced human feedback for reinforcement learning on code generation by large language models. <em>TBD</em>, 1-12. (<a href='https://doi.org/10.1109/TBDATA.2024.3524104'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {This paper studies how AI-assisted programming and large language models (LLM) improve software developers' ability via AI tools (LLM agents) like Github Copilot and Amazon CodeWhisperer, while integrating human feedback to enhance reinforcement learning (RLHF) with crowd-sourced computation to enhance text-to-code generation. Additionally, we demonstrate that our Bayesian optimization framework supports AI alignment in code generation by distributing the feedback collection burden, highlighting the value of collecting human feedback of good quality. Our empirical evaluations demonstrate the efficacy of this approach, showcasing how LLM agents can be effectively trained for improved text-to-code generation. Our Bayesian optimization framework can be designed for general domain-specific languages, promoting the alignment of large language model capabilities with human feedback in AI-assisted programming for code generation.},
  archive  = {J},
  author   = {Man Fai Wong and Chee Wei Tan},
  doi      = {10.1109/TBDATA.2024.3524104},
  journal  = {IEEE Transactions on Big Data},
  month    = {12},
  pages    = {1-12},
  title    = {Aligning crowd-sourced human feedback for reinforcement learning on code generation by large language models},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Is split learning privacy-preserving for fine-tuning large language models?. <em>TBD</em>, 1-12. (<a href='https://doi.org/10.1109/TBDATA.2024.3524101'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {With the success of pre-trained large language models in various tasks, users, individuals and enterprises alike, may need to fine-tune these models with their own datasets. Split learning was proposed to divide the model and place a portion on each user's own device, and intermediate results in each iteration of training will be sent to the server to complete the forward pass. There were concerns in the literature about whether private data can be leaked by sending such intermediate results from the training process. In this paper, we conduct empirical studies on typical large language models, such as GPT-2, OPT, Llama, and Qwen, to show that in most situations, an honest-but-curious server is not able to reconstruct private data using such intermediate results. To find out the reason why large language models preserve data privacy better in these situations, we present our theoretical analyses on these empirical observations. In one special case, where a state-of-the-art existing attack can reconstruct data in the first iteration, we show that it can be easily defended with a simple but effective solution leveraging publicly accessible data.},
  archive  = {J},
  author   = {Dixi Yao and Baochun Li},
  doi      = {10.1109/TBDATA.2024.3524101},
  journal  = {IEEE Transactions on Big Data},
  month    = {12},
  pages    = {1-12},
  title    = {Is split learning privacy-preserving for fine-tuning large language models?},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Data reconstruction and protection in federated learning for fine-tuning large language models. <em>TBD</em>, 1-13. (<a href='https://doi.org/10.1109/TBDATA.2024.3524105'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Federated learning can facilitate multiple parties to train a shared model on their own private data in a communication-efficient manner. It offers significant benefits for fine-tuning pre-trained large language models, as it supports distributed fine-tuning with a wider range of diverse data while preserving data privacy. However, recent research has revealed a potential privacy vulnerability in federated learning, specifically in the sharing of gradients from clients to server. This vulnerability can lead to the leakage of training data for Transformer-based large language models, thereby allowing the recovery of textual data. In this paper, we conduct a comprehensive evaluation of the effectiveness of the state-of-the-art gradient leakage attacks on textual data within the context of fine-tuning large language models. Our findings reveal that the key element for the attack's success — the target gradient — is not as readily obtainable for the adversary as previously assumed, particularly in regards to the Transformer architecture and practical federated learning settings. A technical error in their implementations has inadvertently caused the gradient to become more associated with the target data than intended. With the error fixed and when following the conventional federated learning framework, gradient leakage attacks pose minimal threats to large language models.},
  archive  = {J},
  author   = {Fei Wang and Baochun Li},
  doi      = {10.1109/TBDATA.2024.3524105},
  journal  = {IEEE Transactions on Big Data},
  month    = {12},
  pages    = {1-13},
  title    = {Data reconstruction and protection in federated learning for fine-tuning large language models},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cloud computing assisted mobile healthcare systems using distributed data analytic model. <em>TBD</em>, 1-12. (<a href='https://doi.org/10.1109/TBDATA.2023.3244015'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Distributed cloud technologies enable mobile healthcare applications to support end users constantly. Data from electronic health records is made available through combination of user needs and heuristic mining. Because of inefficient data storage and reorganization, service and recommendation failures occur prematurely. A Distributed Data Analytics and Organization Model (DDAOM) is established in this article as a solution to the inefficiency of managing large amounts of data. Using this method, errors caused by performing several computations or storing large amounts of data in the medical field are minimized. Data organization and mining under predetermined schedules or factors provide information relevant to user services. One-to-many computations with varying input and output data allocations (for services) are executed in federated learning. The local input from several edges may be handled by allocating storage in a decentralized manner. The federated learning system uses the memory of past states to direct the allocation. Differentiating the states is necessary to allocate services and prevent mining in certain areas. With the help of realistic learning iterations, state management is maintained, guaranteeing the smooth deployment of services. Delays in storage and mining, uneven service provisioning, and service backlogs are used to evaluate the effectiveness of the suggested model.},
  archive  = {J},
  author   = {Sunita Dhote and S. Baskar and P. Mohamed Shakeel and Tejas Dhote},
  doi      = {10.1109/TBDATA.2023.3244015},
  journal  = {IEEE Transactions on Big Data},
  month    = {2},
  pages    = {1-12},
  title    = {Cloud computing assisted mobile healthcare systems using distributed data analytic model},
  year     = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Resource-aware federated neural architecture search over heterogeneous mobile devices. <em>TBD</em>, 1-11. (<a href='https://doi.org/10.1109/TBDATA.2022.3227403'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Federated learning has been recently proposed for many clients to collaboratively train a machine learning model in a privacy-preserving manner. However, it also amplifies the difficulty in designing good neural network architecture, especially considering heterogeneous mobile devices. To this end, we propose a novel neural architecture search algorithm, namely FedNAS, which can automatically generate a set of optimal models under federated settings. The main idea is to decouple the two primary steps of the NAS process, i.e, model search and model training, and separately distribute them on the cloud and devices. It also tackles the primary challenge of limited on-device computational and communication resources through its novel designs: FedNAS fully exploits the key opportunity of insufficient model candidate re-training during the architecture search process and incorporates three key optimizations: parallel candidate training on partial clients, early dropping candidates with inferior performance, and dynamic round numbers. Evaluated on typical CNN architectures and large-scale datasets, FedNAS is able to achieve comparable model accuracy as a state-of-the-art NAS algorithm that trains models with centralized data, and also reduces the client cost by up to 200_ or more compared to a straightforward design of federated NAS.},
  archive  = {J},
  author   = {Jinliang Yuan and Mengwei Xu and Yuxin Zhao and Kaigui Bian and Gang Huang and Xuanzhe Liu and Shangguang Wang},
  doi      = {10.1109/TBDATA.2022.3227403},
  journal  = {IEEE Transactions on Big Data},
  month    = {12},
  pages    = {1-11},
  title    = {Resource-aware federated neural architecture search over heterogeneous mobile devices},
  year     = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Privacy-preserving aggregation in federated learning: A survey. <em>TBD</em>, 1-20. (<a href='https://doi.org/10.1109/TBDATA.2022.3190835'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Over the recent years, with the increasing adoption of Federated Learning (FL) algorithms and growing concerns over personal data privacy, Privacy-Preserving Federated Learning (PPFL) has attracted tremendous attention from both academia and industry. Practical PPFL typically allows multiple participants to individually train their machine learning models, which are then aggregated to construct a global model in a privacy-preserving manner. As such, Privacy-Preserving Aggregation (PPAgg) as the key protocol in PPFL has received substantial research interest. This survey aims to fill the gap between a large number of studies on PPFL, where PPAgg is adopted to provide a privacy guarantee, and the lack of a comprehensive survey on the PPAgg protocols applied in FL systems. This survey reviews the PPAgg protocols proposed to address privacy and security issues in FL systems. The focus is placed on the construction of PPAgg protocols with an extensive analysis of the advantages and disadvantages of these selected PPAgg protocols and solutions. Additionally, we discuss the open-source FL frameworks that support PPAgg. Finally, we highlight significant challenges and future research directions for applying PPAgg to FL systems and the combination of PPAgg with other technologies for further security improvement.},
  archive  = {J},
  author   = {Ziyao Liu and Jiale Guo and Wenzhuo Yang and Jiani Fan and Kwok-Yan Lam and Jun Zhao},
  doi      = {10.1109/TBDATA.2022.3190835},
  journal  = {IEEE Transactions on Big Data},
  month    = {7},
  pages    = {1-20},
  title    = {Privacy-preserving aggregation in federated learning: A survey},
  year     = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
