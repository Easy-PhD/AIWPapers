<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TC</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tc">TC - 29</h2>
<ul>
<li><details>
<summary>
(2025). BaDFL: Mitigating model poisoning in decentralized federated learning. <em>TC</em>, 1-12. (<a href='https://doi.org/10.1109/TC.2025.3603683'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decentralized federated learning (DFL) has gained significant attention due to its ability to facilitate collaborative model training without relying on a central server. However, it is highly vulnerable to backdoor attacks, where malicious participants can manipulate model updates to embed hidden functionalities. In this paper, we propose BaDFL, a novel Backdoor Attack defense mechanism for Decentralized Federated Learning. BaDFL enhances robustness by applying strategic model clipping at the local update level. To the best of our knowledge, BaDFL is the first decentralized federated learning algorithm with theoretical guarantees against model poisoning attacks. Specifically, BaDFL achieves an asymptotically optimal convergence rate of $O(\frac{1}{\sqrt{nT}})$, where n is the number of nodes and T is the global maximum iteration number. Furthermore, we provide a comprehensive analysis under two different attack scenarios, showing that BaDFL maintains robustness within a specific defense radius. Extensive experimental results show that, on average, BaDFL can effectively defend against model poisoning within 6 mitigation rounds, with less than a 1% drop in accuracy.},
  archive      = {J_TC},
  author       = {Yuan Yuan and Anhao Zhou and Xiao Zhang and Yifei Zou and Yangguang Shi and Dongxiao Yu},
  doi          = {10.1109/TC.2025.3603683},
  journal      = {IEEE Transactions on Computers},
  month        = {9},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Comput.},
  title        = {BaDFL: Mitigating model poisoning in decentralized federated learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ecomap: Sustainability-driven optimization of multi-tenant DNN execution on edge servers. <em>TC</em>, 1-13. (<a href='https://doi.org/10.1109/TC.2025.3604487'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge computing systems struggle to efficiently manage multiple concurrent deep neural network (DNN) workloads while meeting strict latency requirements, minimizing power consumption, and maintaining environmental sustainability. This paper introduces Ecomap, a sustainability-driven framework that dynamically adjusts the maximum power threshold of edge devices based on real-time carbon intensity. Ecomap incorporates the innovative use of mixed-quality models, allowing it to dynamically replace computationally heavy DNNs with lighter alternatives when latency constraints are violated, ensuring service responsiveness with minimal accuracy loss. Additionally, it employs a transformer-based estimator to guide efficient workload mappings. Experimental results using NVIDIA Jetson AGX Xavier demonstrate that Ecomap reduces carbon emissions by an average of 30% and achieves a 25% lower carbon delay product (CDP) compared to state-of-the-art methods, while maintaining comparable or better latency and power efficiency.},
  archive      = {J_TC},
  author       = {Varatheepan Paramanayakam and Andreas Karatzas and Dimitrios Stamoulis and Iraklis Anagnostopoulos},
  doi          = {10.1109/TC.2025.3604487},
  journal      = {IEEE Transactions on Computers},
  month        = {9},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Comput.},
  title        = {Ecomap: Sustainability-driven optimization of multi-tenant DNN execution on edge servers},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Low-storage verifiable data streaming with efficient revocation approach. <em>TC</em>, 1-12. (<a href='https://doi.org/10.1109/TC.2025.3604531'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Verifiable data streaming (VDS) is proposed to authenticate a sequence of ordered data, such that the misbehavior on the data returned by cloud server can be effectively detected. VDS also allows to efficiently replace the outsourced data by another value. However, the old authentication information can make the expired data pass the verification. To prevent this attack, VDS schemes must provide a revocation approach to revoke the old authentication information. The current approach employs the tree-like authentication structure or cryptographic accumulator, which will influence the efficiency of the VDS scheme. In this work, we find an approach to construct the low-storage VDS scheme supporting efficient revocation. Towards this end, we fully exploit the property of chameleon hash function with ephemeral trapdoor to propose a signature, which is the crucial step to construct the VDS scheme. In our VDS scheme, the size of the authentication information can be reduced to be less than the scale of the data streaming (i.e., low storage). Furthermore, the client is able to revoke the old authentication information in an efficient manner, where she only needs to release a message (i.e., efficient revocation). The performance evaluation shows that the proposed VDS scheme is efficient and practical.},
  archive      = {J_TC},
  author       = {Haining Yang and Dengguo Feng and Jing Qin},
  doi          = {10.1109/TC.2025.3604531},
  journal      = {IEEE Transactions on Computers},
  month        = {9},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Comput.},
  title        = {Low-storage verifiable data streaming with efficient revocation approach},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CoFormer: Collaborating with heterogeneous edge devices for scalable transformer inference. <em>TC</em>, 1-14. (<a href='https://doi.org/10.1109/TC.2025.3604473'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The impressive performance of transformer models has sparked the deployment of intelligent applications on resource-constrained edge devices. However, ensuring high-quality service for real-time edge systems is a significant challenge due to the considerable computational demands and resource requirements of these models. Existing strategies typically either offload transformer computations to other devices or directly deploy compressed models on individual edge devices. These strategies, however, result in either considerable communication overhead or suboptimal trade-offs between accuracy and efficiency. To tackle these challenges, we propose a collaborative inference system for general transformer models, termed CoFormer. The central idea behind CoFormer is to exploit the divisibility and integrability of transformer. An off-the-shelf large transformer can be decomposed into multiple smaller models for distributed inference, and their intermediate results are aggregated to generate the final output. We formulate an optimization problem to minimize both inference latency and accuracy degradation under heterogeneous hardware constraints. DeBo algorithm is proposed to first solve the optimization problem to derive the decomposition policy, and then progressively calibrate decomposed models to restore performance. We demonstrate the capability to support a wide range of transformer models on heterogeneous edge devices, achieving up to 3.1× inference speedup with large transformer models. Notably, CoFormer enables the efficient inference of GPT2-XL with 1.6 billion parameters on edge devices, reducing memory requirements by 76.3%. CoFormer can also reduce energy consumption by approximately 40% while maintaining satisfactory inference performance.},
  archive      = {J_TC},
  author       = {Guanyu Xu and Zhiwei Hao and Li Shen and Yong Luo and Fuhui Sun and Xiaoyan Wang and Han Hu and Yonggang Wen},
  doi          = {10.1109/TC.2025.3604473},
  journal      = {IEEE Transactions on Computers},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Comput.},
  title        = {CoFormer: Collaborating with heterogeneous edge devices for scalable transformer inference},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient conjunctive geometric range query over encrypted spatial data with learned index. <em>TC</em>, 1-14. (<a href='https://doi.org/10.1109/TC.2025.3604470'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing popularity of geo-positioning technologies and mobile Internet, spatial data query services have attracted extensive attention. To protect the confidentiality of sensitive information outsourced to cloud servers, much efforts have been devoted to designing geometric range query schemes over encrypted spatial data without affecting availability. However, existing works focus on the privacy-preserving schemes with traditional tree indexes, causing more computing and storage issues. In this paper, we propose an efficient conjunctive geometric range query scheme over encrypted spatial data with a learned index. In particular, we design a new privacy-preserving learned index for spatial data to reduce the search space and storage overhead. The main idea is to add noise disturbance to the objective function instead of directly adding it to output results, reducing the leakage of private information and ensuring the correctness of output results. Moreover, we propose a spatial segmentation algorithm to avoid accessing a large number of unnecessary Z codes in the query process. The formal security analysis shows that our scheme ensures index data security and query privacy. Simulation results show that the query efficiency is improved while the storage overhead is significantly reduced compared with the state-of-the-art schemes.},
  archive      = {J_TC},
  author       = {Mingyue Li and Chunfu Jia and Ruizhong Du and Guanxiong Ha},
  doi          = {10.1109/TC.2025.3604470},
  journal      = {IEEE Transactions on Computers},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Comput.},
  title        = {Efficient conjunctive geometric range query over encrypted spatial data with learned index},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). StageWise: Accelerating persistent key-value stores by thread model redesigning. <em>TC</em>, 1-14. (<a href='https://doi.org/10.1109/TC.2025.3605763'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the emergence of fast NVMe SSDs, key-value stores are becoming more CPU-efficient in order to reap their bandwidth. However, current CPU-optimized key-value stores adopt suboptimal intra- and inter-thread models, hence incurring memory-level stalling and load imbalance that hinder cores from realizing their full potential. We present STAGEWISE, an CPU-efficient key-value store on fast NVMe SSDs with high throughput. To achieve this, we introduce a new thread model for StageWise to process KV requests. Specifically, STAGEWISE converts the processing of each KV request into multiple asynchronous stages, and thus enables pipelining across all stages. STAGEWISE further introduces a client-driven share-index architecture to ease inter-thread load imbalance and maximize the pipelining opportunity. Guided by Little’s Law, STAGEWISE improves concurrency, and therefore efficiently uses CPU to reach higher throughput. Extensive experimental results show that STAGEWISE outperforms CPUoptimized key-value stores (e.g., KVell) by up to 3.5× with writeintensive workloads, and storage-optimized ones (e.g., RocksDB) by over an order of magnitude. STAGEWISE also shows higher read performance and excellent scalability under various workloads.},
  archive      = {J_TC},
  author       = {Zeqi Li and Youmin Chen and Qing Wang and Youyou Lu and Jiwu Shu},
  doi          = {10.1109/TC.2025.3605763},
  journal      = {IEEE Transactions on Computers},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Comput.},
  title        = {StageWise: Accelerating persistent key-value stores by thread model redesigning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Competition-style sorting networks (CSN): A framework for hardware-based sorting operations. <em>TC</em>, 1-14. (<a href='https://doi.org/10.1109/TC.2025.3605766'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sorting operations are considered to be a significant part of any computer system and are widely used in many applications. In applications where sorting has to be efficiently accomplished (i.e., in O(1) time) on small-sized entries, hardware accelerators, such as ASICs, FPGAs, or GPUs, are used to speed up the sorting operations. In the literature, the bitonic sort algorithm (or variants thereof) is still considered to be the most commonly used approach in many hardware sort implementations for decades. However, the time complexity of the bitonic sort is O((log(n))2) for sorting n elements, which does not satisfy the constant-time constraint we demand for our setting. In this paper, we propose competition-style sorting networks (CSNs), a framework for designing hardware-based competition-style class of sorting networks that captures all forms of two-stage sorting networks where the first stage (competition) consists of pairwise comparisons and the second stage (evaluation) ranks the entries and sorts them. To illustrate the utility of this framework, we develop and test one instance of this design, called the Competition Sort Algorithm (CSA), which has a time complexity of O(1), and specifically, one clock cycle. We implemented and tested CSA on both an Intel Cyclone V FPGA and the NVIDIA Quadro T1000 GPU then measured its gain, which combines the trade-offs between the relative speedup and the relative area increase, against the bitonic sort. Our results show that the CSA achieves a significant gain of up to 11.01× on the FPGA and a relative speedup of up to 3.32× on the GPU. We also compare the area, power, and latency of CSA with the bitonic sort algorithm on the FPGA.},
  archive      = {J_TC},
  author       = {Abbas A. Fairouz and Jassim M. Aljuraidan and Ameer Mohammed},
  doi          = {10.1109/TC.2025.3605766},
  journal      = {IEEE Transactions on Computers},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Comput.},
  title        = {Competition-style sorting networks (CSN): A framework for hardware-based sorting operations},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatial-temporal embodied carbon models with dual carbon attribution for embodied carbon accounting of computer systems. <em>TC</em>, 1-13. (<a href='https://doi.org/10.1109/TC.2025.3605743'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Embodied carbon is the carbon emissions in the manufacturing process of products, which dominates the overall carbon footprint in many industries. Existing studies derive the embodied carbon through life cycle analysis (LCA) reports. Current LCA reports only provide the carbon emission of a product class, e.g. 28nm CPU, whereas a product instance can be made in various regions and time periods. Carbon emissions depend on the electricity generation process, which has spatial-temporal dynamics. Therefore, the embodied carbon of a product instance can differ from its product class. Additionally, different carbon attribution methods (e.g., location-based and market-based) can affect the carbon emissions of electricity, thus further affecting the embodied carbon of products. In this paper, we present new Spatial-Temporal Embodied Carbon (STEC) accounting models with dual attribution methods. We observe significant differences between STEC and current models, e.g., for 7nm CPU the difference is 13.69%. We further examine the impact of STEC models on existing embodied carbon accounting schemes on computer applications, such as Large Language Model (LLM) training and LLM inference. We observe that using STEC results in much greater differences in the embodied carbon of certain applications as compared to others (e.g., 32.26% vs. 6.35%).},
  archive      = {J_TC},
  author       = {Xiaoyang Zhang and Yijie Yang and Dan Wang},
  doi          = {10.1109/TC.2025.3605743},
  journal      = {IEEE Transactions on Computers},
  month        = {9},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Comput.},
  title        = {Spatial-temporal embodied carbon models with dual carbon attribution for embodied carbon accounting of computer systems},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). OOLU: An operation-based optimized sparse LU decomposition accelerator for circuit simulation. <em>TC</em>, 1-14. (<a href='https://doi.org/10.1109/TC.2025.3605751'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As scientific and engineering challenges grow in complexity and scale, the demand for effective solutions for sparse matrix computations becomes increasingly critical. LU decomposition, known for its ability to reduce computational load and enhance numerical stability, serves as a promising approach. This study focuses on accelerating sparse LU decomposition for circuit simulations, addressing the prolonged simulation times caused by large circuit matrices. We present a novel Operation-based Optimized LU (OOLU) decomposition architecture that significantly improves circuit analysis efficiency. OOLU employs a VLIW-like processing element array and incorporates a scheduler that decomposes computations into a fine-grained operational task flow graph, maximizing inter-operation parallelism. Specialized scheduling and data mapping strategies are applied to align with the adaptable pipelined framework and the characteristics of circuit matrices. The OOLU architecture is prototyped on an FPGA and validated through extensive tests on the University of Florida sparse matrix collection, benchmarked against multiple platforms. The accelerator achieves speedups ranging from 3.48× to 32.25× (average 12.51×) over the KLU software package. It also delivers average speedups of 2.64× over a prior FPGA accelerator and 25.18× and 32.27× over the GPU accelerators STRUMPACK and SFLU, respectively, highlighting the substantial efficiency gains our approach delivers.},
  archive      = {J_TC},
  author       = {Ke Hu and Fan Yang},
  doi          = {10.1109/TC.2025.3605751},
  journal      = {IEEE Transactions on Computers},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Comput.},
  title        = {OOLU: An operation-based optimized sparse LU decomposition accelerator for circuit simulation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). JCSRC: Joint client selection and resource configuration for energy-efficient multi-task federated learning. <em>TC</em>, 1-14. (<a href='https://doi.org/10.1109/TC.2025.3605765'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) enables privacy-preserving distributed machine learning by training models on edge client devices using their local data without revealing their raw data. In edge environments, various applications require different neural network models, making it crucial to perform joint training of multiple models on edge devices, known as multi-task FL. While existing multi-task FL approaches enhance resource utilization on edge devices through adaptive resource configuration or client selection, optimizing either of these aspects alone may lead to suboptimality. Therefore, in this paper, we explore a joint client selection and resource configuration method called JCSRC for multi-task FL, aiming to maximize energy efficiency in environments with limited computation and communication resources and heterogeneous client devices. Firstly, we formalize this problem as a mixed-integer nonlinear programming problem considering all these characteristics and prove its NP-hardness. To address this problem, we first design a multi-agent reinforcement learning (MARL)-based client selection method that selects appropriate clients for each task to train their models. The MARL method makes client selection decisions based on the clients’ data quality, energy efficiency, communication, and computation capacity to ensure fast convergence and energy efficiency. Then, we design a particle swarm optimization (PSO)-based resource configuration scheme that configures appropriate computation and bandwidth resources for each task on each client. The PSO scheme makes resource configuration decisions based on theoretically derived optimal CPU frequency and bandwidth to achieve high energy efficiency. Finally, we carry out extensive simulations and testbed-based experiments to validate our proposed JCSRC. The results demonstrate that, in comparison to state-of-the-art solutions, JCSRC can save energy consumption by up to 59% to achieve the target accuracy.},
  archive      = {J_TC},
  author       = {Junpeng Ke and Junlong Zhou and Dan Meng and Yue Zeng and Yizhou Shi and Xiangmou Qu and Song Guo},
  doi          = {10.1109/TC.2025.3605765},
  journal      = {IEEE Transactions on Computers},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Comput.},
  title        = {JCSRC: Joint client selection and resource configuration for energy-efficient multi-task federated learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid approach to refine WCRT bounds for DAG scheduling using anomaly classification. <em>TC</em>, 1-14. (<a href='https://doi.org/10.1109/TC.2025.3603674'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by the performance demands and stringent timing requirements of safety-critical systems like avionics and autonomous vehicles, research has focused on providing timing guarantees for the scheduling of Directed Acyclic Graph (DAG) tasks in multicore systems. The structural complexity and timing anomalies make this problem challenging. Existing methods bound the Worst-Case Response Time (WCRT) of tasks through static analysis, but these bounds are complicated, difficult to validate, and often remain pessimistic for many scheduling scenarios. Runtime intervention can be effective in eliminating timing anomalies and providing timing guarantees; however, it is ineffective for anomaly-free scheduling scenarios, leads to non-work-conserving schedules, and incurs additional overhead. This paper proposes a hybrid approach to identify timing anomalies in DAG scheduling scenarios within a system, providing tighter WCRT solutions. The static analysis first offers a sufficient anomaly test to directly identify some anomaly-free DAG scheduling scenarios. Leveraging a wide range of scheduling data collected from the running system or its simulator, we then apply a machine learning approach to train a binary classification model, achieving an accuracy of 99.5%. Identifying the anomaly status enables the application of more precise WCRT bounds for different scheduling scenarios, leading to improved system performance. Specifically, we shorten the WCRT bounds for anomaly-free DAG scheduling by an average of up to 21.58%, with a maximum reduction of up to 55.47% compared to the state-of-the-art method.},
  archive      = {J_TC},
  author       = {Nan Chen and Xiaotian Dai and Alan Burns and Iain Bate},
  doi          = {10.1109/TC.2025.3603674},
  journal      = {IEEE Transactions on Computers},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Comput.},
  title        = {A hybrid approach to refine WCRT bounds for DAG scheduling using anomaly classification},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stochastic modeling of intrusion tolerant systems based on redundancy and diversity. <em>TC</em>, 1-14. (<a href='https://doi.org/10.1109/TC.2025.3606189'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To cope with unforeseen attacks to software systems in critical application domains, redundancy-based ITSs schemes are among popular countermeasures to deploy. Designing the adequate ITS for the stated security requirements calls for stochastic analysis supports, able to assess the impact of variety of attack patterns on different ITS configurations. As contribution to this purpose, a stochastic model for ITS is proposed, whose novel aspects are the ability to account for both camouflaging components and for correlation aspects between the security failures affecting the diverse implementations of the software cyber protections adopted in the ITS. Extensive analyses are conducted to show the applicability of the model; the obtained results allow to understand the limits and strengths of selected ITS configurations when subject to attacks occurring in unfavorable conditions for the defender.},
  archive      = {J_TC},
  author       = {Silvano Chiaradonna and Felicita Di Giandomenico and Giulio Masetti},
  doi          = {10.1109/TC.2025.3606189},
  journal      = {IEEE Transactions on Computers},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Comput.},
  title        = {Stochastic modeling of intrusion tolerant systems based on redundancy and diversity},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DIVIDE: Efficient RowHammer defense via in-DRAM cache-based hot data isolation. <em>TC</em>, 1-14. (<a href='https://doi.org/10.1109/TC.2025.3603729'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RowHammer poses a serious reliability challenge to modern DRAM systems. As technology scales down, DRAM resistance to RowHammer has decreased by 30× over the past decade, causing an increasing number of benign applications to suffer from this issue. However, existing defense mechanisms have three limitations: 1) they rely on inefficient mitigation techniques, such as time-consuming victim row refresh; 2) they do not reduce the number of effective RowHammer attacks, leading to frequent mitigations; and 3) they fail to recognize that frequently accessed data is not only a root cause of RowHammer but also presents an opportunity for performance optimization. In this paper, we observe that frequently accessed hot data plays a distinct role in security and efficiency: it can induce RowHammer by interfering with adjacent cold data, while also being performance-critical due to its frequent accesses. To this end, we propose Data Isolation via In-DRAM Cache (DIVIDE), a novel defense mechanism that leverages in-DRAM cache to isolate and exploit hot data. DIVIDE offers three key benefits: 1) It reduces the number of effective RowHammer attacks, as hot data in the cache cannot interfere with each other. 2) It provides a simple yet effective mitigation measure by isolating hot data from cold data. 3) It caches frequently accessed hot data, improving average access latency. DIVIDE employs a two-level protection structure: the first level mitigates RowHammer in cache arrays with high efficiency, while the second level addresses the remaining threats in normal arrays to ensure complete protection. Owing to the high in-DRAM cache hit rate, DIVIDE efficiently mitigates RowHammer while preserving both the performance and energy efficiency of the in-DRAM cache. At a RowHammer threshold of 128, DIVIDE with probabilistic mitigation achieves an average performance improvement of 19.6% and energy savings of 20.4% over DDR4 DRAM for fourcore workloads. Compared to an unprotected in-DRAM cache DRAM, DIVIDE incurs only a 2.1% performance overhead while requiring just a modest 1KB per-channel CAM in the memory controller, with no modification to the DRAM chip.},
  archive      = {J_TC},
  author       = {Haitao Du and Yuxuan Yang and Song Chen and Yi Kang},
  doi          = {10.1109/TC.2025.3603729},
  journal      = {IEEE Transactions on Computers},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Comput.},
  title        = {DIVIDE: Efficient RowHammer defense via in-DRAM cache-based hot data isolation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Practical signature-free multivalued validated byzantine agreement and asynchronous common subset in constant time. <em>TC</em>, 1-14. (<a href='https://doi.org/10.1109/TC.2025.3607476'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract—Asynchronous common subset (ACS) is a powerful paradigm enabling applications such as Byzantine fault-tolerance (BFT) and multi-party computation (MPC). The most efficient ACS framework in the information-theoretic setting is due to Ben-Or, Kelmer, and Rabin (BKR, 1994). The BKR ACS protocol has been both theoretically and practically impactful. BKR ACS has an O(log $n$) running time (where $n$ is the number of replicas) due to the usage of $n$ parallel asynchronous binary agreement (ABA) instances, impacting both performance and scalability. Indeed, for a network of 16∼64 replicas, the parallel ABA phase occupies about 95%∼97% of the total runtime. A long-standing open problem is whether we can build an ACS framework with O(1) time while not increasing the message or communication complexity of the BKR protocol. We resolve the open problem, presenting the first constant-time ACS protocol with O($n$3) messages in the information-theoretic and signature-free settings. Our key ingredient is the first information-theoretic and constant-time multivalued validated Byzantine agreement (MVBA) protocol. Our results can improveߞasymptotically and concretelyߞvarious applications using ACS and MVBA. As an example, we implement FIN, a BFT protocol instantiated using our framework. Via a 121-server deployment on Amazon EC2, we show FIN reduces the overhead of the ABA phase to as low as 1.23% of the total runtime.},
  archive      = {J_TC},
  author       = {Xin Wang and Xiao Sui and Sisi Duan and Haibin Zhang},
  doi          = {10.1109/TC.2025.3607476},
  journal      = {IEEE Transactions on Computers},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Comput.},
  title        = {Practical signature-free multivalued validated byzantine agreement and asynchronous common subset in constant time},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fluid kernels: Seamlessly conquering the embedded computing continuum. <em>TC</em>, 1-14. (<a href='https://doi.org/10.1109/TC.2025.3605745'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To achieve seamless portability across the embedded computing continuum, we introduce a new kernel architecture: fluid kernels. Fluid kernels can be thought of as the intersection between embedded unikernels and general purpose monolithic kernels, allowing to seamlessly develop applications both in kernel space and user space in a unified way. This scalable kernel architecture can manage the trade-off between performance, code size, isolation and security. We compare our fluid kernel implementation, Miosix, to Linux and FreeRTOS on the same hardware with standard benchmarks. Compared to Linux, we achieve an average speedup of 3.5× and a maximum of up to 15.4×. We also achieve an average code size reduction of 84% and a maximum of up to 90%. By moving application code from user space to kernel space, an additional code size reduction up to 56% and a speedup up to 1.3× can be achieved. Compared to FreeRTOS, the use of Miosix only costs a moderate amount of code size (at most 47KB) for significant advantages in application performance with speedups averaging at 1.5× and up to 5×.},
  archive      = {J_TC},
  author       = {Federico Terraneo and Daniele Cattaneo},
  doi          = {10.1109/TC.2025.3605745},
  journal      = {IEEE Transactions on Computers},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Comput.},
  title        = {Fluid kernels: Seamlessly conquering the embedded computing continuum},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightweight graph partitioning enhanced by implicit knowledge. <em>TC</em>, 1-14. (<a href='https://doi.org/10.1109/TC.2025.3612730'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph partitioning as a classic NP-complete problem, is the most fundamental procedure that needs to be performed before parallel computations. Partitioners can be divided into vertex- and edge-based approaches. Recently, both approaches are employing a streaming heuristic to find approximate solutions. It is lightweight in space and time complexities, but suffers from suboptimal partitioning quality, especially for directed graphs where the explicit knowledge provided for heuristic is limited. This paper thereby proposes new heuristics for not only vertex-based but also edge-based partitioning. They improve quality by additionally utilizing implicit knowledge, which is embedded in the local streaming view and the global graph view. Memory reduction techniques are presented to extract this knowledge with negligible space costs. That preserves the lightweight advantages of streaming partitioning. Besides, we study parallel acceleration and restreaming, to further boost the partitioning efficiency and quality. Extensive experiments validate that our proposals outperform the state-of-the-art competitors.},
  archive      = {J_TC},
  author       = {Zhigang Wang and Gongtai Sun and Ning Wang and Lixin Gao and Chuanfei Xu and Yu Gu and Ge Yu and Zhihong Tian},
  doi          = {10.1109/TC.2025.3612730},
  journal      = {IEEE Transactions on Computers},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Comput.},
  title        = {Lightweight graph partitioning enhanced by implicit knowledge},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ElasticEC: Achieving fast and elastic redundancy transitioning in erasure-coded clusters. <em>TC</em>, 1-13. (<a href='https://doi.org/10.1109/TC.2025.3614839'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Erasure coding has been extensively deployed in today’s commodity HPC systems against unexpected failures. To adapt to the varying access characteristics and reliability demands, storage clusters have to perform redundancy transitioning via tuning the coding parameters, which unfortunately gives rise to substantial transitioning traffic. We present ElasticEC, a fast and elastic redundancy transitioning approach for erasure-coded clusters. ElasticEC first minimizes the transitioning traffic via proposing a relocation-aware stripe reorganization mechanism and a collecting-and-encoding algorithm. It further heuristically balances the transitioning traffic across nodes. We implement ElasticEC in Hadoop HDFS and conduct extensive experiments on a real-world cloud storage cluster, showing that ElasticEC can reduce 71.1-92.6% of the transitioning traffic and shorten 65.9-90.7% of the transitioning time.},
  archive      = {J_TC},
  author       = {Yuhui Cai and Guowen Gong and Zhirong Shen and Jiahui Yang and Jiwu Shu},
  doi          = {10.1109/TC.2025.3614839},
  journal      = {IEEE Transactions on Computers},
  month        = {9},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Comput.},
  title        = {ElasticEC: Achieving fast and elastic redundancy transitioning in erasure-coded clusters},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unleashing the power of differential fault attacks on QARMAv2. <em>TC</em>, 1-12. (<a href='https://doi.org/10.1109/TC.2025.3603728'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {QARMAv2, a family of lightweight block ciphers introduced in ToSC 2023, is an evolution of the original QARMA design, specifically constructed to accommodate more extended tweak values while simultaneously enhancing security measures. In this paper, for the first time, we present differential fault analysis (DFA) of all the QARMAv2 variants by introducing an approach to utilize the fault propagation patterns at the nibble level, with the goal of identifying relevant faulty ciphertexts and vulnerable fault positions. Introducing six random nibble faults strategically into the (r – 1)-th and (r – 2)-th backward rounds of the r-round QARMAv2-64 significantly reduces the secret key space from 2128 to 232. Additionally, when targeting QARMAv2-128-128, it demands the introduction of six random nibble faults to effectively reduce the secret key space from 2128 to a remarkably reduced 224. To conclude, we also explore the potential extension of our methods to conduct DFA on other versions of QARMAv2. To the best of our knowledge, this marks the first instance of a differential fault attack targeting the QARMAv2 tweakable block cipher family, signifying an important direction in cryptographic analysis.},
  archive      = {J_TC},
  author       = {Soumya Sahoo and Debasmita Chakraborty and Santanu Sarkar},
  doi          = {10.1109/TC.2025.3603728},
  journal      = {IEEE Transactions on Computers},
  month        = {8},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Comput.},
  title        = {Unleashing the power of differential fault attacks on QARMAv2},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive federated learning through dynamic model splitting and multi-objective clustering. <em>TC</em>, 1-14. (<a href='https://doi.org/10.1109/TC.2025.3603681'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) enables multiple parties to collaboratively train models without centralizing data, making it ideal for privacy-sensitive applications. However, the heterogeneity and resource limitation of devices pose a critical challenge to the collaborative training process, incurring a significant communication cost to achieve convergence. Existing research has attempted to use clustering to address these issues. However, these approaches relied on a single clustering objective, limiting their effectiveness in a multifaceted heterogeneous environment. In this paper, we propose FedMSC, which employs an evolutionary-based multi-objective optimization approach to organize clients into distinct clusters via their similarities on independent factors such as response speed and local model updates. FedMSC iteratively generates Pareto-optimal cluster solutions, ensuring that no single solution outperforms another, while concurrently optimizing multiple objectives. Moreover, to account for computational diversity across clusters, FedMSC adopts a multi-exit training strategy in which the model is divided into blocks of layers, each equipped with auxiliary classifiers for early inference. Meanwhile, we devise a unique algorithm which dynamically assigns model blocks to devices through combinatorial optimization of devices’ resource capabilities and the computational requirements of the blocks. Experimental results demonstrate that FedMSC significantly reduce communication costs while maintaining a comparable accuracy to the baselines.},
  archive      = {J_TC},
  author       = {Ousman Manjang and Yanlong Zhai and Jun Shen and Adil Sarwar and Liehuang Zhu},
  doi          = {10.1109/TC.2025.3603681},
  journal      = {IEEE Transactions on Computers},
  month        = {8},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Comput.},
  title        = {Adaptive federated learning through dynamic model splitting and multi-objective clustering},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bandwidth on a budget: Real-time configuration for edge video analysis. <em>TC</em>, 1-14. (<a href='https://doi.org/10.1109/TC.2025.3603711'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In an era marked by technological innovation, visual applications have become ubiquitous in everyday life. Harnessing the power of computer vision, these applications process and interpret video data from edge cameras, facilitating tasks such as object detection and vehicle counting. Yet, implementing complex deep learning models on cameras with limited computational capacity poses significant challenges. Furthermore, the bandwidth constraints and fluctuating nature of wide-area networks present substantial difficulties for video analysis systems dependent on cloud computing. This paper first characterizes the relationship between different parameter combinations (such as frame rate and resolution) and video analysis accuracy through offline analysis. It proposes a video stream analysis configuration selection scheme, SPStream, for slowly changing scenes, and a configuration file switching strategy, SPStream+, for rapidly changing scenes. These strategies use idle resources at the camera edge end to select the optimal configuration in real-time, adjust video encoding quality, and dynamically switch configuration files based on the changing states of object motion. Finally, a real-time video stream analysis system for vehicle counting and pedestrian detection suitable for both scenarios is designed, which saves bandwidth to the greatest extent while meeting the accuracy requirements of users and achieving high accuracy of video analysis.},
  archive      = {J_TC},
  author       = {Sheng Chen and Jie Deng and Xiaoyi Tao and Xin Xie and Renrui Tan and Tu Hong and Xiulong Liu},
  doi          = {10.1109/TC.2025.3603711},
  journal      = {IEEE Transactions on Computers},
  month        = {8},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Comput.},
  title        = {Bandwidth on a budget: Real-time configuration for edge video analysis},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved error bounds for floating-point quotients. <em>TC</em>, 1-8. (<a href='https://doi.org/10.1109/TC.2025.3585341'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let $x_{0}, y_{1}, \dots, y_{k}$ be nonzero floating-point numbers in base $\beta \geq 2$ and precision $p \geq 1$. Let $z := x_{0}/ y_{1}/ \dots/ y_{k}$, whereby the divisions are evaluated from left to right, and let $\widehat{z}$ be the corresponding floating-point evaluation according to the IEEE 754 standard in rounding to nearest. We prove that, in absence of underflow and overflow, $|\widehat{z}-z| \leq k\text{u}|z|$ provided that $k \leq \sqrt{\omega/\beta} \text{u}^{-1/3}$. Here $u := \frac{1}{2} \beta^{1-p}$ denotes the relative rounding error unit and $\omega := 2$ if $\beta$ is even and $\omega := 1$ if $\beta$ is odd. Thus, the relative rounding error of k consecutive floating-point divisions is bounded by ku. This improves on the classical Wilkinson-type bound $\gamma_{k} := k \text{u}/(1 - k \text{u})$.},
  archive      = {J_TC},
  author       = {Florian Bünger},
  doi          = {10.1109/TC.2025.3585341},
  journal      = {IEEE Transactions on Computers},
  month        = {7},
  pages        = {1-8},
  shortjournal = {IEEE Trans. Comput.},
  title        = {Improved error bounds for floating-point quotients},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deconstructing the smart redbelly blockchain. <em>TC</em>, 1-12. (<a href='https://doi.org/10.1109/TC.2024.3475573'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Typical blockchain nodes replicate the execution of requests, which include native transfers and smart contract executions. With the shift of the Web towards Web3, modern blockchains suffer from congestion which prevents them to handle user requests. Recent studies showed that modern blockchains perform poorly or lose requests to realistic Decentralized Application (DApp) workloads, impairing the shift towards Web3. In this paper, we present Smart Redbelly Blockchain (SRBB) which handles realistic DApp workloads. Smart Redbelly Blockchain improves blockchain performance with (1) Transaction Validation and Propagation Reduction, (2) caching optimizations and (3) fast block execution. SRBB outperforms Algorand, Avalanche, Diem, Ethereum, Quorum and Solana when deployed over 5 continents and under the realistic workloads of NASDAQ, Uber and FIFA using the Diablo benchmark suite. Next, we decouple SRBB that improves the peak throughput of SRBB for the NASDAQ workload by 33% and reduces its latency by 20%.},
  archive      = {J_TC},
  author       = {Deepal Tennakoon and Vincent Gramoli},
  doi          = {10.1109/TC.2024.3475573},
  journal      = {IEEE Transactions on Computers},
  month        = {10},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Comput.},
  title        = {Deconstructing the smart redbelly blockchain},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Local migration model of images based on deep learning against adversarial attacks. <em>TC</em>, 1. (<a href='https://doi.org/10.1109/TC.2021.3075715'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Neural Networks (DNNs) have achieved remarkable results in various tasks. However, DNNs are easily deceived by small input disturbances, which are called adversarial attacks. The adversarial attack is to deliberately add some subtle interference that humans cannot detect to the input sample, causing the model to give a wrong output with high confidence. Deep-Learning-as-a-Service (DLaaS) has become a current hot trend, and it also introduces challenging security issues. Therefore, in this paper, we propose a local migration model of confrontational attack images based on deep learning. The confrontational examples of the physical world are disguised as natural styles through the migration model to deceive human observers. Specifically, the model converts the small counter-interference into a specific pattern, and then camouflages the foreground or background or local target area of the image to achieve a high degree of invisibility. Due to the flexibility of the interference setting of this method, it can be used to help DNNs assess their robustness, and it can be used to achieve privacy protection and data security detection.},
  archive      = {J_TC},
  author       = {Hua Huang and Xinxin Liu},
  doi          = {10.1109/TC.2021.3075715},
  journal      = {IEEE Transactions on Computers},
  month        = {4},
  pages        = {1},
  shortjournal = {IEEE Trans. Comput.},
  title        = {Local migration model of images based on deep learning against adversarial attacks},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Notice of retraction: Deadlock-free adaptive routing in networks -on-chip using overlapping virtual networks. <em>TC</em>, 1. (<a href='https://doi.org/10.1109/TC.2021.3067320'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retracted.},
  archive      = {J_TC},
  author       = {Dong Xiang and Xiang Ji and Yuan Cai and Binzhang Fu},
  doi          = {10.1109/TC.2021.3067320},
  journal      = {IEEE Transactions on Computers},
  month        = {3},
  pages        = {1},
  shortjournal = {IEEE Trans. Comput.},
  title        = {Notice of retraction: Deadlock-free adaptive routing in networks -on-chip using overlapping virtual networks},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2016). SSD in-storage computing for search engines. <em>TC</em>, 1. (<a href='https://doi.org/10.1109/TC.2016.2608818'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {SSD-based in-storage computing (called ”Smart SSDs”) allows application-specific codes to execute inside SSDs to exploit the high internal bandwidth and energy-efficient processors. As a result, Smart SSDs have been successfully deployed in many industry settings, e.g., Samsung, IBM, Teradata, and Oracle. Moreover, researchers have also demonstrated their potential opportunities in database systems, data mining, and big data processing. However, it remains unknown whether search engine systems can benefit from Smart SSDs. This work takes a first step to answer this question. The major research issue is what search engine query processing operations can be cost-effectively offloaded to SSDs. For this, we carefully identified the five most commonly used search engine operations that could potentially benefit from Smart SSDs: intersection, ranked intersection, ranked union, difference, and ranked difference. With close collaboration with Samsung, we offloaded the above five operations of Apache Lucene (a widely used open-source search engine) to Samsungs Smart SSD. Finally, we conducted extensive experiments to evaluate the system performance and tradeoffs by using both synthetic datasets and real datasets. The experimental results show that Smart SSDs significantly reduce the query latency by a factor of 2-3 and energy consumption by 6-10 for most of the aforementioned operations.},
  archive      = {J_TC},
  author       = {Jianguo Wang and Dongchul Park and Yannis Papakonstantinou and Steven Swanson},
  doi          = {10.1109/TC.2016.2608818},
  journal      = {IEEE Transactions on Computers},
  month        = {9},
  pages        = {1},
  shortjournal = {IEEE Trans. Comput.},
  title        = {SSD in-storage computing for search engines},
  year         = {2016},
}
</textarea>
</details></li>
<li><details>
<summary>
(2016). An innovation approach for optimal resource allocation in emergency management. <em>TC</em>, 1. (<a href='https://doi.org/10.1109/TC.2016.2601331'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In metropolitan regions, emergency events with different severity levels usually require multiple resources that have appropriate functionalities, money expenditure, moving velocities, etc. These resources could distribute over an extensive area with different ownerships. Solving the resource allocation problem for such an event involves complicated collaboration of multiple emergency departments under strict time constraints. Traditional resource allocation approaches usually have difficulties to efficiently find out the best resource assignment within the time limits by considering the large number of possibilities, which result in a considerable increase in fatalities. In this paper, a multiagent-based decentralised resource allocation approach using the domain transportation theory is proposed to handle a multi-task emergency event. The proposed approach is designed to effectively select appropriate resources without the global information and to concurrently generate the resource deployment plans for multiple tasks by considering the severity level of an emergency event. In the experiments, the proposed approach is tested along with other related approaches, and the experimental results indicate that the proposed approach can efficiently generate the optimal solution in terms of resource allocation time and money expenditure.},
  archive      = {J_TC},
  author       = {Jihang Zhang and Minjie Zhang and Fenghui Ren and Jiakun Liu},
  doi          = {10.1109/TC.2016.2601331},
  journal      = {IEEE Transactions on Computers},
  month        = {8},
  pages        = {1},
  shortjournal = {IEEE Trans. Comput.},
  title        = {An innovation approach for optimal resource allocation in emergency management},
  year         = {2016},
}
</textarea>
</details></li>
<li><details>
<summary>
(2016). In-storage computing for hadoop MapReduce framework: Challenges and possibilities. <em>TC</em>, 1. (<a href='https://doi.org/10.1109/TC.2016.2595566'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solid State Drives (SSDs) were initially developed as faster storage devices intended to replace conventional magnetic Hard Disk Drives (HDDs). However, high computational capabilities enable SSDs to be computing nodes, not just faster storage devices. Such capability is generally called ”In-Storage Computing (ISC)”. Today’s Hadoop MapReduce framework has become a de facto standard for big data processing. This paper explores In-Storage Computing challenges and opportunities for the Hadoop MapReduce framework. For this, we integrate a Hadoop MapReduce system with ISC SSD devices that implement the Hadoop Mapper inside real SSD firmware. This offloads Map tasks from the host MapReduce system to the ISC SSDs. We additionally optimize the host Hadoop system to make the best use of our proposed ISC Hadoop system. Experimental results demonstrate our ISC Hadoop MapReduce system achieves a remarkable performance gain (2.3 faster) as well as significant energy savings (11.5 lower) compared to a typical Hadoop MapReduce system. Further, the experiment suggests such ISC augmented systems can provide a very promising computing model in terms of a system scalability.},
  archive      = {J_TC},
  author       = {Dongchul Park and Jianguo Wang and Yang-Suk Kee},
  doi          = {10.1109/TC.2016.2595566},
  journal      = {IEEE Transactions on Computers},
  month        = {7},
  pages        = {1},
  shortjournal = {IEEE Trans. Comput.},
  title        = {In-storage computing for hadoop MapReduce framework: Challenges and possibilities},
  year         = {2016},
}
</textarea>
</details></li>
<li><details>
<summary>
(2013). Novel techniques for smart adaptive multiprocessor SoCs. <em>TC</em>, 1. (<a href='https://doi.org/10.1109/TC.2013.57'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing concerns of power efficiency, silicon reliability and performance scalability motivate research in the area of adaptive embedded systems, i.e. systems endowed with decisional capacity, capable of online decision making so as to meet certain performance criteria. The scope of possible adaptation strategies is subject to the targeted architecture specifics, and may range from simple scenario-driven frequency/voltage scaling to rather complex heuristic-driven algorithm selection. This paper advocates the design of distributed memory homogeneous multiprocessor systems as a suitable template for best exploiting adaptation features, thereby tackling the aforementioned challenges. The proposed solution lies in the combined use of a typical application processor for global orchestration along with such an adaptive multiprocessor core for the handling of data-intensive computation. This paper describes an exploratory homogeneous multiprocessor template designed from the ground up for scalability and adaptation. The proposed contributions aim at increasing architecture efficiency through smart distributed control of architectural parameters such as frequency, and enhanced techniques for load balancing such as task migration and dynamic multithreading.},
  archive      = {J_TC},
  author       = {Luciano Ost and Rafael Garibotti and Gilles Sassatelli and Gabriel Marchesan Almeida and Rémi Busseuil and Anastasiia Butko and Michel Robert and Jürgen Becker},
  doi          = {10.1109/TC.2013.57},
  journal      = {IEEE Transactions on Computers},
  month        = {3},
  pages        = {1},
  shortjournal = {IEEE Trans. Comput.},
  title        = {Novel techniques for smart adaptive multiprocessor SoCs},
  year         = {2013},
}
</textarea>
</details></li>
<li><details>
<summary>
(2011). A new chaos-based cryptosystem for secure transmitted images. <em>TC</em>, 1. (<a href='https://doi.org/10.1109/TC.2011.16'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel and robust chaos-based cryptosystem for secure transmitted images and four other versions. In the proposed block encryption/decryption algorithm, a 2D chaotic map is used to shuffle the image pixel positions. Then, substitution (confusion) and permutation (diffusion) operations on every block, with multiple rounds, are combined using two perturbed chaotic PWLCM maps. The perturbing orbit technique improves the statistical properties of encrypted images. The obtained error propagation in various standard cipher block modes demonstrates that the proposed cryptosystem is suitable to transmit cipher data over a corrupted digital channel. Finally, to quantify the security level of the proposed cryptosystem, many tests are performed and experimental results show that the suggested cryptosystem has a high security level.},
  archive      = {J_TC},
  author       = {Abir Awad},
  doi          = {10.1109/TC.2011.16},
  journal      = {IEEE Transactions on Computers},
  month        = {1},
  pages        = {1},
  shortjournal = {IEEE Trans. Comput.},
  title        = {A new chaos-based cryptosystem for secure transmitted images},
  year         = {2011},
}
</textarea>
</details></li>
</ul>

</body>
</html>
