<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TNNLS</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tnnls">TNNLS - 144</h2>
<ul>
<li><details>
<summary>
(2025). Learning counterfactual fair representation under covariate shift via reflux. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3613549'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in counterfactual fairness have shifted focus from flawed group fairness metrics to ensuring individual-level fairness through counterfactual reasoning. However, most existing approaches remain limited to in-processing strategies—injecting fairness constraints into predictive models—while largely overlooking the potential of data preprocessing to mitigate inherent biases. Moreover, few methods address the critical challenge of real-world distribution shift, which can compromise the generalizability of fair models across domains. In this article, we propose the counterfactual reflux variational autoencoder (CRVAE), a novel framework for generating counterfactual samples and learning fair representations. To the best of our knowledge, this is the first work to explicitly consider counterfactual fair representation learning under covariate shift, enabling both single-domain and covariate shift prediction tasks. For fairness, we introduce a Reflux technique that enforces consistency between factual and counterfactual representations. For transferability, we incorporate a domain discriminator to align fair representations across domains. Experimental results show that our approach improves fairness with minimal performance loss and maintains generalization across domains. Furthermore, CRVAE can be flexibly combined with existing in-processing fairness methods. Future work may explore extending this framework to settings with limited causal graph knowledge.},
  archive      = {J_TNNLS},
  author       = {Yiliang Xia and Xiaohang Zhang and Zhengren Li},
  doi          = {10.1109/TNNLS.2025.3613549},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Learning counterfactual fair representation under covariate shift via reflux},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unbiased semantic decoding with vision foundation models for few-shot segmentation. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3611497'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot segmentation (FSS) has garnered significant attention. Many recent approaches attempt to introduce the segment anything model (SAM) to handle this task. With the strong generalization ability and rich object-specific extraction ability of the SAM model, such a solution shows great potential in FSS. However, the decoding process of SAM highly relies on accurate and explicit prompts, making previous approaches mainly focus on extracting prompts from the support set, which is insufficient to activate the generalization ability of SAM, and this design is easy to result in a biased decoding process when adapting to the unknown classes. In this work, we propose an unbiased semantic decoding (USD) strategy integrated with SAM, which extracts target information from both the support and query set simultaneously to perform consistent predictions guided by the semantics of the contrastive language-image pretraining (CLIP) model. Specifically, to enhance the unbiased semantic discrimination of SAM, we design two feature enhancement strategies that leverage the semantic alignment capability of CLIP to enrich the original SAM features, mainly including a global supplement at the image level to provide a generalize category indicate with support image and a local guidance at the pixel level to provide a useful target location with query image. Besides, to generate target-focused prompt embeddings, a learnable visual–text target prompt generator (VTPG) is proposed by interacting target text embeddings and clip visual features. Without requiring retraining of the vision foundation models, the features with semantic discrimination draw attention to the target region through the guidance of prompt with rich target information. Experiments on both the PASCAL- $5^{i}$ and COCO- $20^{i}$ show that our proposed method outperforms the existing approaches by a clear margin and achieves new state-of-the-art performances.},
  archive      = {J_TNNLS},
  author       = {Jin Wang and Bingfeng Zhang and Jian Pang and Weifeng Liu and Baodi Liu and Honglong Chen},
  doi          = {10.1109/TNNLS.2025.3611497},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Unbiased semantic decoding with vision foundation models for few-shot segmentation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Three-dimensional multiobject tracking based on voxel masking encoder and deep hashing paradigm. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3613354'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In autonomous driving, accurate 3-D multiobject tracking (MOT) plays a key role in ensuring vehicle safety. However, due to the complexity of the environment, existing methods still face many challenges when dealing with long-distance objects, partial occlusions, and interference from similar categories. To tackle these challenges, we propose a 3-D MOT framework based on a voxel masking encoder (VME) and a deep hashing paradigm (DHP). We introduce a masking strategy that processes voxel features from near to far while maintaining feature sparsity, effectively capturing global contextual information between spatial features. Simultaneously, DHP is utilized to generate image hash codes and compute their hamming distance from the category hash codes. This process effectively distinguishes between object categories and thus avoids cross-category object dissociation. In addition, we propose a distance optimization matching (DOM) method that uses geometric dimensions and spatial distances to build a cost matrix, achieving more efficient and precise object associations. Results from experiments conducted on the KITTI dataset reveal that our framework delivers outstanding tracking performance, surpassing other advanced methods in tracking accuracy. The code is released at https://github.com/lsy-collab/VD-MOT},
  archive      = {J_TNNLS},
  author       = {Saiyu Li and Zhong Chen and Hui Li and Ye Tao and Ying Gao and Jun Yan},
  doi          = {10.1109/TNNLS.2025.3613354},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Three-dimensional multiobject tracking based on voxel masking encoder and deep hashing paradigm},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optical-cue-guided diffusion probabilistic model for reflection removal. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3612402'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a novel reflection removal algorithm that integrates a flash-based optical cue into a diffusion model to control the recovery of the transmission image. The algorithm accepts a pair of ambient and flash images as inputs, and a flash-only image, which corresponds to the one captured with flash as the sole illumination source, is derived from the inputs. In light of the reflection-free nature of the flash-only image, we use it to guide the diffusion model to reconstruct the structures of the transmission image. A feature distillation scheme is designed to infer the chromatic attributes of the transmission image from the ambient image, and the features are used to modulate the generative priors learned by the diffusion model. We use time-aware strategies to ensure the synchronization between feature distillation and the dynamic image generation process of the diffusion model. The performance of the proposed algorithm is sequentially optimized in latent and pixel spaces. We also develop a plug-and-play fidelity-enhancing module (FEM) and integrate it into the proposed model to enable the faithful reconstruction of fine-granular visual characteristics of the target scene and reduce artifacts. Comparative experiments demonstrate that the proposed algorithm shows superior quantitative and qualitative performance over state-of-the-art methods in real-world scenarios. By leveraging the optical cue and the generative capability of the diffusion model, the algorithm can accurately restore the visual details of the transmission image even in the presence of strong reflections, and it also exhibits satisfactory robustness against nonlinear image representation and misalignment.},
  archive      = {J_TNNLS},
  author       = {Feiyang Zhang and Yuenan Li and Xiaoliang Chang},
  doi          = {10.1109/TNNLS.2025.3612402},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Optical-cue-guided diffusion probabilistic model for reflection removal},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hard sample mining: A new paradigm of efficient and robust model training. <em>TNNLS</em>, 1-21. (<a href='https://doi.org/10.1109/TNNLS.2025.3610948'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past two decades, deep learning (DL) has achieved unprecedented breakthroughs across diverse application domains spanning computer vision (CV) to natural language processing (NLP). However, despite significant advances in computational resources and algorithmic frameworks, the training of deep neural networks continues to present formidable challenges due to persistent issues of training inefficiency and inherent data distribution biases. Recent years have witnessed the emergence of hard sample mining (HSM) as a promising paradigm to mitigate training inefficiencies and enhance model robustness through representative sample selection. Although HSM is reshaping contemporary AI research, its critical role in enabling efficient and robust model training has not yet been systematically explored. This article presents a comprehensive survey of HSM methodologies by: 1) establishing unified definitions of hard samples through rigorous sample complexity quantification criteria; 2) proposing a systematic taxonomy of HSM approaches with in-depth technical analysis; and 3) identifying pivotal research frontiers in this evolving field. This survey not only consolidates the foundations of HSM but also provides a roadmap for advancing efficient, robust, and generalizable deep learning models.},
  archive      = {J_TNNLS},
  author       = {Lei Liu and Yunji Liang and Xiaokai Yan and Luwen Huangfu and Sagar Samtani and Zhiwen Yu and Yanyong Zhang and Daniel D. Zeng},
  doi          = {10.1109/TNNLS.2025.3610948},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-21},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Hard sample mining: A new paradigm of efficient and robust model training},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modal detection informed classification evaluation via ensemble networks for expensive constrained multimodal optimization. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3612490'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The evaluation of objective and constraint involving expensive simulations or physical experiments with multiple optimal solutions is referred to as expensive constrained multimodal optimization problems (ECMMOPs). Under limited real function evaluations (FEs), it is challenging to find multiple optimal solutions accurately while satisfying constraints. To address these issues, this article studies a self-clustering particle swarm optimization algorithm with modal detection informed classification evaluation (MDICE) to solve ECMMOPs. To deal with multimodality, a surrogate-assisted self-clustering update mechanism is first designed to update individuals in each modality. Following that, a novel modal detection strategy is proposed based on the awareness of fitness landscapes to identify all potential modal seeds. For better utilization of FEs, a modality-guided classification evaluation strategy is designed to efficiently generate infilling samples for each constraint and modality. Moreover, to address the complex constraints, a surrogate-assisted feasibility search strategy is developed to quickly search for feasible solutions at a lower evaluation cost. Experimental results on 33 benchmark functions with various characteristics indicate that MDICE outperforms four state-of-the-art surrogate-assisted evolutionary algorithms.},
  archive      = {J_TNNLS},
  author       = {Kunjie Yu and Fan Chen and Mingyuan Yu and Jing Liang and Ke Chen},
  doi          = {10.1109/TNNLS.2025.3612490},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Modal detection informed classification evaluation via ensemble networks for expensive constrained multimodal optimization},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing the output of long short-term memory cell for high-frequency forecasting in financial markets. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3611887'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-frequency trading (HFT) requires fast data processing without information lags for precise stock price forecasting. This high-paced stock price forecasting is usually based on vectors that need to be treated as sequential and time-independent signals due to the time irregularities that are inherent in HFT. A well-documented and tested method that considers these time irregularities is a type of recurrent neural network (NN), named long short-term memory (LSTM) NN. This type of NN is formed based on cells that perform sequential and stale calculations via gates and states without knowing whether their order, within the cell, is optimal. In this article, we propose a revised and real-time adjusted LSTM cell that selects the best gate or state as its final output. Our cell is running under a shallow topology, has a minimal look-back period, and is trained online. This revised cell achieves lower forecasting error compared to other recurrent NNs (RNNs) for online HFT forecasting tasks such as the limit order book (LOB) mid-price (MP) prediction as it has been tested on two high-liquid U.S. and two less-liquid Nordic stocks.},
  archive      = {J_TNNLS},
  author       = {Adamantios Ntakaris and Moncef Gabbouj and Juho Kanniainen},
  doi          = {10.1109/TNNLS.2025.3611887},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Optimizing the output of long short-term memory cell for high-frequency forecasting in financial markets},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). All-to-all connected oscillator ising machines and their application as associative memory. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3609571'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic behaviors of the classical Kuramoto models have been widely studied. The dynamics of the all-to-all connected oscillator Ising machines (OIMs) is similar to that of the classical Kuramoto models, with the main difference being that there is an additional term in OIMs, called the second harmonic term. However, the dynamic behavior of an all-to-all connected OIM is significantly different and its intricate properties are largely unexplored. In this article, we study in detail the properties of the all-to-all connected OIMs and explore their application as associative memory. The number of patterns such an OIM can store increases exponentially with respect to the number of oscillators. To improve the performance of the OIMs for associative memory, we propose a new harmonic term so that the resulting OIM achieves pattern retrieval with high accuracy in the presence of a high level of noise.},
  archive      = {J_TNNLS},
  author       = {Yi Cheng and Zongli Lin},
  doi          = {10.1109/TNNLS.2025.3609571},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {All-to-all connected oscillator ising machines and their application as associative memory},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedMPS: Federated learning in a synergy of multi-level prototype-based contrastive learning and soft label generation. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3611832'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) facilitates collaborative training among multiple clients while preserving data privacy by eliminating raw data transmission. However, the inherent data heterogeneity among participants induces bias during collaborative learning, significantly degrading the performance of local models. Existing FL solutions face critical challenges in achieving efficient knowledge transmission, particularly with respect to insufficient information extraction or excessive communication costs, which result in slow convergence and inferior performance. To address these limitations, we propose a novel FL framework in a synergy of multi-level prototype-based contrastive learning (CL) and soft label generation, named FedMPS. The proposed method first constructs multi-level prototypes from different layers of the model to capture semantic information in high-level features and detailed information in low-level features. These prototypes are then utilized through CL to enhance intra-class discriminability and intra-class consistency in the feature space. In addition, a prototype-guided soft label generation module is introduced to model latent interclass relationships in the output space. Instead of exchanging model parameters, FedMPS transmits only prototypes and soft labels, effectively reducing global knowledge shift and communication costs. Extensive experimental studies on six publicly available datasets validate the effectiveness of the proposed method when compared to the current state-of-the-art FL approaches. The code is available at github.com/wenxinyang1026/FedMPS},
  archive      = {J_TNNLS},
  author       = {Wenxin Yang and Xingchen Hu and Xiubin Zhu and Rouwan Wu and Witold Pedrycz and Xinwang Liu and Jincai Huang},
  doi          = {10.1109/TNNLS.2025.3611832},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {FedMPS: Federated learning in a synergy of multi-level prototype-based contrastive learning and soft label generation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Syntax-oriented shortcut: A syntax level perturbing algorithm for preventing text data from being learned. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3609842'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The vast availability of free data has been critical to the success of large language models (LLMs). With the widespread use of LLMs, more and more concerns have been raised about the unauthorized use of publicly available data. To protect data from unauthorized use for training models, researchers have proposed adding imperceptible perturbations into image data so that models would be misled by the generated shortcut features and cannot mine information from these images. However, due to the inherent discrete property and semantic complexity of texts, directly applying these methods to text will cause semantic changes, resulting in meaningless shortcut features being constructed. To tackle this problem, in this article, we design a novel Unlearnable text examples generation algorithm via syntax-oriented shortcut (UTE-SS) by incorporating the syntactic structure of texts. Specifically, we propose a syntax template generator (STG) to generate the optimal perturbing syntax for a given category, which will realize imperceptible perturbations. Then, a perturbing text generator (PTG) is designed to perturb the in-class texts with the selected syntax template to stably deviate from the original texts. Along this line, models will be misled to learn the shortcut between the syntax template and the category, so as to keep text examples unlearnable. Extensive experiments over eight advanced Transformer-based pretrained language models (PLMs) on four different natural language processing (NLP) tasks demonstrate the effectiveness and flexibility of our proposed algorithm. Our method is easy to implement, and the code is publicly available at https://github.com/libolb/UTE-SS.},
  archive      = {J_TNNLS},
  author       = {Bo Li and Kun Zhang and Xi Chen and Richang Hong},
  doi          = {10.1109/TNNLS.2025.3609842},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Syntax-oriented shortcut: A syntax level perturbing algorithm for preventing text data from being learned},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedNK-RF: Federated kernel learning with heterogeneous data and optimal rates. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3612728'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) has become a mainstream decentralized learning paradigm due to its privacy-preserving features. However, the heterogeneity of data in FL can reduce predictive accuracy and complicate the analysis of the generalization properties of FL methods. In this article, we propose efficient federated kernel learning (FedK) algorithms and study their generalization properties. We first devise FedK with random features (FedK-RF), which acquires global information through sharing RF of local data subsets, enhancing predictive capability while protecting privacy. We then propose federated Nyström approximation with RF (FedNK-RF) that reduces errors resulted from RF. Furthermore, using integral operator theory, we derive the excess risk bounds with minimax optimal rates, which illustrate the impacts from data heterogeneity and shared information. Finally, we conduct several experiments that demonstrate the superiority of the proposed FedNK-RF.},
  archive      = {J_TNNLS},
  author       = {Xuning Zhang and Jian Li and Rong Yin and Weiping Wang},
  doi          = {10.1109/TNNLS.2025.3612728},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {FedNK-RF: Federated kernel learning with heterogeneous data and optimal rates},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PID: A parameter-efficient isolation domain-incremental learning framework for signal modulation classification. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3615307'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks have achieved promising progress in signal modulation classification (SMC), playing an essential role in a variety of applications such as cognitive radio networks, cyber defense, and electronic surveillance. However, most existing SMC methods still follow the traditional machine learning paradigm that trains on static closed datasets, lacking the ability to cope with the challenge of continuous data distribution shifts in real communication scenarios. Directly applying the model to a new environment may lead to severe degradation of classification performance on previous scenarios, i.e., catastrophic forgetting. To address this, this article proposes the first domain-incremental learning (DIL) paradigm for SMC and designs a parameter-efficient isolation DIL (PID) method, which enables SMC models to rapidly adjust to new scenarios by extending only a few parameters, while significantly retaining classification capabilities on previous scenarios. Specifically, we first propose a parameter space decomposition-based classifier (PSD), separating the model parameters into a set of bases and corresponding coefficients. By freezing the bases and fine-tuning the low-dimensional coefficients, the catastrophic forgetting problem can be efficiently eliminated. Furthermore, we design a scene-aware domain controller (SDC) to select the most suitable domain-specific coefficients for each sample, thereby maintaining the SMC model’s classification capabilities across all domains. The extensive experimental results show the superiority of the proposed PID, which achieves state-of-the-art (SOTA) overall performance. The code will be available at: https://github.com/SMC-IL/PID},
  archive      = {J_TNNLS},
  author       = {Guanchun Wang and Ziyi Liu and Xiangrong Zhang and Yifan Chen and Yifang Zhang and Jin Zhu and Licheng Jiao},
  doi          = {10.1109/TNNLS.2025.3615307},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {PID: A parameter-efficient isolation domain-incremental learning framework for signal modulation classification},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DMutDE: Dual-view mutual distillation framework for knowledge graph embeddings. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3608503'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs (KGs) have caught more and more attention in recent years. Currently, in some practical scenarios, KG embedding (KGE) models are expected to reduce their spatial complexity without losing much performance to address the challenges of storage limitations and knowledge reasoning efficiency. To achieve this, existing works use one or more large and high-performance teacher models to improve the performance of a lightweight student model via knowledge distillation (KD), thus meeting the requirements of some practical complicated applications. However, in resource-constrained scenarios, obtaining high-performance teacher models is challenging due to high training costs and significant storage requirements. Thus, enhancing the student model’s performance without large teacher models is crucial. To address this issue, we propose Dual-View Mutual Distillation Framework for Knowledge Graph Embeddings (DMutDE), a distillation framework leveraging mutual learning for peer-to-peer distillation between two KGE models with different architectures. In KGE models, we notice that the way of modeling relational directed edges determines the model view of KGE model for learning KG data. Thus, integrating the model views from two different KGE models by KD into a student KGE model can improve its generalization, so as to increase its performance. To identify an effective dual-view fusion method, we design two modules in the DMutDE framework. Specifically, we design a novel soft-label fusion (SLF) module for noise filtering and response knowledge transfer. Then, we propose an entity embedding distillation (EED) module to distill structural features from each other. Finally, we conduct several comprehensive experiments on the standard open-source benchmarks to demonstrate that our framework achieves the state-of-the-art results. The code is available at https://github.com/RuizhouLiu/DMutDE},
  archive      = {J_TNNLS},
  author       = {Ruizhou Liu and Zhe Wu and Yiling Wu and Zongsheng Cao and Qianqian Xu and Qingming Huang},
  doi          = {10.1109/TNNLS.2025.3608503},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {DMutDE: Dual-view mutual distillation framework for knowledge graph embeddings},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multigranularity deep graph convolutional neural network node clustering leveraging spatial information. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3615830'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of information explosion, clustering analysis of graph-structured data and empty graph-structured data is of great significance for extracting the intrinsic value of data. From the perspective of spatial information, empty graph-structured data and graph-structured data are essentially the same type of data, both containing rich spatial information. However, there is currently no general clustering method that can handle both types of data, and the clustering methods applicable to empty graph-structured data pay little attention to the spatial information they contain. Meanwhile, graph convolutional neural networks (GCN) have made significant progress in processing graph-structured data, but applying them to empty graph-structured data still faces challenges because the latter lacks an explicit topological structure. To address these problems, this study proposes a multigranularity deep GCN node clustering method leveraging spatial information (CMDGCN). It converts empty graph-structured data into graph-structured data using the $k$ -nearest neighbor (k-nn) algorithm and constructs multigranularity graph structures based on feature segmentation to extend the network depth to deep layers, thereby addressing the issue of shallow network layers in traditional GCN models. In addition, this study improves the self-expressiveness principle, ensuring that the learned similarity matrix not only depends on the node embedding representation but also incorporates the original structural information of the graph, resulting in a high-quality and interpretable similarity matrix. Furthermore, through experimental verification on multiple graph-structured datasets and empty graph-structured datasets, our method outperforms existing methods in several key indicators, proving its effectiveness and robustness. This achievement not only provides new methods and perspectives for graph node clustering but also offers new effective tools for processing empty graph-structured data.},
  archive      = {J_TNNLS},
  author       = {Bin Yu and Haibo Yang},
  doi          = {10.1109/TNNLS.2025.3615830},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Multigranularity deep graph convolutional neural network node clustering leveraging spatial information},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Theoretical convergence analysis and initialization comparisons of deep soft-thresholding networks. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3614196'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft-thresholding (ST) has been widely used in deep neural networks. Its fundamental network structure is a deep soft-thresholding fully connected network (ST-FCN). However, training deep ST-FCN to achieve convergence remains time-consuming or even encounters gradient explosion, in part because the convergence behavior is not fully understood. To address this issue, this article proves the relationship between the convergence of deep ST-FCN and the values of network weights and biases. Theoretical analysis shows that, as the number of network layers approaches infinity, deep ST-FCN converges when the network weights tend to an identity matrix, while the biases tend to zero. Following this guidance, we initialize the network weights as the identity matrix, compare it with other representative initialization methods (Gaussian, He, LeCun, Xavier, and Uniform), and quantify their effects on network convergence. Extensive results on a synthetic spectrum dataset and real-world datasets (MNIST and CIFAR-10) demonstrate that initializing the weights to the identity matrix and the bias to zero leads to fast and stable convergence. These conclusions are further supported by additional experiments and statistical analysis on deeper ST networks (with more than ten layers) and other representative architectures (DenseNet-161, ResNet-152, and VGG-19), and more challenging benchmarks (CIFAR-100, STL-10, and Tiny ImageNet). This work provides a theoretical foundation for understanding the convergence of ST neural networks. Furthermore, convergence theory analysis for deep recurrent neural networks (RNNs) with ST is deduced.},
  archive      = {J_TNNLS},
  author       = {Chunyan Xiong and Mengxue Zhang and Tong Wei and Yihui Huang and Jian Cao and Qingrui Cai and Zhong Chen and Xiaobo Qu},
  doi          = {10.1109/TNNLS.2025.3614196},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Theoretical convergence analysis and initialization comparisons of deep soft-thresholding networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MDSF-YOLO: Advancing object detection with a multiscale dilated sequence fusion network. <em>TNNLS</em>, 1-12. (<a href='https://doi.org/10.1109/TNNLS.2025.3617122'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and fast detection of traffic signs is critical for autonomous driving, particularly in complex environments with diverse sign scales and varying detection distances. Existing approaches, incorporating attention modules or modifying detection heads, frequently encounter high rates of false positives and omissions due to the increased sampling depth. To address these limitations, we propose MDSF-you only look once (YOLO), a novel detection framework that integrates multiscale sequence fusion (MSF) for synergistic feature integration across granularities, enhancing the precision of both localization and semantic information fusion. Additionally, our dilated-wise residual (DWR) module leverages dilated convolutions and channel-wise reparameterization to improve fine-grained feature extraction. The architecture further introduces a $P_{2}$ detection head for shallow features and fully decouples all detection heads, optimizing target localization and category identification. Extensive experiments on the TT100K and CCTSDB2021 datasets demonstrate the superiority of MDSF-YOLO over benchmark models, including YOLOv11s, with significant improvements in mAP by 8.8% and 2.4% on respective datasets while substantially reducing false positives and leakage rate. Besides, the marked improvement of MDSF-YOLO on the VisDrone2019 dataset verifies its enhanced capability to address drone-based object detection. These advances underscore the efficiency and robustness of the proposed model, providing a promising solution for autonomous driving and similar object detection scenarios.},
  archive      = {J_TNNLS},
  author       = {Yu Sun and Chong Zhang and Xian Li and Xuyang Jing and Hui Kong and Qing-Guo Wang},
  doi          = {10.1109/TNNLS.2025.3617122},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {MDSF-YOLO: Advancing object detection with a multiscale dilated sequence fusion network},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FGPLFA: Fine-grained pseudo-labeling and feature alignment for source-free unsupervised domain adaptation. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3616236'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Source-free unsupervised domain adaptation (SFUDA) aims to improve performance in unlabeled target domain data without accessing source domain data. This is crucial in scenarios with data-sharing restrictions due to privacy or compliance constraints. Existing SFUDA approaches often rely on pseudo-labeling techniques based on entropy or confidence metrics. These often overlook fine-grained data features, resulting in noisy pseudo-labels that degrade model performance. To overcome this limitation, we develop a new method called fine-grained pseudo-labeling and feature alignment (FGPLFA) to enhance SFUDA’s performance. FGPLFA starts with a gradient-based metric that integrates insights from both model knowledge and data features, creating a more reliable sample metric. To enhance fine granularity, the fine-grained pseudo-labeling (FGPL) module was introduced. This module clusters data based on the magnitude and direction of gradients, allowing for dataset partitioning into subsets at the sample level. The subsets are pseudo-labeled with category-specificity and domain specificity, establishing a multilevel granularity structure that reduces noisy pseudo-labels. Subsequently, the mean-covariance adjustment feature alignment (MCAFA) method was introduced. Features from the subsets are aligned in a specified sequence, enhancing model adaptability in the target domain. Extensive experiments conducted across multiple datasets validate the superiority of FGPLFA.},
  archive      = {J_TNNLS},
  author       = {Zhongyi Wen and Qiang Li and Yatong Wang and Huaizong Shao and Guoming Sun},
  doi          = {10.1109/TNNLS.2025.3616236},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {FGPLFA: Fine-grained pseudo-labeling and feature alignment for source-free unsupervised domain adaptation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel pattern learning framework with enhanced scalability for continuous optimization. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3610993'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiobjective optimization problems (MOPs) arise in numerous real-world scenarios, yet finding their solutions with optimal trade-offs can be a formidable challenge. This article studies the continuous optimization problem involving large-scale variables, many objectives, and intricate constraints, which is rarely comprehensively discussed in existing works, due to the coexisting difficulties posed by the curse of dimensionality, selection pressure, and feasibility restrictions. To address these problems, this work pioneers a novel optimization framework, optimization pattern learning, embedded with machine learning (ML) techniques. Within this framework, the concept of measurable order and its corresponding learning mechanism are proposed to extract valuable knowledge from solutions. This measurable order is a general form of those orders used explicitly or implicitly in the existing studies, providing a more flexible means to evaluate solutions for efficient optimization adaptively. By substituting original solutions with their measurable orders, this framework effectively avoids the selection pressure from many objectives and the feasibility restrictions from intricate constraints. Furthermore, two novel ML models based on measurable orders are developed to progressively learn effective optimization patterns from iterative data in high-dimensional search spaces. Leveraging these learned patterns, this framework successfully addresses the curse of dimensionality from large-scale variables and thus achieves efficient optimization. Owing to the strong adaptability and search capabilities of this framework, it also demonstrates excellent scalability as the number of variables, objectives, and constraints increases. Extensive simulations validate the effectiveness of the framework and underscore its competitiveness relative to state-of-the-art algorithms in this field.},
  archive      = {J_TNNLS},
  author       = {Jian Qin and Yuanqiu Mo and Hongzhe Liu and Zhi-Hui Zhan and Wenwu Yu},
  doi          = {10.1109/TNNLS.2025.3610993},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A novel pattern learning framework with enhanced scalability for continuous optimization},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Boosting few-shot hyperspectral image classification through dynamic fusion and hierarchical enhancement. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3615950'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot learning has garnered increasing attention in hyperspectral image classification (HSIC) due to its potential to reduce dependency on labor-intensive and costly labeled data. However, most existing methods are constrained to feature extraction using a single image patch of fixed size, and typically neglect the pivotal role of the central pixel in feature fusion, leading to inefficient information utilization. In addition, the correlations among sample features have not been fully explored, thereby weakening feature expressiveness and hindering cross-domain knowledge transfer. To address these issues, we propose a novel few-shot HSIC framework incorporating dynamic fusion and hierarchical enhancement. Specifically, we first introduce a robust feature extraction module, which effectively combines the content concentration of small patches with the noise robustness of large patches, and further captures local spatial correlations through a central-pixel-guided dynamic pooling strategy. Such patch-to-pixel dynamic fusion enables a more comprehensive and robust extraction of ground object information. Then, we develop a support–query hierarchical enhancement module that integrates intraclass self-attention and interclass cross-attention mechanisms. This process not only enhances support-level and query-level feature representation but also facilitates the learning of more informative prior knowledge from the abundantly labeled source domain. Moreover, to further increase feature discriminability, we design an intraclass consistency loss and an interclass orthogonality loss, which collaboratively encourage intraclass samples to be closer together and interclass samples to be more separable in the metric space. Experimental results on four benchmark datasets demonstrate that our method substantially improves classification accuracy and consistently outperforms competing approaches. Code is available at https://github.com/guoying918/DFHE2025},
  archive      = {J_TNNLS},
  author       = {Ying Guo and Bin Fan and Yuchao Dai and Yan Feng and Mingyi He},
  doi          = {10.1109/TNNLS.2025.3615950},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Boosting few-shot hyperspectral image classification through dynamic fusion and hierarchical enhancement},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedMKD: Hybrid feature guided multilayer fusion knowledge distillation in heterogeneous federated learning. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3615230'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, federated learning (FL) has received widespread attention for its ability to enable collaborative training across multiple clients while protecting user privacy, especially demonstrating significant value in scenarios such as medical data analysis, where strict privacy protection is required. However, most existing FL frameworks mainly focus on data heterogeneity without fully addressing the challenge of heterogeneous model aggregation among clients. To address this problem, this article proposes a novel FL framework called FedMKD. This framework introduces proxy models as a medium for knowledge sharing between clients, ensuring efficient and secure interactions while effectively utilizing the knowledge in each client’s data. In order to improve the efficiency of asymmetric knowledge transfer between proxy models and private models, a hybrid feature-guided multilayer fusion knowledge distillation (MKD) learning method is proposed, which eliminates the dependence on public data. Extensive experiments were conducted using a combination of multiple heterogeneous models under diverse data distributions. The results demonstrate that FedMKD efficiently aggregates model knowledge.},
  archive      = {J_TNNLS},
  author       = {Peng Han and Han Xiao and Shenhai Zheng and Yuanyuan Li and Guanqiu Qi and Zhiqin Zhu},
  doi          = {10.1109/TNNLS.2025.3615230},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {FedMKD: Hybrid feature guided multilayer fusion knowledge distillation in heterogeneous federated learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HKANLP: Link prediction with hyperspherical embeddings and Kolmogorov–Arnold networks. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3614341'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Link prediction (LP) is fundamental to graph-based applications, yet existing graph autoencoders (GAEs) and variational GAEs (VGAEs) often struggle with intrinsic graph properties, particularly the presence of negative eigenvalues in adjacency matrices, which limits their adaptability and predictive performance. To address this limitation, we propose Hyperspherical Kolmogorov–Arnold Networks for LP (HKANLP), a novel framework that combines multiple graph neural network (GNN)-based representation learning strategies with Kolmogorov–Arnold networks (KANs) in a hyperspherical embedding space. Specifically, our model leverages the von Mises–Fisher (vMF) distribution to impose geometric consistency in the latent space and employs KANs as universal function approximators to reconstruct adjacency matrices, thereby mitigating the impact of negative eigenvalues and enhancing spectral diversity. Extensive experiments on homophilous, heterophilous, and large-scale graph datasets demonstrate that HKANLP achieves superior LP performance and robustness compared to state-of-the-art baselines. Furthermore, visualization analyses illustrate the model’s effectiveness in capturing complex structural patterns. The source code of our model is publicly available at https://github.com/zxj8806/HKANLP/},
  archive      = {J_TNNLS},
  author       = {Wenchuan Zhang and Wentao Fan and Weifeng Su and Nizar Bouguila},
  doi          = {10.1109/TNNLS.2025.3614341},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {HKANLP: Link prediction with hyperspherical embeddings and Kolmogorov–Arnold networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IML-spikeformer: Input-aware multilevel spiking transformer for speech processing. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3615971'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural networks (SNNs), inspired by biological neural mechanisms, represent a promising neuromorphic computing paradigm that offers energy-efficient alternatives to traditional artificial neural networks (ANNs). Despite proven effectiveness, SNN architectures have struggled to achieve competitive performance on large-scale speech processing tasks. Two key challenges hinder progress: 1) the high computational overhead during training caused by multitimestep spike firing and 2) the absence of large-scale SNN architectures tailored to speech processing tasks. To overcome the issues, we introduce the input-aware multilevel spikeformer (IML-Spikeformer), a spiking transformer architecture specifically designed for large-scale speech processing. Central to our design is the input-aware multilevel spike (IMLS) mechanism, which simulates multitimestep spike firing within a single timestep using an adaptive, input-aware thresholding scheme. IML-Spikeformer further integrates a reparameterized spiking self-attention (RepSSA) module with a hierarchical decay mask (HDM), forming the HD-RepSSA module. This module enhances the precision of attention maps and enables modeling of multiscale temporal dependencies in speech signals. Experiments demonstrate that IML-Spikeformer achieves word error rates (WERs) of 6.0% on AiShell-1 and 3.4% on Librispeech-960, comparable to conventional ANN transformers while reducing theoretical inference energy consumption by $4.64\times $ and $4.32\times $ , respectively. IML-Spikeformer marks an advance of scalable SNN architectures for large-scale speech processing in both task performance and energy efficiency. Our source code and model checkpoints are publicly available at github.com/Pooookeman/IML-Spikeformer},
  archive      = {J_TNNLS},
  author       = {Zeyang Song and Shimin Zhang and Yuhong Chou and Jibin Wu and Haizhou Li},
  doi          = {10.1109/TNNLS.2025.3615971},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {IML-spikeformer: Input-aware multilevel spiking transformer for speech processing},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inhibiting error exacerbation in offline reinforcement learning with data sparsity. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3615982'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Offline reinforcement learning (RL) aims to learn effective agents from previously collected datasets, facilitating the safety and efficiency of RL by avoiding real-time interaction. However, in practical applications, the approximation error of the out-of-distribution (OOD) state–actions can cause considerable overestimation due to error exacerbation during training, finally degrading the performance. In contrast to prior works that merely addressed the OOD state–actions, we discover that all data introduces estimation error whose magnitude is directly related to data sparsity. Consequently, the impact of data sparsity is inevitable and vital when inhibiting the error exacerbation. In this article, we propose an offline RL approach to inhibit error exacerbation with data sparsity (IEEDS), which includes a novel value estimation method to consider the impact of data sparsity on the training of agents. Specifically, the value estimation phase includes two innovations: 1) replace Q-net with V-net, a smaller and denser state space makes data more concentrated, contributing to more accurate value estimation and 2) introduce state sparsity to the training by design state-aware-sparsity Markov decision process (MDP), further lessening the impact of sparse states. We theoretically prove the convergence of IEEDS under state-aware-sparsity MDP. Extensive experiments on offline RL benchmarks reveal that IEEDS’s superior performance.},
  archive      = {J_TNNLS},
  author       = {Fan Zhang and Malu Zhang and Wenyu Chen and Siying Wang and Xin Zhang and Jiayin Li and Yang Yang},
  doi          = {10.1109/TNNLS.2025.3615982},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Inhibiting error exacerbation in offline reinforcement learning with data sparsity},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semi-supervised breast lesion segmentation using confidence-ranked features and bi-level prototypes. <em>TNNLS</em>, 1-12. (<a href='https://doi.org/10.1109/TNNLS.2025.3616332'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated lesion segmentation through breast ultrasound (BUS) images is an essential prerequisite in computer-aided diagnosis. However, the task of breast segmentation remains challenging, due to the time-consuming and labor-intensive process of acquiring precise labeled data, as well as severely ambiguous lesion boundaries and low contrast in BUS images. In this article, we propose a novel semi-supervised breast segmentation framework based on confidence-ranked features and bi-level prototypes (CoBiNet) to alleviate these issues. Our outputs are derived from two branches: classifier and projector. In the projector branch, we first rank the features by multilevel sampling to obtain multiple feature sets with different confidence levels. Then, these sets are progressed in two directions. One is to acquire local prototypes at each level by local sampling and perform trans-confidence level (TCL) contrastive learning. This encourages the low-confidence features to converge to the high-confidence features, which enhances the model’s ability to recognize ambiguous regions. The other process is to generate more representative global prototypes by global sampling, followed by generating more reliable predictions and performing cross-guidance (CG) consistency learning with the classifier output predictions, facilitating knowledge transfer between the structure-aware projector and the category-discriminative classifier branches. Extensive experiments on two well-known public datasets, BUSI and UDIAT, demonstrate the superiority of our method over state-of-the-art approaches. Codes will be released upon publication.},
  archive      = {J_TNNLS},
  author       = {Siyao Jiang and Huisi Wu and Yu Zhou and Junyang Chen and Jing Qin},
  doi          = {10.1109/TNNLS.2025.3616332},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Semi-supervised breast lesion segmentation using confidence-ranked features and bi-level prototypes},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal cross-city semantic segmentation based on similarity-inspired fusion and invertible transformation learning network. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3617345'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal cross-city semantic segmentation aims to adapt a network trained on multiple labeled source domains (MSDs) from one city to multiple unlabeled target domains (MTDs) in another city, where the multiple domains refer to different sensor modalities. However, remote sensing data from different sensors increases the extent of domain shift in the fused domain space, making feature alignment more challenging. Meanwhile, traditional fusion methods only consider complementarity within MSDs (or MTDs), which wastes cross-domain relevant information and neglects control over domain shift. To address the above issues, we propose a similarity-inspired fusion and invertible transformation learning network (SFITNet) for multimodal cross-city semantic segmentation. To alleviate the increasing alignment difficulty in multimodal fused domains, an invertible transformation learning strategy (ITLS) is proposed, which adopts a topological perspective on unsupervised domain adaptation. This strategy aims to simulate the potential distribution transformation function between the MSD and the MTD based on invertible neural networks (INNs) after feature fusion, thereby performing distribution alignment independently within the two feature spaces. A cross-domain similarity-inspired information interaction module (CDSiM) is also designed, which considers the correspondence between the MSD and the MTD in the fusion stage, effectively utilizes multimodal complementary information and promotes the subsequent alignment of fused domain shifts. The semantic segmentation tests are completed on the public C2Seg-AB dataset and a new multimodal cross-city Su-Wu dataset. Compared with some state-of-the-art techniques, the experimental results demonstrated the superiority of the proposed SFITNet.},
  archive      = {J_TNNLS},
  author       = {Lijia Dong and Wen Jiang and Zhengyi Xu and Jie Geng},
  doi          = {10.1109/TNNLS.2025.3617345},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Multimodal cross-city semantic segmentation based on similarity-inspired fusion and invertible transformation learning network},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature enhancement module based on class-centric loss for fine-grained visual classification. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3613791'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel feature enhancement module designed for fine-grained visual classification tasks, which can be seamlessly integrated into various backbone architectures, including both convolutional neural network (CNN)-based and Transformer-based networks. The plug-and-play module outputs pixel-level feature maps and performs a weighted fusion of filtered features to enhance fine-grained feature representation. We introduce a class-centric loss function that optimizes the alignment of samples with their target class centers by pulling them toward the center of the target class while simultaneously pushing them away from the center of the most visually similar nontarget classes. Soft labels are employed to mitigate overfitting, ensuring the model generalizes well to unseen examples. Our approach consistently delivers significant improvements in accuracy across various mainstream backbone architectures, underscoring its versatility and robustness. Furthermore, we achieved the highest accuracy on the NABirds (NAB) and our proprietary lock cylinder datasets. We have released our source code and pretrained model on GitHub: https://github.com/Richard5413/FEM-CC.git},
  archive      = {J_TNNLS},
  author       = {Daohui Wang and He Xinyu and Shujing Lyu and Wei Tian and Yue Lu},
  doi          = {10.1109/TNNLS.2025.3613791},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Feature enhancement module based on class-centric loss for fine-grained visual classification},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distill to delete: Unlearning in graph networks with knowledge distillation. <em>TNNLS</em>, 1-11. (<a href='https://doi.org/10.1109/TNNLS.2025.3607995'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph unlearning has emerged as a pivotal method to delete information from an already trained graph neural network (GNN). One may delete nodes, a class of nodes, edges, or a class of edges. An unlearning method enables the GNN model to comply with data protection regulations (i.e., the right to be forgotten), adapt to evolving data distributions, and reduce the GPU-hours carbon footprint by avoiding repetitive retraining. Removing specific graph elements from graph data is challenging due to the inherent intricate relationships and neighborhood dependencies. Existing partitioning and aggregation-based methods have limitations due to their poor handling of local graph dependencies and additional overhead costs. Our work takes a novel approach to address these challenges in graph unlearning through knowledge distillation, as it distills to delete in GNN (D2DGN). It is an efficient model-agnostic distillation framework where the complete graph knowledge is divided and marked for retention and deletion. It performs distillation with response-based soft targets and feature-based node embedding while minimizing KL-divergence. The unlearned model effectively removes the influence of the deleted graph elements while preserving knowledge about the retained graph elements. D2DGN surpasses the performance of existing methods when evaluated on various real-world graph datasets by up to $\mathbf {43.1\%}$ (AUC) in edge and node unlearning tasks. Other notable advantages include better efficiency, better performance in removing target elements, preservation of performance for the retained elements, and zero overhead costs. Source code: https://github.com/MachineUnlearn/D2DGN},
  archive      = {J_TNNLS},
  author       = {Yash Sinha and Murari Mandal and Mohan Kankanhalli},
  doi          = {10.1109/TNNLS.2025.3607995},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {10},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Distill to delete: Unlearning in graph networks with knowledge distillation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unveiling group-specific distributed concept drift: A fairness imperative in federated learning. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3601834'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the evolving field of machine learning, ensuring group fairness has become a critical concern, prompting the development of algorithms designed to mitigate bias in decision-making processes. Group fairness refers to the principle that a model’s decisions should be equitable across different groups defined by sensitive attributes such as gender or race, ensuring that individuals from privileged groups and unprivileged groups are treated fairly and receive similar outcomes. However, achieving fairness in the presence of group-specific concept drift remains an unexplored frontier, and our research represents pioneering efforts in this regard. Group-specific concept drift refers to situations where one group experiences concept drift over time, while another does not, leading to a decrease in fairness even if accuracy (ACC) remains fairly stable. Within the framework of federated learning (FL), where clients collaboratively train models, its distributed nature further amplifies these challenges since each client can experience group-specific concept drift independently while still sharing the same underlying concept, creating a complex and dynamic environment for maintaining fairness. The most significant contribution of our research is the formalization and introduction of the problem of group-specific concept drift and its distributed counterpart, shedding light on its critical importance in the field of fairness. In addition, leveraging insights from prior research, we adapt an existing distributed concept drift adaptation algorithm to tackle group-specific distributed concept drift, which uses a multimodel approach, a local group-specific drift detection mechanism, and continuous clustering of models over time. The findings from our experiments highlight the importance of addressing group-specific concept drift and its distributed counterpart to advance fairness in machine learning.},
  archive      = {J_TNNLS},
  author       = {Teresa Salazar and João Gama and Helder Araújo and Pedro Henriques Abreu},
  doi          = {10.1109/TNNLS.2025.3601834},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Unveiling group-specific distributed concept drift: A fairness imperative in federated learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A decomposition optimization-based multiobjective reinforcement learning algorithm for obtaining nonconvex pareto fronts. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3603165'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiobjective reinforcement learning (MORL) aims to seek a complete Pareto front (PF) with different compromise policies in multiobjective Markov decision processes (MOMDPs). However, most MORL algorithms currently have a limitation in handling the MOMDPs with nonconvex PFs. In this article, we propose a nonlinear MORL algorithm based on decomposition and variance reduction (MORL/D-VR) to overcome this limitation. MORL/D-VR adopts the Tchebycheff approach to transform a given MOMDP into a set of single-objective Markov decision processes (MDPs) and subsequently applies an improved policy gradient algorithm, called expected utility policy gradient (EUPG), to solve each single-objective MDP efficiently. We analyze the Pareto optimality of employing the Tchebycheff approach and policy gradient methods that use the full return to update policy for solving MOMDPs. The analysis shows that such a case can identify any Pareto optimal policy regardless of the shape of PFs theoretically. This can provide a theoretical guarantee for applying the Tchebycheff approach and EUPG in MORL/D-VR to obtain the policies within the nonconvex PFs. Moreover, we devise a new baseline for EUPG to reduce the variance of gradient updates and adopt a weight vector adaptation method to improve diversity. The experimental results show that MORL/D-VR achieves a desirable performance in handling problems with different convex and nonconvex PFs and outperforms current state-of-the-art MORL algorithms.},
  archive      = {J_TNNLS},
  author       = {Tianyang Li and Ying Meng and Lixin Tang},
  doi          = {10.1109/TNNLS.2025.3603165},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A decomposition optimization-based multiobjective reinforcement learning algorithm for obtaining nonconvex pareto fronts},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DA-PFL: Dynamic affinity aggregation in personalized federated learning under class imbalance. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3598818'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized federated learning (PFL) has become a hot research topic that can learn a personalized learning model for each client. Existing PFL models prefer to aggregate similar clients with similar data distribution to improve the performance of learning models. However, similarity-based PFL methods may exacerbate the class imbalance problem. In this article, we propose a novel dynamic affinity-based PFL (DA-PFL) model to alleviate the class imbalanced problem during federated learning. Specifically, we build an affinity metric from a complementary perspective to guide which clients should be aggregated. We then design a dynamic aggregation strategy that adjusts client aggregation based on the affinity metric in each round, thereby reducing the risk of class imbalance. Extensive experiments demonstrate that the proposed DA-PFL model can significantly improve the accuracy of each client in four real-world datasets with state-of-the-art comparison methods.},
  archive      = {J_TNNLS},
  author       = {Xu Yang and Jiyuan Feng and Yongxin Tong and Lingzhi Wang and Songyue Guo and Binxing Fang and Qing Liao},
  doi          = {10.1109/TNNLS.2025.3598818},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {DA-PFL: Dynamic affinity aggregation in personalized federated learning under class imbalance},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust PID-type iterative learning control for nonlinear square and nonsquare systems. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3601656'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, a novel PID-type adaptive iterative learning control (AILC) method is proposed for a class of nonlinear systems with unspecified control gain matrices and bounded iterative-varying uncertainties. Unlike the existing iterative learning method with accumulation of control information, the new PID-type AILC avoids control information accumulation in traditional iterative learning control (ILC), maintaining convergence based on error information and confining iteration to parameter estimation, suitable for amplitude- or frequency-limited controllers. Different from the existing approaches of P-type AILC, this work extends ILC advances to PID-type AILC for nonlinear square or nonsquare systems with unknown control gain matrices, enhancing robustness through simultaneous convergence of integral and proportional error terms over a larger range. This analysis method diverges from traditional approaches relying on contraction mappings or asymptotic stability theorems; error convergence is analyzed using inequalities of a composite energy function (CEF). The effectiveness of this work has been validated through two illustrated examples. The results show that compared with P-type AILC, the convergence speed can be increased by approximately two to three times.},
  archive      = {J_TNNLS},
  author       = {Kechao Xu and Bo Meng and Zhen Wang and Xia Huang},
  doi          = {10.1109/TNNLS.2025.3601656},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Robust PID-type iterative learning control for nonlinear square and nonsquare systems},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Privacy-preserving video anomaly detection: A survey. <em>TNNLS</em>, 1-22. (<a href='https://doi.org/10.1109/TNNLS.2025.3600252'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The video anomaly detection (VAD) aims to automatically analyze spatiotemporal patterns in surveillance videos collected from open spaces to detect anomalous events that may cause harm, such as fighting, stealing, and car accidents. However, vision-based surveillance systems such as closed-circuit television (CCTV) often capture personally identifiable information. The lack of transparency and interpretability in video transmission and usage raises public concerns about privacy and ethics, limiting the real-world application of VAD. Recently, researchers have focused on privacy concerns in VAD by conducting systematic studies from various perspectives, including data, features, and systems, making privacy-preserving VAD (P2VAD) a hotspot in the AI community. However, the current research in P2VAD is fragmented, and prior reviews have mostly focused on methods using RGB sequences, overlooking privacy leakage and appearance bias considerations. To address this gap, this article is the first to systematically review the progress of P2VAD, defining its scope and providing an intuitive taxonomy. We outline the basic assumptions, learning frameworks, and optimization objectives of various approaches, analyzing their strengths, weaknesses, and potential correlations. In addition, we provide open access to research resources such as benchmark datasets and available code. Finally, we discuss key challenges and future opportunities from the perspectives of AI development and P2VAD deployment, aiming to the guide future work in the field.},
  archive      = {J_TNNLS},
  author       = {Yang Liu and Siao Liu and Xiaoguang Zhu and Hao Yang and Jielin Li and Juncen Guo and Liangyu Teng and Dingkang Yang and Yan Wang and Jing Liu},
  doi          = {10.1109/TNNLS.2025.3600252},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-22},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Privacy-preserving video anomaly detection: A survey},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nesterov accelerated gradient tracking with adam for distributed online optimization. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3604059'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents an accelerated distributed optimization algorithm for online optimization problems over large-scale networks. The proposed algorithm’s iteration only relies on local computation and communication. To effectively adapt to dynamic changes and achieve a fast convergence rate while maintaining good convergence performance, we design a new algorithm called NGTAdam. This algorithm combines the Nesterov acceleration technique with an adaptive moment estimation method. The convergence of NGTAdam is evaluated by evaluating its dynamic regret through the use of linear system inequality. For online convex optimization problems, we provide an upper bound on the dynamic regret of NGTAdam, which depends on the initial conditions and the time-varying nature of the optimization problem. Moreover, we show that if the time-varying part of this upper bound is sublinear with time, the dynamic regret is also sublinear. Through a variety of numerical experiments, we demonstrate that NGTAdam outperforms state-of-the-art distributed online optimization algorithms.},
  archive      = {J_TNNLS},
  author       = {Yanxu Su and Qingyang Sheng and Xiasheng Shi and Chaoxu Mu and Changyin Sun},
  doi          = {10.1109/TNNLS.2025.3604059},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Nesterov accelerated gradient tracking with adam for distributed online optimization},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fine-grained Audio–Visual event localization. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3600878'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Audio–visual event localization (AVEL) aims to recognize events in videos by associating audio–visual information. However, events involved in existing AVEL tasks are usually coarse-grained events. Actually, finer-grained events are sometimes necessary to be distinguished, especially in certain expert-level applications or rich-content-generation studies. However, this is challenging because they are more difficult to detect or distinguish compared with coarse-grained events. To better address this problem, we discuss a new setting of fine-grained AVEL from dataset to method. First, we constructed the first fine-grained audio–visual event dataset, which is called IT-AVE, relying on videos of playing musical instruments, containing 13k video clips and over 52k audio–visual events. All events are labeled from professional music practitioners, and the event categories are all derived from playing techniques, which are fine-grained with little interclass variation. Next, we designed a new fine-grained event localization method, spatial–temporal video event detector (SVED), which focuses on the challenges that fine-grained events are more imperceptible and prone to be disturbed. Finally, we conduct extensive experiments based on the proposed IT-AVE dataset versus fine-grained versions of two existing related datasets, including UnAV-22 derived from UnAV-100 and FineAction-AV derived from FineAction. Experimental results demonstrate the effectiveness of our method. We hope that this work will contribute to the exploration of an integrated understanding of audio–visual videos.},
  archive      = {J_TNNLS},
  author       = {Baoyu Fan and Lu Liu and Xiaochuan Li and Runze Zhang and Liang Jin and Jin Zhang},
  doi          = {10.1109/TNNLS.2025.3600878},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Fine-grained Audio–Visual event localization},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrating clinical knowledge graphs and gradient-based neural systems for enhanced melanoma diagnosis via the seven-point checklist. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3600443'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The seven-point checklist (7PCL) is a widely used diagnostic tool in dermoscopy for identifying malignant melanoma by assigning point values to seven specific attributes. However, the traditional 7PCL is limited to distinguishing between malignant melanoma and melanocytic nevi (MN) and falls short in scenarios where multiple skin diseases with appearances similar to melanoma coexist. To address this limitation, we propose a novel diagnostic framework that integrates a clinical knowledge-based topological graph (CKTG) with a gradient diagnostic strategy featuring a data-driven weighting (GD-DDW) system. The CKTG captures both the internal and external relationships among the 7PCL attributes, while the GD-DDW emulates dermatologists’ diagnostic processes, prioritizing visual observation before making predictions. Additionally, we introduce a multimodal feature extraction approach leveraging a dual-attention mechanism to enhance feature extraction through cross-modal interaction and unimodal collaboration. This method incorporates meta-information to uncover interactions between clinical data and image features, ensuring more accurate and robust predictions. Our approach, evaluated on the EDRA dataset, achieved an average AUC of 88.6%, demonstrating superior performance in melanoma detection and feature prediction. This integrated system provides data-driven benchmarks for clinicians, significantly enhancing the precision of melanoma diagnosis.},
  archive      = {J_TNNLS},
  author       = {Yuheng Wang and Tianze Yu and Jiayue Cai and Sunil Kalia and Harvey Lui and Z. Jane Wang and Tim K. Lee},
  doi          = {10.1109/TNNLS.2025.3600443},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Integrating clinical knowledge graphs and gradient-based neural systems for enhanced melanoma diagnosis via the seven-point checklist},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Surfer: A world model-based framework for vision-language robot manipulation. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3594117'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considering how to make the model accurately understand and follow natural language instructions and perform actions consistent with world knowledge is a key challenge in robot manipulation. This mainly includes human fuzzy instruction reasoning and the following of physical knowledge. Therefore, the embodied intelligence agent must have the ability to model world knowledge from training data. However, most existing vision and language robot manipulation methods mainly operate in less realistic simulators and language settings and lack explicit modeling of world knowledge. To bridge this gap, we introduce a novel and simple robot manipulation framework, called Surfer. It is based on the world model, treats robot manipulation as a state transfer of the visual scene, and decouples it into two parts: action and scene. Then, the generalization ability of the model on new instructions and new scenes is enhanced by explicit modeling of the action and scene prediction in multimodal information. In addition, we built a robot manipulation simulation platform that supports physics execution based on the MuJoCo physics engine. It can automatically generate demonstration training data and test data, effectively reducing labor costs. To conduct a comprehensive and systematic evaluation of the visual-language understanding and physical execution of the manipulation model, we also created a robotic manipulation benchmark with different difficulty levels, called SeaWave. It contains four visual-language manipulation tasks of different difficulty levels and can provide a standardized testing platform for embedded AI agents in multimodal environments. Overall, we hope Surfer can freely surf in the robot’s SeaWave benchmark. Extensive experiments show that Surfer consistently outperforms all baselines significantly in all manipulation tasks. On average, Surfer achieved a success rate of 54.74% on the defined four levels of manipulation tasks, exceeding the best baseline performance of 51.07%. The simulator, code, and benchmarks are released at https://pzhren.github.io/Surfer.},
  archive      = {J_TNNLS},
  author       = {Pengzhen Ren and Kaidong Zhang and Hetao Zheng and Zixuan Li and Yuhang Wen and Fengda Zhu and Shikui Ma and Xiaodan Liang},
  doi          = {10.1109/TNNLS.2025.3594117},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Surfer: A world model-based framework for vision-language robot manipulation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Koopman-driven linearized model-based offline planning with application to freeway ramp metering. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3605015'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a novel model-based planning framework for freeway ramp metering (RM), denoted as Koopman-driven linearized model-based offline planning (KLMOP). This framework integrates the model predictive control (MPC) and offline reinforcement learning (RL) under assumptions of a linear Markov decision process (MDP) with the Koopman operator. KLMOP introduces a fully linearized control framework by learning and modeling the dynamics, reward function, and value function in a latent space through a Koopman-based latent dynamical model (KLDM) and a pessimistic value iteration (PEVI) algorithm. This formulation builds upon the connection between Koopman operator theory and linear MDP. Contrastive learning is employed to ensure the expressiveness and structural conditions of the latent representation in linear MDP, enabling accurate reward prediction and efficient policy optimization. The MPC-based planning policy, then, leverages these components to solve a linear MPC problem efficiently in the latent space. Extensive simulation studies demonstrate that KLMOP significantly improves computational efficiency and control performance as compared with existing baseline methods for RM control. This framework provides a theoretically grounded and computationally efficient approach to linearizing nonlinear control problems, and its learning-based design makes it adaptable to broader applications.},
  archive      = {J_TNNLS},
  author       = {Tao Zhou and Chuanye Gu and Chee Peng Lim and Jinlong Yuan},
  doi          = {10.1109/TNNLS.2025.3605015},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Koopman-driven linearized model-based offline planning with application to freeway ramp metering},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Expandable residual approximation for knowledge distillation. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3602118'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation (KD) aims to transfer knowledge from a large-scale teacher model to a lightweight one, significantly reducing computational and storage requirements. However, the inherent learning capacity gap between the teacher and student often hinders the sufficient transfer of knowledge, motivating numerous studies to address this challenge. Inspired by the progressive approximation principle in the Stone–Weierstrass theorem, we propose expandable residual approximation (ERA), a novel KD method that decomposes the approximation of residual knowledge into multiple steps, reducing the difficulty of mimicking the teacher’s representation through a divide-and-conquer approach. Specifically, ERA employs a multibranched residual network (MBRNet) to implement this residual knowledge decomposition. Additionally, a teacher weight integration (TWI) strategy is introduced to mitigate the capacity disparity by reusing the teacher’s head weights. Extensive experiments show that ERA improves the Top-1 accuracy on ImageNet classification benchmark by 1.41% and the AP on the MS COCO object detection benchmark by 1.40, as well as achieving leading performance across computer vision tasks.},
  archive      = {J_TNNLS},
  author       = {Zhaoyi Yan and Binghui Chen and Yunfan Liu and Qixiang Ye},
  doi          = {10.1109/TNNLS.2025.3602118},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Expandable residual approximation for knowledge distillation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Long-tail class incremental learning via bias calibration with application to continuous fault diagnosis. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3602182'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class incremental learning (CIL) offers a promising framework for continuous fault diagnosis (CFD), allowing networks to accumulate knowledge from streaming industrial data and recognize new fault classes. However, current CIL methods assume a balanced data stream, which does not align with the long-tail distribution of fault classes in real industrial scenarios. To fill this gap, this article investigates the impact of long-tail bias in the data stream on the CIL training process through the experimental analysis. Observations show that long-tail bias in the data stream has a cascading effect, affecting the retention of old task knowledge and learning new tasks. Concurrently, the incremental model encounters challenges in identifying samples that conflict with its biases. Accordingly, we propose a CFD method called long-tail CIL via bias calibration (LTCIL-BC), which aims to improve the learning of bias-conflicting samples through bias exploration and debiasing. Specifically, LTCIL-BC simultaneously trains a primary debiased network and an auxiliary biased network. Then, a bias-indicating score is developed to provide insight into model bias and data bias based on the prediction error of the primary and auxiliary models, respectively. LTCIL-BC subsequently adjusts the logits of the debiased network using the bias-indicating score to guide optimization, thereby better utilizing the role of old class exemplars and reducing catastrophic forgetting. Experiments on power system (PS) and secure water treatment (SWaT) datasets demonstrate the superior performance of LTCIL-BC in CFD, achieving up to 9% improvement over state-of-the-art baselines in multiple long-tailed CIL setting. Comprehensive results demonstrate the effectiveness of LTCIL-BC in jointly addressing data and model bias during calibration and prioritizing bias-conflicting samples.},
  archive      = {J_TNNLS},
  author       = {Dongyue Chen and Zongxia Xie and Wenlong Yu and Qinghua Hu},
  doi          = {10.1109/TNNLS.2025.3602182},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Long-tail class incremental learning via bias calibration with application to continuous fault diagnosis},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evidential graph contrastive alignment for source-free blending-target domain adaptation. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3603224'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we first tackle a more realistic domain adaptation (DA) setting: source-free blending-target DA (SF-BTDA), where we cannot access to source-domain data while facing mixed multiple target domains without any domain labels in prior. Compared to existing DA scenarios, SF-BTDA generally faces the coexistence of different label shifts in different targets, along with noisy target pseudolabels generated from the source model. In this article, we propose a new method called evidential graph contrastive alignment (EGCA) to decouple the blending-target domain and alleviate the effect of noisy target pseudolabels. First, to improve the quality of pseudo target labels, we propose a calibrated evidential learning (CEL) module to iteratively improve both the accuracy and certainty of the resulting model and adaptively generate high-quality pseudo target labels. Second, we design a graph contrastive learning with the domain distance matrix and confidence-uncertainty criterion, to minimize the distribution gap of samples of the same class in the blending-target domain, which alleviates the coexistence of different label shifts in blended targets. We conduct a new benchmark based on three standard DA datasets, and EGCA outperforms other methods with considerable gains and achieves comparable results compared with those that have domain labels or source data in prior.},
  archive      = {J_TNNLS},
  author       = {Juepeng Zheng and Guowen Li and Yibin Wen and Jinxiao Zhang and Runmin Dong and Haohuan Fu},
  doi          = {10.1109/TNNLS.2025.3603224},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Evidential graph contrastive alignment for source-free blending-target domain adaptation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Incremental learning for defect segmentation with efficient transformer semantic complement. <em>TNNLS</em>, 1-10. (<a href='https://doi.org/10.1109/TNNLS.2025.3604956'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In industrial scenarios, semantic segmentation of surface defects is vital for identifying, localizing, and delineating defects. However, new defect types constantly emerge with product iterations or process updates. Existing defect segmentation models lack incremental learning capabilities, and direct fine-tuning (FT) often leads to catastrophic forgetting. Furthermore, low contrast between defects and background, as well as among defect classes, exacerbates this issue. To address these challenges, we introduce a plug-and-play Transformer-based semantic complement module (TSCM). With only a few added parameters, it injects global contextual features from multi-head self-attention into shallow convolutional neural network (CNN) feature maps, compensating for convolutional receptive-field limits and fusing global and local information for better segmentation. For incremental updates, we propose multi-scale spatial pooling distillation (MSPD), which uses pseudo-labeling and multi-scale pooling to preserve both short- and long-range spatial relations and provides smooth feature alignment between teacher and student. Additionally, we adopt an adaptive weight fusion (AWF) strategy with a dynamic threshold that assigns higher weights to parameters with larger updates, achieving an optimal balance between stability and plasticity. The experimental results on two industrial surface defect datasets demonstrate that our method outperforms existing approaches in various incremental segmentation scenarios.},
  archive      = {J_TNNLS},
  author       = {Xiqi Li and Zhifu Huang and Ge Ma and Yu Liu},
  doi          = {10.1109/TNNLS.2025.3604956},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Incremental learning for defect segmentation with efficient transformer semantic complement},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust missing value imputation with proximal optimal transport for low-quality IIoT data. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3601130'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate imputation of missing data is crucial in the Industrial Internet-of-Things (IIoT), where operations are often compromised by noisy samples from harsh environments. Traditional imputation methods struggle with such noise due to their black-box nature or lack of adaptability. To address this issue, we recast data imputation as a distribution alignment challenge, utilizing the flexibility of optimal transport (OT) to handle noisy samples. Specifically, we first introduce the Proximal Optimal Transport (POT) problem, where the transportation cost is obtained by the network simplex approach with a selective matching mechanism, which renders it capable of matching distributions with noisy samples. Subsequently, we propose the POT-I framework, where the objective is to minimize the transport cost of POT. The produced gradient is used to refine the imputation value, which achieves missing data imputation (MDI) while getting robustness to noisy samples. Experiments on real-world IIoT datasets demonstrate the superiority of POT-I over state-of-the-art imputation methods.},
  archive      = {J_TNNLS},
  author       = {Hao Wang and Zhichao Chen and Yuan Shen and Hui Zheng and Degui Yang and Dangjun Zhao and Buge Liang},
  doi          = {10.1109/TNNLS.2025.3601130},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Robust missing value imputation with proximal optimal transport for low-quality IIoT data},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiagent inductive policy optimization. <em>TNNLS</em>, 1-12. (<a href='https://doi.org/10.1109/TNNLS.2025.3601360'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Policy optimization methods are promising to tackle high-complexity reinforcement learning (RL) tasks with multiple agents. In this article, we derive a general trust region for policy optimization methods by considering the effect of subpolicy combinations among agents in multiagent environments. Based on this trust region, we propose an inductive objective to train the policy function, which can ensure agents learn monotonically improving policies. Furthermore, we observe that the policy always updates very weakly before falling into a local optimum. To address this, we introduce a cost regarding policy distance in the inductive objective to strengthen the motivation of agents to explore new policies. This approach strikes a balance during training, where the policy update step size remains within the constraints of the trust region, preventing excessive updates while avoiding getting stuck in local optima. Simulations on wind farm (WF) control tasks and two multiagent benchmarks demonstrate the high performance of the proposed multiagent inductive policy optimization (MAIPO) method.},
  archive      = {J_TNNLS},
  author       = {Yubo Huang and Xiaowei Zhao},
  doi          = {10.1109/TNNLS.2025.3601360},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Multiagent inductive policy optimization},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bicriteria policy optimization for high-accuracy reinforcement learning. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3605362'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In essence, reinforcement learning (RL) solves optimal control problem (OCP) by employing a neural network (NN) to fit the optimal policy from state to action. The accuracy of policy approximation is often very low in complex control tasks, leading to unsatisfactory control performance compared with online optimal controllers. A primary reason is that the landscape of value function is always not only rugged in most areas but also flat on the bottom, which damages the convergence to the minimum point. To address this issue, we develop a bicriteria policy optimization (BPO) algorithm, which leverages a few optimal demonstration trajectories to guide the policy search at the gradient level. Different from conventional problem definition, BPO seeks to solve a bicriteria OCP, which has two homomorphic objectives: one is from the standard reward signals and the other is to align the demonstration trajectories. We introduce two co-state variables, one for each objectives, and formulate two Hamiltonians for this bicriteria OCP. The resulting new optimality condition preserves the minimum values of both Hamiltonians. Furthermore, we find that gradient conflict is a key obstacle to simultaneously descending both Hamiltonians, and its impact is negatively proportional to the inner product between the ideal and actual gradients. A minimax optimization problem is built at each RL iteration to minimize conflicts between two homomorphic objectives, whose solution for policy updating is referred to as harmonic gradient. By converting its inner optimization loop into a linear programming with convex trust region constraint, we simplify this problem into a single-loop maximization problem with much increased computational efficiency. Experiment tests on both linear and nonlinear control tasks validate the effectiveness of our BPO algorithm on the accuracy improvement of policy network.},
  archive      = {J_TNNLS},
  author       = {Guojian Zhan and Xiangteng Zhang and Feihong Zhang and Letian Tao and Shengbo Eben Li},
  doi          = {10.1109/TNNLS.2025.3605362},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Bicriteria policy optimization for high-accuracy reinforcement learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised Visible–Infrared ReID via pseudo-label correction and modality-level alignment. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3591641'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised visible–infrared person reidentification (UVI-ReID) has recently gained great attention due to its potential for enhancing human detection in diverse environments without labeling. Previous methods utilize intramodality clustering and cross-modality feature matching to achieve UVI-ReID. However, there exist two challenges: 1) noisy pseudo-labels might be generated in the clustering process and 2) the cross-modality feature alignment via matching the marginal distribution of visible and infrared modalities may misalign the different identities from the two modalities. In this article, we first conduct a theoretical analysis where an interpretable generalization upper bound is introduced. Based on the analysis, we then propose a novel unsupervised cross-modality person reidentification framework (PRAISE). Specifically, to address the first challenge, we propose a pseudo-label correction (PLC) strategy that utilizes a beta mixture model (BMM) to predict the probability of misclustering-based network’s memory effect and rectifies the correspondence by adding a perceptual term to contrastive learning. Next, we introduce a modality-level alignment (MLA) strategy that generates paired visible–infrared latent features and reduces the modality gap by aligning the labeling function of visible and infrared features to learn identity-discriminative and modality-invariant features. Experimental results on two benchmark datasets demonstrate that our method achieves a state-of-the-art (SOTA) performance than the unsupervised visible-ReID methods.},
  archive      = {J_TNNLS},
  author       = {Yexin Liu and Weiming Zhang and Athanasios V. Vasilakos and Lin Wang},
  doi          = {10.1109/TNNLS.2025.3591641},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Unsupervised Visible–Infrared ReID via pseudo-label correction and modality-level alignment},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). When to align: Dynamic behavior consistency for multiagent systems via intrinsic rewards. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3598301'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multiagent systems, learning optimal behavior policies for individual agents remains a challenging yet crucial task. While recent research has made strides in this area, the issue of when agents should maintain consistent behaviors with one another is still not adequately addressed. This article proposes a novel approach to enable agents to autonomously decide whether their behaviors should align with those of their peers by leveraging intrinsic rewards to optimize their policies. We define behavior consistency as the divergence between the actions taken by two agents given the same observations. To encourage agents to be aware of each other’s behaviors, we propose dynamic consistency-based intrinsic reward (DCIR), which guides agents in determining when to synchronize their behaviors. In addition, we introduce a dynamic scaling network (DSN) that provides learnable scaling factors at each time step, enabling agents to dynamically decide the extent of rewarding consistent behavior. Our method is evaluated on environments including Multiagent Particle, Google Research Football, and StarCraft II Micromanagement. Experimental results demonstrate its effectiveness in learning optimal policies.},
  archive      = {J_TNNLS},
  author       = {Kunyang Lin and Yufeng Wang and Peihao Chen and Runhao Zeng and Yinjie Lei and Siyuan Zhou and Qing Du and Mingkui Tan and Chuang Gan},
  doi          = {10.1109/TNNLS.2025.3598301},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {When to align: Dynamic behavior consistency for multiagent systems via intrinsic rewards},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conv4Rec: A 1-by-1 convolutional autoencoder for user profiling through joint analysis of implicit and explicit feedback. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3597051'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a new convolutional autoencoder architecture for user modeling and recommendation tasks with several improvements over the state of the art. First, our model has the flexibility to learn a set of associations and combinations between different interaction types in a way that carries over to each user and item. Second, our model is able to learn jointly from both the explicit ratings and the implicit information in the sampling pattern (which we refer to as ”implicit feedback”). It can also make separate predictions for the probability of consuming content and the likelihood of granting it a high rating if observed. This not only allows the model to make predictions for both the implicit and explicit feedback, but also increases the informativeness of the predictions: in particular, our model can identify items that users would not have been likely to consume naturally, but would be likely to enjoy if exposed to them. Finally, we provide several generalization bounds for our model, which, to the best of our knowledge, are among the first generalization bounds for autoencoders in a Recommender systems setting; we also show that optimizing our loss function guarantees the recovery of the exact sampling distribution over interactions up to a small error in total variation. In experiments on several real-life datasets, we achieve state-of-the-art performance on both the implicit and explicit feedback prediction tasks despite relying on a single model for both, and benefiting from additional interpretability in the form of individual predictions for the probabilities of each possible rating.},
  archive      = {J_TNNLS},
  author       = {Antoine Ledent and Petr Kasalický and Rodrigo Alves and Hady W. Lauw},
  doi          = {10.1109/TNNLS.2025.3597051},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Conv4Rec: A 1-by-1 convolutional autoencoder for user profiling through joint analysis of implicit and explicit feedback},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Channelwise regional integrate and multiple firing neuron: Improving the spatiotemporal learning of spiking neural networks. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3606849'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural networks (SNNs) can be operated in an event-driven manner to save energy consumption of artificial neural networks (ANNs), which has attracted enormous research interests for their high biological plausibility and powerful spatiotemporal information processing. However, representative studies only evaluated SNNs on static temporal tasks or short sequence tasks, which could not fully demonstrate the advantages of SNNs in spatiotemporal learning. In addition, we point out that the existing directly trained SNNs to face the problems of long-term memory, network degeneration, gradient saturation, and heterogeneity learning, these limit the performance of SNNs. In this article, we propose channelwise regional integrate and multiple firing (CRIMF) neuron to improve the spatiotemporal learning of SNNs. First, CRIMF neuron contains a new internal state of regional current that enhances the memory of spiking neurons and facilitates the learning of temporal information over long time steps. Second, CRIMF neuron is implemented with the multiple firing mechanisms; it is able to adjust the distribution of membrane potential and membrane potential gradient in the single firing mechanism, thus mitigating the underactivation and gradient saturation. Third, CRIMF neuron is trained with the channelwise learning strategy for the targeted learning of different types of temporal features, and an index of differentiation degree is proposed to visualize the effectiveness of the channelwise learning strategy. We also introduce the regional current reset equation and normalize the input of postsynaptic neurons in spatiotemporal dimension to avoid network degeneration. Finally, we select two emotion electroencephalogram (EEG) datasets and perform the evaluations based on manual features and raw signals. Experimental results show that CRIMF-based SNNs outperform the state-of-the-art methods in static temporal task, and CRIMF neurons are superior to the advanced spiking neurons and recurrent units of ANNs in dynamic temporal task, using low energy consumption.},
  archive      = {J_TNNLS},
  author       = {Mincheng Cai and Quan Liu and Kun Chen and Li Ma},
  doi          = {10.1109/TNNLS.2025.3606849},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Channelwise regional integrate and multiple firing neuron: Improving the spatiotemporal learning of spiking neural networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive modality balanced online knowledge distillation for Brain–Eye–Computer-based dim object detection. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3605710'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advanced cognition can be measured from the human brain using brain–computer interfaces (BCIs). Integrating these interfaces with computer vision techniques, which possess efficient feature extraction capabilities, can achieve more robust and accurate detection of dim targets in aerial images. However, existing target detection methods primarily concentrate on homogeneous data, lacking efficient and versatile processing capabilities for heterogeneous multimodal data. In this article, we first build a brain–eye–computer-based object detection system for aerial images under few-shot conditions. This system detects suspicious targets using region proposal networks (RPNs), evokes the event-related potential (ERP) signal in electroencephalogram (EEG) through the eye-tracking-based slow serial visual presentation (ESSVP) paradigm, and constructs the EEG–image data pairs with eye movement data. Then, an adaptive modality balanced online knowledge distillation (AMBOKD) method is proposed to recognize dim objects with the EEG–image data. AMBOKD fuses EEG and image features using a multihead attention module, establishing a new modality with comprehensive features. To enhance the performance and robust capability of the fusion modality, simultaneous training and mutual learning between modalities are enabled by end-to-end online KD (OKD). During the learning process, an adaptive modality balancing module is proposed to ensure multimodal equilibrium by dynamically adjusting the weights of the importance and the training gradients across various modalities. The effectiveness and superiority of our method are demonstrated by comparing it with existing state-of-the-art methods. Additionally, experiments conducted on public datasets and real-world scenarios demonstrate the reliability and practicality of the proposed system and the designed method. The dataset and the source code can be found at: https://github.com/lizixing23/AMBOKD},
  archive      = {J_TNNLS},
  author       = {Zixing Li and Chao Yan and Zhen Lan and Xiaojia Xiang and Han Zhou and Jun Lai and Dengqing Tang},
  doi          = {10.1109/TNNLS.2025.3605710},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Adaptive modality balanced online knowledge distillation for Brain–Eye–Computer-based dim object detection},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AMAP: Automatic multihead attention pruning by similarity-based pruning indicator. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3606750'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the strong performance of transformers, quadratic computation complexity of self-attention presents challenges in applying them to vision tasks. Linear attention reduces this complexity from quadratic to linear, offering a strong computation–performance tradeoff. To further optimize this, automatic pruning is an effective method to find a structure that maximizes performance within a target resource through training without any heuristic approaches. However, directly applying it to multihead attention is not straightforward due to channel mismatch. In this article, we propose an automatic pruning method to deal with this problem. Different from existing methods that rely solely on training without any prior knowledge, we integrate channel similarity-based weights into the pruning indicator to preserve the more informative channels within each head. Then, we adjust the pruning indicator to enforce that channels are removed evenly across all heads, thereby avoiding any channel mismatch. We incorporate a reweight module to mitigate information loss due to channel removal and introduce an effective pruning indicator initialization for linear attention, based on the attention differences between the original structure and each channel. By applying our pruning method to the FLattenTransformer on ImageNet-1K, which incorporates original and linear attention mechanisms, we achieve a 30% reduction of FLOPs in a near lossless manner. It also has 1.96% of accuracy gain over the DeiT-B model while reducing FLOPs by 37%, and 1.05% accuracy increase over the Swin-B model with a 10% reduction in FLOPs as well. The proposed method outperforms previous state-of-the-art efficient models and the recent pruning methods.},
  archive      = {J_TNNLS},
  author       = {Eunho Lee and Youngbae Hwang},
  doi          = {10.1109/TNNLS.2025.3606750},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {AMAP: Automatic multihead attention pruning by similarity-based pruning indicator},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unified framework for matrix backpropagation. <em>TNNLS</em>, 1-7. (<a href='https://doi.org/10.1109/TNNLS.2025.3607405'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computing matrix gradient has become a key aspect in modern signal processing/machine learning, with the recent use of matrix neural networks requiring matrix backpropagation. In this field, two main methods exist to calculate the gradient of matrix functions for symmetric positive definite (SPD) matrices, namely, the Daleckiǐ–Kreǐn/Bhatia formula and the Ionescu method. However, there appear to be a few errors. This brief aims to demonstrate each of these formulas in a self-contained and unified framework, to prove theoretically their equivalence, and to clarify inaccurate results of the literature. A numerical comparison of both methods is also provided in terms of computational speed and numerical stability to show the superiority of the Daleckiǐ–Kreǐn/Bhatia approach. We also extend the matrix gradient to the general case of diagonalizable matrices. Convincing results with the two backpropagation methods are shown on the EEG-based BCI competition dataset with the implementation of an SPDNet, yielding around 80% accuracy for one subject. Daleckiǐ–Kreǐn/Bhatia formula achieves an 8% time gain during training and handles degenerate cases.},
  archive      = {J_TNNLS},
  author       = {Gatien Darley and Stéphane Bonnet},
  doi          = {10.1109/TNNLS.2025.3607405},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-7},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A unified framework for matrix backpropagation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Theoretical advances on stochastic configuration networks. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3608555'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article advances the theoretical foundations of stochastic configuration networks (SCNs) by rigorously analyzing their convergence properties, approximation guarantees, and the limitations of nonadaptive randomized methods. We introduce a principled objective function that aligns incremental training with orthogonal projection, ensuring maximal residual reduction at each iteration without recomputing output weights. Under this formulation, we derive a novel necessary and sufficient condition for strong convergence in Hilbert spaces and establish sufficient conditions for uniform geometric convergence, offering the first theoretical justification of the SCN residual constraint. To assess the feasibility of unguided random initialization, we present a probabilistic analysis showing that even small support shifts markedly reduce the likelihood of sampling effective nodes in high-dimensional settings, thereby highlighting the necessity of adaptive refinement in the sampling distribution. Motivated by these insights, we propose greedy SCNs (GSCNs) and two optimized variants—Newton–Raphson GSCN (NR-GSCN) and particle swarm optimization GSCN (PSO-GSCN)—that incorporate Newton–Raphson refinement and particle swarm-based exploration to improve node selection. Empirical results on synthetic and real-world datasets demonstrate that the proposed methods achieve faster convergence, better approximation accuracy, and more compact architectures compared to existing SCN training schemes. Collectively, this work establishes a rigorous theoretical and algorithmic framework for SCNs, laying out a principled foundation for subsequent developments in the field of randomized neural network (NN) training.},
  archive      = {J_TNNLS},
  author       = {Xiufeng Yan and Dianhui Wang and Ivan Y. Tyukin},
  doi          = {10.1109/TNNLS.2025.3608555},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Theoretical advances on stochastic configuration networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatial–Temporal diffusion model for matrix factorization. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3605215'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Matrix factorization (MF) is a fundamental problem in machine learning, which is usually used as a feature learning method in various fields. For complex data involving spatiotemporal interactions, MF that only handles 2-D data will disrupt spatial dependence or temporal dynamics, failing to effectively couple spatial information with temporal factors. According to Markov chain principle, the spatial information of the present time is related to the spatial state of the previous time. We propose a spatial–temporal diffusion model for MF (STDMF), which uses graph diffusion to couple spatial–temporal information. Then, MF is used to learn the joint feature of data and spatial–temporal diffusion graph. Specifically, STDMF utilizes the graph diffusion with physical laws to generate spatial–temporal structure information. It obtains the underlying core structure of complex systems from a global perspective, which enhances the generalization ability of MF in noisy time-series data. To learn the lowest rank subspace of MF in time-series data, STDMF uses structural learning to constrain the rank of the learned features. Finally, STDMF is applied to clustering and anomaly detection of dynamic graph. The effectiveness of this method is verified by sufficient experiments, especially for noisy data.},
  archive      = {J_TNNLS},
  author       = {Chenxi Tian and Wenming Wu and Lingling Li and Xu Liu and Fang Liu and Wenping Ma and Licheng Jiao and Shuyuan Yang},
  doi          = {10.1109/TNNLS.2025.3605215},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Spatial–Temporal diffusion model for matrix factorization},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Continual diffuser (CoD): Mastering continual offline RL with experience rehearsal. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3598928'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial neural networks, especially recent diffusion-based models, have shown remarkable superiority in gaming, control, and QA systems, where the training tasks’ datasets are usually static. However, in real-world applications, such as robotic control of reinforcement learning (RL), the tasks are changing, and new tasks arise in a sequential order. This situation poses the new challenge of plasticity–stability tradeoff for training an agent who can adapt to task changes and retain acquired knowledge. In view of this, we propose a rehearsal-based continual diffusion model, called continual diffuser (CoD), to endow the diffuser with the capabilities of quick adaptation (plasticity) and lasting retention (stability). Specifically, we first construct an offline benchmark that contains 90 tasks from multiple domains. Then, we train the CoD on each task with sequential modeling and conditional generation for making decisions. Next, we preserve a small portion of previous datasets as the rehearsal buffer and replay it to retain the acquired knowledge. Extensive experiments on a series of tasks show that CoD can achieve a promising plasticity–stability tradeoff and outperform existing diffusion-based methods and other representative baselines on most tasks. The source code is available at https://github.com/JF-Hu/Continual_Diffuser.},
  archive      = {J_TNNLS},
  author       = {Jifeng Hu and Li Shen and Sili Huang and Zhejian Yang and Hechang Chen and Lichao Sun and Yi Chang and Dacheng Tao},
  doi          = {10.1109/TNNLS.2025.3598928},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Continual diffuser (CoD): Mastering continual offline RL with experience rehearsal},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FEU-diff: A diffusion model with fuzzy evidence-driven dynamic uncertainty fusion for medical image segmentation. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3609085'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffusion models, as a class of generative frameworks based on step-wise denoising, have recently attracted significant attention in the field of medical image segmentation. However, existing diffusion-based methods typically rely on static fusion strategies to integrate conditional priors with denoised features, making them difficult to adaptively balance their respective contributions at different denoising stages. Moreover, these methods often lack explicit modeling of pixel-level uncertainty in ambiguous regions, which may lead to the loss of structural details during the iterative denoising process, ultimately compromising the accuracy (Acc) and completeness of the final segmentation results. To this end, we propose FEU-Diff, a diffusion-based segmentation framework that integrates fuzzy evidence modeling and uncertainty fusion (UF) mechanisms. Specifically, a fuzzy semantic enhancement (FSE) module is designed to model pixel-level uncertainty through Gaussian membership functions and fuzzy logic rules, enhancing the model’s ability to identify and represent ambiguous boundaries. An evidence dynamic fusion (EDF) module estimates feature confidence via a Dirichlet-based distribution and adaptively guides the fusion of conditional information and denoised features across different denoising stages. Furthermore, the UF module quantifies discrepancies among multisource predictions to compensate for structural detail loss during the iterative denoising process. Extensive experiments on four public datasets show that FEU-Diff consistently outperforms state-of-the-art (SOTA) methods, achieving an average gain of 1.42% in the Dice similarity coefficient (DSC), 1.47% in intersection over union (IoU), and a 2.26 mm reduction in the 95th percentile Hausdorff distance (HD95). In addition, our method generates uncertainty maps that enhance clinical interpretability.},
  archive      = {J_TNNLS},
  author       = {Sheng Geng and Shu Jiang and Tao Hou and Hongcheng Yao and Jiashuang Huang and Weiping Ding},
  doi          = {10.1109/TNNLS.2025.3609085},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {FEU-diff: A diffusion model with fuzzy evidence-driven dynamic uncertainty fusion for medical image segmentation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Restoring noisy demonstration for imitation learning with diffusion models. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3607111'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imitation learning (IL) aims to learn a policy from expert demonstrations and has been applied to various applications. By learning from the expert policy, IL methods do not require environmental interactions or reward signals. However, most existing IL algorithms assume perfect expert demonstrations, but expert demonstrations often contain imperfections caused by errors from human experts or sensor/control system inaccuracies. To address the above problems, this work proposes a filter-and-restore framework to best leverage expert demonstrations with inherent noise. Our proposed method first filters clean samples from the demonstrations and then learns conditional diffusion models to recover the noisy ones. We evaluate our proposed framework and existing methods in various domains, including robot arm manipulation, dexterous manipulation, and locomotion. The experiment results show that our proposed framework consistently outperforms existing methods across all the tasks. Ablation studies further validate the effectiveness of each component and demonstrate the framework’s robustness to different noise types and levels. These results confirm the practical applicability of our framework to noisy offline demonstration data.},
  archive      = {J_TNNLS},
  author       = {Shang-Fu Chen and Co Yong and Shao-Hua Sun},
  doi          = {10.1109/TNNLS.2025.3607111},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Restoring noisy demonstration for imitation learning with diffusion models},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Peak-padding: Clustering by padding density peaks with the minimum padding cost. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3606527'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering complex-shaped clusters is still chal lenging for most existing clustering algorithms. Herein, the peak-padding clustering algorithm (PeakPad)—clustering by padding density peaks with the minimum padding cost—is proposed. PeakPad executes clustering on the density surface and views complex-shaped clusters as combinations of highly associated single-peak clusters. The minimum padding cost that fully considers the surrounding context of a density peak is proposed to reflect a density peak’s center potential, enabling PeakPad to have robust center detection performance. Unlike mean-shift (MSC), which detects centers based on their attributes in a complex-shaped density surface embedded in the high-dimensional space of density and features, PeakPad detects centers in a standard-shaped surface embedded in the 2-D density-change (DC) density space (composed of density and DC feature). Such standardization allows PeakPad to have fast and robust cluster center detection performance on complex-shaped clusters based on the minimum padding cost. Besides, PeakPad can provide a reasonable evaluation of the association between single-peak clusters by using the minimum padding cost. As a result, PeakPad can fast capture complex-shaped clusters, achieve robust center detection performance, and be suitable for large datasets. Benchmark test results on both synthetic and real datasets demonstrate the effectiveness of PeakPad.},
  archive      = {J_TNNLS},
  author       = {Junyi Guan and Bingbing Jiang and Weiguo Sheng and Yangyang Zhao and Sheng Li and Xiongxiong He},
  doi          = {10.1109/TNNLS.2025.3606527},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Peak-padding: Clustering by padding density peaks with the minimum padding cost},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging semi-supervised learning and meta-learning for re-identification in few-shot spatiotemporal anomaly detection. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3578642'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting spatiotemporal anomalies is imperative for addressing critical societal and engineering challenges, including public safety assurance, environmental hazard identification, epidemic surveillance, and transportation system optimization. Existing methodologies, however, face persistent limitations due to sparse labeled datasets and the inherent complexity of dynamic spatiotemporal systems. In order to bridge this gap, we present unsupervised-semi-supervised stacking (USemiS), a novel framework that synergizes semi-supervised learning with ensemble meta-learning. USemiS introduces three core innovations: 1) unsupervised component learners that extract low-level representations of heterogeneous anomalies, 2) a consensus-based tuning mechanism that dynamically weights robust learners via stability metrics, and 3) spatiotemporal MixUp (ST-MixUp), a tailored augmentation strategy that interpolates anomalies across spatial and temporal dimensions to enhance decision boundaries. By integrating these components, USemiS effectively disentangles latent anomaly patterns while mitigating label scarcity. Evaluated on large-scale traffic anomaly and crowd fall detection datasets, USemiS achieves state-of-the-art performance, outperforming existing methods by 1.3% and 2.1% in AUC under extreme low-label regimes (0.4% and 0.8% labeled data, respectively). These results underscore USemiS’s capacity to generalize across diverse spatiotemporal contexts, offering a scalable and robust solution for real-world applications where labeled anomalies are scarce yet critical.},
  archive      = {J_TNNLS},
  author       = {Zhen Zhou and Ziyuan Gu and Pan Liu and Wenwu Yu and Zhiyuan Liu},
  doi          = {10.1109/TNNLS.2025.3578642},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Leveraging semi-supervised learning and meta-learning for re-identification in few-shot spatiotemporal anomaly detection},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward an effective action-region tracking framework for fine-grained video action recognition. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3602089'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained action recognition (FGAR) aims to identify subtle and distinctive differences among fine-grained action categories. However, current recognition methods often capture coarse-grained motion patterns but struggle to identify subtle details in local regions evolving over time. In this work, we introduce the action-region tracking (ART) framework, a novel solution leveraging a query-response mechanism to discover and track the dynamics of distinctive local details, enabling distinguishing similar actions effectively. Specifically, we propose a region-specific semantic activation module that employs discriminative and text-constrained semantics serve as queries to capture the most action-related region responses in each video frame, facilitating interaction among spatial and temporal dimensions with corresponding video features. The captured region responses are then organized into action tracklets, which characterize the region-based action dynamics by linking related responses across different video frames in a coherent sequence. The text-constrained queries are designed to expressly encode nuanced semantic representations derived from the textual descriptions of action labels, as extracted by the language branches within visual language models. To optimize generated action tracklets, we design a multilevel tracklet contrastive constraint among multiple region responses at spatial and temporal levels, which can effectively distinguish individual region responses in each video frame (spatial level) and establish the correlation of similar region responses between adjacent video frames (temporal level). In addition, we implement a task-specific fine-tuning mechanism to refine textual semantics during training. This ensures that the semantic representations encoded by vision language models (VLMs) are not only preserved but also optimized for specific task preferences. Comprehensive experiments on several widely used action recognition benchmarks, i.e., FineGym, Diving48, NTURGB-D, Kinetics, and Something-Something, clearly demonstrate the superiority to previous state-of-the-art baselines.},
  archive      = {J_TNNLS},
  author       = {Baoli Sun and Yihan Wang and Xinzhu Ma and Zhihui Wang and Kun Lu and Zhiyong Wang},
  doi          = {10.1109/TNNLS.2025.3602089},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Toward an effective action-region tracking framework for fine-grained video action recognition},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contrastive federated learning for graph anomaly detection. <em>TNNLS</em>, 1-12. (<a href='https://doi.org/10.1109/TNNLS.2025.3601449'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph anomaly detection (GAD) refers to identifying abnormal graph nodes or edges that heavily deviate from normal observations. Existing approaches inevitably suffer from the influence of imbalanced data and privacy protection. This shortcoming poses challenges in optimizing node embeddings and detecting multitype anomalies simultaneously, resulting in decreased accuracy of existing GAD models. To address this shortcoming, we introduce a new federated learning model for graph anomaly detection (FedGAD). FedGAD enables collaborative unsupervised learning among decentralized data centers without requiring direct access to the distributed subgraphs. Specifically, FedGAD masks and reconstructs the neighborhood features to enhance the knowledge of node representations. Considering the data diversity across distributed clients, we also design a cross-clients’ node representation module that enables nodes to reconstruct neighbors by leveraging information from other clients. Furthermore, we use a multiscale contrastive learning function, which includes both structure-level and contextual-level learning functions, to detect graph anomalies in the condition that subgraphs located at different clients show imbalanced data distributions. Experimental results on seven benchmark datasets demonstrate the superior performance of FedGAD compared with baseline methods, verifying its capability of improving GAD performance.},
  archive      = {J_TNNLS},
  author       = {Hui Fang and Yang Gao and Peng Zhang and Sheng Zhou and Hongyang Chen and Jiajun Bu and Haishuai Wang},
  doi          = {10.1109/TNNLS.2025.3601449},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Contrastive federated learning for graph anomaly detection},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Coupled tensor decomposition for compact network representation. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3609797'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we introduce an approach called coupled filters decomposition, which builds on the key observation that redundancy exists among filters in a convolutional layer, meaning that similar filters can produce partially overlapping outputs. Leveraging this insight, we propose a joint decomposition of filters using coupled tensor decompositions, specifically coupled canonical polyadic decomposition (CPD), which enables the sharing of a common factor matrix across similar filters. This joint factorization not only reduces the number of parameters but also lowers computational complexity by eliminating redundant computations. To further improve efficiency, we first cluster the filters before decomposition. The grouping relies on a custom metric based on the subspace spanned by the shared-mode factor. Within each group, the coupling constraint is less restrictive. Extensive experiments across various architectures, datasets, and tasks validate the effectiveness of our method, demonstrating its competitive performance compared to state-of-the-art model compression techniques. Our code is available for research purposes at https://codec-ai.github.io/},
  archive      = {J_TNNLS},
  author       = {Van Tien Pham and Yassine Zniyed and Thanh Phuong Nguyen},
  doi          = {10.1109/TNNLS.2025.3609797},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Coupled tensor decomposition for compact network representation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A self-supervised learning framework for soft robot proprioception. <em>TNNLS</em>, 1-7. (<a href='https://doi.org/10.1109/TNNLS.2025.3610759'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The inherent compliant nature of soft robots can offer remarkable advantages over their rigid counterparts in terms of safety to human users and adaptability in unstructured environments. However, this feature also magnifies the complexity of their bodies, rendering their proprioception, and hence their control, extremely challenging. Given this intricacy, machine learning is a potent candidate for extracting proprioceptive insights from sensor data due to its proven capabilities in tackling analogous issues in computer vision (CV) and natural language processing (NLP). Recently, key aspects of soft robot proprioception have been addressed via learning-based techniques, but most of these are rooted in the supervised learning (SL) paradigm. This typically requires collecting a large number of costly annotated training samples, thereby constraining its widespread and speedy adoption in real-world applications. To mitigate this limitation, we propose a self-SL framework for soft robot proprioception. Our method utilizes vast unannotated data for network pretraining by self-SL. Then, the pretrained model is fine-tuned with a limited set of annotated samples by SL. We validate the proposed method’s efficacy on a high-resolution 3-D morphological reconstruction task using a publicly available dataset. Remarkably, our approach is shown to necessitate only about 1/20 of annotated samples to achieve better performance than the fully supervised method.},
  archive      = {J_TNNLS},
  author       = {Delin Hu and Huazhi Dong and Francesco Giorgio-Serchi and Yunjie Yang},
  doi          = {10.1109/TNNLS.2025.3610759},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-7},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A self-supervised learning framework for soft robot proprioception},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Vision mamba: A comprehensive survey and taxonomy. <em>TNNLS</em>, 1-21. (<a href='https://doi.org/10.1109/TNNLS.2025.3610435'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {State space model (SSM) is a mathematical model used to describe and analyze the behavior of dynamic systems. This model has witnessed numerous applications in several fields, including control theory, signal processing, economics, and machine learning. In the field of deep learning, SSMs are used to process sequence data, such as time series analysis, natural language processing (NLP), and video understanding. By mapping sequence data to state space, long-term dependencies in the data can be better captured. In particular, modern SSMs have shown strong representational capabilities in NLP, especially in long sequence modeling, while maintaining linear time complexity. In particular, based on the latest SSMs, Mamba merges time-varying parameters into SSMs toward efficient training and inference. Given its impressive efficiency and strong long-range dependency modeling capability, Mamba is expected to become a new AI architecture that may be capable of surpassing Transformer. Recently, a number of works attempt to study the potential of Mamba in various fields, such as general vision, multimodal learning, medical image analysis, and remote sensing image analysis, by extending Mamba from natural language domain to visual domain. To fully understand Mamba in the visual domain, we conduct a comprehensive survey and present a taxonomy study. This survey focuses on Mamba’s application to a variety of visual tasks and data types, and discusses its predecessors, recent advances, and far-reaching impact on a wide range of domains.},
  archive      = {J_TNNLS},
  author       = {Xiao Liu and Chenxu Zhang and Fuxiang Huang and Shuyin Xia and Guoyin Wang and Lei Zhang},
  doi          = {10.1109/TNNLS.2025.3610435},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-21},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Vision mamba: A comprehensive survey and taxonomy},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reinforcement learning-based boundary-optimized control of flexible manipulators under jointly connected switching topologies. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3609134'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article pioneers the study of boundary-optimized fault-tolerant tracking control for flexible manipulators in a switching digraph with a heterogeneous linear leader. Compared with existing research, the proposed methods have several features. First, a distributed observer is designed to observe the leader’s information in a general switching graph where communication can be interrupted. Second, a new partial differential equation (PDE)-based fault observer (FO) is designed to estimate unknown faults using only a few boundary states. Third, a novel long-term integral cost function is formulated to minimize angle-tracking errors, vibration deflections, and control energy in flexible manipulators. The ideal boundary optimal control laws are, then, derived and approximated using actor–critic neural networks (NNs) based on reinforcement learning (RL). Under the proposed fully distributed optimized fault-tolerant controllers, the closed-loop flexible manipulator’s error states are proven uniformly ultimately bounded (UUB). Finally, the effectiveness of the proposed method is demonstrated through numerical simulation results.},
  archive      = {J_TNNLS},
  author       = {Xiangqian Yao and Lin Li and Yu Liu},
  doi          = {10.1109/TNNLS.2025.3609134},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Reinforcement learning-based boundary-optimized control of flexible manipulators under jointly connected switching topologies},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Physics-guided time-interactive-frequency network for cross-domain few-shot hyperspectral image classification. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3608294'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, domain alignment and metric-based few-shot learning (FSL) have been introduced into hyperspectral image classification (HSIC) to solve the issues of uneven data distribution and scarcity of annotated data faced in practical applications. However, existing cross-domain few-shot methods ignore pivotal frequency priors of the complex field, which contribute to better category discrimination and knowledge transfer. To address this issue, we propose a novel physics-guided time-interactive-frequency network (PTFNet) for cross-domain few-shot HSIC, enabling the extraction of both frequency priors and spatial features (termed “time domain” following Fourier convention) simultaneously through a lightweight time-interactive-frequency module (TiF-Module) as a pioneering effort. Meanwhile, a spectral Fourier-based augmentation module (SFA-Module) is designed to decouple the frequency priors and enhance the diversity of distribution of physical attributes to imitate the domain shift. Then, the physics consistency loss is introduced to regularize the diverse embeddings to approximate the center of each category’s physical attributes, guiding the network to excavate more transferable knowledge of source domain (SD). Furthermore, to fully exploit the discriminant time–frequency information and further improve the accuracy of boundary pixels, a set of multiorientation homogeneous prototypes is adopted to represent each class comprehensively, and an intuitive and flexible uncertainty-rectified bidirectional random walk strategy is applied to replace the Euclidean metric for more reliable classification. The experimental results on four public datasets demonstrate the prominent performance of the proposed PTFNet.},
  archive      = {J_TNNLS},
  author       = {Jiaojiao Li and Hailong Wu and Rui Song and Haitao Xu and Yunsong Li and Qian Du},
  doi          = {10.1109/TNNLS.2025.3608294},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Physics-guided time-interactive-frequency network for cross-domain few-shot hyperspectral image classification},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Time series classification based on supervised contrastive learning and homoscedastic uncertainty. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3607901'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, contrastive learning (CL) frameworks have been widely applied to multivariate time series classification (MTSC) tasks. However, existing methods lack task-specific guidance, leading to limitations in fully capturing the complex dynamics and invariant representations in time series data. Motivated by the auxiliary tasks in multitask learning (MTL) and to fully utilize the rich frequency-domain information of time series data, we propose a novel time series classification framework, uncertainty-based time–frequency supervised CL (U-TFSCL). This framework uses SCL in the time and frequency domains and time–frequency consistency as auxiliary tasks to improve the primary task of using only instance-level labels for time series classification. Furthermore, inspired by the homogeneous uncertainty in MTL, we derive a novel uncertainty loss function, which automatically adjusts the weights according to the degree of uncertainty of different tasks to optimize the learning and prediction process of the model. The proposed framework is evaluated on MTSC tasks, including human activity recognition (HAR), air writing, and gesture recognition. In addition, we create a human–drone interaction (HDI) dataset consisting of 20 subjects and conduct real-world experiments to evaluate the proposed framework. The extensive experiments conducted in various settings verify the effectiveness of the proposed framework.},
  archive      = {J_TNNLS},
  author       = {Tao Zhang and Ke Li and Shaofan Wang},
  doi          = {10.1109/TNNLS.2025.3607901},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Time series classification based on supervised contrastive learning and homoscedastic uncertainty},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal quaternion representation network for multisource remote sensing data classification. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3610892'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The effective integration and classification of hyperspectral images (HSIs) and light detection and ranging (LiDAR) data is of great significance in Earth observation missions, which are confronted with challenges such as insufficient information utilization and feature heterogeneity. This article proposes a multimodal quaternion representation network (MMQRN) for multisource remote sensing (RS) data classification. Specifically, we first propose the multimodal quaternion representation (MMQR), which employs the orthogonal imaginary components of quaternions to model the complex nonlinear interactions among complementary features, thereby enabling their comprehensive fusion and utilization. Subsequently, we design a multimodal feature cross-fusion (MFCF) framework to integrate multisource, multimodal, and multilevel features adequately. Finally, we leverage the ability to capture long-term dependencies of transformers to design a quaternion convolutional transformer network (QCTN) for modeling global and local spatial–spectral information, respectively. Experiments conducted on three multisource RS datasets demonstrate the superior performance of the proposed MMQRN relative to other state-of-the-art classification methods.},
  archive      = {J_TNNLS},
  author       = {Yu-Le Wei and Heng-Chao Li and Jian-Li Wang and Yu-Bang Zheng and Jie Pan and Qian Du},
  doi          = {10.1109/TNNLS.2025.3610892},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Multimodal quaternion representation network for multisource remote sensing data classification},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HSG-net: Point cloud completion via heuristic structure growing. <em>TNNLS</em>, 1-12. (<a href='https://doi.org/10.1109/TNNLS.2025.3610101'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing point cloud completion methods rely on extracting latent codes from a partial point cloud to reconstruct a complete structure. However, the complexity of the partial point clouds, making the completion results of such methods less satisfactory, especially in long-distance (away from partial point cloud) areas. To tackle this challenge, we propose a point cloud completion network via heuristic structure growing (HSG-Net), which progressively completes the close-distance structure through an iterative heuristic structure growth strategy. Particularly, a novel data preprocessing (DP) method is proposed to obtain ground truth (GT) with specific structural integrity, guiding the network to learn close-distance structural information. In addition, the proposed consistency constraint displacement module (CCDM) is employed to fulfill structure growth, and a feature memory module (FMM) further enhances the quality of the grown structure. Furthermore, a proposed local information generator is used to further refine the structure-grown point cloud, fetching the final result. Extensive quantitative and qualitative results demonstrate that our HSG-Net outperforms the state-of-the-art methods.},
  archive      = {J_TNNLS},
  author       = {Xiaojun Chen and Junxian Chen and Ying Liu and Ruihui Li},
  doi          = {10.1109/TNNLS.2025.3610101},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {HSG-net: Point cloud completion via heuristic structure growing},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fuzzy rule-based differentiable representation learning. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3609722'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Representation learning is a key area in machine learning and deep learning, focusing on extracting meaningful features to support downstream tasks such as classification and clustering. Current mainstream representation learning methods primarily rely on nonlinear data mining techniques such as kernel methods and deep neural networks (DNNs) to extract abstract knowledge from complex datasets. However, most of them are “black-box” methods, lacking transparency and interpretability in the learning process, which constrain their practical utility. To this end, this article introduces a novel representation learning method called fuzzy rule-based differentiable representation learning (FRDRL), which is grounded in an interpretable fuzzy rule-based model. Specifically, it is built upon the Takagi–Sugeno–Kang fuzzy system (TSK-FS) to map input data to a high-dimensional fuzzy feature space through the antecedent part of the TSK-FS. Subsequently, a novel differentiable optimization method is proposed for learning in the consequent part, which preserves interpretability and transparency while effectively capturing nonlinear relationships in the data. By retaining the essence of traditional optimization and parameterizing key components as differentiable modules, the method improves performance without sacrificing interpretability. Moreover, a second-order geometry preservation strategy is incorporated to further improve robustness. Extensive evaluations conducted on various benchmark datasets validate the superiority of the proposed method. The source codes are available at https://github.com/BBKing49/FEDRL},
  archive      = {J_TNNLS},
  author       = {Wei Zhang and Zhaohong Deng and Guanjin Wang and Kup-Sze Choi},
  doi          = {10.1109/TNNLS.2025.3609722},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Fuzzy rule-based differentiable representation learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ape optimizer: A p-power adaptive filter-based approach for deep learning optimization. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3610665'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has been widely applied in various domains. Current widely-used optimizers, such as SGD, Adam, and their variants, are designed based on the assumption that the gradient noise generated during model training follows a Gaussian distribution. However, recent empirical studies have found that the gradient noise often does not follow a Gaussian distribution. Instead, the noise exhibits heavy-tailed characteristics consistent with an $\alpha $ -stable distribution, casting doubt on the performance and robustness of optimizers designed under the assumption of Gaussian noise. Inspired by the least mean p-power (LMP) algorithm from the field of adaptive filtering, we propose a novel optimizer called Ape for deep learning. Ape integrates a p-power adjustment mechanism to compress large gradients and amplify small ones, mitigating the impact of heavy-tailed gradient distributions. It also employs an approach for estimating second moments tailored to $\alpha $ -stable distributions. Extensive experiments on benchmark datasets demonstrate Ape’s effectiveness in improving both accuracy and training speed compared to existing optimizers. The Ape optimizer showcases the potential of cross-disciplinary approaches in advancing deep learning optimization techniques and lays the groundwork for future innovations in this domain.},
  archive      = {J_TNNLS},
  author       = {Yufei Jin and Han Yang and Xinrui Wang and Yingche Xu and Zhuoran Zhang},
  doi          = {10.1109/TNNLS.2025.3610665},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Ape optimizer: A p-power adaptive filter-based approach for deep learning optimization},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mars express orbiter power consumption prediction based on bionic hierarchical learning network. <em>TNNLS</em>, 1-12. (<a href='https://doi.org/10.1109/TNNLS.2025.3611001'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting power consumption for the Mars Express (MEX) mission is essential for optimizing its operational lifespan and mission assignments. However, the complexity of the Martian environment and the extended solar cycle obscure the periodicity of power consumption, making it difficult for existing methods to capture both intraperiodic and interperiodic features. This study introduces the bionic hierarchical learning network (BHL-Net) to enhance power consumption predictions. Leveraging 2-D frequency preprocessing and brain visual modeling techniques, BHL-Net mimics natural image encoding in the prefrontal cortex (PFC) to improve predictive performance. It incorporates a temporal oscillation activation module and a stripe intensity attention module to focus on local features, while a multihead attention adaptive aggregation module identifies key global features. Comparative experiments show that BHL-Net outperforms existing transformer-based models for MEX power consumption prediction. Ablation studies further validate the effectiveness of the FFT-based 2-D transformation and bionic attention framework. By emulating human brain response coding mechanisms, BHL-Net captures variations within and between complex cycles, providing a competitive solution for time series prediction in industrial applications.},
  archive      = {J_TNNLS},
  author       = {Zhuoyi Qian and Zhen Chen and Ershun Pan},
  doi          = {10.1109/TNNLS.2025.3611001},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Mars express orbiter power consumption prediction based on bionic hierarchical learning network},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing reinforcement learning with cross-domain knowledge transfer via seeded graph matching. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3606751'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transfer reinforcement learning (TRL) aims to boost the efficiency of reinforcement learning (RL) agents by leveraging knowledge from related tasks. Prior research primarily focuses on intradomain transfer, overlooking the complexities of transferring knowledge across tasks with differing state and action spaces. Recent efforts in cross-domain TRL aim to bridge this gap by establishing mappings between disparate source and target spaces, thereby enabling knowledge transfer across RL tasks with varied state and action configurations. However, existing studies often rely on strict prior assumptions about the relationships between state spaces, which limits their practical generality. In this article, we propose a novel approach to cross-domain TRL based on seeded graph matching, which enables alignment between source and target tasks regardless of differences in their state–action spaces. In particular, we model RL tasks as directed graphs, identify seed node pairs based on common RL properties, and devise a graph matching algorithm to align the source and target tasks by leveraging their structural characteristics. Building on this alignment, we introduce a policy-based transfer algorithm that improves the performance of the target RL task as its RL process progresses. Finally, we conduct comprehensive empirical studies on both discrete and continuous tasks with diverse state–action spaces. The experimental results validate the effectiveness of the proposed algorithm.},
  archive      = {J_TNNLS},
  author       = {Gengzhi Zhang and Liang Feng and Xuefeng Chen and Ke Tang and Kay Chen Tan},
  doi          = {10.1109/TNNLS.2025.3606751},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Enhancing reinforcement learning with cross-domain knowledge transfer via seeded graph matching},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Virtual target-oriented neural learning for robust optimal tracking control of discrete strict-feedback systems. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3604566'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a hierarchical neural learning (HNL) algorithm for optimal tracking control (OTC) of nonlinear strict-feedback systems (SFSs) with unmatched disturbances (uMDs) and unknown dynamics. Leveraging the recursive structure of SFSs, we introduce the virtual target (VT) construction scheme in which each VT is a nonlinear mapping of the current state and desired output, thereby eliminating the noncausal that typically plagues discrete-time SFS control. The VTs serve as auxiliary inputs for low-order subsystems, while a time-varying affine Hamilton–Jacobi–Isaacs (HJI) formulation establishes an explicit relationship between the auxiliary control and the disturbance. The controller is synthesized directly from input–output data, removing the need for an accurate plant model. Within an adaptive dynamic programming (ADP) framework, we further enhance the neural architecture by replacing the conventional action network with a tracking network (T-network) whose energy function merges gradient information with future tracking errors, ensuring that each policy update simultaneously reduces control effort and improves tracking accuracy. Simulations confirm that the proposed HNL scheme achieves outstanding performance in both (optimal) tracking modes, exhibiting strong robustness to uMDs and significant model uncertainties.},
  archive      = {J_TNNLS},
  author       = {Ying Yan and Huaguang Zhang and Jiayue Sun and Zhongyang Ming},
  doi          = {10.1109/TNNLS.2025.3604566},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Virtual target-oriented neural learning for robust optimal tracking control of discrete strict-feedback systems},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An empirical study of federated learning on IoT–Edge devices: Resource allocation and heterogeneity. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3611415'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, billions of phones, internet-of-things (IoT), and edge devices around the world generate data continuously, enabling many machine-learning (ML)-based products and applications. However, due to increasing privacy concerns and regulations, these data tend to reside on devices (clients) instead of being centralized for performing traditional ML model training. Federated learning (FL) is a distributed approach in which a single server and multiple clients collaboratively build an ML model without moving data away from clients. Whereas existing studies on FL have their own experimental evaluations, most experiments were conducted using a simulation setting or a small-scale testbed. This might limit the understanding of FL implementation in realistic environments. In this empirical study, we systematically conduct extensive experiments on a large network of IoT and edge devices (called IoT–Edge devices) to present FL real-world characteristics, including learning performance and operation (computation and communication) costs. Moreover, we mainly concentrate on heterogeneous scenarios, which is the most challenging issue of FL. By investigating the feasibility of on-device implementation, our study provides valuable insights for researchers and practitioners, promoting the practicality of FL and assisting in improving the current design of real FL systems.},
  archive      = {J_TNNLS},
  author       = {Kok-Seng Wong and Duc-Manh Nguyen and Khiem Le and Long Ho and Cuong Do and Danh Le-Phuoc},
  doi          = {10.1109/TNNLS.2025.3611415},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {An empirical study of federated learning on IoT–Edge devices: Resource allocation and heterogeneity},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed FilterNet reinforcement learning for achieving output consensus in heterogeneous multiplayer multiagent systems. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3609525'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the leader–follower consensus problem in multiagent systems with heterogeneous agent dynamics and multiple internal players per agent, each with distinct and interaffected objectives. Formulated as a multiplayer differential game per agent, the goal is to achieve output consensus among all agents while ensuring Nash equilibrium controls across each agent’s internal players. To address this challenge, we introduce a distributed control framework that integrates both feedforward (regulator-based) and feedback (game-theoretic Riccati-based) components. We further design a FilterNet reinforcement learning (RL) architecture that solves the control solutions while eliminating the need for large-scale distributed data storage. Organized into four layers, FilterNet handles admissible policy identification, online initialization, asynchronous updates for Nash policy convergence, and real-time regulator solutions. This design reduces data requirements, ensures initial excitation, and accelerates convergence. Theoretical guarantees establish conditions for solvability and convergence. Numerical simulations and comparisons with existing methods confirm the effectiveness and superiority of the proposed approach.},
  archive      = {J_TNNLS},
  author       = {Jiacheng Wu and Bosen Lian and Changyun Wen and Yang Zhu},
  doi          = {10.1109/TNNLS.2025.3609525},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Distributed FilterNet reinforcement learning for achieving output consensus in heterogeneous multiplayer multiagent systems},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust fine-grained visual categorization via cyclical attention. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3608560'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained visual categorization (FGVC) in open-world settings frequently encounters heavy occlusion (HO) samples that compromise discriminative features. However, effectively addressing heavy occlusion remains a challenge. Existing methods often either discard the occluded parts or utilize them through additional techniques such as image inpainting or multimodel strategies, each with its own set of advantages and limitations. In this article, we propose a novel approach inspired by human self-regulated learning (SRL) behavior: cyclical attention that leverages occluded regions through the attention recalibration in the feedback loop. In particular, we introduce a new multi-instance model where occluded parts are essential due to a special feedback structure at the basis of a cooperative game mechanism. This mimics SRL to re-evaluate the previous attention-based image patch selection strategy. We then embed the proposed multi-instance model into a transformer architecture, creating an SRL-FGVC transformer. The key innovation of this design is the cyclical attention, with the forward and feedback self-attention formulating a cooperative union to mitigate attention bias. Extensive experiments on six public datasets and an additional dataset we established demonstrate that the SRL-FGVC transformer consistently outperforms existing approaches in HO scenarios. This work presents a promising new direction for robust FGVC in challenging real-world conditions.},
  archive      = {J_TNNLS},
  author       = {Bin Kang and Dong Liang and Daoyuan Chen and Tianyu Ding and Mingqiang Wei},
  doi          = {10.1109/TNNLS.2025.3608560},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Robust fine-grained visual categorization via cyclical attention},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Temporal and heterogeneous graph neural network for remaining useful life prediction. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3592788'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting remaining useful life (RUL) plays a crucial role in the prognostics and health management of industrial systems that involve a variety of interrelated sensors. Given a constant stream of time-series sensory data from such systems, deep learning (DL) models have risen to prominence at identifying complex, nonlinear temporal dependencies in these data. In addition to the temporal dependencies of individual sensors, spatial dependencies emerge as important correlations among these sensors, which can be naturally modeled by a temporal graph that describes time-varying spatial relationships. However, the majority of existing studies have relied on capturing discrete snapshots of this temporal graph, a coarse-grained approach that leads to a loss of temporal information. Moreover, given the variety of heterogeneous sensors, it becomes vital that such inherent heterogeneity is leveraged for RUL prediction in temporal sensor graphs. To capture the nuances of the temporal and spatial relationships and heterogeneous characteristics in an interconnected graph of sensors, we introduce a novel model named temporal and heterogeneous graph neural networks (THGNNs). Specifically, THGNN aggregates historical data from neighboring nodes to accurately capture the temporal dynamics and spatial correlations within the stream of sensor data in a fine-grained manner. Moreover, the model leverages feature-wise linear modulation (FiLM) to address the diversity of sensor types, significantly improving the model’s capacity to learn the heterogeneity in the data sources. Finally, we have validated the effectiveness of our approach through comprehensive experiments. Our empirical findings demonstrate significant advancements on the N-CMAPSS dataset, achieving improvements of up to 19.2% and 31.6% in terms of two different evaluation metrics over state-of-the-art methods.},
  archive      = {J_TNNLS},
  author       = {Zhihao Wen and Yuan Fang and Pengcheng Wei and Fayao Liu and Zhenghua Chen and Min Wu},
  doi          = {10.1109/TNNLS.2025.3592788},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Temporal and heterogeneous graph neural network for remaining useful life prediction},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Anchor-based multiview subspace clustering with anchor-wise and class-wise alignments. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3589264'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiview subspace clustering has shown promising performance in multimedia and data mining applications. However, its employment in large-scale datasets is limited due to its quadratic or even cubic computational complexity. The anchor graph strategy, which selects a few important samples (anchors) to represent the whole data for different views, has been introduced to address this challenge. These methods rely on a heuristic assumption that the correspondence and class structures between the sets of anchors across different views are the same. This assumption ignores the difference in the ordering of anchors with respect to their associated classes and the number of anchors belonging to the same class from different views. As a result, this can lead to unsatisfactory clustering results due to incorrect anchorwise and classwise alignments. To tackle this issue, this article proposes an anchor-based multiview subspace clustering with anchorwise and classwise alignments (AMCA2) method. Specifically, the proposed method simultaneously aligns and fuses multiple anchor graphs anchor wisely and class wisely via learning permutation matrices and utilizing the Hadamard product. To further enhance the clustering performance of AMCA2, we propose a novel anchor selection method called kernel anchor selection (KAS) to select more representative anchors. Extensive experiments on ten benchmark datasets are conducted to show the superiority and effectiveness of AMCA2 over the state-of-the-art methods.},
  archive      = {J_TNNLS},
  author       = {Ye Liu and Hongshan Pu and Junjun Pan and Michael K. Ng and Hongmin Cai},
  doi          = {10.1109/TNNLS.2025.3589264},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Anchor-based multiview subspace clustering with anchor-wise and class-wise alignments},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MBUNeXt: Multibranch encoder aggregation network based on layer-fusion strategy for multimodal brain tumor segmentation. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3593297'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal brain tumor segmentation (BraTS), integrated with surgical robots and navigation systems, enables accurate surgical interventions while maximizing the preservation of surrounding healthy brain tissue. However, multimodal brain scans suffer from large interclass differences in brain tumor subregions and information redundancy, leading to inadequate fusion of multimodal information and significantly affecting the accuracy of BraTS. To address the above problems, we propose a multibranch encoder aggregation (MEA) network based on a layer-fusion strategy called multibranch UNeXt (MBUNeXt). The network comprises three well-designed modules: the multimodal feature attention (MFA) module, the MEA module, and the large-kernel convolution skip (LCS)-connection module. These modules work together to achieve precise segmentation of brain tumors. Specifically, the MFA module preserves the intermodality similarity structure through attention mechanisms and Gaussian modulation functions, thereby filtering redundant information. Then, the MEA module exploits the correlations among multiple modalities to effectively integrate multimodal hybrid feature representation and optimize multimodal information fusion. In addition, the LCS module constructs multiple groups of depthwise separable convolutions with large kernel, which can guide the network to attend to features at different scales, thereby addressing the issue of significant interclass differences in brain tumor subregions. The experimental results on the large-scale public datasets, BraTS2019 and BraTS2021, which consist of approximately 5000 3-D brain scans, demonstrate that our proposed method has achieved SOTA performance, with average Dice scores of 85.84% and 91.11%, respectively. It also performs well on the BraTS-Africa2024 dataset with low imaging quality, confirming its robustness. The code is available at https://github.com/liuqinghao2018/MBUNeXt},
  archive      = {J_TNNLS},
  author       = {Qinghao Liu and Yuehao Zhu and Min Liu and Zhao Yao and Yaonan Wang and Erik Meijering},
  doi          = {10.1109/TNNLS.2025.3593297},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {MBUNeXt: Multibranch encoder aggregation network based on layer-fusion strategy for multimodal brain tumor segmentation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Discovering Spatiotemporal–Individual coupled features from nonstandard Tensors—A novel dynamic graph mixer approach. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3592692'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we present the dynamic graph mixer (DGM), a novel model for learning spatiotemporal-individual coupled features from high-dimensional and incomplete (HDI) tensors, which frequently represent dynamic interactions among real-world data samples. In contrast to existing methods, the proposed DGM possesses the following three advantages when learning representations from HDI tensors. First, it performs light graph message passing based on the conjoint attentions learned by jointly modeling latent features and implicit structures to extract the high-order connectivity. Second, a multilayer nonlinear tensor neural network (TNN) is adopted to learn the intricate attribute features of node–node–time from different views. Third, it follows the Tucker decomposition paradigm in a data density-oriented modeling mechanism to integrate node representations, preserving the overall multidimensional interaction patterns. In addition, we provide theoretical evidence that the key components in DGM can significantly improve expressiveness. Extensive experiments conducted on eight testing datasets of HDI tensors demonstrate that DGM outperforms state-of-the-art methods in both learning accuracy and efficiency.},
  archive      = {J_TNNLS},
  author       = {Fanghui Bi and Tiantian He and Yew-Soon Ong and Xin Luo},
  doi          = {10.1109/TNNLS.2025.3592692},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Discovering Spatiotemporal–Individual coupled features from nonstandard Tensors—A novel dynamic graph mixer approach},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond RMSE and MAE: Introducing EAUC to unmask hidden bias and unfairness in dyadic regression models. <em>TNNLS</em>, 1-12. (<a href='https://doi.org/10.1109/TNNLS.2025.3593059'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dyadic regression models, which output real-valued predictions for pairs of entities, are fundamental in many domains [e.g., obtaining user-product ratings in recommender systems (RSs)] and promising and under exploration in others (e.g., tuning patient–drug dosages in precision pharmacology). In this work, we prove that nonuniform observed value distributions of individual entities lead to severe biases in state-of-the-art models, skewing predictions toward the average of observed past values for the entity and providing worse-than-random predictive power in eccentric yet crucial cases; we name this phenomenon eccentricity bias. We show that global error metrics like root-mean-squared error (RMSE) are insufficient to capture this bias, and we introduce eccentricity area under the curve (EAUC) as a novel metric that can quantify it in all studied domains and models. We prove the intuitive interpretation of EAUC by experimenting with naive post-training bias corrections and theorize other options to use EAUC to guide the construction of fair models. This work contributes a bias-aware evaluation of dyadic regression to prevent unfairness in critical real-world applications of such systems.},
  archive      = {J_TNNLS},
  author       = {Jorge Paz-Ruza and Amparo Alonso-Betanzos and Bertha Guijarro-Berdiñas and Brais Cancela and Carlos Eiras-Franco},
  doi          = {10.1109/TNNLS.2025.3593059},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Beyond RMSE and MAE: Introducing EAUC to unmask hidden bias and unfairness in dyadic regression models},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DDCNet: Advanced decoupling of degradation and content for adverse weather image restoration. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3594492'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adverse weather image restoration aims to recover clear images from those affected by weather conditions such as rain, haze, and snow. Different weather types affect images in distinct ways, necessitating specific degradation removal strategies, while content reconstruction generally benefits from a consistent approach since the underlying image structure remains largely consistent. Previous methods, despite their ability to handle multiple weather conditions within a single framework, often failed to adequately separate these two critical processes, thereby adversely affecting image restoration quality. In this article, we present DDCNet, a novel framework designed to explicitly decouple degradation removal and content reconstruction when processing various adverse weather conditions within a unified network. We achieve this by separating tailored degradation removal from uniform content reconstruction at the feature level, based on channel statistics. Additionally, we utilize the Fourier transform to enhance both processes. Furthermore, to address the differing optimization directions required by different adverse weather types, we propose a novel degradation mapping (DM) loss function to constrain their respective optimization paths. Extensive experiments show that DDCNet establishes new performance standards across multiple adverse weather scenarios.},
  archive      = {J_TNNLS},
  author       = {Xi Wang and Xueyang Fu and Yurui Zhu and Zheng-Jun Zha},
  doi          = {10.1109/TNNLS.2025.3594492},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {DDCNet: Advanced decoupling of degradation and content for adverse weather image restoration},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing domain generalization in medical image segmentation with global and local prompts. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3590956'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Enhancing domain generalization (DG) is a crucial and compelling research pursuit within the field of medical image segmentation, owing to the inherent heterogeneity observed in medical images. The recent success with large-scale pre-trained vision models (PVMs), such as Vision Transformer (ViT), inspires us to explore their application in this specific area. While a straightforward strategy involves fine-tuning the PVM using supervised signals from the source domains, this approach overlooks the domain shift issue and neglects the rich knowledge inherent in the instances themselves. To overcome these limitations, we introduce a novel framework enhanced by global and local prompts (GLPs). Specifically, to adapt PVM in the medical DG scenario, we explicitly separate domain-shared and domain-specific knowledge in the form of GLPs. Furthermore, we develop an individualized domain adapter to intricately investigate the relationship between each target domain sample and the source domains. To harness the inherent knowledge within instances, we devise two innovative regularization terms from both the consistency and anatomy perspectives, encouraging the model to preserve instance discriminability and organ position invariance. Extensive experiments and in-depth discussions in both vanilla and semi-supervised DG scenarios deriving from five diverse medical datasets consistently demonstrate the superior segmentation performance achieved by GLP. Our code and datasets are publicly available at https://github.com/xmed-lab/GLP.},
  archive      = {J_TNNLS},
  author       = {Chuang Zhao and Xiaomeng Li},
  doi          = {10.1109/TNNLS.2025.3590956},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Enhancing domain generalization in medical image segmentation with global and local prompts},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interactive graph learning for multilevel network alignment. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3592415'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of network alignment aims to identify corresponding nodes across multiple networks, with applications in various fields such as social network analysis and bioinformatics. Traditional methods typically focus on the topological structure of networks at a specific level, but they may overlook important properties exhibited by many networks, such as scale-free properties and specific power-law structures often found in social networks. Consequently, these methods fail to effectively capture and utilize such information, leading to misalignment. In this article, we propose a network alignment framework that incorporates both topological and attribute information from multiple levels in the network, including homogeneity, power-law, and higher order structures. We introduce a Euclidean hyperbolic interactive graph learning method specifically designed for modeling power-law structures in networks, aiming to improve the accuracy of network alignment. To evaluate the effectiveness of our proposed method, we conduct experiments on several real-world datasets. The results demonstrate that our approach achieves higher accuracy compared to other advanced baselines.},
  archive      = {J_TNNLS},
  author       = {Pengfei Jiao and Yuanqi Liu and Yinghui Wang and Huijun Tang and Zhidong Zhao and Shirui Pan},
  doi          = {10.1109/TNNLS.2025.3592415},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Interactive graph learning for multilevel network alignment},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Observer-based event-triggered fault-tolerant synchronization for memristive neural networks subject to multiple failures. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3596704'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, the synchronization problem of memristive neural networks (MNNs) subjected to multiple failures is investigated. First, a general form of fault model is introduced into the MNNs, which can represent and summarize various process faults, actuator faults, and their coupling. Subsequently, with the help of designing intermediate variables, two types of fault function observers based on state feedback and output feedback are constructed, and their effectiveness is verified through a generalization of Halanay-type inequalities. Then, based on the designed observers and the event-triggered strategy, two classes of fault-tolerant synchronization schemes are designed for the considered MNNs. By adjusting the controller parameter conditions, finite-time and fixed-time synchronization or quasi-synchronization of the considered MNNs system can be achieved, respectively. Finally, the effectiveness of the provided fault observers and synchronization strategies is verified through simulation and comparison experiments.},
  archive      = {J_TNNLS},
  author       = {Mingxin Wang and Song Zhu and Xiaoyang Liu and Shiping Wen and Chaoxu Mu},
  doi          = {10.1109/TNNLS.2025.3596704},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Observer-based event-triggered fault-tolerant synchronization for memristive neural networks subject to multiple failures},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving sample efficiency of reinforcement learning with background knowledge from large language models. <em>TNNLS</em>, 1-12. (<a href='https://doi.org/10.1109/TNNLS.2025.3590731'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low sample efficiency is an enduring challenge of reinforcement learning (RL). With the advent of versatile large language models (LLMs), recent works impart common-sense knowledge to accelerate policy learning for RL processes. However, we note that such guidance is often tailored for one specific task but loses generalizability. In this article, we introduce a framework that harnesses LLMs to extract background knowledge of an environment, which contains general understandings of the entire environment, making various downstream RL tasks benefit from one-time knowledge representation. We ground LLMs by feeding a few precollected experiences and requesting them to delineate background knowledge of the environment. Afterward, we represent the output knowledge as potential functions for potential-based reward shaping, which has a good property for maintaining policy optimality from task rewards. We instantiate three variants to prompt LLMs for background knowledge, including writing code, annotating pReferences, and assigning goals. Our experiments show that these methods achieve significant sample efficiency improvements in a spectrum of downstream tasks from Minigrid and Crafter domains.},
  archive      = {J_TNNLS},
  author       = {Fuxiang Zhang and Junyou Li and Yi-Chen Li and Zongzhang Zhang and Yang Yu and Deheng Ye},
  doi          = {10.1109/TNNLS.2025.3590731},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Improving sample efficiency of reinforcement learning with background knowledge from large language models},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DLCNN: A deep logic convolutional network for interpretable fault diagnosis of hoist mechanism on ship-to-shore cranes. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3594346'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fault diagnosis of hoist mechanisms in ship-to-shore cranes (STSCs) is paramount for maintaining shipping schedules and ensuring personnel safety at ports. Although deep networks have achieved some success in diagnosing faults in hoist mechanisms, their opaque nature often precludes them from providing trustworthy explanations for their decisions. To address this problem, this article introduces a deep logic convolutional neural network (DLCNN), which incorporates two symbolic languages (confidence and classification rules) to visualize how convolutional neural networks (CNNs) work. Confidence rules are extracted from logic convolutions (LCs). In the LC, confidence rules are designed from three perspectives—information loss, the tradeoff between soundness and interpretability, and quantitative reasoning—to provide a comprehensive understanding of the feature learning and reasoning of stacked convolutions. Besides, classification rules are extracted from CNN’s full-connected layers to elucidate implicit relationships between fault features and labels. Our experimental investigations on an STSC testbed demonstrate that DLCNNs have powerful performance in fault recognition, interpretability, and potential engineering value.},
  archive      = {J_TNNLS},
  author       = {Xiaoqiang Liao and Dong Wang and Xinguo Ming and Min Xia},
  doi          = {10.1109/TNNLS.2025.3594346},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {DLCNN: A deep logic convolutional network for interpretable fault diagnosis of hoist mechanism on ship-to-shore cranes},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Constraint-driven causal representation learning for vigilance robust estimation in Brain–Computer interface. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3594434'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vigilance estimation is a critical task within the field of brain–computer interfaces, extensively applied in monitoring and optimizing user states during human–machine interaction using electroencephalography (EEG). However, most existing vigilance prediction frameworks are prone to spurious correlations stemming from inherent biases in collected data. These biases involve relevant but vigilance-independent information, which may lack robustness when applied to different data distributions, i.e., out-of-distribution (OOD) scenarios. The core idea of this study is to learn constraints that capture causal information from the input based on the assumed underlying data generating process. Leveraging the disentanglement and invariance principles behind the assumptions, we propose a constraint-driven causal representation learning (CCRL) to identify and separate spurious latent variables from biased training data for generalized vigilance estimation. The CCRL training process consists of two phases: self-supervised pretraining and constraint-driven causal information disentanglement. In the first phase, based on the masked autoencoder (MAE) architecture, unlabeled training data are used for reconstructing pretext tasks to capture the comprehensive and intrinsic contextual information from EEG data, which provides a powerful input for downstream disentanglement learning. In the second phase, we propose a novel disentanglement strategy to learn spurious-free latent representations causally related to the vigilance state driven by adversarial and invariance constraints. Comprehensive validation experiments conducted on two well-known public datasets demonstrate the effectiveness and superiority of the proposed framework. In general, this work has promising implications for addressing OOD challenges in vigilance estimation.},
  archive      = {J_TNNLS},
  author       = {Xuan Zhang and Wang Zheng and Zhigang Li and Yi Yang and Weijia Liu and Hongxin Cai and Junru Zhu and Jingyu Liu and Bin Hu and Qunxi Dong},
  doi          = {10.1109/TNNLS.2025.3594434},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Constraint-driven causal representation learning for vigilance robust estimation in Brain–Computer interface},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Strategic evolutionary reinforcement learning with operator selection and experience filter. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3596553'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The shared replay buffer is the core of synergy in evolutionary reinforcement learning (ERL). Existing methods overlooked the objective conflict between population evolution in evolutionary algorithm and ERL, leading to poor quality of the replay buffer. In this article, we propose a strategic ERL algorithm with operator selection and experience filter (SERL-OS-EF) to address the objective conflict issue and improve the synergy from three aspects: 1) an operator selection strategy is proposed to enhance the performance of all individuals, thereby fundamentally improving the quality of experiences generated by the population; 2) an experience filter is introduced to filter the experiences obtained from the population, maintaining the long-term high quality of the buffer; and 3) a dynamic mixed sampling strategy is introduced to improve the efficiency of RL agent learning from the buffer. Experiments in four MuJoCo locomotion environments and three Ant-Maze environments with deceptive rewards demonstrate the superiority of the proposed method. In addition, the practical significance of the proposed method is verified on a low-carbon multienergy microgrid (MEMG) energy management task.},
  archive      = {J_TNNLS},
  author       = {Kaitong Zheng and Ya-Hui Jia and Kejiang Ye and Wei-Neng Chen},
  doi          = {10.1109/TNNLS.2025.3596553},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Strategic evolutionary reinforcement learning with operator selection and experience filter},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cluster-aware few-shot molecular property prediction with factor disentanglement. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3590240'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Molecular property prediction plays a crucial role in drug discovery, but is always challenged by the limited number of effective labels. Compared with existing methods, we argue that the auxiliary properties of the molecule and the heterogeneous structure of different property prediction tasks have always been ignored. In this article, we propose a novel framework termed Meta-DREAM for few-shot molecular property prediction, which tailors to learning the transferable knowledge within different clusters of tasks. Specifically, we first construct a heterogeneous molecule relation graph (HMRG) with molecule–property and molecule–molecule relations to utilize many-to-many correlations between properties and molecules. The meta-learning episode can, then, be reformulated as a subgraph of HMRG. Next, we propose a disentangled graph encoder to explicitly discriminate the underlying factors of the task. In addition, we introduce a soft clustering module to group each factorized task representation into appropriate clusters and preserve knowledge generalization within a cluster and customization among clusters. In this way, each disentangled factor serves as a cluster-aware parameter gate for the task-specific meta-learner. Extensive experiments on five commonly used molecular datasets show that Meta-DREAM consistently outperforms existing state-of-the-art methods and verifies the effectiveness of each module.},
  archive      = {J_TNNLS},
  author       = {Haodong Zhang and Tao Ren and Yifan Wang and Fanchun Meng and Wei Ju and Ying Tian},
  doi          = {10.1109/TNNLS.2025.3590240},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Cluster-aware few-shot molecular property prediction with factor disentanglement},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gen-GraphEx: Generative in-distribution graph explanations for time-efficient model-level interpretability of GNNs. <em>TNNLS</em>, 1-16. (<a href='https://doi.org/10.1109/TNNLS.2025.3589330'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have become the prevailing methodology for addressing graph data-related tasks, permeating critical domains like recommendation systems and drug development. The necessity for trustworthiness and interpretability of GNNs has risen to the forefront, especially given their direct impact on end users’ lives. To address this need, we present Gen-GraphEx, a model-agnostic, model-level explanation method that prioritizes user centricness by eliminating the need for having access to the hidden layers of the GNN model it seeks to explain. Given a particular class label, Gen-GraphEx learns a graph generative model (GGM) that produces explanation graphs that not only contain discriminative patterns that the GNN has learned for that class but also lie in distribution with real graphs that belong to that class according to the GNN. Unlike existing state-of-the-art models, Gen-GraphEx also has the unique ability to interpolate the GGMs of two target classes to generate instances that lie near the decision boundary of the two classes giving a deeper insight into the model’s decision-making. Its advantages over existing methods in the literature also include nonreliance on another subsequent deep learning module for explanation generation, ability to generate graphs with various node and edge features, and being more computationally efficient. Extensive validation and thorough comparative analysis of the proposed approach is carried out across an array of real and synthetic datasets that consistently demonstrate its exceptional performance and competitiveness ranking alongside state-of-the-art model-level explainers. Our code is available at https://github.com/amisayan/Gen-GraphEx},
  archive      = {J_TNNLS},
  author       = {Sayan Saha and Monidipa Das and Sanghamitra Bandyopadhyay},
  doi          = {10.1109/TNNLS.2025.3589330},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Gen-GraphEx: Generative in-distribution graph explanations for time-efficient model-level interpretability of GNNs},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distilling reasoning ability from large language models with adaptive thinking. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3591266'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chain-of-thought distillation (CoT-distillation) aims to endow small language models (SLMs) with reasoning ability to improve their performance toward specific tasks by allowing them to imitate the reasoning procedure of large language models (LLMs) beyond simply predicting the answers. Most existing CoT-distillation methods adopt a pre-thinking mechanism, allowing the SLM to generate a rationale before answering. In this way, pre-thinking enables SLM to analyze questions but makes answer correctness sensitive to minor errors in rationale. Therefore, we propose a robust post-thinking mechanism to generate answers before the rationale. Thanks to this answer-first setting: 1) the answer can escape from the rationale-sensitive problem; 2) the rationale serves as an error amplifier, making SLM focus on learning hard samples; and 3) the inferring efficiency can also benefit. Although post-thinking brings many advantages, it may lose the ability to analyze complex questions compared to pre-thinking. Therefore, a plug-and-play adaptive-thinking mechanism is proposed to integrate the merits of pre-thinking and post-thinking, in which a perception module based on soft prompt tuning is introduced to prompt SLM to answer or think first according to the complexity of questions. Extensive experiments are conducted across 12 datasets and 2 language models to demonstrate the effectiveness of the proposed mechanism.},
  archive      = {J_TNNLS},
  author       = {Xiaoshu Chen and Sihang Zhou and Ke Liang and Xinwang Liu},
  doi          = {10.1109/TNNLS.2025.3591266},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Distilling reasoning ability from large language models with adaptive thinking},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Event-triggered mixed nonzero-sum game optimal control for modular robotic manipulator performing coordinated operation tasks. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3595563'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Taking advantage of high-performance intelligent robots to solve the coordination control problem such as assembly, handling, and installation, transportation is gradually becoming a kind of frontier subject with great scientific research value in the field of robotics. However, due to possible conflicts and inconsistencies between the manipulator and the operating object, it is challenging to design the optimal coordination control scheme between human and robot. This article presents an event-triggered mixed nonzero-sum game optimal control method, which considers both nonzero-sum game and cooperative game cases, for modular robotic manipulator (MRM) systems performing coordinated operation tasks. First, the joint torque feedback technique and joint task assignment method are employed to establish the dynamic model of MRM subsystem, and then, the global state-space description is deduced. For the unknown information containing interconnected dynamic coupling (IDC) terms and friction modeling errors, an adaptive neural network (NN) identifier is established by utilizing the measured input–output data of each joint module. The adaptive updating law guarantees that the NN weight error finally converged to a minimum neighborhood of zero. To ensure the optimality of system overall performance, the corresponding value functions reflecting the interconnectedness among each joint subsystem and manipulated object are constructed. Based on the idea of differential game, the coordination control problem of MRM system is transformed into a mixed nonzero-sum game problem among each joint module and the operated object. Next, by constructing a single critic NN with learning structure, the optimal value function is approximated to solve the event-based Hamiltonian equations, and then, the optimal control strategy of each player is obtained. Finally, the Lyapunov theory is used to analyze system stability, and the effectiveness of the presented method is reinforced by experimental results.},
  archive      = {J_TNNLS},
  author       = {Tianjiao An and Xiaogang Dong and Bo Dong and Hucheng Jiang and Lei Liu and Bing Ma},
  doi          = {10.1109/TNNLS.2025.3595563},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Event-triggered mixed nonzero-sum game optimal control for modular robotic manipulator performing coordinated operation tasks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedLSC: Improving communication efficiency and robustness in federated learning with stragglers and adversaries. <em>TNNLS</em>, 1-16. (<a href='https://doi.org/10.1109/TNNLS.2025.3590015'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite significant progress in federated learning (FL), persistent challenges, such as stragglers, adversaries, and communication costs remain. To address these issues, we propose FedLSC, a novel FL framework that leverages layer-selected correlation (LSC) to enhance both robustness and efficiency. In contrast to the existing methods, FedLSC does not rely on public data during model training, making it more practical and resilient in real-world scenarios. FedLSC introduces three key innovations: 1) preprocessing of layer selection (LS), which identifies significant layers to reduce communication costs and performance degradation; 2) local updates using LS-based scaled sign-stochastic gradient descent (SSS), introducing a layer-specific scaling mechanism to mitigate performance loss from quantization and significantly reduce communication costs; and 3) model aggregation via LSC-based schemes, which enhances robustness by processing only the significant layers and mitigating the impact of stragglers and adversaries. Furthermore, integrating the SSS scheme into FedLSC reduces communication costs to as little as 0.01% of those in state-of-the-art (SOTA) method while maintaining performance. Evaluations conducted across various FL scenarios show that FedLSC effectively supports robust performance and efficiency, even in bandwidth-constrained environments, thereby confirming its practicality in modern FL applications.},
  archive      = {J_TNNLS},
  author       = {Hyeong-Gun Joo and Songnam Hong and Dong-Joon Shin},
  doi          = {10.1109/TNNLS.2025.3590015},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {FedLSC: Improving communication efficiency and robustness in federated learning with stragglers and adversaries},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Wormhole dynamics in deep neural networks. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3591614'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work investigates the generalization behavior of deep neural networks (DNNs), focusing on the phenomenon of “fooling examples,” where DNNs confidently classify inputs that appear random or unstructured to humans. To explore this phenomenon, we introduce an analytical framework based on maximum likelihood estimation (MLE), without adhering to conventional numerical approaches that rely on gradient-based optimization and explicit labels. Our analysis reveals that DNNs operating in an overparameterized regime exhibit a collapse in the output feature space. While this collapse improves network generalization, adding more layers eventually leads to a state of degeneracy, where the model learns trivial solutions by mapping distinct inputs to the same output, resulting in zero loss. Further investigation demonstrates that this degeneracy can be bypassed using our newly derived “wormhole” solution. The wormhole solution, when applied to arbitrary fooling examples, reconciles meaningful labels with random ones and provides a novel perspective on shortcut learning. These findings offer deeper insights into DNN generalization and highlight directions for future research on learning dynamics in unsupervised settings to bridge the gap between theory and practice.},
  archive      = {J_TNNLS},
  author       = {Yen-Lung Lai and Zhe Jin},
  doi          = {10.1109/TNNLS.2025.3591614},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Wormhole dynamics in deep neural networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Progressive structure preservation and detail refinement for remote sensing single-image super-resolution. <em>TNNLS</em>, 1-17. (<a href='https://doi.org/10.1109/TNNLS.2025.3589209'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in deep-learning-based remote sensing image super-resolution (RSISR) have garnered significant attention. Conventional models typically perform upsampling at the end of the architecture, which reduces computational effort but leads to information loss and limits image quality. Moreover, the structural complexity and texture diversity of remote sensing images pose challenges in detail preservation. While transformer-based approaches improve global feature capture, they often introduce redundancy and overlook local details. To address these issues, we propose a novel progressive structure preservation and detail refinement super-resolution (PSPDR-SR) model, designed to enhance both structural integrity and fine details in RSISR. The model comprises two primary subnetworks: the structure-aware super-resolution (SaSR) subnetwork and the detail recovery and refinement (DR&R) subnetwork. To efficiently leverage multilayer and multiscale feature representations, we introduce coarse-to-fine dynamic information transmission (C2FDIT) and fine-to-coarse dynamic information transmission (F2CDIT) modules, which facilitate the extraction of richer details from low-resolution (LR) remote sensing images. These modules integrate transformers and convolutional long short-term memory (ConvLSTM) blocks to form dynamic information transmission modules (DITMs), enabling effective bidirectional feature transmission both horizontally and vertically. This method ensures comprehensive feature fusion, mitigates redundant information, and preserves essential extracted features within the deep network. Experimental results demonstrate that PSPDR-SR outperforms the state-of-the-art approaches on two benchmark datasets in both quantitative and qualitative evaluations, excelling in structure preservation and detail enhancement across various metrics, including SSIM, MS_SSIM, learned perceptual image patch similarity (LPIPS), deep image structure and texture similarity (DISTS), spatial correlation coefficient (SCC), and spectral angle mapper (SAM).},
  archive      = {J_TNNLS},
  author       = {Wei-Yen Hsu and Shih-Hao Huang and Jing-Wen Lin},
  doi          = {10.1109/TNNLS.2025.3589209},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-17},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Progressive structure preservation and detail refinement for remote sensing single-image super-resolution},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey of attacks on large Vision–Language models: Resources, advances, and future trends. <em>TNNLS</em>, 1-21. (<a href='https://doi.org/10.1109/TNNLS.2025.3592935'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the significant development of large models in recent years, large vision–language models (LVLMs) have demonstrated remarkable capabilities across a wide range of multimodal understanding and reasoning tasks. Compared with traditional large language models (LLMs), LVLMs present great potential and challenges due to their closer proximity to the multiresource real-world applications and the complexity of multimodal processing. However, the vulnerability of LVLMs is relatively underexplored, posing potential security risks in the daily use of LVLM applications. In this article, we provide a comprehensive review of the various forms of existing LVLM attacks. Specifically, we first introduce the background of attacks targeting LVLMs, including the attack preliminary, attack challenges, and attack resources. Then, we systematically review the development of LVLM attack methods, such as adversarial attacks that manipulate model outputs, jailbreak attacks that exploit model vulnerabilities for unauthorized actions, prompt injection attacks that engineer the prompt type and pattern, and data poisoning that affects model training. Finally, we discuss promising future research directions in LVLM attacks. We believe that our survey provides insights into the current landscape of LVLM vulnerabilities, inspiring more researchers to explore and mitigate potential safety issues in LVLM developments.},
  archive      = {J_TNNLS},
  author       = {Daizong Liu and Mingyu Yang and Xiaoye Qu and Pan Zhou and Yu Cheng and Wei Hu},
  doi          = {10.1109/TNNLS.2025.3592935},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-21},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A survey of attacks on large Vision–Language models: Resources, advances, and future trends},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning a better SPD network for signal classification: A riemannian batch normalization method. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3589362'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Symmetric positive definite (SPD) matrices have been widely used as Riemannian feature descriptors in various scientific fields, due to their capacity to encode effective manifold-valued representations. Inspired by the architectural principles of Euclidean deep learning, the emerging SPD neural networks have achieved more robust signal classification. Among these advancements, Riemannian batch normalization (RBN) based on the affine-invariant Riemannian metric (AIRM) has emerged as a key technique for enhancing the learning capability of SPD-based networks. Nevertheless, the reliance of singular value decomposition (SVD) makes this metric relatively unstable for the computation of SPD matrices, especially for the ill-conditioned case. To address this limitation, we propose a novel RBN algorithm based on the recently introduced log-Cholesky metric (LCM), which leverages Cholesky decomposition. Unlike AIRM, the LCM offers enhanced numerical stability and allows for more efficient computation. Specifically, the LCM-based Riemannian operators such as Fr $\acute {\mathrm {e}}$ chet mean and parallel transport (PT) are much simpler than those of AIRM, and both have closed forms. Besides, since LCM is the pullback metric from the Cholesky manifold via Cholesky decomposition, the LCM-based RBN on the SPD manifold can be computed in the Cholesky manifold, further boosting the efficiency. Extensive experiments conducted on four benchmarking datasets certify the effectiveness of our proposed algorithm. The source code is now available at: https://github.com/jjscc/CBN.git.},
  archive      = {J_TNNLS},
  author       = {Rui Wang and Shaocheng Jin and Zhenyu Cai and Ziheng Chen and Xiao-Jun Wu and Josef Kittler},
  doi          = {10.1109/TNNLS.2025.3589362},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Learning a better SPD network for signal classification: A riemannian batch normalization method},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bidirectional multiscale efficient dilated convolutional recurrent neural network improved by swarm intelligence optimization. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3596244'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, bidirectional convolutional recurrent neural networks (RNNs) have made significant breakthroughs in addressing a wide range of challenging problems related to time series and prediction applications. However, the performance of the models is highly dependent on the hyperparameters chosen. Hence, we propose an automatic method for hyperparameter optimization and apply a bidirectional convolutional RNN based on the improved swarm intelligence optimization (sparrow search) to solve regression prediction problems. Specifically, a parallel multiscale dilated convolution (PMDC) module was designed to capture both local and global spatial correlations. This method utilizes convolution with different dilation rates to expand the receptive field without increasing the complexity of the model. Meanwhile, it integrates parallel multiscale structures to extract features at different scales and enhance the model’s understanding of the input data. Then, the bidirectional gated recurrent units (BGRUs) learn temporal information from the convolutional features. To address the limitations of empirical hyperparameter selection, such as slow training and low efficiency, a novel PMDC-BGRU model integrated with a pretrained sparrow search algorithm (SSA) was proposed for hyperparameter optimization. Finally, experiments on multiple datasets verified the superiority of the algorithm and explained the flexibility of intelligent optimization algorithms in solving model parameter optimization.},
  archive      = {J_TNNLS},
  author       = {Qinwei Fan and Shuai Zhao and Jacek M. Zurada and Tingwen Huang and Xiaolong Qin and Rui Zhang},
  doi          = {10.1109/TNNLS.2025.3596244},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Bidirectional multiscale efficient dilated convolutional recurrent neural network improved by swarm intelligence optimization},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Information-state-based reinforcement learning for the control of partially observed nonlinear systems. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3593259'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article develops a model-based reinforcement learning (RL) approach to the closed-loop control of nonlinear dynamical systems with a partial nonlinear observation model. We propose an “information-state”-based approach to rigorously transform the partially observed problem into a fully observed problem where the information state consists of the past several observations and control inputs. We further show the equivalence of the transformed and the initial partially observed optimal control problems and provide the conditions to solve for the deterministic optimal solution. We develop a data-based generalization of the iterative linear quadratic regulator (ILQR) for the RL of partially observed systems using a local linear time-varying model of the information-state dynamics approximated by an autoregressive-moving-average (ARMA) model that is generated using only the input–output data. This approach allows us to design a local perturbation feedback control law that provides an optimum solution to the partially observed feedback design problem locally. The efficacy of the developed method is shown by controlling complex high-dimensional nonlinear dynamical systems in the presence of model and sensing uncertainty.},
  archive      = {J_TNNLS},
  author       = {Raman Goyal and Mohamed Naveed Gul Mohamed and Ran Wang and Aayushman Sharma and Suman Chakravorty},
  doi          = {10.1109/TNNLS.2025.3593259},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Information-state-based reinforcement learning for the control of partially observed nonlinear systems},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attribute prompt alignment network for zero-shot learning. <em>TNNLS</em>, 1-7. (<a href='https://doi.org/10.1109/TNNLS.2025.3598191'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the vanilla zero-shot learning (ZSL) paradigm, category attributes is the key for knowledge generalizable transfer from seen to unseen classes. By contrast, the current contrastive language-image pretraining (CLIP) model relies on the category names to achieve a more general ZSL-like prediction. When vanilla ZSL meets general CLIP, however, most existing methods on both sides struggle to benefit from each other. In this brief, we resort to attribute prompt tuning (APT) for improving the knowledge transferability from the pretrained CLIP model to the downstream ZSL framework for pursuing desirable feature representations. Our approach, termed as attribute prompt alignment network (APAN), leverages APT for cross-network feature alignment (CFA). In this way, we can investigate the effects of CLIP to vanilla ZSL task in the era of large model by the two branch APAN architecture. Specifically, APT takes as an input the templates of class attribute descriptions to produce attribute prompts, which are further used to both guide the localizations of visual regions across two frozen feature extraction networks, through a visual-semantic interaction attention. This enables APAN to progressively refine and align these cross-network features, thus resulting in generalizable feature representations that can capture fine-grained attribute information. For CFA, we simply introduce prediction alignment loss that constrains the predictions from these two cross-network visual features. Experimental results on three benchmark datasets well demonstrate that APAN outperforms the state-of-the-art methods by absorbing generalizable knowledge from CLIP models.},
  archive      = {J_TNNLS},
  author       = {Guo-Sen Xie and Junyi Li and Ting Guo and Xiangbo Shu and Fang Zhao and Zheng Zhang and Ling Shao},
  doi          = {10.1109/TNNLS.2025.3598191},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-7},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Attribute prompt alignment network for zero-shot learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge-GPT guided generalizable reinforcement learning for intelligent emergency generator tripping in power system. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3596964'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emergency control is essential for ensuring transient stability in power systems after faults. This study addresses the limitations in existing methods by proposing a knowledge-generative pretrained transformer (GPT)-guided generalizable reinforcement learning (RL) approach for intelligent emergency generator tripping. This approach incorporates general electrical principles and knowledge-GPT to assist deep reinforcement learning (DRL). The general electrical principles involve identifying severely disturbed generators and selecting appropriate control actions through dynamic probability. The knowledge-GPT model extracts insights from an expert strategy knowledge base, reshaping the DRL reward structure by comparing the DRL strategy with the knowledge-GPT outputs. This paradigm is designed to leverage electrical laws and domain expertise to guide the DRL training process, thereby enhancing both training efficiency and electrical consistency. To enhance generalization capability under topological changes, message passing neural networks (NNs) are integrated into the DRL architecture, effectively simulating power flow dynamics in transmission lines. The proposed method is validated through simulations on the IEEE 39-bus system and the Northeast power grid of China, demonstrating superior control effectiveness and adaptability compared to existing approaches, offering a more robust solution for emergency control in complex power systems.},
  archive      = {J_TNNLS},
  author       = {Bing Wang and Tianjing Wang and Yong Tang and Yanhao Huang},
  doi          = {10.1109/TNNLS.2025.3596964},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Knowledge-GPT guided generalizable reinforcement learning for intelligent emergency generator tripping in power system},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). REaMA: Building biomedical relation extraction specialized large language models through instruction tuning. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3596257'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming to identify entity pairs with biomedical semantic relations and assign specific relation types, biomedical relation extraction (BioRE) plays a critical role in biomedical text mining and information extraction (IE). Recent studies indicate that general large language models (LLMs) have made some breakthroughs in general relation extraction (RE) tasks. However, even the advanced open-source LLMs struggle with BioRE tasks. For example, WizardLM-70B and LLaMA-2-70B achieve F-scores of 14.05 and 12.21 on the BioRED dataset, respectively, significantly lagging behind the state-of-the-art (SOTA) method which scores 65.17. To address this gap, a multitask instruction-tuning framework is proposed, which can transform general LLMs into BioRE-specialized models with our meticulously curated instruction dataset, REInstruct, comprising 150000 diverse and quality instruction-response pairs. Consequently, we introduce REaMA, a series of open-source LLMs with sizes of 7B and 13B specifically tailored for BioRE tasks. Experimental results on seven representative BioRE datasets show that both REaMA-2-7B and REaMA-2-13B acquire promising performance on all datasets. Remarkably, the larger REaMA-2-13B outperforms the current SOTA method on five out of seven datasets. The result exhibits the effectiveness of instruction-tuning on REInstruct in eliciting strong RE capabilities in LLMs. Furthermore, we show that incorporating chain of thought (CoT) into REInstruct can further enhance the generalization ability of REaMA. The project is available at https://github.com/stzpp/REaMA},
  archive      = {J_TNNLS},
  author       = {Yidan Zhang and Junlin Yu and Guobo Li and Zhenan He and Gary G. Yen},
  doi          = {10.1109/TNNLS.2025.3596257},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {REaMA: Building biomedical relation extraction specialized large language models through instruction tuning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward the extension and enhanced representation for ambiguous query with search heterogeneous graph learning. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3599630'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In an online search, users often input an ambiguous short query to search engines, which leads to search engines being unable to accurately understand the true users’ query intent. Thus, enhancing the users’ query intent is necessary. Traditional methods of guessing and inferring user intentions are based on either personal past search data, or the group’s search history data. The former faces the cold start problem for new users due to the lack of search history data, while the latter cannot accurately get the intent of new search requests due to different users having different intentions even for the same search query. To solve the above issues and to enhance the representation of search requests by adding some query keywords, we construct a user-query-document search heterogeneous graph with users’ search history data of their friend networks, which can express the behavioral features and interrelationships of searches. To facilitate the enhanced representation of a query intent, we present TAHAN, a type-aware heterogeneous graph attention network (GAT) model. Extensive experiments on real-world datasets show that our method not only outperforms the state-of-the-art models, but also achieves superior performance in addressing the data sparsity and cold-start problems.},
  archive      = {J_TNNLS},
  author       = {Youli Fang and Guosun Zeng},
  doi          = {10.1109/TNNLS.2025.3599630},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Toward the extension and enhanced representation for ambiguous query with search heterogeneous graph learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Soft sensing for time series with irregular sampling internals based on a denoising interval attention LSTM network. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3598583'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prediction of key quality variables plays an important role in industrial status identification and monitoring. Due to process disturbance and hard device limitation, data collection in modern industries often exhibits high noise and irregular data sampling. To solve the above problems, this article proposes a stacked supervised and reconstructed input denoising autoencoder integrated with internal attention long short-term memory (SSRDAE-IALSTM) network for soft sensing modeling. First, a stacked supervised and reconstructed input denoising autoencoder (SSRDAE) is designed. Compared with the original DAE, each supervised and reconstructed input DAE (SRDAE) can simultaneously reconstruct the process data and quality data at the output layer, aiming to reduce information loss and extract quality-related features. Second, the denoised features are fed into the interval attention LSTM (IALSTM) to adjust the influence of different historical samples on the current sample in irregular sampling data to capture long-term temporal features. Finally, performance validations are carried out on an industrial debutanizer column and a penicillin fermentation process. The experimental results show that the proposed model can enhance the learning ability of process features and obtain better prediction performance than other comparison methods.},
  archive      = {J_TNNLS},
  author       = {Yuchen He and Xueqin Yang and Lijuan Qian and Le Yao and Lingjian Ye and Ping Wu and Gangyue Ye and Weirong Ye and Yafang Shen},
  doi          = {10.1109/TNNLS.2025.3598583},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Soft sensing for time series with irregular sampling internals based on a denoising interval attention LSTM network},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fast wang kWTA with application in sealed-bid uniform price auction. <em>TNNLS</em>, 1-6. (<a href='https://doi.org/10.1109/TNNLS.2025.3597722'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this brief, two fast discrete-time Wang kWTA (Fast Wang kWTA) algorithms are presented with an application in sealed-bid uniform price auctions. These algorithms can either be implemented in centralized or distributed manner. The structure of the Fast Wang kWTA is essentially the same as the original Wang k-winner-take-all (kWTA), except that our state update method is based on bisection method instead of gradient descent. By that, the number of iterations for getting correct output is largely reduced. Besides, the number is just a factor depended on the guess of the maximum input value. It is independent of the number of inputs, the number of winners, and the learning step size. The number of iterations is far smaller than the number required in the original Wang kWTA. In sequel, this Fast Wang kWTA is particularly suitable to be applied in solving the winner (resp. price) determination in real time and in distributed manner for a sealed-bid auction. In addition, the Fast Wang kWTA can ensure bidding price protection even if the communicated data are not encrypted and leaked.},
  archive      = {J_TNNLS},
  author       = {John Sum and Chi-Sing Leung and Janet Chun-Chi Chang},
  doi          = {10.1109/TNNLS.2025.3597722},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-6},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A fast wang kWTA with application in sealed-bid uniform price auction},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hyperbolic hierarchical representation learning for generalized category discovery. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3597074'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the problem of generalized category discovery (GCD), an advanced and challenging semi-supervised learning scenario that deals with unlabeled data from both known and novel categories. Although recent research has effectively engaged with this issue, these studies typically map features into Euclidean space, which fails to maintain the latent semantic hierarchy of the training samples effectively. This limitation restricts the exploration of more detailed and rich information and degrades the performance in discovering new categories. The emerging field of hyperbolic representation learning suggests that hyperbolic geometry could be advantageous for extracting semantic information to tackle this problem. Motivated by this, we proposed hyperbolic hierarchical representation learning for GCD (HypGCD). Specifically, HypGCD enhances representations in hyperbolic space, building upon the Euclidean space representation from two perspectives: instance-class level and instance-instance level. At the instance-class level, HypGCD endeavors to construct well-defined clusters, with each sample forming a robust hierarchical cluster structure. Concurrently, at the instance-instance level, HypGCD anticipates that a subset of samples will display a tree-like structure in local space, which aligns more closely with real-world scenarios. Finally, HypGCD optimizes the Euclidean and hyperbolic space collectively to obtain refined features. Additionally, we show that HypGCD is exceptionally effective, achieving state-of-the-art (SOTA) results on several datasets. The code is available at https://github.com/DuannYu/HypGCD },
  archive      = {J_TNNLS},
  author       = {Yu Duan and Feiping Nie and Huimin Chen and Zhanxuan Hu and Rong Wang and Xuelong Li},
  doi          = {10.1109/TNNLS.2025.3597074},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Hyperbolic hierarchical representation learning for generalized category discovery},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive learning rate methods for complex-valued neural networks. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3596513'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial neural networks (ANNs) have become a popular tool in digital signal processing (DSP). Among the widespread ANN architectures, complex-valued neural networks (CVNNs) have been extensively studied in image processing and telecommunications. Unlike their real-valued counterparts, CVNNs can handle signals directly in the complex domain. Due to this capability, CVNNs usually exhibit higher accuracy and improved convergence compared to real-valued neural networks (RVNNs). Despite their improved performance in several applications, CVNNs still lag behind RVNNs in terms of learning techniques and heuristics. In this context, we propose adaptive learning rate approaches for CVNNs, extending the well-known adaptive gradient (AdaGrad), root-mean-square propagation (RMSProp), AdaMax, AMSGrad, softplus AMSGrad (SAMSGrad), Nesterov-accelerated adaptive moment estimation (Nadam), and DiffGrad to the complex domain. Computational complexities of the proposed optimizers are analyzed for CVNN architectures. Results are compared in terms of mean-squared-error convergence.},
  archive      = {J_TNNLS},
  author       = {Kayol S. Mayer and Jonathan A. Soares and Ariadne A. Cruz and Dalton S. Arantes},
  doi          = {10.1109/TNNLS.2025.3596513},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Adaptive learning rate methods for complex-valued neural networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Geometric deep learning for the rubik’s cube group. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3599009'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Rubik’s cube, a widely recognized combinatorial puzzle with an astronomically vast state space, has been the subject of various research experiments with neural networks used as heuristic estimators to navigate the state-space exploration. However, prior efforts have overlooked the intriguing symmetries inherent to this domain. Drawing on geometric deep learning principles, this article introduces a novel neural architecture that explicitly leverages these symmetries, grounded in a rigorous group-theoretical analysis. The design of the proposed symmetry-invariant model is then validated empirically through an innovative universal procedure for detecting model symmetry invariance. Finally, experimental results demonstrate that the symmetry-aware neural architecture exhibits enhanced generalization and problem-solving efficacy compared with the state of the art.},
  archive      = {J_TNNLS},
  author       = {Martin Krutský and Gustav Šír},
  doi          = {10.1109/TNNLS.2025.3599009},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Geometric deep learning for the rubik’s cube group},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Joint trajectory replanning for mars ascent vehicle under propulsion system faults: A suboptimal learning-based warm-start approach. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3598120'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a suboptimal joint trajectory replanning (SJTR) method for Mars ascent vehicle (MAV) launch missions under propulsion system faults. Conventional step-by-step trajectory replanning may fail to make timely decisions, risking mission failure. The SJTR method formulates a joint convex optimization problem of target orbit and flight trajectory after a fault. By applying penalty coefficients for terminal constraints, it adheres to the orbit redecision principles, enabling a concise and rapid solution. To further enhance the convergence and the accuracy of orbit-type determination, a learning-based warm-start scheme is proposed. Offline, a deep neural network (DNN) is trained with data generated by various trajectory replanning methods following the redecision principles. Online, the DNN provides initial guesses for the time optimization variables based on the fault scenario. Numerical simulations on mass flow rate and specific impulse drops validate the reliability of the proposed method, demonstrating at least 49.5% higher computational efficiency compared with the upgrading and downgrading replanning methods.},
  archive      = {J_TNNLS},
  author       = {Kun Li and Guangtao Ran and Yanning Guo and Ju H. Park and Yao Zhang},
  doi          = {10.1109/TNNLS.2025.3598120},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Joint trajectory replanning for mars ascent vehicle under propulsion system faults: A suboptimal learning-based warm-start approach},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IRPruneDeXt: Efficient infrared small target detection via musical wavelet-regularized channel pruning. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3594958'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infrared small target detection (IRSTD) refers to detecting faint targets in infrared (IR) images, which has achieved notable progress with the advent of deep learning. However, the drive for improved detection accuracy has led to larger, intricate models with redundant parameters, causing storage and computation inefficiencies. In this pioneering study, we introduce the concept of utilizing network pruning to enhance the efficiency of IRSTD. Due to the challenge posed by low signal-to-noise ratios (SNRs) and the absence of detailed semantic information in IR images, directly applying existing pruning techniques yields suboptimal performance. To address this, we propose a novel wavelet structure-regularized multidimensional musical scale soft channel pruning (SCP) method, giving rise to the efficient IRPruneDeXt model. Our approach involves representing the weight matrix in the wavelet domain and formulating a wavelet channel pruning (WCP) strategy. We incorporate wavelet regularization to induce structural sparsity without incurring extra memory usage. Additionally, we design a multidimensional musical scale soft channel reconstruction (MMSCR) method that adapts the strategy across temporal and spatial dimensions to preserve key target information and prevent premature pruning. By leveraging interactions between criteria, it balances pruning and reconstruction through a musical scale feedback effect, achieving an optimal sparse structure while maintaining overall sparsity. Through extensive experiments on many widely used benchmarks, our IRPruneDeXt method surpasses established techniques in both model complexity and accuracy. Specifically, when employing U-net as the baseline network, IRPruneDeXt achieves a 65.68% reduction in parameters and a 51.77% decrease in floating-point operations (FLOPs) while improving intersection over union (IoU) from 73.31% to 76.17% and normalized IoU (nIoU) from 70.92% to 75.08%. The code is available at github.com/hd0013/IRPruneDet},
  archive      = {J_TNNLS},
  author       = {Mingjin Zhang and Jin Feng and Handi Yang and Jie Guo and Yunsong Li and Xinbo Gao},
  doi          = {10.1109/TNNLS.2025.3594958},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {IRPruneDeXt: Efficient infrared small target detection via musical wavelet-regularized channel pruning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust multivariate time series forecasting against intraseries and interseries transitional shift. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3593156'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The nonstationary nature of real-world multivariate time series (MTS) data presents forecasting models with a formidable challenge of the time-variant distribution of time series, referred to as distribution shift. Existing studies on the distribution shift mostly adhere to adaptive normalization techniques for alleviating temporal mean and covariance shifts or time-variant modeling for capturing temporal shifts. Despite improving model generalization, these normalization-based methods often assume a time-invariant transition between outputs and inputs but disregard specific intraseries/interseries correlations, while time-variant models overlook the intrinsic causes of the distribution shift. This limits the model’s expressiveness and interpretability in tackling the distribution shift for MTS forecasting. To mitigate such a dilemma, we present a unified Probabilistic Graphical Model to Jointly capture intraseries/interseries correlations and model the time-variant transitional distribution and instantiate a neural framework called JointPGM for nonstationary MTS forecasting. Specifically, JointPGM first employs multiple Fourier basis functions to learn dynamic time factors and designs two distinct learners: intraseries and interseries learners. The intraseries learner effectively captures temporal dynamics by utilizing temporal gates, while the interseries learner explicitly models spatial dynamics through multihop propagation, incorporating Gumbel-softmax sampling. These two types of series dynamics are subsequently fused into a latent variable, which is inversely employed to infer time factors, generate a final prediction, and perform the reconstruction. We validate the effectiveness and efficiency of JointPGM through extensive experiments on six highly nonstationary MTS datasets, achieving state-of-the-art (SOTA) forecasting performance of MTS forecasting.},
  archive      = {J_TNNLS},
  author       = {Hui He and Qi Zhang and Kun Yi and Xiaojun Xue and Shoujin Wang and Liang Hu and Longbing Cao},
  doi          = {10.1109/TNNLS.2025.3593156},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Robust multivariate time series forecasting against intraseries and interseries transitional shift},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Satellite pose set estimation by uncertainty-guided conformal keypoint detection. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3598481'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Satellite pose estimation constitutes a critical technology in the aerospace tasks. The tradeoff between accuracy and efficiency becomes paramount for successful mission execution, due to the limited computational resources of on-board systems. Existing methods predominantly provide single-point estimations, which fall short of fulfilling the uncertainty quantification requirements demanded by safety-critical space operations. To address these problems, we first propose uncertainty-guided conformal keypoint detection to predict keypoint inductive conformal prediction (IndCP) set and then design a uncertainty propagation strategy to obtain pose uncertainty set. Specifically, we build our method upon a transformer-based keypoint predictor, which directly outputs uncertainty-guided keypoints. We first propose a nonconformal function to generate keypoint IndCP set to cover the ground-truth keypoint with a certain probability. We then apply Monte Carlo to sample within the keypoint IndCP set and estimate the poses by solving the perspective-n-point (PnP) problem. The top-n poses with the smallest conformal reprojection error are used to construct a convex hull, which are defined as the pose uncertainty set. Furthermore, we take the mean of the top-n poses as the average pose. Experiments on the Spacecraft PosE Estimation challenge Dataset (SPEED) and LineMOD Occlusion (LMO) dataset show that not only the average pose demonstrates higher accuracy but also the pose uncertainty sets can cover the true pose with the certain probability.},
  archive      = {J_TNNLS},
  author       = {Jinghao Wang and Zhang Li and Cong Sun and Yulan Guo and Zi Wang and Qifeng Yu},
  doi          = {10.1109/TNNLS.2025.3598481},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Satellite pose set estimation by uncertainty-guided conformal keypoint detection},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Extrapolation convolution for data prediction on a 2-D grid: Bridging spatial and frequency domains with applications in image outpainting and compressed sensing. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3598745'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extrapolation plays a critical role in machine/deep learning (ML/DL), enabling models to predict data points beyond their training constraints, particularly useful in scenarios deviating significantly from training conditions. This article addresses the limitations of current convolutional neural networks (CNNs) in extrapolation tasks within image restoration and compressed sensing (CS). While CNNs show potential in tasks such as image outpainting and CS, traditional convolutions are limited by their reliance on interpolation, failing to fully capture the dependencies needed for predicting values outside the known data. This work proposes an extrapolation convolution (EC) framework that models missing data prediction as an extrapolation problem using linear prediction within DL architectures. The approach is applied in two domains: first, image outpainting, where EC in encoder–decoder (EnDec) networks replaces conventional interpolation methods to reduce artifacts and enhance fine detail representation; second, Fourier-based CS-magnetic resonance imaging (CS-MRI), where it predicts high-frequency signal values from undersampled measurements in the frequency domain, improving reconstruction quality and preserving subtle structural details at high acceleration factors. Comparative experiments demonstrate that the proposed EC-DecNet and FDRN outperform traditional CNN-based models, achieving high-quality image reconstruction with finer details, as shown by improved peak signal-to-noise ratio (PSNR), structural similarity index (SSIM), and kernel inception distance (KID)/Frechet inception distance (FID) scores. Ablation studies and analysis highlight the effectiveness of larger kernel sizes and multilevel semi-supervised learning in FDRN for enhancing extrapolation accuracy in the frequency domain.},
  archive      = {J_TNNLS},
  author       = {Vazim Ibrahim and Faouzi Alaya Cheikh and Vijayan K. Asari and Joseph Suresh Paul},
  doi          = {10.1109/TNNLS.2025.3598745},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Extrapolation convolution for data prediction on a 2-D grid: Bridging spatial and frequency domains with applications in image outpainting and compressed sensing},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ReCL: A plug-and-play module for enhancing generalized category discovery using transport-based method to uncover the relationship in samples. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3598594'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning systems excel in closed-set environments but face challenges in open-set settings due to mismatched label spaces between training and test data. Generalized category discovery (GCD) is one of such real-world open-set learning problems. In GCD, given a dataset, only a subset of samples is labeled. The model is expected to simultaneously classify samples from labeled and unlabeled classes. Contrastive learning plays a critical role in solving the GCD problem, used to learn discriminative features for samples. However, in contrast to labeled data, due to the absence of label information, unlabeled samples rely solely on unsupervised contrastive loss to learn discriminated features by keeping different views of the same data consistent. Unfortunately, this approach often overlooks the relationships within unlabeled samples. In this article, we propose a relationship-based contrastive learning (ReCL) module. In ReCL, we use a transport-based assignment method to find appropriate samples for each unlabeled data point. Then, a prototype-based fusion method is applied to merge these selected samples, creating a positive anchor in contrastive learning that helps pull the unlabeled samples closer to the corresponding positive anchor. Extensive experimental evaluation across different domains demonstrates that our method can be seamlessly integrated with various existing GCD models and further improve them to achieve the state-of-the-art performance across different benchmarks. Notably, we also analyze the sample selection process between our transport-based method and the cosine similarity-based method. The results show that our method provides samples that contain semantic similarity while offering greater diversity.},
  archive      = {J_TNNLS},
  author       = {Pinzhuo Tian and Qiubo Ma and Hang Yu and Jie Lu},
  doi          = {10.1109/TNNLS.2025.3598594},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {ReCL: A plug-and-play module for enhancing generalized category discovery using transport-based method to uncover the relationship in samples},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advancing generalization in PINNs through latent-space representations. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3598617'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics-informed neural networks (PINNs) have made significant strides in modeling dynamical systems governed by partial differential equations (PDEs). However, their generalization capabilities across varying scenarios remain limited. To overcome this limitation, we propose physics-informed dynamics representation learner (PiDo), a novel physics-informed neural PDE solver designed to generalize effectively across diverse PDE configurations, including varying initial conditions, PDE coefficients, and training-time horizons. PiDo exploits the shared underlying structure of dynamical systems with different properties by projecting PDE solutions into a latent space using auto-decoding. It then learns the dynamics of these latent representations, conditioned on the PDE coefficients. Despite its promise, integrating latent dynamics models within a physics-informed framework poses challenges due to the optimization difficulties associated with physics-informed losses. To address these challenges, we introduce a novel approach that diagnoses and mitigates these issues within the latent space. This strategy employs straightforward yet effective regularization techniques, enhancing both the temporal extrapolation performance and the training stability of PiDo. We validate PiDo on a range of benchmarks, including 1-D combined equations and 2-D Navier–Stokes equations. In addition, we demonstrate the transferability of its learned representations to downstream applications such as long-term integration and inverse problems.},
  archive      = {J_TNNLS},
  author       = {Honghui Wang and Yifan Pu and Shiji Song and Gao Huang},
  doi          = {10.1109/TNNLS.2025.3598617},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Advancing generalization in PINNs through latent-space representations},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A bioinspired deep learning framework for saliency-based image quality assessment. <em>TNNLS</em>, 1-11. (<a href='https://doi.org/10.1109/TNNLS.2025.3598716'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advancements in deep learning have led to significant progress in no-reference (NR) image quality assessment (NR-IQA) for evaluating the perceived quality of digital images without relying on a reference. However, existing NR-IQA models remain suboptimal in handling complex and diverse natural images. Visual saliency constitutes a critical element for enhancing the reliability of NR-IQA, but the optimal use of saliency in deep learning-based NR-IQA has not heretofore been significantly explored. In this article, we present a novel method for integrating saliency in NR-IQA, which is motivated by the saliency-based visual search mechanism that different parts of the visual input are visited by the focus of attention (FOA) in the order of decreasing saliency. By dividing saliency into the high and low levels of FOA, we build a bioinspired deep neural network–BioSIQNet–based on a multitask learning (MTL) framework. The network architecture consists of two saliency-specific tasks and one primary image quality assessment (IQA) task. The low and high saliency (HS) are separately encoded and integrated into the early and deeper layers of the IQA network, respectively, analogous to the hierarchical processing in the visual cortex of the brain that allocates low attentional resources to process the simple patterns and high resources to learn intricate representations. We demonstrate that leveraging the synergy between visual attention and image quality perception and joint learning of these interconnected visual tasks can enhance the overall learning capabilities of the primary IQA model. Experiments validate the effectiveness of our proposed BioSIQNet for NR-IQA.},
  archive      = {J_TNNLS},
  author       = {Huasheng Wang and Yueran Ma and Hongchen Tan and Xiaochang Liu and Ying Chen and Hantao Liu},
  doi          = {10.1109/TNNLS.2025.3598716},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A bioinspired deep learning framework for saliency-based image quality assessment},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CRL: An efficient autonomous exploration framework for large-scale environments with contrastive-driven reinforcement learning. <em>TNNLS</em>, 1-12. (<a href='https://doi.org/10.1109/TNNLS.2025.3597164'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous exploration in large-scale environments is impeded by two critical challenges, namely, suboptimal viewpoint selection resulting from inadequate feature extraction and the continuously rising computational costs as the environment expands. Existing methods struggle to simultaneously tackle these dual challenges within cohesive frameworks. In response, we present an efficient autonomous exploration framework with contrastive-driven reinforcement learning. Inspired by human cognitive mechanisms that reinforce crucial information recognition through contrast, our study implements contrastive constraints on nodes of varying utility levels within high-dimensional feature spaces, achieving a decoupling of their latent representations. This capability empowers decision networks to explicitly capture key regional characteristics, thereby enhancing the precision of optimal viewpoint selection. Moreover, to mitigate the issues of backtracking and redundant exploration, we design specialized training rules that enforce effective action constraints, further enhancing viewpoint selection. Additionally, we propose a novel graph rarefaction algorithm to tackle computational costs, simplifying computational complexities while maintaining performance standards. Compared to the state-of-the-art (SOTA) approaches, our method achieves 6.7% shorter path lengths, while also demonstrates robust generalization capabilities through real-world robotic experiments across multiple real-world scenarios.},
  archive      = {J_TNNLS},
  author       = {Benke Gao and Hao Chen and Quan Liu and Hanqiang Deng and Jian Huang and Yan-Jun Liu},
  doi          = {10.1109/TNNLS.2025.3597164},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {CRL: An efficient autonomous exploration framework for large-scale environments with contrastive-driven reinforcement learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Recurrent network expansion for class incremental learning. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3601373'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class incremental learning (CIL) is the key to achieving adaptive vision intelligence, and one of the main streams for CIL is network expansion (NE). However, state-of-the-art (SOTA) methods usually suffer from feature diffusion, growing parameters, feature confusion, and classifier bias. In view of this, a novel dynamic structure dubbed as recurrent NE (RNE) is proposed by establishing connections among task experts. Specifically, the previous task experts transfer features sequentially through a shared module and the new task expert makes adjustments based on received features rather than reextracted ones, thereby focusing more on the key area and avoiding feature diffusion. Furthermore, the RNE is compressed by replacing additional task experts with lightened ones, in order to significantly reduce the number of parameters while keeping the performance almost unaltered. In addition, feature confusion is alleviated by a decoupled classifier and classifier bias is corrected by pseudo-feature generation. Extensive experiments on four widely adopted benchmark datasets, i.e., CIFAR-100, ImageNet-100, Food-101, and ImageNet-1K, have demonstrated that RNE achieves SOTA performance in both ordinary and challenging CIL settings.},
  archive      = {J_TNNLS},
  author       = {Kai Jiang and Xueru Bai and Feng Zhou},
  doi          = {10.1109/TNNLS.2025.3601373},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Recurrent network expansion for class incremental learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DSPFL: A deep-layer sign sharing personalized federated learning scheme for mitigating poisoning attacks. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3601078'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rise of the smart industry, machine learning (ML) has become a popular method to improve the security of the Industrial Internet of Things (IIoT) by training anomaly detection models. Federated learning (FL) is a distributed ML scheme that facilitates anomaly detection on IIoT by preserving data privacy and breaking data silos. However, poisoning attacks pose significant threats to FL, where adversaries upload poisoned local models to the aggregation server, thereby degrading model accuracy. The prevalence of non-independent and identically distributed (non-IID) data across IIoT devices further exacerbates this threat, as it naturally leads to diverse local models, making malicious ones harder to distinguish. To address the above challenges, we propose a deep-layer sign-sharing personalized FL (DSPFL) scheme. DSPFL innovatively aggregates only the signs of stochastic gradients (SignSGD) from the deep layers of local models during training. This targeted aggregation enhances the robustness of the shared components against poisoning attacks, while shallow layers are retained locally to preserve personalization. This integrated approach improves the accuracy and resilience of personalized local models on IIoT devices under poisoning attacks. Extensive experimental results show that DSPFL consistently achieves up to 20% higher and more stable overall personalized model accuracy compared to state-of-the-art methods under specific poisoning attacks.},
  archive      = {J_TNNLS},
  author       = {Chenhao Xu and Nasrin Sohrabi and Youyang Qu and Hai Dong and Zahir Tari and Xun Yi},
  doi          = {10.1109/TNNLS.2025.3601078},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {DSPFL: A deep-layer sign sharing personalized federated learning scheme for mitigating poisoning attacks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient high-dimensional learning with adaptive gaussian RBF networks. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3601366'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radial basis function neural networks (RBFNNs) are widely applied due to their rapid modeling capabilities and efficient learning performance. However, when dealing with high-dimensional data, RBFNNs encounter two critical limitations: the hidden layer responses using Gaussian kernels suffer from ineffective activation and numeric underflow; and the estimation of output layer weights typically involves tedious parameter tuning and inefficient loading of high-dimensional feature matrices. To overcome these challenges, we first propose a dimensionality-adaptive Gaussian kernel function (DAGKF) equipped with a novel width adjustment mechanism that flexibly mitigates the numerical difficulties inherent in high-dimensional spaces. Moreover, to avoid processing entire feature matrices simultaneously, we introduce a multioutput coordinate descent (MOCD) algorithm that enables parallel computation across multioutput systems. Building upon MOCD, we further develop the joint residual MOCD (JRMOCD) algorithm, which incorporates a joint residual criterion for more effective weight estimation. The convergence of the JRMOCD algorithm is rigorously proven. Extensive experiments demonstrate the superior performance of the proposed methods, particularly in high-dimensional settings.},
  archive      = {J_TNNLS},
  author       = {Xiaoyu Gao and Xuetao Xie and Jian Wang and Sergey V. Ablameyko and Nikhil R. Pal},
  doi          = {10.1109/TNNLS.2025.3601366},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Efficient high-dimensional learning with adaptive gaussian RBF networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SSPPI: Cross-modality enhanced Protein–Protein interaction prediction from sequence and structure perspectives. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3599927'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances have shown great promise in mining multimodal protein knowledge for better protein–protein interaction (PPI) prediction by enriching the representation of proteins. However, existing solutions lack a comprehensive consideration of both local patterns and global dependencies in proteins, hindering the full exploitation of modal information. Additionally, the inherent disparities between modalities are often disregarded, which may lead to inferior modality complementarity effects. To address these issues, we propose a cross-modality enhanced PPI prediction method from the perspectives of protein sequence and structure modalities, namely SSPPI. In this framework, our main contribution is that we integrate both sequence and structural modalities of proteins and employ an alignment and fusion method between modalities to further generate more comprehensive protein representations for PPI prediction. Specifically, we design two modal representation modules (Convformer and Graphormer) tailored for protein sequence and structure modalities, respectively, to enhance the quality of modal representation. Subsequently, we introduce a Cross-modality enhancer module to achieve alignment and fusion between modalities, thereby generating more informative modal joint representations. Finally, we devise a cross-protein fusion (CPF) module to model residue interaction processes between proteins, thereby enriching the joint representation of protein pairs. Extensive experimentation on four benchmark datasets demonstrates that our proposed model surpasses all current state-of-the-art (SOTA) methods. The source codes are publicly available at the following link https://github.com/bixiangpeng/SSPPI/},
  archive      = {J_TNNLS},
  author       = {Xiangpeng Bi and Wenjian Ma and Huasen Jiang and Weigang Lu and Zhiqiang Wei and Shugang Zhang},
  doi          = {10.1109/TNNLS.2025.3599927},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {SSPPI: Cross-modality enhanced Protein–Protein interaction prediction from sequence and structure perspectives},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ChebMixer: Efficient graph representation learning with MLP mixer. <em>TNNLS</em>, 1-12. (<a href='https://doi.org/10.1109/TNNLS.2025.3589316'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have achieved remarkable success in learning graph representations, especially graph Transformers, which have recently shown superior performance on various graph mining tasks. However, the graph Transformer generally treats nodes as tokens, which results in quadratic complexity regarding the number of nodes during self-attention computation. The graph multilayer perceptron (MLP) mixer addresses this challenge using the efficient MLP Mixer technique from computer vision. However, the time-consuming process of extracting graph tokens limits its performance. In this article, we present a novel architecture named ChebMixer, a newly proposed graph MLP Mixer that uses fast Chebyshev polynomials-based spectral filtering to extract a sequence of tokens. First, we produce multiscale representations of graph nodes via fast Chebyshev polynomial-based spectral filtering. Next, we consider each node’s multiscale representations as a sequence of tokens and refine the node representation with an effective MLP Mixer. Finally, we aggregate the multiscale representations of nodes through Chebyshev interpolation. Owing to the powerful representation capabilities and fast computational properties of the MLP Mixer, we can quickly extract more informative node representations to improve the performance of downstream tasks. The experimental results prove our significant improvements in various scenarios, ranging from homogeneous and heterophilic graph node classification to medical image segmentation. Compared with NAGphormer, the average performance improved by 1.45% on homogeneous graphs and 4.15% on heterophilic graphs. And the average performance improved by 1.39% on medical image segmentation tasks compared with VM-UNet. We will release the source code after this article is accepted.},
  archive      = {J_TNNLS},
  author       = {Xiaoyan Kui and Haonan Yan and Qinsong Li and Min Zhang and Liming Chen and Beiji Zou},
  doi          = {10.1109/TNNLS.2025.3589316},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {ChebMixer: Efficient graph representation learning with MLP mixer},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Domain information mining and state-guided adaptation network for multispectral image segmentation. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3589574'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Segment anything model (SAM), as a prompt-based image segmentation foundation model, demonstrates strong task versatility and domain generalization (DG) capabilities, providing a new direction for solving cross-scene segmentation tasks. However, SAM still has limitations in multispectral cross-domain segmentation tasks, mainly reflected in: 1) insufficient information utilization, which is reflected in the neglect of nonvisible spectral information and the shift information contained in source domain (SD) samples and target domain (TD) samples; and 2) lack of cross-domain strategies, which leads to insufficient cross-domain adaptation (DA) ability in downstream tasks. To address these challenges, we combine the respective advantages of masked autoencoder (MAE) and cross-domain strategies, propose an improved SAM DA network structure called domain information mining and state-guided adaptation network (DSAnet), aiming to enhance SAM’s performance in multispectral cross-domain segmentation tasks from both data and task levels. At the data level, DSAnet incorporates a style masking learning component, which randomly masks image features and replaces them with domain-specific learnable tokens, integrated with the image reconstruction task, to mine the style information and domain invariance of the image itself. At the task level, DSAnet introduces domain state learning and style-guided segmentation: domain state learning, through a state sequence modeling approach, designs specific state representations for SD and TD to capture interdomain differences, thereby reducing task shift. Meanwhile, the learned domain state information can be directly applied to the inference stage. Style prompt segmentation guides the segmentation training process of SD images with TD style prompts, improving SAM’s adaptability in cross-domain multispectral segmentation downstream tasks. Extensive experiments on three multitemporal multispectral image (MSI) datasets demonstrate the superiority of the proposed method compared to state-of-the-art cross-domain strategies and SAM variant methods.},
  archive      = {J_TNNLS},
  author       = {Boyu Zhao and Mengmeng Zhang and Wei Li and Yunhao Gao and Junjie Wang},
  doi          = {10.1109/TNNLS.2025.3589574},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Domain information mining and state-guided adaptation network for multispectral image segmentation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive neighborhood-resonated graph convolution network for undirected weighted graph representation. <em>TNNLS</em>, 1-12. (<a href='https://doi.org/10.1109/TNNLS.2025.3589224'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An undirected weighted graph (UWG) is the fundamental data representation in various real applications. A graph convolution network is frequently utilized for representation learning to a UWG. Nevertheless, existing graph convolutional networks (GCNs) only consider a node’s neighborhood during the embedding propagation, which regrettably decreases its representation learning capability due to the information loss in the modeling phase. Motivated by this discovery, this study proposes an adaptive neighborhood-resonated graph convolution network (ANR-GCN) with the following ideas: 1) establishing the weighted embedding propagation with the consideration of link weights in a UWG, thereby incorporating the interaction strength of each node pair into the ANR-GCN model; 2) building the neighborhood-regularization (NR) to make each node resonate with its neighborhoods, thus reinforcing the informative neighborhood information for improving the ANR-GCN’s representation capability to the complex topology of the target UWG; and 3)diversifying the NR effects following the attention principle for guaranteeing the ANR-GCN’s learning capacity. The proposed ANR-GCN’s representation learning ability to a UWG is theoretically guaranteed from the perspectives of bounded generalization error and uniform stability. Extensive experiments on four UWG datasets illustrate that the proposed ANR-GCN significantly outperforms state-of-the-art GCNs in missing edge detection in a UWG, which evidently demonstrates its superior performance.},
  archive      = {J_TNNLS},
  author       = {Jiufang Chen and Ye Yuan and Xin Luo and Xinbo Gao},
  doi          = {10.1109/TNNLS.2025.3589224},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {An adaptive neighborhood-resonated graph convolution network for undirected weighted graph representation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Progressive training for learning from label proportions. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3590131'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning from label proportions (LLPs), which aims to learn an instance-level classifier using proportion-based grouped training data, has garnered increasing attention in the field of machine learning. Existing deep learning-based LLP methods employ end-to-end pipelines to derive proportional loss functions via the Kullback–Leibler (KL) divergence between bag-level prior and posterior class distributions. However, the optimal solutions of these methods often struggle to conform to the given proportions, inevitably leading to degradation in the final classification performance. In this article, we address this issue by proposing a novel progressive training method for LLP, termed PT-LLP, which strives to meet the proportion constraints from the bag level to the instance level. Specifically, we first train a model by using the existing KL-divergence-based LLP methods that are consistent with bag-level proportion information. Then, we impose additional constraints on strict proportion consistency to the classifier to further move toward a more ideal solution by reformulating it as a constrained optimization problem, which can be efficiently solved using optimal transport (OT) algorithms. In particular, the knowledge distillation is employed as a transition stage to transfer the bag-level information to the instance level using a teacher–student framework. Finally, our framework is model-agnostic and demonstrates significant performance improvements through extensive experiments on different datasets when incorporated into other deep LLP methods as the first training stage.},
  archive      = {J_TNNLS},
  author       = {Jiabin Liu and Bo Wang and Yuping Zhang and Huadong Wang and Biao Li and Xin Shen and Gang Kou},
  doi          = {10.1109/TNNLS.2025.3590131},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Progressive training for learning from label proportions},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). OS-RRG: Observation state-aware radiology report generation with balanced diagnosis and attention intervention. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3589103'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radiology report generation (RRG) aims to automatically generate detailed textual descriptions and diagnoses for clinical radiography, alleviating radiologists’ workloads, aiding inexperienced radiologists, and minimizing errors. RRG is challenging due to the need to generate coherent and clinically accurate multisentence reports that describe various medical conditions. Although previous diagnosis-guided methods achieve impressive diagnostic accuracy by explicitly converting the identified observation states (OSs) (e.g., positive, negative, and uncertain) to descriptions, these methods still struggle in accurate observation-state identification and establishing precise state-to-description alignment. These challenges largely stem from the two aspects of imbalance (interclass and intraclass) inherent in observation states. In this article, we introduce a novel framework, observation state-aware radiology report generator (OS-RRG), designed to improve both the identification of states and their alignment with clinical descriptions. Our approach includes a state-aware balancing diagnosis (SBD) module to address both interclass and intraclass imbalances, an issue that previous methods have overlooked, resulting in suboptimal identification performance. In addition, we propose a novel technique called state-guided attention intervention (SAI), which dynamically adjusts focus on critical diagnostic features through a targeted filtering and enhancement mechanism. Furthermore, we propose a task-specific learning paradigm that decouples the identification and alignment processes into independent pathways, significantly enhancing the overall performance. Experiments on the MIMIC-CXR and IU-Xray benchmarks demonstrate the superior diagnostic accuracy of our method, which outperforms existing state-of-the-art techniques. The code will be made publicly available at https://github.com/xmed-lab/OS_RRG},
  archive      = {J_TNNLS},
  author       = {Honglong Yang and Hui Tang and Shanshan Song and Xiaomeng Li},
  doi          = {10.1109/TNNLS.2025.3589103},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {OS-RRG: Observation state-aware radiology report generation with balanced diagnosis and attention intervention},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online adaptable offline RL with guidance model. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3589418'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning (RL) has emerged as a promising approach across various applications, yet its reliance on repeated trial-and-error learning to develop effective policies from scratch poses significant challenges for deployment in scenarios where interaction is costly or constrained. In this work, we investigate the offline-to-online RL paradigm, wherein policies are initially pretrained using offline historical datasets and subsequently fine-tuned with a limited amount of online interaction. Previous research has suggested that efficient offline pretraining is crucial for achieving optimal final performance. However, it is challenging to incorporate appropriate conservatism to prevent the overestimation of out-of-distribution (OOD) data while maintaining adaptability for online fine-tuning. To address these issues, we propose an effective offline RL algorithm that integrates a guidance model to introduce suitable conservatism and ensure seamless adaptability to online fine-tuning. Our rigorous theoretical analysis and extensive experimental evaluations demonstrate better performance of our novel algorithm, underscoring the critical role played by the guidance model in enhancing its efficacy.},
  archive      = {J_TNNLS},
  author       = {Xun Wang and Jingmian Wang and Zhuzhong Qian and Bolei Zhang},
  doi          = {10.1109/TNNLS.2025.3589418},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Online adaptable offline RL with guidance model},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A switched system model for exponential stability and dissipativity of delayed neural networks. <em>TNNLS</em>, 1-10. (<a href='https://doi.org/10.1109/TNNLS.2025.3590251'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates the problems of exponential stability and dissipativity for neural networks with time-varying delays. To capture more information on the delay and its derivative in constructing Lyapunov–Krasovskii functionals (LKFs), the original delayed neural network (DNN) is modeled as a switching system with two modes, corresponding to cases where the delay derivative is positive or negative. This model provides extra freedom in constructing a proper LKF, allowing for the selection of different Lyapunov matrices in each mode. By applying the average dwell time (ADT) technique, several criteria for exponential stability and exponential dissipativity are obtained for DNNs. Two extensively studied benchmark examples and a quadruple-tank process control system are provided to demonstrate the superiority of the proposed criteria over some existing methods and to verify the practical applicability of the approach.},
  archive      = {J_TNNLS},
  author       = {Hong-Bing Zeng and Zong-Jun Zhu and Shen-Ping Xiao and Xian-Ming Zhang},
  doi          = {10.1109/TNNLS.2025.3590251},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A switched system model for exponential stability and dissipativity of delayed neural networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Find hidden modality divergence: Adversarial aware learning for unsupervised Visible–Infrared person re-identification. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3591116'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised visible–infrared person re-identifi-cation (Unsupervised VI-ReID) aims to learn discriminative identity features under the large modality gap without any labeled data. Currently, the state-of-the-art methods optimize cross-modality differences by using contrastive learning as the underlying paradigm. However, they neglect the problem of modality divergence during the cross-modality optimization process. This problem means that the interclass instances between the cross-modality intraclass gaps can make cross-modality intraclass instances difficult to get closer to each other in the feature space due to the effect of contrastive learning on these interclass instances. To alleviate the negative impact of the modality divergence problem, we propose an adversarial aware learning (ADAL) framework to explore the instances that generate modal divergence and adversarially optimize these explored instances. Specifically, on the one hand, we explore the optimization directions of each cluster during the cross-modality optimization process, and the cluster centroids generating positive optimization are facilitated, while the others generating negative optimization are penalized. On the other hand, we further consider the instance-level optimization process, which increases the affinities of the positive instance pairs with large cross-modality gaps to further improve the centroid-level optimization. Extensive experiments conducted on the visible–infrared person Re-ID datasets show that the proposed method is used as a universally applicable plug-in module to add the existing unsupervised VI-ReID methods, which outperforms the existing state-of-the-art approaches.},
  archive      = {J_TNNLS},
  author       = {Yuxuan Liu and Hongwei Ge and Yong Luo and Chunguo Wu},
  doi          = {10.1109/TNNLS.2025.3591116},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Find hidden modality divergence: Adversarial aware learning for unsupervised Visible–Infrared person re-identification},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SimAD: A simple dissimilarity-based approach for time-series anomaly detection. <em>TNNLS</em>, 1-12. (<a href='https://doi.org/10.1109/TNNLS.2025.3590220'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the prevalence of reconstruction-based deep learning methods, time-series anomaly detection (TSAD) remains a tremendous challenge. Existing approaches often struggle with limited temporal contexts, insufficient representation of normal patterns, and flawed evaluation metrics, all of which hinder their effectiveness in detecting anomalous behavior. To address these issues, we introduce a simple dissimilarity-based approach for time-series anomaly detection (SimAD). Specifically, SimAD first incorporates a patching-based feature extractor capable of processing extended temporal windows and employs the EmbedPatch encoder to fully integrate normal behavioral patterns. Second, we design an innovative ContrastFusion module in SimAD, which strengthens the robustness of anomaly detection by highlighting the distributional differences between normal and abnormal data. Third, we introduce two robust enhanced evaluation metrics, unbiased affiliation (UAff) and normalized affiliation (NAff), designed to overcome the limitations of existing metrics by providing better distinctiveness and semantic clarity. The reliability of these two metrics has been demonstrated by both theoretical and experimental analyses. Experiments conducted on seven diverse time-series datasets clearly demonstrate SimAD’s superior performance compared with state-of-the-art (SOTA) methods, achieving relative improvements of 19.85% on ${F}1$ , 4.44% on Aff-F1, 77.79% on NAff-F1, and 9.69% on AUC on six multivariate datasets. Code and pretrained models are available at https://github.com/EmorZz1G/SimAD},
  archive      = {J_TNNLS},
  author       = {Zhijie Zhong and Zhiwen Yu and Xing Xi and Yue Xu and Wenming Cao and Yiyuan Yang and Kaixiang Yang and Jane You},
  doi          = {10.1109/TNNLS.2025.3590220},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {SimAD: A simple dissimilarity-based approach for time-series anomaly detection},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solving scalable multiagent routing problems with reinforcement learning. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3591311'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiagent routing problems, arising from practical applications, such as logistics, transportation, and emergency response, face challenges due to the exponential growth of the search space with increasing problem scales. This article proposes RouteMaker to address the often-overlooked multiagent routing problems involving dedicated multiple depots. RouteMaker leverages role-interaction-based graph neural network (RIGNN) to realize effective locations assignments and integrates an advanced planner to plan travel path for each agent. RouteMaker is trained on small-scale problems and can produce comparable or superior approximate optimal solutions compared with the best heuristic baselines. Notably, the learned RouteMaker generalizes seamlessly to large-scale problems and real-world problems without the need for fine-tuning, delivering significantly higher quality solutions in relatively less time. For scenarios involving 40 agents and 1000 locations, RouteMaker achieves over $600\times $ speed improvement and more than 88% cost reduction, compared with the representative classical heuristic solver (ORTools).},
  archive      = {J_TNNLS},
  author       = {Yujiao Hu and Yuan Yao and Jinchao Chen and Zhihao Wang and Qingmin Jia and Yan Pan},
  doi          = {10.1109/TNNLS.2025.3591311},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Solving scalable multiagent routing problems with reinforcement learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SpeGCL: Self-supervised graph spectrum contrastive learning without positive samples. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3589861'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph contrastive learning (GCL) has emerged as a powerful method for dealing with noise and fluctuations in graph-structured data, and can be applied to social networks and knowledge graphs. Although various graph augmentation strategies have emerged in the field of GCL, traditional graph convolutional network (GCN) mainly tends to preserve smooth features and has difficulty capturing fine-grained changes between different views. To address the above issue, we first construct Fourier graph neural network (FourierGNN) from the perspective of graph spectrum learning, which captures different frequency components by stacking multiple Fourier graph operations (FGO) layers in Fourier space. Then, we find that the difference between the high-frequency information of two augmented graphs should be larger than the difference between the low-frequency information. Next, we theoretically prove that focusing only on pushing negative pairs farther away can more effectively achieve performance advantages. By leveraging these discoveries, we propose a novel self-supervised graph spectrum contrastive learning framework, i.e., SpeGCL, and design an effective contrastive strategy to optimize this goal. We also provide a theoretical justification for the efficacy of using only negative samples in SpeGCL. Extensive experiments have been conducted on unsupervised, transfer, and semi-supervised learning tasks to show that SpeGCL outperforms existing state-of-the-art (SOTA) GCL methods.},
  archive      = {J_TNNLS},
  author       = {Yuntao Shou and Xiangyong Cao and Deyu Meng},
  doi          = {10.1109/TNNLS.2025.3589861},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {SpeGCL: Self-supervised graph spectrum contrastive learning without positive samples},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust fault-aware extreme learning machine based on maximum correntropy. <em>TNNLS</em>, 1-9. (<a href='https://doi.org/10.1109/TNNLS.2025.3590097'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extreme learning machine (ELM) is an effective and efficient neural model for universal approximation. However, its practical performance can degrade due to weight noise, node faults, and outliers. This brief introduces a robust ELM algorithm designed to address these issues and enhance network robustness. We first analyze the square error of the classic ELM, considering both weight noise and node faults. By integrating an outlier-resistant method, the maximum correntropy criterion (MCC), we derive a new objective function to bolster network resilience. This leads to the development of the robust fault-aware ELM (RFAELM) algorithm. The convergence property of RFAELM is rigorously proven. For validation, the proposed algorithm is evaluated in various noise and fault levels using eight different benchmark datasets. The simulation results, encompassing all imperfect conditions and datasets, verify the robustness and generalization of this new algorithm. Also, the new algorithm is compared with other robust ELM algorithms using different statistical measurements. The superior performance of RFAELM substantiates its significant improvement over existing algorithms.},
  archive      = {J_TNNLS},
  author       = {Yuqi Xiao and Muideen Adegoke and Chi-Sing Leung and Kwok Wa Leung},
  doi          = {10.1109/TNNLS.2025.3590097},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-9},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Robust fault-aware extreme learning machine based on maximum correntropy},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SMTLNet: Domain prior-inspired tooth segmentation based on self-supervised manifold transfer learning. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3591003'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate identification and delineation of teeth in cone-beam computed tomography (CBCT) images are crucial in the advancement of digital dentistry technology. Teeth exhibit high interclass similarity and often have fuzzy boundaries. In addition, it is difficult to obtain teeth samples due to the time-consuming annotation process. However, existing methods typically fail to incorporate this domain-specific prior information under limited labeled samples, which limits the improvement of segmentation performance. Based on the intrinsic characteristics of the tooth CBCT images, a self-supervised manifold transfer learning network (SMTLNet) is proposed to improve segmentation accuracy. Initially, an object-oriented self-supervised pretraining approach is designed to fully explore valuable image representations from unannotated images, and this helps reduce dependence on labeled samples. Furthermore, a manifold optimization strategy is employed to regularize the segmentation model to separate interclass samples while compacting intraclass neighbors. Finally, to address the issue of blurred tooth boundaries, a multiscale boundary constraint module is developed to extract multiscale boundary-aware features, and more discriminative tooth descriptions can be acquired in this way. The proposed SMTLNet method is evaluated on clinical datasets containing diverse challenging cases (e.g., impacted wisdom teeth, crowded dentition), and it achieves state-of-the-art performance with dice similarity coefficients (DSCs) of 91.8%/89.08% and Jaccard similarities (JSs) of 86.71%/82.87% under full (100%) and limited (20%) training data regimes, respectively. The method maintains anatomical precision with Hausdorff distances (HDs) of 1.41 mm (high-resource) and 2.35 mm (low-resource), demonstrating strong clinical applicability in digital dentistry workflows.},
  archive      = {J_TNNLS},
  author       = {Yue Zhao and Ruoyu Wu and Pengyu Dai and Hong Huang and Yang Liu},
  doi          = {10.1109/TNNLS.2025.3591003},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {SMTLNet: Domain prior-inspired tooth segmentation based on self-supervised manifold transfer learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning granularity-aware affordances from human-object interaction for tool-based functional dexterous grasping. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3591538'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To enable robots to use tools, the initial step is teaching robots to employ dexterous gestures for touching specific areas precisely where tasks are performed. Affordance features of objects serve as a bridge in the functional interaction between agents and objects. However, leveraging these affordance cues to help robots achieve functional tool grasping remains unresolved. To address this, we propose a granularity-aware affordance feature extraction method for locating functional affordance areas and predicting dexterous coarse gestures. We study the intrinsic mechanisms of human tool use. On the one hand, we use fine-grained affordance features of object-functional finger contact areas to locate functional affordance regions. On the other hand, we use highly activated coarse-grained affordance features in hand–object interaction regions to predict grasp gestures. Additionally, we introduce a model-based postprocessing module that transforms affordance localization and gesture prediction into executable robotic actions. This forms GAAF-Dex, a complete framework that learns granularity-aware affordances from human–object interaction to enable tool-based functional grasping with dexterous hands. Unlike fully supervised methods that require extensive data annotation, we employ a weakly supervised approach to extract relevant cues from exocentric (Exo) images of hand–object interactions to supervise feature extraction in egocentric (Ego) images. To support this approach, we have constructed a small-scale dataset, functional affordance hand (FAH)-object interaction dataset, which includes nearly 6k images of functional hand–object interaction Exo images and Ego images of 18 commonly used tools performing six tasks. Extensive experiments on the dataset demonstrate that our method outperforms state-of-the-art methods, and real-world localization and grasping experiments validate the practical applicability of our approach. The source code and the established dataset are available at https://github.com/yangfan293/GAAF-DEX},
  archive      = {J_TNNLS},
  author       = {Fan Yang and Wenrui Chen and Kailun Yang and Haoran Lin and Dongsheng Luo and Conghui Tang and Zhiyong Li and Yaonan Wang},
  doi          = {10.1109/TNNLS.2025.3591538},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Learning granularity-aware affordances from human-object interaction for tool-based functional dexterous grasping},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interpretable cross-modal alignment network for EEG visual decoding with algorithm unrolling. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3592646'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate decoding in electroencephalography (EEG) technology, particularly for rapid visual stimuli, remains challenging due to the low signal-to-noise ratio (SNR). Additionally, existing neural networks struggle with issues related to generalization and interpretability. This article proposes a cross-modal aligned network, E2IVAE, which leverages shared information from multiple modalities for self-supervised alignment of EEG to images for extracting visual perceptual information and features a novel EEG encoder, ISTANet, based on algorithm unrolling. This network framework significantly enhances the accuracy and stability of EEG decoding for object recognition in novel classes while reducing the extensive neural data typically required for training neural decoders. The proposed ISTANet employs algorithm unrolling to transform the multilayer sparse coding algorithm into an end-to-end format, extracting features from noisy EEG signals while incorporating the interpretability of traditional machine learning. The experimental results demonstrate that our method achieves SOTA top-1 accuracy of 62.39% and top-5 accuracy of 88.98% on a comprehensive rapid serial visual presentation (RSVP) dataset for public comparison in a 200-class zero-shot neural decoding task. Additionally, ISTANet enables visualization and analysis of multiscale atom features and overall reconstruction features, exploring biological plausibility across temporal, spatial, and spectral dimensions. On another more challenging RSVP large-scale dataset, the proposed framework also achieves significantly above chance-level performance, proving its robustness and generalization. This research provides critical insights into neural decoding and brain–computer interfaces (BCIs) within the fields of cognitive science and artificial intelligence.},
  archive      = {J_TNNLS},
  author       = {Daowen Xiong and Liangliang Hu and Jiahao Jin and Yikang Ding and Congming Tan and Jing Zhang and Yin Tian},
  doi          = {10.1109/TNNLS.2025.3592646},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Interpretable cross-modal alignment network for EEG visual decoding with algorithm unrolling},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Vector quantization-based clustered federated learning with global feature anchors for improved representation and generalization. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3589186'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustered federated learning (CFL) addresses the challenge of data heterogeneity in federated learning (FL) by customizing models for different groups of clients. However, existing CFL methods heavily rely on indirect metrics, such as model parameters, gradient information, or loss function values, for client clustering. These approaches often fail to fully capture the diversity and intrinsic characteristics of client data distributions, leading to inaccurate representations of client data features. To address this issue, we propose a novel CFL framework called vector quantization-based CFL (VQCFL). First, we introduce a vector quantization network (VQNet), which effectively captures the intrinsic structure of client data by mapping the local feature space into discrete feature dictionary vectors. In addition, to prevent drift in the feature dictionary vectors, we propose a global feature anchor strategy that aligns feature dictionary vectors across clients, ensuring consistent updates within the same feature space. Furthermore, we present a novel cross-cluster knowledge-sharing mechanism that integrates feature information from different clusters through global aggregation of feature dictionary vectors. Combined with a personalized cross-cluster classifier weight adjustment strategy, this mechanism significantly enhances the model’s generalization performance in the presence of mixed data heterogeneity. Experimental results under various settings demonstrate that VQCFL achieves superior local personalization and global generalization performance.},
  archive      = {J_TNNLS},
  author       = {Xiaohong Chen and Yuhang Zhang and Xuesong Xu and Dongbin Hu and Guanying Xu},
  doi          = {10.1109/TNNLS.2025.3589186},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Vector quantization-based clustered federated learning with global feature anchors for improved representation and generalization},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Knowledge-guided semantic transfer network for few-shot image recognition. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2023.3240195'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning-based models have been shown to outperform human beings in many computer vision tasks with massive available labeled training data in learning. However, humans have an amazing ability to easily recognize images of novel categories by browsing only a few examples of these categories. In this case, few-shot learning comes into being to make machines learn from extremely limited labeled examples. One possible reason why human beings can well learn novel concepts quickly and efficiently is that they have sufficient visual and semantic prior knowledge. Toward this end, this work proposes a novel knowledge-guided semantic transfer network (KSTNet) for few-shot image recognition from a supplementary perspective by introducing auxiliary prior knowledge. The proposed network jointly incorporates vision inferring, knowledge transferring, and classifier learning into one unified framework for optimal compatibility. A category-guided visual learning module is developed in which a visual classifier is learned based on the feature extractor along with the cosine similarity and contrastive loss optimization. To fully explore prior knowledge of category correlations, a knowledge transfer network is then developed to propagate knowledge information among all categories to learn the semantic-visual mapping, thus inferring a knowledge-based classifier for novel categories from base categories. Finally, we design an adaptive fusion scheme to infer the desired classifiers by effectively integrating the above knowledge and visual information. Extensive experiments are conducted on two widely used Mini-ImageNet and Tiered-ImageNet benchmarks to validate the effectiveness of KSTNet. Compared with the state of the art, the results show that the proposed method achieves favorable performance with minimal bells and whistles, especially in the case of one-shot learning.},
  archive      = {J_TNNLS},
  author       = {Zechao Li and Hao Tang and Zhimao Peng and Guo-Jun Qi and Jinhui Tang},
  doi          = {10.1109/TNNLS.2023.3240195},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Knowledge-guided semantic transfer network for few-shot image recognition},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multiagent reinforcement learning with graphical mutual information maximization. <em>TNNLS</em>, 1-10. (<a href='https://doi.org/10.1109/TNNLS.2023.3243557'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Communication learning is an important research direction in the multiagent reinforcement learning (MARL) domain. Graph neural networks (GNNs) can aggregate the information of neighbor nodes for representation learning. In recent years, several MARL methods leverage GNN to model information interactions between agents to coordinate actions and complete cooperative tasks. However, simply aggregating the information of neighboring agents through GNNs may not extract enough useful information, and the topological relationship information is ignored. To tackle this difficulty, we investigate how to efficiently extract and utilize the rich information of neighbor agents as much as possible in the graph structure, so as to obtain high-quality expressive feature representation to complete the cooperation task. To this end, we present a novel GNN-based MARL method with graphical mutual information (MI) maximization to maximize the correlation between input feature information of neighbor agents and output high-level hidden feature representations. The proposed method extends the traditional idea of MI optimization from graph domain to multiagent system, in which the MI is measured from two aspects: agent features information and agent topological relationships. The proposed method is agnostic to specific MARL methods and can be flexibly integrated with various value function decomposition methods. Considerable experiments on various benchmarks demonstrate that the performance of our proposed method is superior to the existing MARL methods.},
  archive      = {J_TNNLS},
  author       = {Shifei Ding and Wei Du and Ling Ding and Jian Zhang and Lili Guo and Bo An},
  doi          = {10.1109/TNNLS.2023.3243557},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Multiagent reinforcement learning with graphical mutual information maximization},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust and rotation-equivariant contrastive learning. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2023.3243258'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contrastive learning (CL) methods achieve great success by learning the invariant representation from various transformations. However, rotation transformations are considered harmful to CL and are rarely used, which results in failure when the objects show unseen orientations. This article proposes a representation focus shift network (RefosNet), which adds the rotation transformations to CL methods to improve the robustness of representation. First, the RefosNet constructs the rotation-equivariant mapping between the features of the original image and the rotated ones. Then, the RefosNet learns semantic-invariant representations (SIRs) based on explicitly decoupling the rotation-invariant features and the rotation-equivariant features. Moreover, an adaptive gradient passivation strategy is introduced to gradually shift the representation focus to invariant representations. This strategy can prevent catastrophic forgetting of the rotation equivariance, which is beneficial to the generalization of representations in both seen and unseen orientations. We adapt the baseline methods (i.e.“, SimCLR” and “momentum contrast (MoCo) v2”) to work with RefosNet to verify the performance. Extensive experimental results show that our method achieves significant improvements on the task of recognition. On ObjectNet-13 with unseen orientations, RefosNet gains 7.12% in terms of classification accuracy compared with SimCLR. On datasets in seen orientation, the performance improves by 5.5% on ImageNet-100, 7.29% on STL10, and 1.93% on CIFAR10. In addition, RefosNet has strong generalization on Place205, PASCAL VOC, and Caltech 101. Our method has also achieved satisfactory results in image retrieval tasks.},
  archive      = {J_TNNLS},
  author       = {Gairui Bai and Wei Xi and Xiaopeng Hong and Xinhui Liu and Yang Yue and Songwen Zhao},
  doi          = {10.1109/TNNLS.2023.3243258},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Robust and rotation-equivariant contrastive learning},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hierarchical dynamic graph convolutional network with interpretability for EEG-based emotion recognition. <em>TNNLS</em>, 1-12. (<a href='https://doi.org/10.1109/TNNLS.2022.3225855'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph convolutional networks (GCNs) have shown great prowess in learning topological relationships among electroencephalogram (EEG) channels for EEG-based emotion recognition. However, most existing GCN-only methods are designed with a single spatial pattern, lacking connectivity enhancement within local functional regions and ignoring the data dependencies of EEG original data. In this article, hierarchical dynamic GCN (HD-GCN) is proposed to explore dynamic multilevel spatial information among EEG channels, with discriminative features of EEG signals as auxiliary information. Specifically, representation learning in topological space consists of two branches: one for extracting global dynamic information and one for exploring augmentation information in local functional regions. In each branch, a layerwise adjacency matrix is utilized to enrich the expressive power of GCN. Furthermore, a data-dependent auxiliary information module (AIM) is developed to capture multidimensional fusion features. Extensive experiments on two public datasets, SJTU emotion EEG dataset (SEED) and DREAMER, demonstrate that the proposed method consistently exceeds state-of-the-art methods. Interpretability analysis of the proposed model is performed, discovering the active brain regions and important electrode pairs related to emotion.},
  archive      = {J_TNNLS},
  author       = {Mengqing Ye and C. L. Philip Chen and Tong Zhang},
  doi          = {10.1109/TNNLS.2022.3225855},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {12},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Hierarchical dynamic graph convolutional network with interpretability for EEG-based emotion recognition},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep adversarial inconsistent cognitive sampling for multiview progressive subspace clustering. <em>TNNLS</em>, 1-11. (<a href='https://doi.org/10.1109/TNNLS.2021.3093419'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep multiview clustering methods have achieved remarkable performance. However, all of them failed to consider the difficulty labels (uncertainty of ground truth for training samples) over multiview samples, which may result in a nonideal clustering network for getting stuck into poor local optima during the training process; worse still, the difficulty labels from the multiview samples are always inconsistent, and such a fact makes it even more challenging to handle. In this article, we propose a novel deep adversarial inconsistent cognitive sampling (DAICS) method for multiview progressive subspace clustering. A multiview binary classification (easy or difficult) loss and a feature similarity loss are proposed to jointly learn a binary classifier and a deep consistent feature embedding network, throughout an adversarial minimax game over difficulty labels of multiview consistent samples. We develop a multiview cognitive sampling strategy to select the input samples from easy to difficult for multiview clustering network training. However, the distributions of easy and difficult samples are mixed together, hence not trivial to achieve the goal. To resolve it, we define a sampling probability with a theoretical guarantee. Based on that, a golden section mechanism is further designed to generate a sample set boundary to progressively select the samples with varied difficulty labels via a gate unit, which is utilized to jointly learn a multiview common progressive subspace and clustering network for more efficient clustering. Experimental results on four real-world datasets demonstrate the superiority of DAICS over state-of-the-art methods.},
  archive      = {J_TNNLS},
  author       = {Renhao Sun and Yang Wang and Zhao Zhang and Richang Hong and Meng Wang},
  doi          = {10.1109/TNNLS.2021.3093419},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Deep adversarial inconsistent cognitive sampling for multiview progressive subspace clustering},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bioinspired gain-modulated recurrent neural network for controlling musculoskeletal robot. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2021.3071196'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The motor cortex can arouse abundant transient responses to generate complex movements with the regulation of neuromodulators, while its architecture remains unchanged. This characteristic endows humans with flexible and robust abilities in adapting to dynamic environments, which is exactly the bottleneck in the control of complex robots. In this article, inspired by the mechanisms of the motor cortex in encoding information and modulating motor commands, a biologically plausible gain-modulated recurrent neural network is proposed to control a highly redundant, coupled, and nonlinear musculoskeletal robot. As the characteristics observed in the motor cortex, this network is able to learn gain patterns for arousing transient responses to complete the desired movements, while the connections of synapses keep unchanged, and the dynamic stability of the network is maintained. A novel learning rule that mimics the mechanism of neuromodulators in regulating the learning process of the brain is put forward to learn gain patterns effectively. Meanwhile, inspired by error-based movement correction mechanism in the cerebellum, gain patterns learned from demonstration samples are leveraged as prior knowledge to improve calculation efficiency of the network in controlling novel movements. Experiments were conducted on an upper extremity musculoskeletal model with 11 muscles and a general articulated robot to perform goal-directed tasks. The results indicate that the gain-modulated neural network can effectively control a complex robot to complete various movements with high accuracy, and the proposed algorithms make it possible to realize fast generalization and incremental learning ability.},
  archive      = {J_TNNLS},
  author       = {Shanlin Zhong and Junjie Zhou and Hong Qiao},
  doi          = {10.1109/TNNLS.2021.3071196},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {4},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Bioinspired gain-modulated recurrent neural network for controlling musculoskeletal robot},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
