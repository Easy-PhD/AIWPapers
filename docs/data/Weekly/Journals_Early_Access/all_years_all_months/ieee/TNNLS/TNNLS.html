<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TNNLS</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tnnls">TNNLS - 256</h2>
<ul>
<li><details>
<summary>
(2025). Unveiling group-specific distributed concept drift: A fairness imperative in federated learning. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3601834'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the evolving field of machine learning, ensuring group fairness has become a critical concern, prompting the development of algorithms designed to mitigate bias in decision-making processes. Group fairness refers to the principle that a model’s decisions should be equitable across different groups defined by sensitive attributes such as gender or race, ensuring that individuals from privileged groups and unprivileged groups are treated fairly and receive similar outcomes. However, achieving fairness in the presence of group-specific concept drift remains an unexplored frontier, and our research represents pioneering efforts in this regard. Group-specific concept drift refers to situations where one group experiences concept drift over time, while another does not, leading to a decrease in fairness even if accuracy (ACC) remains fairly stable. Within the framework of federated learning (FL), where clients collaboratively train models, its distributed nature further amplifies these challenges since each client can experience group-specific concept drift independently while still sharing the same underlying concept, creating a complex and dynamic environment for maintaining fairness. The most significant contribution of our research is the formalization and introduction of the problem of group-specific concept drift and its distributed counterpart, shedding light on its critical importance in the field of fairness. In addition, leveraging insights from prior research, we adapt an existing distributed concept drift adaptation algorithm to tackle group-specific distributed concept drift, which uses a multimodel approach, a local group-specific drift detection mechanism, and continuous clustering of models over time. The findings from our experiments highlight the importance of addressing group-specific concept drift and its distributed counterpart to advance fairness in machine learning.},
  archive      = {J_TNNLS},
  author       = {Teresa Salazar and João Gama and Helder Araújo and Pedro Henriques Abreu},
  doi          = {10.1109/TNNLS.2025.3601834},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Unveiling group-specific distributed concept drift: A fairness imperative in federated learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A decomposition optimization-based multiobjective reinforcement learning algorithm for obtaining nonconvex pareto fronts. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3603165'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiobjective reinforcement learning (MORL) aims to seek a complete Pareto front (PF) with different compromise policies in multiobjective Markov decision processes (MOMDPs). However, most MORL algorithms currently have a limitation in handling the MOMDPs with nonconvex PFs. In this article, we propose a nonlinear MORL algorithm based on decomposition and variance reduction (MORL/D-VR) to overcome this limitation. MORL/D-VR adopts the Tchebycheff approach to transform a given MOMDP into a set of single-objective Markov decision processes (MDPs) and subsequently applies an improved policy gradient algorithm, called expected utility policy gradient (EUPG), to solve each single-objective MDP efficiently. We analyze the Pareto optimality of employing the Tchebycheff approach and policy gradient methods that use the full return to update policy for solving MOMDPs. The analysis shows that such a case can identify any Pareto optimal policy regardless of the shape of PFs theoretically. This can provide a theoretical guarantee for applying the Tchebycheff approach and EUPG in MORL/D-VR to obtain the policies within the nonconvex PFs. Moreover, we devise a new baseline for EUPG to reduce the variance of gradient updates and adopt a weight vector adaptation method to improve diversity. The experimental results show that MORL/D-VR achieves a desirable performance in handling problems with different convex and nonconvex PFs and outperforms current state-of-the-art MORL algorithms.},
  archive      = {J_TNNLS},
  author       = {Tianyang Li and Ying Meng and Lixin Tang},
  doi          = {10.1109/TNNLS.2025.3603165},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A decomposition optimization-based multiobjective reinforcement learning algorithm for obtaining nonconvex pareto fronts},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DA-PFL: Dynamic affinity aggregation in personalized federated learning under class imbalance. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3598818'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized federated learning (PFL) has become a hot research topic that can learn a personalized learning model for each client. Existing PFL models prefer to aggregate similar clients with similar data distribution to improve the performance of learning models. However, similarity-based PFL methods may exacerbate the class imbalance problem. In this article, we propose a novel dynamic affinity-based PFL (DA-PFL) model to alleviate the class imbalanced problem during federated learning. Specifically, we build an affinity metric from a complementary perspective to guide which clients should be aggregated. We then design a dynamic aggregation strategy that adjusts client aggregation based on the affinity metric in each round, thereby reducing the risk of class imbalance. Extensive experiments demonstrate that the proposed DA-PFL model can significantly improve the accuracy of each client in four real-world datasets with state-of-the-art comparison methods.},
  archive      = {J_TNNLS},
  author       = {Xu Yang and Jiyuan Feng and Yongxin Tong and Lingzhi Wang and Songyue Guo and Binxing Fang and Qing Liao},
  doi          = {10.1109/TNNLS.2025.3598818},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {DA-PFL: Dynamic affinity aggregation in personalized federated learning under class imbalance},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust PID-type iterative learning control for nonlinear square and nonsquare systems. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3601656'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, a novel PID-type adaptive iterative learning control (AILC) method is proposed for a class of nonlinear systems with unspecified control gain matrices and bounded iterative-varying uncertainties. Unlike the existing iterative learning method with accumulation of control information, the new PID-type AILC avoids control information accumulation in traditional iterative learning control (ILC), maintaining convergence based on error information and confining iteration to parameter estimation, suitable for amplitude- or frequency-limited controllers. Different from the existing approaches of P-type AILC, this work extends ILC advances to PID-type AILC for nonlinear square or nonsquare systems with unknown control gain matrices, enhancing robustness through simultaneous convergence of integral and proportional error terms over a larger range. This analysis method diverges from traditional approaches relying on contraction mappings or asymptotic stability theorems; error convergence is analyzed using inequalities of a composite energy function (CEF). The effectiveness of this work has been validated through two illustrated examples. The results show that compared with P-type AILC, the convergence speed can be increased by approximately two to three times.},
  archive      = {J_TNNLS},
  author       = {Kechao Xu and Bo Meng and Zhen Wang and Xia Huang},
  doi          = {10.1109/TNNLS.2025.3601656},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Robust PID-type iterative learning control for nonlinear square and nonsquare systems},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Privacy-preserving video anomaly detection: A survey. <em>TNNLS</em>, 1-22. (<a href='https://doi.org/10.1109/TNNLS.2025.3600252'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The video anomaly detection (VAD) aims to automatically analyze spatiotemporal patterns in surveillance videos collected from open spaces to detect anomalous events that may cause harm, such as fighting, stealing, and car accidents. However, vision-based surveillance systems such as closed-circuit television (CCTV) often capture personally identifiable information. The lack of transparency and interpretability in video transmission and usage raises public concerns about privacy and ethics, limiting the real-world application of VAD. Recently, researchers have focused on privacy concerns in VAD by conducting systematic studies from various perspectives, including data, features, and systems, making privacy-preserving VAD (P2VAD) a hotspot in the AI community. However, the current research in P2VAD is fragmented, and prior reviews have mostly focused on methods using RGB sequences, overlooking privacy leakage and appearance bias considerations. To address this gap, this article is the first to systematically review the progress of P2VAD, defining its scope and providing an intuitive taxonomy. We outline the basic assumptions, learning frameworks, and optimization objectives of various approaches, analyzing their strengths, weaknesses, and potential correlations. In addition, we provide open access to research resources such as benchmark datasets and available code. Finally, we discuss key challenges and future opportunities from the perspectives of AI development and P2VAD deployment, aiming to the guide future work in the field.},
  archive      = {J_TNNLS},
  author       = {Yang Liu and Siao Liu and Xiaoguang Zhu and Hao Yang and Jielin Li and Juncen Guo and Liangyu Teng and Dingkang Yang and Yan Wang and Jing Liu},
  doi          = {10.1109/TNNLS.2025.3600252},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-22},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Privacy-preserving video anomaly detection: A survey},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nesterov accelerated gradient tracking with adam for distributed online optimization. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3604059'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents an accelerated distributed optimization algorithm for online optimization problems over large-scale networks. The proposed algorithm’s iteration only relies on local computation and communication. To effectively adapt to dynamic changes and achieve a fast convergence rate while maintaining good convergence performance, we design a new algorithm called NGTAdam. This algorithm combines the Nesterov acceleration technique with an adaptive moment estimation method. The convergence of NGTAdam is evaluated by evaluating its dynamic regret through the use of linear system inequality. For online convex optimization problems, we provide an upper bound on the dynamic regret of NGTAdam, which depends on the initial conditions and the time-varying nature of the optimization problem. Moreover, we show that if the time-varying part of this upper bound is sublinear with time, the dynamic regret is also sublinear. Through a variety of numerical experiments, we demonstrate that NGTAdam outperforms state-of-the-art distributed online optimization algorithms.},
  archive      = {J_TNNLS},
  author       = {Yanxu Su and Qingyang Sheng and Xiasheng Shi and Chaoxu Mu and Changyin Sun},
  doi          = {10.1109/TNNLS.2025.3604059},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Nesterov accelerated gradient tracking with adam for distributed online optimization},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fine-grained Audio–Visual event localization. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3600878'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Audio–visual event localization (AVEL) aims to recognize events in videos by associating audio–visual information. However, events involved in existing AVEL tasks are usually coarse-grained events. Actually, finer-grained events are sometimes necessary to be distinguished, especially in certain expert-level applications or rich-content-generation studies. However, this is challenging because they are more difficult to detect or distinguish compared with coarse-grained events. To better address this problem, we discuss a new setting of fine-grained AVEL from dataset to method. First, we constructed the first fine-grained audio–visual event dataset, which is called IT-AVE, relying on videos of playing musical instruments, containing 13k video clips and over 52k audio–visual events. All events are labeled from professional music practitioners, and the event categories are all derived from playing techniques, which are fine-grained with little interclass variation. Next, we designed a new fine-grained event localization method, spatial–temporal video event detector (SVED), which focuses on the challenges that fine-grained events are more imperceptible and prone to be disturbed. Finally, we conduct extensive experiments based on the proposed IT-AVE dataset versus fine-grained versions of two existing related datasets, including UnAV-22 derived from UnAV-100 and FineAction-AV derived from FineAction. Experimental results demonstrate the effectiveness of our method. We hope that this work will contribute to the exploration of an integrated understanding of audio–visual videos.},
  archive      = {J_TNNLS},
  author       = {Baoyu Fan and Lu Liu and Xiaochuan Li and Runze Zhang and Liang Jin and Jin Zhang},
  doi          = {10.1109/TNNLS.2025.3600878},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Fine-grained Audio–Visual event localization},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrating clinical knowledge graphs and gradient-based neural systems for enhanced melanoma diagnosis via the seven-point checklist. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3600443'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The seven-point checklist (7PCL) is a widely used diagnostic tool in dermoscopy for identifying malignant melanoma by assigning point values to seven specific attributes. However, the traditional 7PCL is limited to distinguishing between malignant melanoma and melanocytic nevi (MN) and falls short in scenarios where multiple skin diseases with appearances similar to melanoma coexist. To address this limitation, we propose a novel diagnostic framework that integrates a clinical knowledge-based topological graph (CKTG) with a gradient diagnostic strategy featuring a data-driven weighting (GD-DDW) system. The CKTG captures both the internal and external relationships among the 7PCL attributes, while the GD-DDW emulates dermatologists’ diagnostic processes, prioritizing visual observation before making predictions. Additionally, we introduce a multimodal feature extraction approach leveraging a dual-attention mechanism to enhance feature extraction through cross-modal interaction and unimodal collaboration. This method incorporates meta-information to uncover interactions between clinical data and image features, ensuring more accurate and robust predictions. Our approach, evaluated on the EDRA dataset, achieved an average AUC of 88.6%, demonstrating superior performance in melanoma detection and feature prediction. This integrated system provides data-driven benchmarks for clinicians, significantly enhancing the precision of melanoma diagnosis.},
  archive      = {J_TNNLS},
  author       = {Yuheng Wang and Tianze Yu and Jiayue Cai and Sunil Kalia and Harvey Lui and Z. Jane Wang and Tim K. Lee},
  doi          = {10.1109/TNNLS.2025.3600443},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Integrating clinical knowledge graphs and gradient-based neural systems for enhanced melanoma diagnosis via the seven-point checklist},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Surfer: A world model-based framework for vision-language robot manipulation. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3594117'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considering how to make the model accurately understand and follow natural language instructions and perform actions consistent with world knowledge is a key challenge in robot manipulation. This mainly includes human fuzzy instruction reasoning and the following of physical knowledge. Therefore, the embodied intelligence agent must have the ability to model world knowledge from training data. However, most existing vision and language robot manipulation methods mainly operate in less realistic simulators and language settings and lack explicit modeling of world knowledge. To bridge this gap, we introduce a novel and simple robot manipulation framework, called Surfer. It is based on the world model, treats robot manipulation as a state transfer of the visual scene, and decouples it into two parts: action and scene. Then, the generalization ability of the model on new instructions and new scenes is enhanced by explicit modeling of the action and scene prediction in multimodal information. In addition, we built a robot manipulation simulation platform that supports physics execution based on the MuJoCo physics engine. It can automatically generate demonstration training data and test data, effectively reducing labor costs. To conduct a comprehensive and systematic evaluation of the visual-language understanding and physical execution of the manipulation model, we also created a robotic manipulation benchmark with different difficulty levels, called SeaWave. It contains four visual-language manipulation tasks of different difficulty levels and can provide a standardized testing platform for embedded AI agents in multimodal environments. Overall, we hope Surfer can freely surf in the robot’s SeaWave benchmark. Extensive experiments show that Surfer consistently outperforms all baselines significantly in all manipulation tasks. On average, Surfer achieved a success rate of 54.74% on the defined four levels of manipulation tasks, exceeding the best baseline performance of 51.07%. The simulator, code, and benchmarks are released at https://pzhren.github.io/Surfer.},
  archive      = {J_TNNLS},
  author       = {Pengzhen Ren and Kaidong Zhang and Hetao Zheng and Zixuan Li and Yuhang Wen and Fengda Zhu and Shikui Ma and Xiaodan Liang},
  doi          = {10.1109/TNNLS.2025.3594117},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Surfer: A world model-based framework for vision-language robot manipulation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dual-discriminator generative adversarial network for anomaly detection. <em>TNNLS</em>, 1-12. (<a href='https://doi.org/10.1109/TNNLS.2025.3585978'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series anomaly detection has shown potential in various fields, such as finance, aerospace, and security. The fuzzy definition of data anomalies, the complexity of data patterns, and the scarcity of abnormal data samples pose significant challenges to anomaly detection. Researchers have extensively employed autoencoders (AEs) and generative adversarial networks (GANs) in studying time series anomaly detection methods. However, relying on reconstruction error, the AE-based anomaly detection algorithm needs more effective regularization methods, rendering it susceptible to the problem of overfitting. Meanwhile, GAN-based anomaly detection algorithms require high-quality training data, significantly impacting their practical deployment. We propose a novel GAN based on a dual-discriminator structure to address these issues. The model first processes the data with the generator to obtain the reconstruction error and then calculates pseudo-labels to divide the data into two categories. One data category is input into the first discriminator, where a minor loss between the data and its reconstructed counterpart is better. The other data category is input into the second discriminator, where a larger loss between the data and its reconstructed counterpart is better. Through this process, the model can effectively constrain the generator, retaining information on normal data during data reconstruction while discarding information on abnormal data. After conducting experiments on multiple benchmark datasets, the proposed GAN based on a dual-discriminator structure achieved good results in anomaly detection, outperforming several advanced methods. Additionally, the model also performed well in practical transformer data.},
  archive      = {J_TNNLS},
  author       = {Da Ding and Youquan Wang and Haicheng Tao and Jia Wu and Jie Cao},
  doi          = {10.1109/TNNLS.2025.3585978},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A dual-discriminator generative adversarial network for anomaly detection},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Koopman-driven linearized model-based offline planning with application to freeway ramp metering. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3605015'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a novel model-based planning framework for freeway ramp metering (RM), denoted as Koopman-driven linearized model-based offline planning (KLMOP). This framework integrates the model predictive control (MPC) and offline reinforcement learning (RL) under assumptions of a linear Markov decision process (MDP) with the Koopman operator. KLMOP introduces a fully linearized control framework by learning and modeling the dynamics, reward function, and value function in a latent space through a Koopman-based latent dynamical model (KLDM) and a pessimistic value iteration (PEVI) algorithm. This formulation builds upon the connection between Koopman operator theory and linear MDP. Contrastive learning is employed to ensure the expressiveness and structural conditions of the latent representation in linear MDP, enabling accurate reward prediction and efficient policy optimization. The MPC-based planning policy, then, leverages these components to solve a linear MPC problem efficiently in the latent space. Extensive simulation studies demonstrate that KLMOP significantly improves computational efficiency and control performance as compared with existing baseline methods for RM control. This framework provides a theoretically grounded and computationally efficient approach to linearizing nonlinear control problems, and its learning-based design makes it adaptable to broader applications.},
  archive      = {J_TNNLS},
  author       = {Tao Zhou and Chuanye Gu and Chee Peng Lim and Jinlong Yuan},
  doi          = {10.1109/TNNLS.2025.3605015},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Koopman-driven linearized model-based offline planning with application to freeway ramp metering},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Expandable residual approximation for knowledge distillation. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3602118'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation (KD) aims to transfer knowledge from a large-scale teacher model to a lightweight one, significantly reducing computational and storage requirements. However, the inherent learning capacity gap between the teacher and student often hinders the sufficient transfer of knowledge, motivating numerous studies to address this challenge. Inspired by the progressive approximation principle in the Stone–Weierstrass theorem, we propose expandable residual approximation (ERA), a novel KD method that decomposes the approximation of residual knowledge into multiple steps, reducing the difficulty of mimicking the teacher’s representation through a divide-and-conquer approach. Specifically, ERA employs a multibranched residual network (MBRNet) to implement this residual knowledge decomposition. Additionally, a teacher weight integration (TWI) strategy is introduced to mitigate the capacity disparity by reusing the teacher’s head weights. Extensive experiments show that ERA improves the Top-1 accuracy on ImageNet classification benchmark by 1.41% and the AP on the MS COCO object detection benchmark by 1.40, as well as achieving leading performance across computer vision tasks.},
  archive      = {J_TNNLS},
  author       = {Zhaoyi Yan and Binghui Chen and Yunfan Liu and Qixiang Ye},
  doi          = {10.1109/TNNLS.2025.3602118},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Expandable residual approximation for knowledge distillation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Long-tail class incremental learning via bias calibration with application to continuous fault diagnosis. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3602182'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class incremental learning (CIL) offers a promising framework for continuous fault diagnosis (CFD), allowing networks to accumulate knowledge from streaming industrial data and recognize new fault classes. However, current CIL methods assume a balanced data stream, which does not align with the long-tail distribution of fault classes in real industrial scenarios. To fill this gap, this article investigates the impact of long-tail bias in the data stream on the CIL training process through the experimental analysis. Observations show that long-tail bias in the data stream has a cascading effect, affecting the retention of old task knowledge and learning new tasks. Concurrently, the incremental model encounters challenges in identifying samples that conflict with its biases. Accordingly, we propose a CFD method called long-tail CIL via bias calibration (LTCIL-BC), which aims to improve the learning of bias-conflicting samples through bias exploration and debiasing. Specifically, LTCIL-BC simultaneously trains a primary debiased network and an auxiliary biased network. Then, a bias-indicating score is developed to provide insight into model bias and data bias based on the prediction error of the primary and auxiliary models, respectively. LTCIL-BC subsequently adjusts the logits of the debiased network using the bias-indicating score to guide optimization, thereby better utilizing the role of old class exemplars and reducing catastrophic forgetting. Experiments on power system (PS) and secure water treatment (SWaT) datasets demonstrate the superior performance of LTCIL-BC in CFD, achieving up to 9% improvement over state-of-the-art baselines in multiple long-tailed CIL setting. Comprehensive results demonstrate the effectiveness of LTCIL-BC in jointly addressing data and model bias during calibration and prioritizing bias-conflicting samples.},
  archive      = {J_TNNLS},
  author       = {Dongyue Chen and Zongxia Xie and Wenlong Yu and Qinghua Hu},
  doi          = {10.1109/TNNLS.2025.3602182},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Long-tail class incremental learning via bias calibration with application to continuous fault diagnosis},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evidential graph contrastive alignment for source-free blending-target domain adaptation. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3603224'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we first tackle a more realistic domain adaptation (DA) setting: source-free blending-target DA (SF-BTDA), where we cannot access to source-domain data while facing mixed multiple target domains without any domain labels in prior. Compared to existing DA scenarios, SF-BTDA generally faces the coexistence of different label shifts in different targets, along with noisy target pseudolabels generated from the source model. In this article, we propose a new method called evidential graph contrastive alignment (EGCA) to decouple the blending-target domain and alleviate the effect of noisy target pseudolabels. First, to improve the quality of pseudo target labels, we propose a calibrated evidential learning (CEL) module to iteratively improve both the accuracy and certainty of the resulting model and adaptively generate high-quality pseudo target labels. Second, we design a graph contrastive learning with the domain distance matrix and confidence-uncertainty criterion, to minimize the distribution gap of samples of the same class in the blending-target domain, which alleviates the coexistence of different label shifts in blended targets. We conduct a new benchmark based on three standard DA datasets, and EGCA outperforms other methods with considerable gains and achieves comparable results compared with those that have domain labels or source data in prior.},
  archive      = {J_TNNLS},
  author       = {Juepeng Zheng and Guowen Li and Yibin Wen and Jinxiao Zhang and Runmin Dong and Haohuan Fu},
  doi          = {10.1109/TNNLS.2025.3603224},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Evidential graph contrastive alignment for source-free blending-target domain adaptation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Incremental learning for defect segmentation with efficient transformer semantic complement. <em>TNNLS</em>, 1-10. (<a href='https://doi.org/10.1109/TNNLS.2025.3604956'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In industrial scenarios, semantic segmentation of surface defects is vital for identifying, localizing, and delineating defects. However, new defect types constantly emerge with product iterations or process updates. Existing defect segmentation models lack incremental learning capabilities, and direct fine-tuning (FT) often leads to catastrophic forgetting. Furthermore, low contrast between defects and background, as well as among defect classes, exacerbates this issue. To address these challenges, we introduce a plug-and-play Transformer-based semantic complement module (TSCM). With only a few added parameters, it injects global contextual features from multi-head self-attention into shallow convolutional neural network (CNN) feature maps, compensating for convolutional receptive-field limits and fusing global and local information for better segmentation. For incremental updates, we propose multi-scale spatial pooling distillation (MSPD), which uses pseudo-labeling and multi-scale pooling to preserve both short- and long-range spatial relations and provides smooth feature alignment between teacher and student. Additionally, we adopt an adaptive weight fusion (AWF) strategy with a dynamic threshold that assigns higher weights to parameters with larger updates, achieving an optimal balance between stability and plasticity. The experimental results on two industrial surface defect datasets demonstrate that our method outperforms existing approaches in various incremental segmentation scenarios.},
  archive      = {J_TNNLS},
  author       = {Xiqi Li and Zhifu Huang and Ge Ma and Yu Liu},
  doi          = {10.1109/TNNLS.2025.3604956},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Incremental learning for defect segmentation with efficient transformer semantic complement},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Temporal modeling with frozen Vision–Language foundation models for parameter-efficient Text–Video retrieval. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3605657'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal modeling plays an important role in the effective adaption of the powerful pretrained text–image foundation model into text–video retrieval. However, existing methods often rely on additional heavy trainable modules, such as transformer or BiLSTM, which are inefficient. In contrast, we avoid introducing such heavy components by leveraging frozen foundation models. To this end, we propose temporal modeling with frozen vision–language foundation models (TFVL) to model the temporal dynamics with fixed encoders. Specifically, text encoder temporal modeling (TextTemp) and image encoder temporal modeling (ImageTemp) apply frozen text and image encoders within the video head and video backbone, respectively. TextTemp uses a frozen text encoder to interpret frame representations as “visual words” within a temporal “sentence,” capturing temporal dependencies. On the other hand, ImageTemp uses a frozen image encoder to treat all frame tokens as a unified visual entity, learning spatiotemporal information. The total trainable parameters of our method, comprising a lightweight projection and several prompt tokens, are significantly fewer than those in other existing methods. We evaluate the effectiveness of our method on MSR-VTT, DiDeMo, ActivityNet, and LSMDC. Compared with full fine-tuning on MSR-VTT, our TFVL achieves an average 3.25% gain in R@1 with merely 0.35% of the parameters. Extensive experiments demonstrate that the proposed TFVL outperforms state-of-the-art methods with significantly fewer parameters.},
  archive      = {J_TNNLS},
  author       = {Leqi Shen and Tianxiang Hao and Tao He and Yifeng Zhang and Pengzhang Liu and Sicheng Zhao and Jungong Han and Guiguang Ding},
  doi          = {10.1109/TNNLS.2025.3605657},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Temporal modeling with frozen Vision–Language foundation models for parameter-efficient Text–Video retrieval},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust missing value imputation with proximal optimal transport for low-quality IIoT data. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3601130'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate imputation of missing data is crucial in the Industrial Internet-of-Things (IIoT), where operations are often compromised by noisy samples from harsh environments. Traditional imputation methods struggle with such noise due to their black-box nature or lack of adaptability. To address this issue, we recast data imputation as a distribution alignment challenge, utilizing the flexibility of optimal transport (OT) to handle noisy samples. Specifically, we first introduce the Proximal Optimal Transport (POT) problem, where the transportation cost is obtained by the network simplex approach with a selective matching mechanism, which renders it capable of matching distributions with noisy samples. Subsequently, we propose the POT-I framework, where the objective is to minimize the transport cost of POT. The produced gradient is used to refine the imputation value, which achieves missing data imputation (MDI) while getting robustness to noisy samples. Experiments on real-world IIoT datasets demonstrate the superiority of POT-I over state-of-the-art imputation methods.},
  archive      = {J_TNNLS},
  author       = {Hao Wang and Zhichao Chen and Yuan Shen and Hui Zheng and Degui Yang and Dangjun Zhao and Buge Liang},
  doi          = {10.1109/TNNLS.2025.3601130},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Robust missing value imputation with proximal optimal transport for low-quality IIoT data},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiagent inductive policy optimization. <em>TNNLS</em>, 1-12. (<a href='https://doi.org/10.1109/TNNLS.2025.3601360'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Policy optimization methods are promising to tackle high-complexity reinforcement learning (RL) tasks with multiple agents. In this article, we derive a general trust region for policy optimization methods by considering the effect of subpolicy combinations among agents in multiagent environments. Based on this trust region, we propose an inductive objective to train the policy function, which can ensure agents learn monotonically improving policies. Furthermore, we observe that the policy always updates very weakly before falling into a local optimum. To address this, we introduce a cost regarding policy distance in the inductive objective to strengthen the motivation of agents to explore new policies. This approach strikes a balance during training, where the policy update step size remains within the constraints of the trust region, preventing excessive updates while avoiding getting stuck in local optima. Simulations on wind farm (WF) control tasks and two multiagent benchmarks demonstrate the high performance of the proposed multiagent inductive policy optimization (MAIPO) method.},
  archive      = {J_TNNLS},
  author       = {Yubo Huang and Xiaowei Zhao},
  doi          = {10.1109/TNNLS.2025.3601360},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Multiagent inductive policy optimization},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bicriteria policy optimization for high-accuracy reinforcement learning. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3605362'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In essence, reinforcement learning (RL) solves optimal control problem (OCP) by employing a neural network (NN) to fit the optimal policy from state to action. The accuracy of policy approximation is often very low in complex control tasks, leading to unsatisfactory control performance compared with online optimal controllers. A primary reason is that the landscape of value function is always not only rugged in most areas but also flat on the bottom, which damages the convergence to the minimum point. To address this issue, we develop a bicriteria policy optimization (BPO) algorithm, which leverages a few optimal demonstration trajectories to guide the policy search at the gradient level. Different from conventional problem definition, BPO seeks to solve a bicriteria OCP, which has two homomorphic objectives: one is from the standard reward signals and the other is to align the demonstration trajectories. We introduce two co-state variables, one for each objectives, and formulate two Hamiltonians for this bicriteria OCP. The resulting new optimality condition preserves the minimum values of both Hamiltonians. Furthermore, we find that gradient conflict is a key obstacle to simultaneously descending both Hamiltonians, and its impact is negatively proportional to the inner product between the ideal and actual gradients. A minimax optimization problem is built at each RL iteration to minimize conflicts between two homomorphic objectives, whose solution for policy updating is referred to as harmonic gradient. By converting its inner optimization loop into a linear programming with convex trust region constraint, we simplify this problem into a single-loop maximization problem with much increased computational efficiency. Experiment tests on both linear and nonlinear control tasks validate the effectiveness of our BPO algorithm on the accuracy improvement of policy network.},
  archive      = {J_TNNLS},
  author       = {Guojian Zhan and Xiangteng Zhang and Feihong Zhang and Letian Tao and Shengbo Eben Li},
  doi          = {10.1109/TNNLS.2025.3605362},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Bicriteria policy optimization for high-accuracy reinforcement learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised Visible–Infrared ReID via pseudo-label correction and modality-level alignment. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3591641'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised visible–infrared person reidentification (UVI-ReID) has recently gained great attention due to its potential for enhancing human detection in diverse environments without labeling. Previous methods utilize intramodality clustering and cross-modality feature matching to achieve UVI-ReID. However, there exist two challenges: 1) noisy pseudo-labels might be generated in the clustering process and 2) the cross-modality feature alignment via matching the marginal distribution of visible and infrared modalities may misalign the different identities from the two modalities. In this article, we first conduct a theoretical analysis where an interpretable generalization upper bound is introduced. Based on the analysis, we then propose a novel unsupervised cross-modality person reidentification framework (PRAISE). Specifically, to address the first challenge, we propose a pseudo-label correction (PLC) strategy that utilizes a beta mixture model (BMM) to predict the probability of misclustering-based network’s memory effect and rectifies the correspondence by adding a perceptual term to contrastive learning. Next, we introduce a modality-level alignment (MLA) strategy that generates paired visible–infrared latent features and reduces the modality gap by aligning the labeling function of visible and infrared features to learn identity-discriminative and modality-invariant features. Experimental results on two benchmark datasets demonstrate that our method achieves a state-of-the-art (SOTA) performance than the unsupervised visible-ReID methods.},
  archive      = {J_TNNLS},
  author       = {Yexin Liu and Weiming Zhang and Athanasios V. Vasilakos and Lin Wang},
  doi          = {10.1109/TNNLS.2025.3591641},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Unsupervised Visible–Infrared ReID via pseudo-label correction and modality-level alignment},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). When to align: Dynamic behavior consistency for multiagent systems via intrinsic rewards. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3598301'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multiagent systems, learning optimal behavior policies for individual agents remains a challenging yet crucial task. While recent research has made strides in this area, the issue of when agents should maintain consistent behaviors with one another is still not adequately addressed. This article proposes a novel approach to enable agents to autonomously decide whether their behaviors should align with those of their peers by leveraging intrinsic rewards to optimize their policies. We define behavior consistency as the divergence between the actions taken by two agents given the same observations. To encourage agents to be aware of each other’s behaviors, we propose dynamic consistency-based intrinsic reward (DCIR), which guides agents in determining when to synchronize their behaviors. In addition, we introduce a dynamic scaling network (DSN) that provides learnable scaling factors at each time step, enabling agents to dynamically decide the extent of rewarding consistent behavior. Our method is evaluated on environments including Multiagent Particle, Google Research Football, and StarCraft II Micromanagement. Experimental results demonstrate its effectiveness in learning optimal policies.},
  archive      = {J_TNNLS},
  author       = {Kunyang Lin and Yufeng Wang and Peihao Chen and Runhao Zeng and Yinjie Lei and Siyuan Zhou and Qing Du and Mingkui Tan and Chuang Gan},
  doi          = {10.1109/TNNLS.2025.3598301},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {When to align: Dynamic behavior consistency for multiagent systems via intrinsic rewards},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conv4Rec: A 1-by-1 convolutional autoencoder for user profiling through joint analysis of implicit and explicit feedback. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3597051'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a new convolutional autoencoder architecture for user modeling and recommendation tasks with several improvements over the state of the art. First, our model has the flexibility to learn a set of associations and combinations between different interaction types in a way that carries over to each user and item. Second, our model is able to learn jointly from both the explicit ratings and the implicit information in the sampling pattern (which we refer to as ”implicit feedback”). It can also make separate predictions for the probability of consuming content and the likelihood of granting it a high rating if observed. This not only allows the model to make predictions for both the implicit and explicit feedback, but also increases the informativeness of the predictions: in particular, our model can identify items that users would not have been likely to consume naturally, but would be likely to enjoy if exposed to them. Finally, we provide several generalization bounds for our model, which, to the best of our knowledge, are among the first generalization bounds for autoencoders in a Recommender systems setting; we also show that optimizing our loss function guarantees the recovery of the exact sampling distribution over interactions up to a small error in total variation. In experiments on several real-life datasets, we achieve state-of-the-art performance on both the implicit and explicit feedback prediction tasks despite relying on a single model for both, and benefiting from additional interpretability in the form of individual predictions for the probabilities of each possible rating.},
  archive      = {J_TNNLS},
  author       = {Antoine Ledent and Petr Kasalický and Rodrigo Alves and Hady W. Lauw},
  doi          = {10.1109/TNNLS.2025.3597051},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Conv4Rec: A 1-by-1 convolutional autoencoder for user profiling through joint analysis of implicit and explicit feedback},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Channelwise regional integrate and multiple firing neuron: Improving the spatiotemporal learning of spiking neural networks. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3606849'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural networks (SNNs) can be operated in an event-driven manner to save energy consumption of artificial neural networks (ANNs), which has attracted enormous research interests for their high biological plausibility and powerful spatiotemporal information processing. However, representative studies only evaluated SNNs on static temporal tasks or short sequence tasks, which could not fully demonstrate the advantages of SNNs in spatiotemporal learning. In addition, we point out that the existing directly trained SNNs to face the problems of long-term memory, network degeneration, gradient saturation, and heterogeneity learning, these limit the performance of SNNs. In this article, we propose channelwise regional integrate and multiple firing (CRIMF) neuron to improve the spatiotemporal learning of SNNs. First, CRIMF neuron contains a new internal state of regional current that enhances the memory of spiking neurons and facilitates the learning of temporal information over long time steps. Second, CRIMF neuron is implemented with the multiple firing mechanisms; it is able to adjust the distribution of membrane potential and membrane potential gradient in the single firing mechanism, thus mitigating the underactivation and gradient saturation. Third, CRIMF neuron is trained with the channelwise learning strategy for the targeted learning of different types of temporal features, and an index of differentiation degree is proposed to visualize the effectiveness of the channelwise learning strategy. We also introduce the regional current reset equation and normalize the input of postsynaptic neurons in spatiotemporal dimension to avoid network degeneration. Finally, we select two emotion electroencephalogram (EEG) datasets and perform the evaluations based on manual features and raw signals. Experimental results show that CRIMF-based SNNs outperform the state-of-the-art methods in static temporal task, and CRIMF neurons are superior to the advanced spiking neurons and recurrent units of ANNs in dynamic temporal task, using low energy consumption.},
  archive      = {J_TNNLS},
  author       = {Mincheng Cai and Quan Liu and Kun Chen and Li Ma},
  doi          = {10.1109/TNNLS.2025.3606849},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Channelwise regional integrate and multiple firing neuron: Improving the spatiotemporal learning of spiking neural networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive modality balanced online knowledge distillation for Brain–Eye–Computer-based dim object detection. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3605710'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advanced cognition can be measured from the human brain using brain–computer interfaces (BCIs). Integrating these interfaces with computer vision techniques, which possess efficient feature extraction capabilities, can achieve more robust and accurate detection of dim targets in aerial images. However, existing target detection methods primarily concentrate on homogeneous data, lacking efficient and versatile processing capabilities for heterogeneous multimodal data. In this article, we first build a brain–eye–computer-based object detection system for aerial images under few-shot conditions. This system detects suspicious targets using region proposal networks (RPNs), evokes the event-related potential (ERP) signal in electroencephalogram (EEG) through the eye-tracking-based slow serial visual presentation (ESSVP) paradigm, and constructs the EEG–image data pairs with eye movement data. Then, an adaptive modality balanced online knowledge distillation (AMBOKD) method is proposed to recognize dim objects with the EEG–image data. AMBOKD fuses EEG and image features using a multihead attention module, establishing a new modality with comprehensive features. To enhance the performance and robust capability of the fusion modality, simultaneous training and mutual learning between modalities are enabled by end-to-end online KD (OKD). During the learning process, an adaptive modality balancing module is proposed to ensure multimodal equilibrium by dynamically adjusting the weights of the importance and the training gradients across various modalities. The effectiveness and superiority of our method are demonstrated by comparing it with existing state-of-the-art methods. Additionally, experiments conducted on public datasets and real-world scenarios demonstrate the reliability and practicality of the proposed system and the designed method. The dataset and the source code can be found at: https://github.com/lizixing23/AMBOKD},
  archive      = {J_TNNLS},
  author       = {Zixing Li and Chao Yan and Zhen Lan and Xiaojia Xiang and Han Zhou and Jun Lai and Dengqing Tang},
  doi          = {10.1109/TNNLS.2025.3605710},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Adaptive modality balanced online knowledge distillation for Brain–Eye–Computer-based dim object detection},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AMAP: Automatic multihead attention pruning by similarity-based pruning indicator. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3606750'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the strong performance of transformers, quadratic computation complexity of self-attention presents challenges in applying them to vision tasks. Linear attention reduces this complexity from quadratic to linear, offering a strong computation–performance tradeoff. To further optimize this, automatic pruning is an effective method to find a structure that maximizes performance within a target resource through training without any heuristic approaches. However, directly applying it to multihead attention is not straightforward due to channel mismatch. In this article, we propose an automatic pruning method to deal with this problem. Different from existing methods that rely solely on training without any prior knowledge, we integrate channel similarity-based weights into the pruning indicator to preserve the more informative channels within each head. Then, we adjust the pruning indicator to enforce that channels are removed evenly across all heads, thereby avoiding any channel mismatch. We incorporate a reweight module to mitigate information loss due to channel removal and introduce an effective pruning indicator initialization for linear attention, based on the attention differences between the original structure and each channel. By applying our pruning method to the FLattenTransformer on ImageNet-1K, which incorporates original and linear attention mechanisms, we achieve a 30% reduction of FLOPs in a near lossless manner. It also has 1.96% of accuracy gain over the DeiT-B model while reducing FLOPs by 37%, and 1.05% accuracy increase over the Swin-B model with a 10% reduction in FLOPs as well. The proposed method outperforms previous state-of-the-art efficient models and the recent pruning methods.},
  archive      = {J_TNNLS},
  author       = {Eunho Lee and Youngbae Hwang},
  doi          = {10.1109/TNNLS.2025.3606750},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {AMAP: Automatic multihead attention pruning by similarity-based pruning indicator},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unified framework for matrix backpropagation. <em>TNNLS</em>, 1-7. (<a href='https://doi.org/10.1109/TNNLS.2025.3607405'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computing matrix gradient has become a key aspect in modern signal processing/machine learning, with the recent use of matrix neural networks requiring matrix backpropagation. In this field, two main methods exist to calculate the gradient of matrix functions for symmetric positive definite (SPD) matrices, namely, the Daleckiǐ–Kreǐn/Bhatia formula and the Ionescu method. However, there appear to be a few errors. This brief aims to demonstrate each of these formulas in a self-contained and unified framework, to prove theoretically their equivalence, and to clarify inaccurate results of the literature. A numerical comparison of both methods is also provided in terms of computational speed and numerical stability to show the superiority of the Daleckiǐ–Kreǐn/Bhatia approach. We also extend the matrix gradient to the general case of diagonalizable matrices. Convincing results with the two backpropagation methods are shown on the EEG-based BCI competition dataset with the implementation of an SPDNet, yielding around 80% accuracy for one subject. Daleckiǐ–Kreǐn/Bhatia formula achieves an 8% time gain during training and handles degenerate cases.},
  archive      = {J_TNNLS},
  author       = {Gatien Darley and Stéphane Bonnet},
  doi          = {10.1109/TNNLS.2025.3607405},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-7},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A unified framework for matrix backpropagation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Theoretical advances on stochastic configuration networks. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3608555'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article advances the theoretical foundations of stochastic configuration networks (SCNs) by rigorously analyzing their convergence properties, approximation guarantees, and the limitations of nonadaptive randomized methods. We introduce a principled objective function that aligns incremental training with orthogonal projection, ensuring maximal residual reduction at each iteration without recomputing output weights. Under this formulation, we derive a novel necessary and sufficient condition for strong convergence in Hilbert spaces and establish sufficient conditions for uniform geometric convergence, offering the first theoretical justification of the SCN residual constraint. To assess the feasibility of unguided random initialization, we present a probabilistic analysis showing that even small support shifts markedly reduce the likelihood of sampling effective nodes in high-dimensional settings, thereby highlighting the necessity of adaptive refinement in the sampling distribution. Motivated by these insights, we propose greedy SCNs (GSCNs) and two optimized variants—Newton–Raphson GSCN (NR-GSCN) and particle swarm optimization GSCN (PSO-GSCN)—that incorporate Newton–Raphson refinement and particle swarm-based exploration to improve node selection. Empirical results on synthetic and real-world datasets demonstrate that the proposed methods achieve faster convergence, better approximation accuracy, and more compact architectures compared to existing SCN training schemes. Collectively, this work establishes a rigorous theoretical and algorithmic framework for SCNs, laying out a principled foundation for subsequent developments in the field of randomized neural network (NN) training.},
  archive      = {J_TNNLS},
  author       = {Xiufeng Yan and Dianhui Wang and Ivan Y. Tyukin},
  doi          = {10.1109/TNNLS.2025.3608555},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Theoretical advances on stochastic configuration networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatial–Temporal diffusion model for matrix factorization. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3605215'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Matrix factorization (MF) is a fundamental problem in machine learning, which is usually used as a feature learning method in various fields. For complex data involving spatiotemporal interactions, MF that only handles 2-D data will disrupt spatial dependence or temporal dynamics, failing to effectively couple spatial information with temporal factors. According to Markov chain principle, the spatial information of the present time is related to the spatial state of the previous time. We propose a spatial–temporal diffusion model for MF (STDMF), which uses graph diffusion to couple spatial–temporal information. Then, MF is used to learn the joint feature of data and spatial–temporal diffusion graph. Specifically, STDMF utilizes the graph diffusion with physical laws to generate spatial–temporal structure information. It obtains the underlying core structure of complex systems from a global perspective, which enhances the generalization ability of MF in noisy time-series data. To learn the lowest rank subspace of MF in time-series data, STDMF uses structural learning to constrain the rank of the learned features. Finally, STDMF is applied to clustering and anomaly detection of dynamic graph. The effectiveness of this method is verified by sufficient experiments, especially for noisy data.},
  archive      = {J_TNNLS},
  author       = {Chenxi Tian and Wenming Wu and Lingling Li and Xu Liu and Fang Liu and Wenping Ma and Licheng Jiao and Shuyuan Yang},
  doi          = {10.1109/TNNLS.2025.3605215},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Spatial–Temporal diffusion model for matrix factorization},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Continual diffuser (CoD): Mastering continual offline RL with experience rehearsal. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3598928'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial neural networks, especially recent diffusion-based models, have shown remarkable superiority in gaming, control, and QA systems, where the training tasks’ datasets are usually static. However, in real-world applications, such as robotic control of reinforcement learning (RL), the tasks are changing, and new tasks arise in a sequential order. This situation poses the new challenge of plasticity–stability tradeoff for training an agent who can adapt to task changes and retain acquired knowledge. In view of this, we propose a rehearsal-based continual diffusion model, called continual diffuser (CoD), to endow the diffuser with the capabilities of quick adaptation (plasticity) and lasting retention (stability). Specifically, we first construct an offline benchmark that contains 90 tasks from multiple domains. Then, we train the CoD on each task with sequential modeling and conditional generation for making decisions. Next, we preserve a small portion of previous datasets as the rehearsal buffer and replay it to retain the acquired knowledge. Extensive experiments on a series of tasks show that CoD can achieve a promising plasticity–stability tradeoff and outperform existing diffusion-based methods and other representative baselines on most tasks. The source code is available at https://github.com/JF-Hu/Continual_Diffuser.},
  archive      = {J_TNNLS},
  author       = {Jifeng Hu and Li Shen and Sili Huang and Zhejian Yang and Hechang Chen and Lichao Sun and Yi Chang and Dacheng Tao},
  doi          = {10.1109/TNNLS.2025.3598928},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Continual diffuser (CoD): Mastering continual offline RL with experience rehearsal},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FEU-diff: A diffusion model with fuzzy evidence-driven dynamic uncertainty fusion for medical image segmentation. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3609085'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffusion models, as a class of generative frameworks based on step-wise denoising, have recently attracted significant attention in the field of medical image segmentation. However, existing diffusion-based methods typically rely on static fusion strategies to integrate conditional priors with denoised features, making them difficult to adaptively balance their respective contributions at different denoising stages. Moreover, these methods often lack explicit modeling of pixel-level uncertainty in ambiguous regions, which may lead to the loss of structural details during the iterative denoising process, ultimately compromising the accuracy (Acc) and completeness of the final segmentation results. To this end, we propose FEU-Diff, a diffusion-based segmentation framework that integrates fuzzy evidence modeling and uncertainty fusion (UF) mechanisms. Specifically, a fuzzy semantic enhancement (FSE) module is designed to model pixel-level uncertainty through Gaussian membership functions and fuzzy logic rules, enhancing the model’s ability to identify and represent ambiguous boundaries. An evidence dynamic fusion (EDF) module estimates feature confidence via a Dirichlet-based distribution and adaptively guides the fusion of conditional information and denoised features across different denoising stages. Furthermore, the UF module quantifies discrepancies among multisource predictions to compensate for structural detail loss during the iterative denoising process. Extensive experiments on four public datasets show that FEU-Diff consistently outperforms state-of-the-art (SOTA) methods, achieving an average gain of 1.42% in the Dice similarity coefficient (DSC), 1.47% in intersection over union (IoU), and a 2.26 mm reduction in the 95th percentile Hausdorff distance (HD95). In addition, our method generates uncertainty maps that enhance clinical interpretability.},
  archive      = {J_TNNLS},
  author       = {Sheng Geng and Shu Jiang and Tao Hou and Hongcheng Yao and Jiashuang Huang and Weiping Ding},
  doi          = {10.1109/TNNLS.2025.3609085},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {FEU-diff: A diffusion model with fuzzy evidence-driven dynamic uncertainty fusion for medical image segmentation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Restoring noisy demonstration for imitation learning with diffusion models. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3607111'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imitation learning (IL) aims to learn a policy from expert demonstrations and has been applied to various applications. By learning from the expert policy, IL methods do not require environmental interactions or reward signals. However, most existing IL algorithms assume perfect expert demonstrations, but expert demonstrations often contain imperfections caused by errors from human experts or sensor/control system inaccuracies. To address the above problems, this work proposes a filter-and-restore framework to best leverage expert demonstrations with inherent noise. Our proposed method first filters clean samples from the demonstrations and then learns conditional diffusion models to recover the noisy ones. We evaluate our proposed framework and existing methods in various domains, including robot arm manipulation, dexterous manipulation, and locomotion. The experiment results show that our proposed framework consistently outperforms existing methods across all the tasks. Ablation studies further validate the effectiveness of each component and demonstrate the framework’s robustness to different noise types and levels. These results confirm the practical applicability of our framework to noisy offline demonstration data.},
  archive      = {J_TNNLS},
  author       = {Shang-Fu Chen and Co Yong and Shao-Hua Sun},
  doi          = {10.1109/TNNLS.2025.3607111},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Restoring noisy demonstration for imitation learning with diffusion models},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Peak-padding: Clustering by padding density peaks with the minimum padding cost. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3606527'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering complex-shaped clusters is still chal lenging for most existing clustering algorithms. Herein, the peak-padding clustering algorithm (PeakPad)—clustering by padding density peaks with the minimum padding cost—is proposed. PeakPad executes clustering on the density surface and views complex-shaped clusters as combinations of highly associated single-peak clusters. The minimum padding cost that fully considers the surrounding context of a density peak is proposed to reflect a density peak’s center potential, enabling PeakPad to have robust center detection performance. Unlike mean-shift (MSC), which detects centers based on their attributes in a complex-shaped density surface embedded in the high-dimensional space of density and features, PeakPad detects centers in a standard-shaped surface embedded in the 2-D density-change (DC) density space (composed of density and DC feature). Such standardization allows PeakPad to have fast and robust cluster center detection performance on complex-shaped clusters based on the minimum padding cost. Besides, PeakPad can provide a reasonable evaluation of the association between single-peak clusters by using the minimum padding cost. As a result, PeakPad can fast capture complex-shaped clusters, achieve robust center detection performance, and be suitable for large datasets. Benchmark test results on both synthetic and real datasets demonstrate the effectiveness of PeakPad.},
  archive      = {J_TNNLS},
  author       = {Junyi Guan and Bingbing Jiang and Weiguo Sheng and Yangyang Zhao and Sheng Li and Xiongxiong He},
  doi          = {10.1109/TNNLS.2025.3606527},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Peak-padding: Clustering by padding density peaks with the minimum padding cost},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging semi-supervised learning and meta-learning for re-identification in few-shot spatiotemporal anomaly detection. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3578642'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting spatiotemporal anomalies is imperative for addressing critical societal and engineering challenges, including public safety assurance, environmental hazard identification, epidemic surveillance, and transportation system optimization. Existing methodologies, however, face persistent limitations due to sparse labeled datasets and the inherent complexity of dynamic spatiotemporal systems. In order to bridge this gap, we present unsupervised-semi-supervised stacking (USemiS), a novel framework that synergizes semi-supervised learning with ensemble meta-learning. USemiS introduces three core innovations: 1) unsupervised component learners that extract low-level representations of heterogeneous anomalies, 2) a consensus-based tuning mechanism that dynamically weights robust learners via stability metrics, and 3) spatiotemporal MixUp (ST-MixUp), a tailored augmentation strategy that interpolates anomalies across spatial and temporal dimensions to enhance decision boundaries. By integrating these components, USemiS effectively disentangles latent anomaly patterns while mitigating label scarcity. Evaluated on large-scale traffic anomaly and crowd fall detection datasets, USemiS achieves state-of-the-art performance, outperforming existing methods by 1.3% and 2.1% in AUC under extreme low-label regimes (0.4% and 0.8% labeled data, respectively). These results underscore USemiS’s capacity to generalize across diverse spatiotemporal contexts, offering a scalable and robust solution for real-world applications where labeled anomalies are scarce yet critical.},
  archive      = {J_TNNLS},
  author       = {Zhen Zhou and Ziyuan Gu and Pan Liu and Wenwu Yu and Zhiyuan Liu},
  doi          = {10.1109/TNNLS.2025.3578642},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Leveraging semi-supervised learning and meta-learning for re-identification in few-shot spatiotemporal anomaly detection},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward an effective action-region tracking framework for fine-grained video action recognition. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3602089'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained action recognition (FGAR) aims to identify subtle and distinctive differences among fine-grained action categories. However, current recognition methods often capture coarse-grained motion patterns but struggle to identify subtle details in local regions evolving over time. In this work, we introduce the action-region tracking (ART) framework, a novel solution leveraging a query-response mechanism to discover and track the dynamics of distinctive local details, enabling distinguishing similar actions effectively. Specifically, we propose a region-specific semantic activation module that employs discriminative and text-constrained semantics serve as queries to capture the most action-related region responses in each video frame, facilitating interaction among spatial and temporal dimensions with corresponding video features. The captured region responses are then organized into action tracklets, which characterize the region-based action dynamics by linking related responses across different video frames in a coherent sequence. The text-constrained queries are designed to expressly encode nuanced semantic representations derived from the textual descriptions of action labels, as extracted by the language branches within visual language models. To optimize generated action tracklets, we design a multilevel tracklet contrastive constraint among multiple region responses at spatial and temporal levels, which can effectively distinguish individual region responses in each video frame (spatial level) and establish the correlation of similar region responses between adjacent video frames (temporal level). In addition, we implement a task-specific fine-tuning mechanism to refine textual semantics during training. This ensures that the semantic representations encoded by vision language models (VLMs) are not only preserved but also optimized for specific task preferences. Comprehensive experiments on several widely used action recognition benchmarks, i.e., FineGym, Diving48, NTURGB-D, Kinetics, and Something-Something, clearly demonstrate the superiority to previous state-of-the-art baselines.},
  archive      = {J_TNNLS},
  author       = {Baoli Sun and Yihan Wang and Xinzhu Ma and Zhihui Wang and Kun Lu and Zhiyong Wang},
  doi          = {10.1109/TNNLS.2025.3602089},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Toward an effective action-region tracking framework for fine-grained video action recognition},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contrastive federated learning for graph anomaly detection. <em>TNNLS</em>, 1-12. (<a href='https://doi.org/10.1109/TNNLS.2025.3601449'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph anomaly detection (GAD) refers to identifying abnormal graph nodes or edges that heavily deviate from normal observations. Existing approaches inevitably suffer from the influence of imbalanced data and privacy protection. This shortcoming poses challenges in optimizing node embeddings and detecting multitype anomalies simultaneously, resulting in decreased accuracy of existing GAD models. To address this shortcoming, we introduce a new federated learning model for graph anomaly detection (FedGAD). FedGAD enables collaborative unsupervised learning among decentralized data centers without requiring direct access to the distributed subgraphs. Specifically, FedGAD masks and reconstructs the neighborhood features to enhance the knowledge of node representations. Considering the data diversity across distributed clients, we also design a cross-clients’ node representation module that enables nodes to reconstruct neighbors by leveraging information from other clients. Furthermore, we use a multiscale contrastive learning function, which includes both structure-level and contextual-level learning functions, to detect graph anomalies in the condition that subgraphs located at different clients show imbalanced data distributions. Experimental results on seven benchmark datasets demonstrate the superior performance of FedGAD compared with baseline methods, verifying its capability of improving GAD performance.},
  archive      = {J_TNNLS},
  author       = {Hui Fang and Yang Gao and Peng Zhang and Sheng Zhou and Hongyang Chen and Jiajun Bu and Haishuai Wang},
  doi          = {10.1109/TNNLS.2025.3601449},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Contrastive federated learning for graph anomaly detection},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Coupled tensor decomposition for compact network representation. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3609797'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we introduce an approach called coupled filters decomposition, which builds on the key observation that redundancy exists among filters in a convolutional layer, meaning that similar filters can produce partially overlapping outputs. Leveraging this insight, we propose a joint decomposition of filters using coupled tensor decompositions, specifically coupled canonical polyadic decomposition (CPD), which enables the sharing of a common factor matrix across similar filters. This joint factorization not only reduces the number of parameters but also lowers computational complexity by eliminating redundant computations. To further improve efficiency, we first cluster the filters before decomposition. The grouping relies on a custom metric based on the subspace spanned by the shared-mode factor. Within each group, the coupling constraint is less restrictive. Extensive experiments across various architectures, datasets, and tasks validate the effectiveness of our method, demonstrating its competitive performance compared to state-of-the-art model compression techniques. Our code is available for research purposes at https://codec-ai.github.io/},
  archive      = {J_TNNLS},
  author       = {Van Tien Pham and Yassine Zniyed and Thanh Phuong Nguyen},
  doi          = {10.1109/TNNLS.2025.3609797},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Coupled tensor decomposition for compact network representation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A self-supervised learning framework for soft robot proprioception. <em>TNNLS</em>, 1-7. (<a href='https://doi.org/10.1109/TNNLS.2025.3610759'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The inherent compliant nature of soft robots can offer remarkable advantages over their rigid counterparts in terms of safety to human users and adaptability in unstructured environments. However, this feature also magnifies the complexity of their bodies, rendering their proprioception, and hence their control, extremely challenging. Given this intricacy, machine learning is a potent candidate for extracting proprioceptive insights from sensor data due to its proven capabilities in tackling analogous issues in computer vision (CV) and natural language processing (NLP). Recently, key aspects of soft robot proprioception have been addressed via learning-based techniques, but most of these are rooted in the supervised learning (SL) paradigm. This typically requires collecting a large number of costly annotated training samples, thereby constraining its widespread and speedy adoption in real-world applications. To mitigate this limitation, we propose a self-SL framework for soft robot proprioception. Our method utilizes vast unannotated data for network pretraining by self-SL. Then, the pretrained model is fine-tuned with a limited set of annotated samples by SL. We validate the proposed method’s efficacy on a high-resolution 3-D morphological reconstruction task using a publicly available dataset. Remarkably, our approach is shown to necessitate only about 1/20 of annotated samples to achieve better performance than the fully supervised method.},
  archive      = {J_TNNLS},
  author       = {Delin Hu and Huazhi Dong and Francesco Giorgio-Serchi and Yunjie Yang},
  doi          = {10.1109/TNNLS.2025.3610759},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-7},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A self-supervised learning framework for soft robot proprioception},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Vision mamba: A comprehensive survey and taxonomy. <em>TNNLS</em>, 1-21. (<a href='https://doi.org/10.1109/TNNLS.2025.3610435'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {State space model (SSM) is a mathematical model used to describe and analyze the behavior of dynamic systems. This model has witnessed numerous applications in several fields, including control theory, signal processing, economics, and machine learning. In the field of deep learning, SSMs are used to process sequence data, such as time series analysis, natural language processing (NLP), and video understanding. By mapping sequence data to state space, long-term dependencies in the data can be better captured. In particular, modern SSMs have shown strong representational capabilities in NLP, especially in long sequence modeling, while maintaining linear time complexity. In particular, based on the latest SSMs, Mamba merges time-varying parameters into SSMs toward efficient training and inference. Given its impressive efficiency and strong long-range dependency modeling capability, Mamba is expected to become a new AI architecture that may be capable of surpassing Transformer. Recently, a number of works attempt to study the potential of Mamba in various fields, such as general vision, multimodal learning, medical image analysis, and remote sensing image analysis, by extending Mamba from natural language domain to visual domain. To fully understand Mamba in the visual domain, we conduct a comprehensive survey and present a taxonomy study. This survey focuses on Mamba’s application to a variety of visual tasks and data types, and discusses its predecessors, recent advances, and far-reaching impact on a wide range of domains.},
  archive      = {J_TNNLS},
  author       = {Xiao Liu and Chenxu Zhang and Fuxiang Huang and Shuyin Xia and Guoyin Wang and Lei Zhang},
  doi          = {10.1109/TNNLS.2025.3610435},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-21},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Vision mamba: A comprehensive survey and taxonomy},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reinforcement learning-based boundary-optimized control of flexible manipulators under jointly connected switching topologies. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3609134'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article pioneers the study of boundary-optimized fault-tolerant tracking control for flexible manipulators in a switching digraph with a heterogeneous linear leader. Compared with existing research, the proposed methods have several features. First, a distributed observer is designed to observe the leader’s information in a general switching graph where communication can be interrupted. Second, a new partial differential equation (PDE)-based fault observer (FO) is designed to estimate unknown faults using only a few boundary states. Third, a novel long-term integral cost function is formulated to minimize angle-tracking errors, vibration deflections, and control energy in flexible manipulators. The ideal boundary optimal control laws are, then, derived and approximated using actor–critic neural networks (NNs) based on reinforcement learning (RL). Under the proposed fully distributed optimized fault-tolerant controllers, the closed-loop flexible manipulator’s error states are proven uniformly ultimately bounded (UUB). Finally, the effectiveness of the proposed method is demonstrated through numerical simulation results.},
  archive      = {J_TNNLS},
  author       = {Xiangqian Yao and Lin Li and Yu Liu},
  doi          = {10.1109/TNNLS.2025.3609134},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Reinforcement learning-based boundary-optimized control of flexible manipulators under jointly connected switching topologies},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Physics-guided time-interactive-frequency network for cross-domain few-shot hyperspectral image classification. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3608294'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, domain alignment and metric-based few-shot learning (FSL) have been introduced into hyperspectral image classification (HSIC) to solve the issues of uneven data distribution and scarcity of annotated data faced in practical applications. However, existing cross-domain few-shot methods ignore pivotal frequency priors of the complex field, which contribute to better category discrimination and knowledge transfer. To address this issue, we propose a novel physics-guided time-interactive-frequency network (PTFNet) for cross-domain few-shot HSIC, enabling the extraction of both frequency priors and spatial features (termed “time domain” following Fourier convention) simultaneously through a lightweight time-interactive-frequency module (TiF-Module) as a pioneering effort. Meanwhile, a spectral Fourier-based augmentation module (SFA-Module) is designed to decouple the frequency priors and enhance the diversity of distribution of physical attributes to imitate the domain shift. Then, the physics consistency loss is introduced to regularize the diverse embeddings to approximate the center of each category’s physical attributes, guiding the network to excavate more transferable knowledge of source domain (SD). Furthermore, to fully exploit the discriminant time–frequency information and further improve the accuracy of boundary pixels, a set of multiorientation homogeneous prototypes is adopted to represent each class comprehensively, and an intuitive and flexible uncertainty-rectified bidirectional random walk strategy is applied to replace the Euclidean metric for more reliable classification. The experimental results on four public datasets demonstrate the prominent performance of the proposed PTFNet.},
  archive      = {J_TNNLS},
  author       = {Jiaojiao Li and Hailong Wu and Rui Song and Haitao Xu and Yunsong Li and Qian Du},
  doi          = {10.1109/TNNLS.2025.3608294},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Physics-guided time-interactive-frequency network for cross-domain few-shot hyperspectral image classification},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Time series classification based on supervised contrastive learning and homoscedastic uncertainty. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3607901'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, contrastive learning (CL) frameworks have been widely applied to multivariate time series classification (MTSC) tasks. However, existing methods lack task-specific guidance, leading to limitations in fully capturing the complex dynamics and invariant representations in time series data. Motivated by the auxiliary tasks in multitask learning (MTL) and to fully utilize the rich frequency-domain information of time series data, we propose a novel time series classification framework, uncertainty-based time–frequency supervised CL (U-TFSCL). This framework uses SCL in the time and frequency domains and time–frequency consistency as auxiliary tasks to improve the primary task of using only instance-level labels for time series classification. Furthermore, inspired by the homogeneous uncertainty in MTL, we derive a novel uncertainty loss function, which automatically adjusts the weights according to the degree of uncertainty of different tasks to optimize the learning and prediction process of the model. The proposed framework is evaluated on MTSC tasks, including human activity recognition (HAR), air writing, and gesture recognition. In addition, we create a human–drone interaction (HDI) dataset consisting of 20 subjects and conduct real-world experiments to evaluate the proposed framework. The extensive experiments conducted in various settings verify the effectiveness of the proposed framework.},
  archive      = {J_TNNLS},
  author       = {Tao Zhang and Ke Li and Shaofan Wang},
  doi          = {10.1109/TNNLS.2025.3607901},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Time series classification based on supervised contrastive learning and homoscedastic uncertainty},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal quaternion representation network for multisource remote sensing data classification. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3610892'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The effective integration and classification of hyperspectral images (HSIs) and light detection and ranging (LiDAR) data is of great significance in Earth observation missions, which are confronted with challenges such as insufficient information utilization and feature heterogeneity. This article proposes a multimodal quaternion representation network (MMQRN) for multisource remote sensing (RS) data classification. Specifically, we first propose the multimodal quaternion representation (MMQR), which employs the orthogonal imaginary components of quaternions to model the complex nonlinear interactions among complementary features, thereby enabling their comprehensive fusion and utilization. Subsequently, we design a multimodal feature cross-fusion (MFCF) framework to integrate multisource, multimodal, and multilevel features adequately. Finally, we leverage the ability to capture long-term dependencies of transformers to design a quaternion convolutional transformer network (QCTN) for modeling global and local spatial–spectral information, respectively. Experiments conducted on three multisource RS datasets demonstrate the superior performance of the proposed MMQRN relative to other state-of-the-art classification methods.},
  archive      = {J_TNNLS},
  author       = {Yu-Le Wei and Heng-Chao Li and Jian-Li Wang and Yu-Bang Zheng and Jie Pan and Qian Du},
  doi          = {10.1109/TNNLS.2025.3610892},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Multimodal quaternion representation network for multisource remote sensing data classification},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HSG-net: Point cloud completion via heuristic structure growing. <em>TNNLS</em>, 1-12. (<a href='https://doi.org/10.1109/TNNLS.2025.3610101'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing point cloud completion methods rely on extracting latent codes from a partial point cloud to reconstruct a complete structure. However, the complexity of the partial point clouds, making the completion results of such methods less satisfactory, especially in long-distance (away from partial point cloud) areas. To tackle this challenge, we propose a point cloud completion network via heuristic structure growing (HSG-Net), which progressively completes the close-distance structure through an iterative heuristic structure growth strategy. Particularly, a novel data preprocessing (DP) method is proposed to obtain ground truth (GT) with specific structural integrity, guiding the network to learn close-distance structural information. In addition, the proposed consistency constraint displacement module (CCDM) is employed to fulfill structure growth, and a feature memory module (FMM) further enhances the quality of the grown structure. Furthermore, a proposed local information generator is used to further refine the structure-grown point cloud, fetching the final result. Extensive quantitative and qualitative results demonstrate that our HSG-Net outperforms the state-of-the-art methods.},
  archive      = {J_TNNLS},
  author       = {Xiaojun Chen and Junxian Chen and Ying Liu and Ruihui Li},
  doi          = {10.1109/TNNLS.2025.3610101},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {HSG-net: Point cloud completion via heuristic structure growing},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fuzzy rule-based differentiable representation learning. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3609722'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Representation learning is a key area in machine learning and deep learning, focusing on extracting meaningful features to support downstream tasks such as classification and clustering. Current mainstream representation learning methods primarily rely on nonlinear data mining techniques such as kernel methods and deep neural networks (DNNs) to extract abstract knowledge from complex datasets. However, most of them are “black-box” methods, lacking transparency and interpretability in the learning process, which constrain their practical utility. To this end, this article introduces a novel representation learning method called fuzzy rule-based differentiable representation learning (FRDRL), which is grounded in an interpretable fuzzy rule-based model. Specifically, it is built upon the Takagi–Sugeno–Kang fuzzy system (TSK-FS) to map input data to a high-dimensional fuzzy feature space through the antecedent part of the TSK-FS. Subsequently, a novel differentiable optimization method is proposed for learning in the consequent part, which preserves interpretability and transparency while effectively capturing nonlinear relationships in the data. By retaining the essence of traditional optimization and parameterizing key components as differentiable modules, the method improves performance without sacrificing interpretability. Moreover, a second-order geometry preservation strategy is incorporated to further improve robustness. Extensive evaluations conducted on various benchmark datasets validate the superiority of the proposed method. The source codes are available at https://github.com/BBKing49/FEDRL},
  archive      = {J_TNNLS},
  author       = {Wei Zhang and Zhaohong Deng and Guanjin Wang and Kup-Sze Choi},
  doi          = {10.1109/TNNLS.2025.3609722},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Fuzzy rule-based differentiable representation learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ape optimizer: A p-power adaptive filter-based approach for deep learning optimization. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3610665'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has been widely applied in various domains. Current widely-used optimizers, such as SGD, Adam, and their variants, are designed based on the assumption that the gradient noise generated during model training follows a Gaussian distribution. However, recent empirical studies have found that the gradient noise often does not follow a Gaussian distribution. Instead, the noise exhibits heavy-tailed characteristics consistent with an $\alpha $ -stable distribution, casting doubt on the performance and robustness of optimizers designed under the assumption of Gaussian noise. Inspired by the least mean p-power (LMP) algorithm from the field of adaptive filtering, we propose a novel optimizer called Ape for deep learning. Ape integrates a p-power adjustment mechanism to compress large gradients and amplify small ones, mitigating the impact of heavy-tailed gradient distributions. It also employs an approach for estimating second moments tailored to $\alpha $ -stable distributions. Extensive experiments on benchmark datasets demonstrate Ape’s effectiveness in improving both accuracy and training speed compared to existing optimizers. The Ape optimizer showcases the potential of cross-disciplinary approaches in advancing deep learning optimization techniques and lays the groundwork for future innovations in this domain.},
  archive      = {J_TNNLS},
  author       = {Yufei Jin and Han Yang and Xinrui Wang and Yingche Xu and Zhuoran Zhang},
  doi          = {10.1109/TNNLS.2025.3610665},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Ape optimizer: A p-power adaptive filter-based approach for deep learning optimization},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mars express orbiter power consumption prediction based on bionic hierarchical learning network. <em>TNNLS</em>, 1-12. (<a href='https://doi.org/10.1109/TNNLS.2025.3611001'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting power consumption for the Mars Express (MEX) mission is essential for optimizing its operational lifespan and mission assignments. However, the complexity of the Martian environment and the extended solar cycle obscure the periodicity of power consumption, making it difficult for existing methods to capture both intraperiodic and interperiodic features. This study introduces the bionic hierarchical learning network (BHL-Net) to enhance power consumption predictions. Leveraging 2-D frequency preprocessing and brain visual modeling techniques, BHL-Net mimics natural image encoding in the prefrontal cortex (PFC) to improve predictive performance. It incorporates a temporal oscillation activation module and a stripe intensity attention module to focus on local features, while a multihead attention adaptive aggregation module identifies key global features. Comparative experiments show that BHL-Net outperforms existing transformer-based models for MEX power consumption prediction. Ablation studies further validate the effectiveness of the FFT-based 2-D transformation and bionic attention framework. By emulating human brain response coding mechanisms, BHL-Net captures variations within and between complex cycles, providing a competitive solution for time series prediction in industrial applications.},
  archive      = {J_TNNLS},
  author       = {Zhuoyi Qian and Zhen Chen and Ershun Pan},
  doi          = {10.1109/TNNLS.2025.3611001},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Mars express orbiter power consumption prediction based on bionic hierarchical learning network},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing reinforcement learning with cross-domain knowledge transfer via seeded graph matching. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3606751'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transfer reinforcement learning (TRL) aims to boost the efficiency of reinforcement learning (RL) agents by leveraging knowledge from related tasks. Prior research primarily focuses on intradomain transfer, overlooking the complexities of transferring knowledge across tasks with differing state and action spaces. Recent efforts in cross-domain TRL aim to bridge this gap by establishing mappings between disparate source and target spaces, thereby enabling knowledge transfer across RL tasks with varied state and action configurations. However, existing studies often rely on strict prior assumptions about the relationships between state spaces, which limits their practical generality. In this article, we propose a novel approach to cross-domain TRL based on seeded graph matching, which enables alignment between source and target tasks regardless of differences in their state–action spaces. In particular, we model RL tasks as directed graphs, identify seed node pairs based on common RL properties, and devise a graph matching algorithm to align the source and target tasks by leveraging their structural characteristics. Building on this alignment, we introduce a policy-based transfer algorithm that improves the performance of the target RL task as its RL process progresses. Finally, we conduct comprehensive empirical studies on both discrete and continuous tasks with diverse state–action spaces. The experimental results validate the effectiveness of the proposed algorithm.},
  archive      = {J_TNNLS},
  author       = {Gengzhi Zhang and Liang Feng and Xuefeng Chen and Ke Tang and Kay Chen Tan},
  doi          = {10.1109/TNNLS.2025.3606751},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Enhancing reinforcement learning with cross-domain knowledge transfer via seeded graph matching},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Temporal and heterogeneous graph neural network for remaining useful life prediction. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3592788'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting remaining useful life (RUL) plays a crucial role in the prognostics and health management of industrial systems that involve a variety of interrelated sensors. Given a constant stream of time-series sensory data from such systems, deep learning (DL) models have risen to prominence at identifying complex, nonlinear temporal dependencies in these data. In addition to the temporal dependencies of individual sensors, spatial dependencies emerge as important correlations among these sensors, which can be naturally modeled by a temporal graph that describes time-varying spatial relationships. However, the majority of existing studies have relied on capturing discrete snapshots of this temporal graph, a coarse-grained approach that leads to a loss of temporal information. Moreover, given the variety of heterogeneous sensors, it becomes vital that such inherent heterogeneity is leveraged for RUL prediction in temporal sensor graphs. To capture the nuances of the temporal and spatial relationships and heterogeneous characteristics in an interconnected graph of sensors, we introduce a novel model named temporal and heterogeneous graph neural networks (THGNNs). Specifically, THGNN aggregates historical data from neighboring nodes to accurately capture the temporal dynamics and spatial correlations within the stream of sensor data in a fine-grained manner. Moreover, the model leverages feature-wise linear modulation (FiLM) to address the diversity of sensor types, significantly improving the model’s capacity to learn the heterogeneity in the data sources. Finally, we have validated the effectiveness of our approach through comprehensive experiments. Our empirical findings demonstrate significant advancements on the N-CMAPSS dataset, achieving improvements of up to 19.2% and 31.6% in terms of two different evaluation metrics over state-of-the-art methods.},
  archive      = {J_TNNLS},
  author       = {Zhihao Wen and Yuan Fang and Pengcheng Wei and Fayao Liu and Zhenghua Chen and Min Wu},
  doi          = {10.1109/TNNLS.2025.3592788},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Temporal and heterogeneous graph neural network for remaining useful life prediction},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). M4CXR: Exploring multitask potentials of multimodal large language models for chest X-ray interpretation. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3587687'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid evolution of artificial intelligence, especially in large language models (LLMs), has significantly impacted various domains, including healthcare. In chest X-ray (CXR) analysis, previous studies have employed LLMs, but with limitations: either underutilizing the LLMs’ capability for multitask learning or lacking clinical accuracy. This article presents M4CXR, a multimodal LLM designed to enhance CXR interpretation. The model is trained on a visual instruction-following dataset that integrates various task-specific datasets in a conversational format. As a result, the model supports multiple tasks such as medical report generation (MRG), visual grounding, and visual question answering (VQA). M4CXR achieves state-of-the-art clinical accuracy in MRG by employing a chain-of-thought (CoT) prompting strategy, in which it identifies findings in CXR images and subsequently generates corresponding reports. The model is adaptable to various MRG scenarios depending on the available inputs, such as single-image, multiimage, and multistudy contexts. In addition to MRG, M4CXR performs visual grounding at a level comparable to specialized models and demonstrates outstanding performance in VQA. Both quantitative and qualitative assessments reveal M4CXR’s versatility in MRG, visual grounding, and VQA, while consistently maintaining clinical accuracy.},
  archive      = {J_TNNLS},
  author       = {Jonggwon Park and Soobum Kim and Byungmu Yoon and Jihun Hyun and Kyoyun Choi},
  doi          = {10.1109/TNNLS.2025.3587687},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {M4CXR: Exploring multitask potentials of multimodal large language models for chest X-ray interpretation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Anchor-based multiview subspace clustering with anchor-wise and class-wise alignments. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3589264'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiview subspace clustering has shown promising performance in multimedia and data mining applications. However, its employment in large-scale datasets is limited due to its quadratic or even cubic computational complexity. The anchor graph strategy, which selects a few important samples (anchors) to represent the whole data for different views, has been introduced to address this challenge. These methods rely on a heuristic assumption that the correspondence and class structures between the sets of anchors across different views are the same. This assumption ignores the difference in the ordering of anchors with respect to their associated classes and the number of anchors belonging to the same class from different views. As a result, this can lead to unsatisfactory clustering results due to incorrect anchorwise and classwise alignments. To tackle this issue, this article proposes an anchor-based multiview subspace clustering with anchorwise and classwise alignments (AMCA2) method. Specifically, the proposed method simultaneously aligns and fuses multiple anchor graphs anchor wisely and class wisely via learning permutation matrices and utilizing the Hadamard product. To further enhance the clustering performance of AMCA2, we propose a novel anchor selection method called kernel anchor selection (KAS) to select more representative anchors. Extensive experiments on ten benchmark datasets are conducted to show the superiority and effectiveness of AMCA2 over the state-of-the-art methods.},
  archive      = {J_TNNLS},
  author       = {Ye Liu and Hongshan Pu and Junjun Pan and Michael K. Ng and Hongmin Cai},
  doi          = {10.1109/TNNLS.2025.3589264},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Anchor-based multiview subspace clustering with anchor-wise and class-wise alignments},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MBUNeXt: Multibranch encoder aggregation network based on layer-fusion strategy for multimodal brain tumor segmentation. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3593297'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal brain tumor segmentation (BraTS), integrated with surgical robots and navigation systems, enables accurate surgical interventions while maximizing the preservation of surrounding healthy brain tissue. However, multimodal brain scans suffer from large interclass differences in brain tumor subregions and information redundancy, leading to inadequate fusion of multimodal information and significantly affecting the accuracy of BraTS. To address the above problems, we propose a multibranch encoder aggregation (MEA) network based on a layer-fusion strategy called multibranch UNeXt (MBUNeXt). The network comprises three well-designed modules: the multimodal feature attention (MFA) module, the MEA module, and the large-kernel convolution skip (LCS)-connection module. These modules work together to achieve precise segmentation of brain tumors. Specifically, the MFA module preserves the intermodality similarity structure through attention mechanisms and Gaussian modulation functions, thereby filtering redundant information. Then, the MEA module exploits the correlations among multiple modalities to effectively integrate multimodal hybrid feature representation and optimize multimodal information fusion. In addition, the LCS module constructs multiple groups of depthwise separable convolutions with large kernel, which can guide the network to attend to features at different scales, thereby addressing the issue of significant interclass differences in brain tumor subregions. The experimental results on the large-scale public datasets, BraTS2019 and BraTS2021, which consist of approximately 5000 3-D brain scans, demonstrate that our proposed method has achieved SOTA performance, with average Dice scores of 85.84% and 91.11%, respectively. It also performs well on the BraTS-Africa2024 dataset with low imaging quality, confirming its robustness. The code is available at https://github.com/liuqinghao2018/MBUNeXt},
  archive      = {J_TNNLS},
  author       = {Qinghao Liu and Yuehao Zhu and Min Liu and Zhao Yao and Yaonan Wang and Erik Meijering},
  doi          = {10.1109/TNNLS.2025.3593297},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {MBUNeXt: Multibranch encoder aggregation network based on layer-fusion strategy for multimodal brain tumor segmentation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Discovering Spatiotemporal–Individual coupled features from nonstandard Tensors—A novel dynamic graph mixer approach. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3592692'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we present the dynamic graph mixer (DGM), a novel model for learning spatiotemporal-individual coupled features from high-dimensional and incomplete (HDI) tensors, which frequently represent dynamic interactions among real-world data samples. In contrast to existing methods, the proposed DGM possesses the following three advantages when learning representations from HDI tensors. First, it performs light graph message passing based on the conjoint attentions learned by jointly modeling latent features and implicit structures to extract the high-order connectivity. Second, a multilayer nonlinear tensor neural network (TNN) is adopted to learn the intricate attribute features of node–node–time from different views. Third, it follows the Tucker decomposition paradigm in a data density-oriented modeling mechanism to integrate node representations, preserving the overall multidimensional interaction patterns. In addition, we provide theoretical evidence that the key components in DGM can significantly improve expressiveness. Extensive experiments conducted on eight testing datasets of HDI tensors demonstrate that DGM outperforms state-of-the-art methods in both learning accuracy and efficiency.},
  archive      = {J_TNNLS},
  author       = {Fanghui Bi and Tiantian He and Yew-Soon Ong and Xin Luo},
  doi          = {10.1109/TNNLS.2025.3592692},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Discovering Spatiotemporal–Individual coupled features from nonstandard Tensors—A novel dynamic graph mixer approach},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond RMSE and MAE: Introducing EAUC to unmask hidden bias and unfairness in dyadic regression models. <em>TNNLS</em>, 1-12. (<a href='https://doi.org/10.1109/TNNLS.2025.3593059'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dyadic regression models, which output real-valued predictions for pairs of entities, are fundamental in many domains [e.g., obtaining user-product ratings in recommender systems (RSs)] and promising and under exploration in others (e.g., tuning patient–drug dosages in precision pharmacology). In this work, we prove that nonuniform observed value distributions of individual entities lead to severe biases in state-of-the-art models, skewing predictions toward the average of observed past values for the entity and providing worse-than-random predictive power in eccentric yet crucial cases; we name this phenomenon eccentricity bias. We show that global error metrics like root-mean-squared error (RMSE) are insufficient to capture this bias, and we introduce eccentricity area under the curve (EAUC) as a novel metric that can quantify it in all studied domains and models. We prove the intuitive interpretation of EAUC by experimenting with naive post-training bias corrections and theorize other options to use EAUC to guide the construction of fair models. This work contributes a bias-aware evaluation of dyadic regression to prevent unfairness in critical real-world applications of such systems.},
  archive      = {J_TNNLS},
  author       = {Jorge Paz-Ruza and Amparo Alonso-Betanzos and Bertha Guijarro-Berdiñas and Brais Cancela and Carlos Eiras-Franco},
  doi          = {10.1109/TNNLS.2025.3593059},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Beyond RMSE and MAE: Introducing EAUC to unmask hidden bias and unfairness in dyadic regression models},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiple influences maximization under dynamic link strength in multi-agent systems: The competitive and cooperative cases. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3588236'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article addresses the issue of multiple influences maximization under dynamic link strength (MIMDLS) in multi-agent systems (MASs). Initially, a novel model for dynamic link strength within MASs is suggested to facilitate the simulation of multiple influences diffusion. Subsequently, the MIMDLS problem is formulated with both competitive and cooperative scenarios being examined. In response, two diffusion models, specifically the competitive multiple influences independent cascade (Cp-MIIC) model and the cooperative multiple influences linear threshold (Cr-MILT) model, are designed for MASs. Furthermore, a distributed deep reinforcement learning (DRL) framework is established based on MASs by incorporating asynchronous training and updating processes for seed selection in the context of multiple influences. Moreover, the developed distributed DRL algorithm encompasses the estimation of Q value as well as the management of constraints within Cp-MIIC and Cr-MILT models. Finally, comprehensive experiments are conducted to: 1) validate the effectiveness and efficiency of the proposed models and algorithms in terms of multiple influence diffusion and 2) benchmark their performance against state-of-the-art methods.},
  archive      = {J_TNNLS},
  author       = {Mincan Li and Zidong Wang and Simon J. E. Taylor and Kenli Li and Xiangke Liao and Xiaohui Liu},
  doi          = {10.1109/TNNLS.2025.3588236},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Multiple influences maximization under dynamic link strength in multi-agent systems: The competitive and cooperative cases},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DDCNet: Advanced decoupling of degradation and content for adverse weather image restoration. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3594492'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adverse weather image restoration aims to recover clear images from those affected by weather conditions such as rain, haze, and snow. Different weather types affect images in distinct ways, necessitating specific degradation removal strategies, while content reconstruction generally benefits from a consistent approach since the underlying image structure remains largely consistent. Previous methods, despite their ability to handle multiple weather conditions within a single framework, often failed to adequately separate these two critical processes, thereby adversely affecting image restoration quality. In this article, we present DDCNet, a novel framework designed to explicitly decouple degradation removal and content reconstruction when processing various adverse weather conditions within a unified network. We achieve this by separating tailored degradation removal from uniform content reconstruction at the feature level, based on channel statistics. Additionally, we utilize the Fourier transform to enhance both processes. Furthermore, to address the differing optimization directions required by different adverse weather types, we propose a novel degradation mapping (DM) loss function to constrain their respective optimization paths. Extensive experiments show that DDCNet establishes new performance standards across multiple adverse weather scenarios.},
  archive      = {J_TNNLS},
  author       = {Xi Wang and Xueyang Fu and Yurui Zhu and Zheng-Jun Zha},
  doi          = {10.1109/TNNLS.2025.3594492},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {DDCNet: Advanced decoupling of degradation and content for adverse weather image restoration},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing domain generalization in medical image segmentation with global and local prompts. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3590956'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Enhancing domain generalization (DG) is a crucial and compelling research pursuit within the field of medical image segmentation, owing to the inherent heterogeneity observed in medical images. The recent success with large-scale pre-trained vision models (PVMs), such as Vision Transformer (ViT), inspires us to explore their application in this specific area. While a straightforward strategy involves fine-tuning the PVM using supervised signals from the source domains, this approach overlooks the domain shift issue and neglects the rich knowledge inherent in the instances themselves. To overcome these limitations, we introduce a novel framework enhanced by global and local prompts (GLPs). Specifically, to adapt PVM in the medical DG scenario, we explicitly separate domain-shared and domain-specific knowledge in the form of GLPs. Furthermore, we develop an individualized domain adapter to intricately investigate the relationship between each target domain sample and the source domains. To harness the inherent knowledge within instances, we devise two innovative regularization terms from both the consistency and anatomy perspectives, encouraging the model to preserve instance discriminability and organ position invariance. Extensive experiments and in-depth discussions in both vanilla and semi-supervised DG scenarios deriving from five diverse medical datasets consistently demonstrate the superior segmentation performance achieved by GLP. Our code and datasets are publicly available at https://github.com/xmed-lab/GLP.},
  archive      = {J_TNNLS},
  author       = {Chuang Zhao and Xiaomeng Li},
  doi          = {10.1109/TNNLS.2025.3590956},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Enhancing domain generalization in medical image segmentation with global and local prompts},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SFBM: Shared feature bias mitigating for long-tailed image recognition. <em>TNNLS</em>, 1-16. (<a href='https://doi.org/10.1109/TNNLS.2025.3586215'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long-tailed distribution exists in real-world scenario and compromises the performance of recognition models. In this article, we point out that a neural network classifier has a shared feature bias, which tends to regard the shared features among different classes as head-class discriminative features, leading to misclassifications on tail-class samples under long-tailed scenarios. To solve this issue, we propose a shared feature bias mitigating (SFBM) framework. Specifically, we create two parallel classifiers trained concurrently with the baseline classifier, using our special training loss. The parallel classifier weight sums are then used for estimating the shared feature components in baseline classifier weights. Finally, we rectify the baseline classifier by removing the estimated shared feature components from it while supplementing the parallel classifier weights class by class to the rectified classifier weights, mitigating shared feature bias. Our proposed SFBM demonstrates broad compatibility with nearly all recognition methods while maintaining high computational efficiency, as it introduces no additional computation during inference. Extensive experiments on CIFAR10/100-LT, ImageNet-LT, and iNaturalist 2018 demonstrate that simply incorporating SFBM during the training phase consistently boosts the performance of various state-of-the-art methods by significant margins. The complete source code will be made publicly available at https://github.com/bzbz-bot/SFBM},
  archive      = {J_TNNLS},
  author       = {Xinqiao Zhao and Mingjie Sun and Eng Gee Lim and Yao Zhao and Jimin Xiao},
  doi          = {10.1109/TNNLS.2025.3586215},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {SFBM: Shared feature bias mitigating for long-tailed image recognition},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep multimanifold transformation-based multivariate time series fault detection. <em>TNNLS</em>, 1-11. (<a href='https://doi.org/10.1109/TNNLS.2025.3584988'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised fault detection in multivariate time series (MTS) plays a vital role in ensuring the stable operation of complex systems. Traditional methods often assume that normal data follow a single Gaussian distribution and identify anomalies as deviations from this distribution. However, this simplified assumption fails to capture the diversity and structural complexity of real-world time series, which can lead to misjudgments and reduced detection performance in practical applications. To address this issue, we propose a new method that combines a neighborhood-driven data augmentation strategy with a multimanifold representation learning framework. By incorporating information from local neighborhoods, the augmentation module can simulate contextual variations of normal data, enhancing the model’s adaptability to distributional changes. In addition, we design a structure-aware feature learning approach that encourages natural clustering of similar patterns in the feature space while maintaining sufficient distinction between different operational states. Extensive experiments on several public benchmark datasets demonstrate that our method achieves superior performance in terms of both accuracy and robustness, showing strong potential for generalization and real-world deployment.},
  archive      = {J_TNNLS},
  author       = {Hong Liu and Xiuxiu Qiu and Yiming Shi and Miao Xu and Zelin Zang and Zhen Lei},
  doi          = {10.1109/TNNLS.2025.3584988},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Deep multimanifold transformation-based multivariate time series fault detection},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive weighted metric learning network based on fractional domain decoupling for hyperspectral change detection. <em>TNNLS</em>, 1-17. (<a href='https://doi.org/10.1109/TNNLS.2025.3586714'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral image change detection (HSI-CD) possesses strong capabilities in exploring subtle changes in land cover. Due to sensor noise and imaging conditions, different semantic land covers in the same spatial location may exhibit similar spectral characteristics, leading to pseudoinvariant phenomena (identification of changed areas as unchanged areas) and causing a higher rate of false negatives in the model. Existing methods primarily focus on obtaining auxiliary discriminative information from spatial correlations or temporal dependencies. However, the frequency domain, which possesses rich global gradient distribution information, is often overlooked. The fractional Fourier transform (FrFT) is an extension of the Fourier transform (FT), representing a temporal-frequency local transformation suitable for processing nonstationary signals. Furthermore, multiorder fractional Fourier domains provide more observable domains for change discrimination. In this work, the application of FrFT is extended to the field of HSI-CD, and an adaptive weighted metric learning network based on fractional domain decoupling (FrFTML) is proposed. Specifically, the fractional domain decoupling (FrDD) module transforms the original HSI into multiorder FrFT domains and extracts their rich spatial-frequency mixed information, effectively suppressing noise while enhancing the representation of subtle differences. In addition, an adaptive weighted metric learning (AWML) framework is designed to merge multiorder fractional Fourier domain information in an adaptively weighted fusion manner. It introduces deep metric learning to explore the distances between samples of different categories that have relatively high similarity, so as to guide the direction of adaptive weighted fusion. Finally, the differential mask attention (DMA) module is designed to explore global contextual differences between bitemporal HSIs, obtaining change features with well-represented differences. Some experiments conducted on three public datasets indicate that FrFTML outperforms other state-of-the-art methods. Furthermore, the proposed method exhibits superiority in dealing with land cover that may lead to pseudoinvariant phenomena (identification of changed areas as unchanged areas).},
  archive      = {J_TNNLS},
  author       = {Shou Feng and Tianyu Lan and Yuanze Fan and Mengmeng Zhang and Chunhui Zhao and Wei Li and Ran Tao},
  doi          = {10.1109/TNNLS.2025.3586714},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-17},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {An adaptive weighted metric learning network based on fractional domain decoupling for hyperspectral change detection},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interactive graph learning for multilevel network alignment. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3592415'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of network alignment aims to identify corresponding nodes across multiple networks, with applications in various fields such as social network analysis and bioinformatics. Traditional methods typically focus on the topological structure of networks at a specific level, but they may overlook important properties exhibited by many networks, such as scale-free properties and specific power-law structures often found in social networks. Consequently, these methods fail to effectively capture and utilize such information, leading to misalignment. In this article, we propose a network alignment framework that incorporates both topological and attribute information from multiple levels in the network, including homogeneity, power-law, and higher order structures. We introduce a Euclidean hyperbolic interactive graph learning method specifically designed for modeling power-law structures in networks, aiming to improve the accuracy of network alignment. To evaluate the effectiveness of our proposed method, we conduct experiments on several real-world datasets. The results demonstrate that our approach achieves higher accuracy compared to other advanced baselines.},
  archive      = {J_TNNLS},
  author       = {Pengfei Jiao and Yuanqi Liu and Yinghui Wang and Huijun Tang and Zhidong Zhao and Shirui Pan},
  doi          = {10.1109/TNNLS.2025.3592415},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Interactive graph learning for multilevel network alignment},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Observer-based event-triggered fault-tolerant synchronization for memristive neural networks subject to multiple failures. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3596704'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, the synchronization problem of memristive neural networks (MNNs) subjected to multiple failures is investigated. First, a general form of fault model is introduced into the MNNs, which can represent and summarize various process faults, actuator faults, and their coupling. Subsequently, with the help of designing intermediate variables, two types of fault function observers based on state feedback and output feedback are constructed, and their effectiveness is verified through a generalization of Halanay-type inequalities. Then, based on the designed observers and the event-triggered strategy, two classes of fault-tolerant synchronization schemes are designed for the considered MNNs. By adjusting the controller parameter conditions, finite-time and fixed-time synchronization or quasi-synchronization of the considered MNNs system can be achieved, respectively. Finally, the effectiveness of the provided fault observers and synchronization strategies is verified through simulation and comparison experiments.},
  archive      = {J_TNNLS},
  author       = {Mingxin Wang and Song Zhu and Xiaoyang Liu and Shiping Wen and Chaoxu Mu},
  doi          = {10.1109/TNNLS.2025.3596704},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Observer-based event-triggered fault-tolerant synchronization for memristive neural networks subject to multiple failures},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving sample efficiency of reinforcement learning with background knowledge from large language models. <em>TNNLS</em>, 1-12. (<a href='https://doi.org/10.1109/TNNLS.2025.3590731'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low sample efficiency is an enduring challenge of reinforcement learning (RL). With the advent of versatile large language models (LLMs), recent works impart common-sense knowledge to accelerate policy learning for RL processes. However, we note that such guidance is often tailored for one specific task but loses generalizability. In this article, we introduce a framework that harnesses LLMs to extract background knowledge of an environment, which contains general understandings of the entire environment, making various downstream RL tasks benefit from one-time knowledge representation. We ground LLMs by feeding a few precollected experiences and requesting them to delineate background knowledge of the environment. Afterward, we represent the output knowledge as potential functions for potential-based reward shaping, which has a good property for maintaining policy optimality from task rewards. We instantiate three variants to prompt LLMs for background knowledge, including writing code, annotating pReferences, and assigning goals. Our experiments show that these methods achieve significant sample efficiency improvements in a spectrum of downstream tasks from Minigrid and Crafter domains.},
  archive      = {J_TNNLS},
  author       = {Fuxiang Zhang and Junyou Li and Yi-Chen Li and Zongzhang Zhang and Yang Yu and Deheng Ye},
  doi          = {10.1109/TNNLS.2025.3590731},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Improving sample efficiency of reinforcement learning with background knowledge from large language models},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DLCNN: A deep logic convolutional network for interpretable fault diagnosis of hoist mechanism on ship-to-shore cranes. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3594346'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fault diagnosis of hoist mechanisms in ship-to-shore cranes (STSCs) is paramount for maintaining shipping schedules and ensuring personnel safety at ports. Although deep networks have achieved some success in diagnosing faults in hoist mechanisms, their opaque nature often precludes them from providing trustworthy explanations for their decisions. To address this problem, this article introduces a deep logic convolutional neural network (DLCNN), which incorporates two symbolic languages (confidence and classification rules) to visualize how convolutional neural networks (CNNs) work. Confidence rules are extracted from logic convolutions (LCs). In the LC, confidence rules are designed from three perspectives—information loss, the tradeoff between soundness and interpretability, and quantitative reasoning—to provide a comprehensive understanding of the feature learning and reasoning of stacked convolutions. Besides, classification rules are extracted from CNN’s full-connected layers to elucidate implicit relationships between fault features and labels. Our experimental investigations on an STSC testbed demonstrate that DLCNNs have powerful performance in fault recognition, interpretability, and potential engineering value.},
  archive      = {J_TNNLS},
  author       = {Xiaoqiang Liao and Dong Wang and Xinguo Ming and Min Xia},
  doi          = {10.1109/TNNLS.2025.3594346},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {DLCNN: A deep logic convolutional network for interpretable fault diagnosis of hoist mechanism on ship-to-shore cranes},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Constraint-driven causal representation learning for vigilance robust estimation in Brain–Computer interface. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3594434'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vigilance estimation is a critical task within the field of brain–computer interfaces, extensively applied in monitoring and optimizing user states during human–machine interaction using electroencephalography (EEG). However, most existing vigilance prediction frameworks are prone to spurious correlations stemming from inherent biases in collected data. These biases involve relevant but vigilance-independent information, which may lack robustness when applied to different data distributions, i.e., out-of-distribution (OOD) scenarios. The core idea of this study is to learn constraints that capture causal information from the input based on the assumed underlying data generating process. Leveraging the disentanglement and invariance principles behind the assumptions, we propose a constraint-driven causal representation learning (CCRL) to identify and separate spurious latent variables from biased training data for generalized vigilance estimation. The CCRL training process consists of two phases: self-supervised pretraining and constraint-driven causal information disentanglement. In the first phase, based on the masked autoencoder (MAE) architecture, unlabeled training data are used for reconstructing pretext tasks to capture the comprehensive and intrinsic contextual information from EEG data, which provides a powerful input for downstream disentanglement learning. In the second phase, we propose a novel disentanglement strategy to learn spurious-free latent representations causally related to the vigilance state driven by adversarial and invariance constraints. Comprehensive validation experiments conducted on two well-known public datasets demonstrate the effectiveness and superiority of the proposed framework. In general, this work has promising implications for addressing OOD challenges in vigilance estimation.},
  archive      = {J_TNNLS},
  author       = {Xuan Zhang and Wang Zheng and Zhigang Li and Yi Yang and Weijia Liu and Hongxin Cai and Junru Zhu and Jingyu Liu and Bin Hu and Qunxi Dong},
  doi          = {10.1109/TNNLS.2025.3594434},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Constraint-driven causal representation learning for vigilance robust estimation in Brain–Computer interface},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Strategic evolutionary reinforcement learning with operator selection and experience filter. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3596553'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The shared replay buffer is the core of synergy in evolutionary reinforcement learning (ERL). Existing methods overlooked the objective conflict between population evolution in evolutionary algorithm and ERL, leading to poor quality of the replay buffer. In this article, we propose a strategic ERL algorithm with operator selection and experience filter (SERL-OS-EF) to address the objective conflict issue and improve the synergy from three aspects: 1) an operator selection strategy is proposed to enhance the performance of all individuals, thereby fundamentally improving the quality of experiences generated by the population; 2) an experience filter is introduced to filter the experiences obtained from the population, maintaining the long-term high quality of the buffer; and 3) a dynamic mixed sampling strategy is introduced to improve the efficiency of RL agent learning from the buffer. Experiments in four MuJoCo locomotion environments and three Ant-Maze environments with deceptive rewards demonstrate the superiority of the proposed method. In addition, the practical significance of the proposed method is verified on a low-carbon multienergy microgrid (MEMG) energy management task.},
  archive      = {J_TNNLS},
  author       = {Kaitong Zheng and Ya-Hui Jia and Kejiang Ye and Wei-Neng Chen},
  doi          = {10.1109/TNNLS.2025.3596553},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Strategic evolutionary reinforcement learning with operator selection and experience filter},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cluster-aware few-shot molecular property prediction with factor disentanglement. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3590240'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Molecular property prediction plays a crucial role in drug discovery, but is always challenged by the limited number of effective labels. Compared with existing methods, we argue that the auxiliary properties of the molecule and the heterogeneous structure of different property prediction tasks have always been ignored. In this article, we propose a novel framework termed Meta-DREAM for few-shot molecular property prediction, which tailors to learning the transferable knowledge within different clusters of tasks. Specifically, we first construct a heterogeneous molecule relation graph (HMRG) with molecule–property and molecule–molecule relations to utilize many-to-many correlations between properties and molecules. The meta-learning episode can, then, be reformulated as a subgraph of HMRG. Next, we propose a disentangled graph encoder to explicitly discriminate the underlying factors of the task. In addition, we introduce a soft clustering module to group each factorized task representation into appropriate clusters and preserve knowledge generalization within a cluster and customization among clusters. In this way, each disentangled factor serves as a cluster-aware parameter gate for the task-specific meta-learner. Extensive experiments on five commonly used molecular datasets show that Meta-DREAM consistently outperforms existing state-of-the-art methods and verifies the effectiveness of each module.},
  archive      = {J_TNNLS},
  author       = {Haodong Zhang and Tao Ren and Yifan Wang and Fanchun Meng and Wei Ju and Ying Tian},
  doi          = {10.1109/TNNLS.2025.3590240},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Cluster-aware few-shot molecular property prediction with factor disentanglement},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gen-GraphEx: Generative in-distribution graph explanations for time-efficient model-level interpretability of GNNs. <em>TNNLS</em>, 1-16. (<a href='https://doi.org/10.1109/TNNLS.2025.3589330'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have become the prevailing methodology for addressing graph data-related tasks, permeating critical domains like recommendation systems and drug development. The necessity for trustworthiness and interpretability of GNNs has risen to the forefront, especially given their direct impact on end users’ lives. To address this need, we present Gen-GraphEx, a model-agnostic, model-level explanation method that prioritizes user centricness by eliminating the need for having access to the hidden layers of the GNN model it seeks to explain. Given a particular class label, Gen-GraphEx learns a graph generative model (GGM) that produces explanation graphs that not only contain discriminative patterns that the GNN has learned for that class but also lie in distribution with real graphs that belong to that class according to the GNN. Unlike existing state-of-the-art models, Gen-GraphEx also has the unique ability to interpolate the GGMs of two target classes to generate instances that lie near the decision boundary of the two classes giving a deeper insight into the model’s decision-making. Its advantages over existing methods in the literature also include nonreliance on another subsequent deep learning module for explanation generation, ability to generate graphs with various node and edge features, and being more computationally efficient. Extensive validation and thorough comparative analysis of the proposed approach is carried out across an array of real and synthetic datasets that consistently demonstrate its exceptional performance and competitiveness ranking alongside state-of-the-art model-level explainers. Our code is available at https://github.com/amisayan/Gen-GraphEx},
  archive      = {J_TNNLS},
  author       = {Sayan Saha and Monidipa Das and Sanghamitra Bandyopadhyay},
  doi          = {10.1109/TNNLS.2025.3589330},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Gen-GraphEx: Generative in-distribution graph explanations for time-efficient model-level interpretability of GNNs},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distilling reasoning ability from large language models with adaptive thinking. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3591266'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chain-of-thought distillation (CoT-distillation) aims to endow small language models (SLMs) with reasoning ability to improve their performance toward specific tasks by allowing them to imitate the reasoning procedure of large language models (LLMs) beyond simply predicting the answers. Most existing CoT-distillation methods adopt a pre-thinking mechanism, allowing the SLM to generate a rationale before answering. In this way, pre-thinking enables SLM to analyze questions but makes answer correctness sensitive to minor errors in rationale. Therefore, we propose a robust post-thinking mechanism to generate answers before the rationale. Thanks to this answer-first setting: 1) the answer can escape from the rationale-sensitive problem; 2) the rationale serves as an error amplifier, making SLM focus on learning hard samples; and 3) the inferring efficiency can also benefit. Although post-thinking brings many advantages, it may lose the ability to analyze complex questions compared to pre-thinking. Therefore, a plug-and-play adaptive-thinking mechanism is proposed to integrate the merits of pre-thinking and post-thinking, in which a perception module based on soft prompt tuning is introduced to prompt SLM to answer or think first according to the complexity of questions. Extensive experiments are conducted across 12 datasets and 2 language models to demonstrate the effectiveness of the proposed mechanism.},
  archive      = {J_TNNLS},
  author       = {Xiaoshu Chen and Sihang Zhou and Ke Liang and Xinwang Liu},
  doi          = {10.1109/TNNLS.2025.3591266},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Distilling reasoning ability from large language models with adaptive thinking},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Event-triggered mixed nonzero-sum game optimal control for modular robotic manipulator performing coordinated operation tasks. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3595563'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Taking advantage of high-performance intelligent robots to solve the coordination control problem such as assembly, handling, and installation, transportation is gradually becoming a kind of frontier subject with great scientific research value in the field of robotics. However, due to possible conflicts and inconsistencies between the manipulator and the operating object, it is challenging to design the optimal coordination control scheme between human and robot. This article presents an event-triggered mixed nonzero-sum game optimal control method, which considers both nonzero-sum game and cooperative game cases, for modular robotic manipulator (MRM) systems performing coordinated operation tasks. First, the joint torque feedback technique and joint task assignment method are employed to establish the dynamic model of MRM subsystem, and then, the global state-space description is deduced. For the unknown information containing interconnected dynamic coupling (IDC) terms and friction modeling errors, an adaptive neural network (NN) identifier is established by utilizing the measured input–output data of each joint module. The adaptive updating law guarantees that the NN weight error finally converged to a minimum neighborhood of zero. To ensure the optimality of system overall performance, the corresponding value functions reflecting the interconnectedness among each joint subsystem and manipulated object are constructed. Based on the idea of differential game, the coordination control problem of MRM system is transformed into a mixed nonzero-sum game problem among each joint module and the operated object. Next, by constructing a single critic NN with learning structure, the optimal value function is approximated to solve the event-based Hamiltonian equations, and then, the optimal control strategy of each player is obtained. Finally, the Lyapunov theory is used to analyze system stability, and the effectiveness of the presented method is reinforced by experimental results.},
  archive      = {J_TNNLS},
  author       = {Tianjiao An and Xiaogang Dong and Bo Dong and Hucheng Jiang and Lei Liu and Bing Ma},
  doi          = {10.1109/TNNLS.2025.3595563},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Event-triggered mixed nonzero-sum game optimal control for modular robotic manipulator performing coordinated operation tasks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedLSC: Improving communication efficiency and robustness in federated learning with stragglers and adversaries. <em>TNNLS</em>, 1-16. (<a href='https://doi.org/10.1109/TNNLS.2025.3590015'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite significant progress in federated learning (FL), persistent challenges, such as stragglers, adversaries, and communication costs remain. To address these issues, we propose FedLSC, a novel FL framework that leverages layer-selected correlation (LSC) to enhance both robustness and efficiency. In contrast to the existing methods, FedLSC does not rely on public data during model training, making it more practical and resilient in real-world scenarios. FedLSC introduces three key innovations: 1) preprocessing of layer selection (LS), which identifies significant layers to reduce communication costs and performance degradation; 2) local updates using LS-based scaled sign-stochastic gradient descent (SSS), introducing a layer-specific scaling mechanism to mitigate performance loss from quantization and significantly reduce communication costs; and 3) model aggregation via LSC-based schemes, which enhances robustness by processing only the significant layers and mitigating the impact of stragglers and adversaries. Furthermore, integrating the SSS scheme into FedLSC reduces communication costs to as little as 0.01% of those in state-of-the-art (SOTA) method while maintaining performance. Evaluations conducted across various FL scenarios show that FedLSC effectively supports robust performance and efficiency, even in bandwidth-constrained environments, thereby confirming its practicality in modern FL applications.},
  archive      = {J_TNNLS},
  author       = {Hyeong-Gun Joo and Songnam Hong and Dong-Joon Shin},
  doi          = {10.1109/TNNLS.2025.3590015},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {FedLSC: Improving communication efficiency and robustness in federated learning with stragglers and adversaries},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Wormhole dynamics in deep neural networks. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3591614'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work investigates the generalization behavior of deep neural networks (DNNs), focusing on the phenomenon of “fooling examples,” where DNNs confidently classify inputs that appear random or unstructured to humans. To explore this phenomenon, we introduce an analytical framework based on maximum likelihood estimation (MLE), without adhering to conventional numerical approaches that rely on gradient-based optimization and explicit labels. Our analysis reveals that DNNs operating in an overparameterized regime exhibit a collapse in the output feature space. While this collapse improves network generalization, adding more layers eventually leads to a state of degeneracy, where the model learns trivial solutions by mapping distinct inputs to the same output, resulting in zero loss. Further investigation demonstrates that this degeneracy can be bypassed using our newly derived “wormhole” solution. The wormhole solution, when applied to arbitrary fooling examples, reconciles meaningful labels with random ones and provides a novel perspective on shortcut learning. These findings offer deeper insights into DNN generalization and highlight directions for future research on learning dynamics in unsupervised settings to bridge the gap between theory and practice.},
  archive      = {J_TNNLS},
  author       = {Yen-Lung Lai and Zhe Jin},
  doi          = {10.1109/TNNLS.2025.3591614},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Wormhole dynamics in deep neural networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Progressive structure preservation and detail refinement for remote sensing single-image super-resolution. <em>TNNLS</em>, 1-17. (<a href='https://doi.org/10.1109/TNNLS.2025.3589209'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in deep-learning-based remote sensing image super-resolution (RSISR) have garnered significant attention. Conventional models typically perform upsampling at the end of the architecture, which reduces computational effort but leads to information loss and limits image quality. Moreover, the structural complexity and texture diversity of remote sensing images pose challenges in detail preservation. While transformer-based approaches improve global feature capture, they often introduce redundancy and overlook local details. To address these issues, we propose a novel progressive structure preservation and detail refinement super-resolution (PSPDR-SR) model, designed to enhance both structural integrity and fine details in RSISR. The model comprises two primary subnetworks: the structure-aware super-resolution (SaSR) subnetwork and the detail recovery and refinement (DR&R) subnetwork. To efficiently leverage multilayer and multiscale feature representations, we introduce coarse-to-fine dynamic information transmission (C2FDIT) and fine-to-coarse dynamic information transmission (F2CDIT) modules, which facilitate the extraction of richer details from low-resolution (LR) remote sensing images. These modules integrate transformers and convolutional long short-term memory (ConvLSTM) blocks to form dynamic information transmission modules (DITMs), enabling effective bidirectional feature transmission both horizontally and vertically. This method ensures comprehensive feature fusion, mitigates redundant information, and preserves essential extracted features within the deep network. Experimental results demonstrate that PSPDR-SR outperforms the state-of-the-art approaches on two benchmark datasets in both quantitative and qualitative evaluations, excelling in structure preservation and detail enhancement across various metrics, including SSIM, MS_SSIM, learned perceptual image patch similarity (LPIPS), deep image structure and texture similarity (DISTS), spatial correlation coefficient (SCC), and spectral angle mapper (SAM).},
  archive      = {J_TNNLS},
  author       = {Wei-Yen Hsu and Shih-Hao Huang and Jing-Wen Lin},
  doi          = {10.1109/TNNLS.2025.3589209},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-17},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Progressive structure preservation and detail refinement for remote sensing single-image super-resolution},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey of attacks on large Vision–Language models: Resources, advances, and future trends. <em>TNNLS</em>, 1-21. (<a href='https://doi.org/10.1109/TNNLS.2025.3592935'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the significant development of large models in recent years, large vision–language models (LVLMs) have demonstrated remarkable capabilities across a wide range of multimodal understanding and reasoning tasks. Compared with traditional large language models (LLMs), LVLMs present great potential and challenges due to their closer proximity to the multiresource real-world applications and the complexity of multimodal processing. However, the vulnerability of LVLMs is relatively underexplored, posing potential security risks in the daily use of LVLM applications. In this article, we provide a comprehensive review of the various forms of existing LVLM attacks. Specifically, we first introduce the background of attacks targeting LVLMs, including the attack preliminary, attack challenges, and attack resources. Then, we systematically review the development of LVLM attack methods, such as adversarial attacks that manipulate model outputs, jailbreak attacks that exploit model vulnerabilities for unauthorized actions, prompt injection attacks that engineer the prompt type and pattern, and data poisoning that affects model training. Finally, we discuss promising future research directions in LVLM attacks. We believe that our survey provides insights into the current landscape of LVLM vulnerabilities, inspiring more researchers to explore and mitigate potential safety issues in LVLM developments.},
  archive      = {J_TNNLS},
  author       = {Daizong Liu and Mingyu Yang and Xiaoye Qu and Pan Zhou and Yu Cheng and Wei Hu},
  doi          = {10.1109/TNNLS.2025.3592935},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-21},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A survey of attacks on large Vision–Language models: Resources, advances, and future trends},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning a better SPD network for signal classification: A riemannian batch normalization method. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3589362'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Symmetric positive definite (SPD) matrices have been widely used as Riemannian feature descriptors in various scientific fields, due to their capacity to encode effective manifold-valued representations. Inspired by the architectural principles of Euclidean deep learning, the emerging SPD neural networks have achieved more robust signal classification. Among these advancements, Riemannian batch normalization (RBN) based on the affine-invariant Riemannian metric (AIRM) has emerged as a key technique for enhancing the learning capability of SPD-based networks. Nevertheless, the reliance of singular value decomposition (SVD) makes this metric relatively unstable for the computation of SPD matrices, especially for the ill-conditioned case. To address this limitation, we propose a novel RBN algorithm based on the recently introduced log-Cholesky metric (LCM), which leverages Cholesky decomposition. Unlike AIRM, the LCM offers enhanced numerical stability and allows for more efficient computation. Specifically, the LCM-based Riemannian operators such as Fr $\acute {\mathrm {e}}$ chet mean and parallel transport (PT) are much simpler than those of AIRM, and both have closed forms. Besides, since LCM is the pullback metric from the Cholesky manifold via Cholesky decomposition, the LCM-based RBN on the SPD manifold can be computed in the Cholesky manifold, further boosting the efficiency. Extensive experiments conducted on four benchmarking datasets certify the effectiveness of our proposed algorithm. The source code is now available at: https://github.com/jjscc/CBN.git.},
  archive      = {J_TNNLS},
  author       = {Rui Wang and Shaocheng Jin and Zhenyu Cai and Ziheng Chen and Xiao-Jun Wu and Josef Kittler},
  doi          = {10.1109/TNNLS.2025.3589362},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Learning a better SPD network for signal classification: A riemannian batch normalization method},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bidirectional multiscale efficient dilated convolutional recurrent neural network improved by swarm intelligence optimization. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3596244'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, bidirectional convolutional recurrent neural networks (RNNs) have made significant breakthroughs in addressing a wide range of challenging problems related to time series and prediction applications. However, the performance of the models is highly dependent on the hyperparameters chosen. Hence, we propose an automatic method for hyperparameter optimization and apply a bidirectional convolutional RNN based on the improved swarm intelligence optimization (sparrow search) to solve regression prediction problems. Specifically, a parallel multiscale dilated convolution (PMDC) module was designed to capture both local and global spatial correlations. This method utilizes convolution with different dilation rates to expand the receptive field without increasing the complexity of the model. Meanwhile, it integrates parallel multiscale structures to extract features at different scales and enhance the model’s understanding of the input data. Then, the bidirectional gated recurrent units (BGRUs) learn temporal information from the convolutional features. To address the limitations of empirical hyperparameter selection, such as slow training and low efficiency, a novel PMDC-BGRU model integrated with a pretrained sparrow search algorithm (SSA) was proposed for hyperparameter optimization. Finally, experiments on multiple datasets verified the superiority of the algorithm and explained the flexibility of intelligent optimization algorithms in solving model parameter optimization.},
  archive      = {J_TNNLS},
  author       = {Qinwei Fan and Shuai Zhao and Jacek M. Zurada and Tingwen Huang and Xiaolong Qin and Rui Zhang},
  doi          = {10.1109/TNNLS.2025.3596244},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Bidirectional multiscale efficient dilated convolutional recurrent neural network improved by swarm intelligence optimization},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Information-state-based reinforcement learning for the control of partially observed nonlinear systems. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3593259'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article develops a model-based reinforcement learning (RL) approach to the closed-loop control of nonlinear dynamical systems with a partial nonlinear observation model. We propose an “information-state”-based approach to rigorously transform the partially observed problem into a fully observed problem where the information state consists of the past several observations and control inputs. We further show the equivalence of the transformed and the initial partially observed optimal control problems and provide the conditions to solve for the deterministic optimal solution. We develop a data-based generalization of the iterative linear quadratic regulator (ILQR) for the RL of partially observed systems using a local linear time-varying model of the information-state dynamics approximated by an autoregressive-moving-average (ARMA) model that is generated using only the input–output data. This approach allows us to design a local perturbation feedback control law that provides an optimum solution to the partially observed feedback design problem locally. The efficacy of the developed method is shown by controlling complex high-dimensional nonlinear dynamical systems in the presence of model and sensing uncertainty.},
  archive      = {J_TNNLS},
  author       = {Raman Goyal and Mohamed Naveed Gul Mohamed and Ran Wang and Aayushman Sharma and Suman Chakravorty},
  doi          = {10.1109/TNNLS.2025.3593259},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Information-state-based reinforcement learning for the control of partially observed nonlinear systems},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attribute prompt alignment network for zero-shot learning. <em>TNNLS</em>, 1-7. (<a href='https://doi.org/10.1109/TNNLS.2025.3598191'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the vanilla zero-shot learning (ZSL) paradigm, category attributes is the key for knowledge generalizable transfer from seen to unseen classes. By contrast, the current contrastive language-image pretraining (CLIP) model relies on the category names to achieve a more general ZSL-like prediction. When vanilla ZSL meets general CLIP, however, most existing methods on both sides struggle to benefit from each other. In this brief, we resort to attribute prompt tuning (APT) for improving the knowledge transferability from the pretrained CLIP model to the downstream ZSL framework for pursuing desirable feature representations. Our approach, termed as attribute prompt alignment network (APAN), leverages APT for cross-network feature alignment (CFA). In this way, we can investigate the effects of CLIP to vanilla ZSL task in the era of large model by the two branch APAN architecture. Specifically, APT takes as an input the templates of class attribute descriptions to produce attribute prompts, which are further used to both guide the localizations of visual regions across two frozen feature extraction networks, through a visual-semantic interaction attention. This enables APAN to progressively refine and align these cross-network features, thus resulting in generalizable feature representations that can capture fine-grained attribute information. For CFA, we simply introduce prediction alignment loss that constrains the predictions from these two cross-network visual features. Experimental results on three benchmark datasets well demonstrate that APAN outperforms the state-of-the-art methods by absorbing generalizable knowledge from CLIP models.},
  archive      = {J_TNNLS},
  author       = {Guo-Sen Xie and Junyi Li and Ting Guo and Xiangbo Shu and Fang Zhao and Zheng Zhang and Ling Shao},
  doi          = {10.1109/TNNLS.2025.3598191},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-7},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Attribute prompt alignment network for zero-shot learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge-GPT guided generalizable reinforcement learning for intelligent emergency generator tripping in power system. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3596964'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emergency control is essential for ensuring transient stability in power systems after faults. This study addresses the limitations in existing methods by proposing a knowledge-generative pretrained transformer (GPT)-guided generalizable reinforcement learning (RL) approach for intelligent emergency generator tripping. This approach incorporates general electrical principles and knowledge-GPT to assist deep reinforcement learning (DRL). The general electrical principles involve identifying severely disturbed generators and selecting appropriate control actions through dynamic probability. The knowledge-GPT model extracts insights from an expert strategy knowledge base, reshaping the DRL reward structure by comparing the DRL strategy with the knowledge-GPT outputs. This paradigm is designed to leverage electrical laws and domain expertise to guide the DRL training process, thereby enhancing both training efficiency and electrical consistency. To enhance generalization capability under topological changes, message passing neural networks (NNs) are integrated into the DRL architecture, effectively simulating power flow dynamics in transmission lines. The proposed method is validated through simulations on the IEEE 39-bus system and the Northeast power grid of China, demonstrating superior control effectiveness and adaptability compared to existing approaches, offering a more robust solution for emergency control in complex power systems.},
  archive      = {J_TNNLS},
  author       = {Bing Wang and Tianjing Wang and Yong Tang and Yanhao Huang},
  doi          = {10.1109/TNNLS.2025.3596964},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Knowledge-GPT guided generalizable reinforcement learning for intelligent emergency generator tripping in power system},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). REaMA: Building biomedical relation extraction specialized large language models through instruction tuning. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3596257'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming to identify entity pairs with biomedical semantic relations and assign specific relation types, biomedical relation extraction (BioRE) plays a critical role in biomedical text mining and information extraction (IE). Recent studies indicate that general large language models (LLMs) have made some breakthroughs in general relation extraction (RE) tasks. However, even the advanced open-source LLMs struggle with BioRE tasks. For example, WizardLM-70B and LLaMA-2-70B achieve F-scores of 14.05 and 12.21 on the BioRED dataset, respectively, significantly lagging behind the state-of-the-art (SOTA) method which scores 65.17. To address this gap, a multitask instruction-tuning framework is proposed, which can transform general LLMs into BioRE-specialized models with our meticulously curated instruction dataset, REInstruct, comprising 150000 diverse and quality instruction-response pairs. Consequently, we introduce REaMA, a series of open-source LLMs with sizes of 7B and 13B specifically tailored for BioRE tasks. Experimental results on seven representative BioRE datasets show that both REaMA-2-7B and REaMA-2-13B acquire promising performance on all datasets. Remarkably, the larger REaMA-2-13B outperforms the current SOTA method on five out of seven datasets. The result exhibits the effectiveness of instruction-tuning on REInstruct in eliciting strong RE capabilities in LLMs. Furthermore, we show that incorporating chain of thought (CoT) into REInstruct can further enhance the generalization ability of REaMA. The project is available at https://github.com/stzpp/REaMA},
  archive      = {J_TNNLS},
  author       = {Yidan Zhang and Junlin Yu and Guobo Li and Zhenan He and Gary G. Yen},
  doi          = {10.1109/TNNLS.2025.3596257},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {REaMA: Building biomedical relation extraction specialized large language models through instruction tuning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward the extension and enhanced representation for ambiguous query with search heterogeneous graph learning. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3599630'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In an online search, users often input an ambiguous short query to search engines, which leads to search engines being unable to accurately understand the true users’ query intent. Thus, enhancing the users’ query intent is necessary. Traditional methods of guessing and inferring user intentions are based on either personal past search data, or the group’s search history data. The former faces the cold start problem for new users due to the lack of search history data, while the latter cannot accurately get the intent of new search requests due to different users having different intentions even for the same search query. To solve the above issues and to enhance the representation of search requests by adding some query keywords, we construct a user-query-document search heterogeneous graph with users’ search history data of their friend networks, which can express the behavioral features and interrelationships of searches. To facilitate the enhanced representation of a query intent, we present TAHAN, a type-aware heterogeneous graph attention network (GAT) model. Extensive experiments on real-world datasets show that our method not only outperforms the state-of-the-art models, but also achieves superior performance in addressing the data sparsity and cold-start problems.},
  archive      = {J_TNNLS},
  author       = {Youli Fang and Guosun Zeng},
  doi          = {10.1109/TNNLS.2025.3599630},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Toward the extension and enhanced representation for ambiguous query with search heterogeneous graph learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Soft sensing for time series with irregular sampling internals based on a denoising interval attention LSTM network. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3598583'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prediction of key quality variables plays an important role in industrial status identification and monitoring. Due to process disturbance and hard device limitation, data collection in modern industries often exhibits high noise and irregular data sampling. To solve the above problems, this article proposes a stacked supervised and reconstructed input denoising autoencoder integrated with internal attention long short-term memory (SSRDAE-IALSTM) network for soft sensing modeling. First, a stacked supervised and reconstructed input denoising autoencoder (SSRDAE) is designed. Compared with the original DAE, each supervised and reconstructed input DAE (SRDAE) can simultaneously reconstruct the process data and quality data at the output layer, aiming to reduce information loss and extract quality-related features. Second, the denoised features are fed into the interval attention LSTM (IALSTM) to adjust the influence of different historical samples on the current sample in irregular sampling data to capture long-term temporal features. Finally, performance validations are carried out on an industrial debutanizer column and a penicillin fermentation process. The experimental results show that the proposed model can enhance the learning ability of process features and obtain better prediction performance than other comparison methods.},
  archive      = {J_TNNLS},
  author       = {Yuchen He and Xueqin Yang and Lijuan Qian and Le Yao and Lingjian Ye and Ping Wu and Gangyue Ye and Weirong Ye and Yafang Shen},
  doi          = {10.1109/TNNLS.2025.3598583},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Soft sensing for time series with irregular sampling internals based on a denoising interval attention LSTM network},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fast wang kWTA with application in sealed-bid uniform price auction. <em>TNNLS</em>, 1-6. (<a href='https://doi.org/10.1109/TNNLS.2025.3597722'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this brief, two fast discrete-time Wang kWTA (Fast Wang kWTA) algorithms are presented with an application in sealed-bid uniform price auctions. These algorithms can either be implemented in centralized or distributed manner. The structure of the Fast Wang kWTA is essentially the same as the original Wang k-winner-take-all (kWTA), except that our state update method is based on bisection method instead of gradient descent. By that, the number of iterations for getting correct output is largely reduced. Besides, the number is just a factor depended on the guess of the maximum input value. It is independent of the number of inputs, the number of winners, and the learning step size. The number of iterations is far smaller than the number required in the original Wang kWTA. In sequel, this Fast Wang kWTA is particularly suitable to be applied in solving the winner (resp. price) determination in real time and in distributed manner for a sealed-bid auction. In addition, the Fast Wang kWTA can ensure bidding price protection even if the communicated data are not encrypted and leaked.},
  archive      = {J_TNNLS},
  author       = {John Sum and Chi-Sing Leung and Janet Chun-Chi Chang},
  doi          = {10.1109/TNNLS.2025.3597722},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-6},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A fast wang kWTA with application in sealed-bid uniform price auction},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hyperbolic hierarchical representation learning for generalized category discovery. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3597074'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the problem of generalized category discovery (GCD), an advanced and challenging semi-supervised learning scenario that deals with unlabeled data from both known and novel categories. Although recent research has effectively engaged with this issue, these studies typically map features into Euclidean space, which fails to maintain the latent semantic hierarchy of the training samples effectively. This limitation restricts the exploration of more detailed and rich information and degrades the performance in discovering new categories. The emerging field of hyperbolic representation learning suggests that hyperbolic geometry could be advantageous for extracting semantic information to tackle this problem. Motivated by this, we proposed hyperbolic hierarchical representation learning for GCD (HypGCD). Specifically, HypGCD enhances representations in hyperbolic space, building upon the Euclidean space representation from two perspectives: instance-class level and instance-instance level. At the instance-class level, HypGCD endeavors to construct well-defined clusters, with each sample forming a robust hierarchical cluster structure. Concurrently, at the instance-instance level, HypGCD anticipates that a subset of samples will display a tree-like structure in local space, which aligns more closely with real-world scenarios. Finally, HypGCD optimizes the Euclidean and hyperbolic space collectively to obtain refined features. Additionally, we show that HypGCD is exceptionally effective, achieving state-of-the-art (SOTA) results on several datasets. The code is available at https://github.com/DuannYu/HypGCD },
  archive      = {J_TNNLS},
  author       = {Yu Duan and Feiping Nie and Huimin Chen and Zhanxuan Hu and Rong Wang and Xuelong Li},
  doi          = {10.1109/TNNLS.2025.3597074},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Hyperbolic hierarchical representation learning for generalized category discovery},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive learning rate methods for complex-valued neural networks. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3596513'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial neural networks (ANNs) have become a popular tool in digital signal processing (DSP). Among the widespread ANN architectures, complex-valued neural networks (CVNNs) have been extensively studied in image processing and telecommunications. Unlike their real-valued counterparts, CVNNs can handle signals directly in the complex domain. Due to this capability, CVNNs usually exhibit higher accuracy and improved convergence compared to real-valued neural networks (RVNNs). Despite their improved performance in several applications, CVNNs still lag behind RVNNs in terms of learning techniques and heuristics. In this context, we propose adaptive learning rate approaches for CVNNs, extending the well-known adaptive gradient (AdaGrad), root-mean-square propagation (RMSProp), AdaMax, AMSGrad, softplus AMSGrad (SAMSGrad), Nesterov-accelerated adaptive moment estimation (Nadam), and DiffGrad to the complex domain. Computational complexities of the proposed optimizers are analyzed for CVNN architectures. Results are compared in terms of mean-squared-error convergence.},
  archive      = {J_TNNLS},
  author       = {Kayol S. Mayer and Jonathan A. Soares and Ariadne A. Cruz and Dalton S. Arantes},
  doi          = {10.1109/TNNLS.2025.3596513},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Adaptive learning rate methods for complex-valued neural networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Geometric deep learning for the rubik’s cube group. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3599009'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Rubik’s cube, a widely recognized combinatorial puzzle with an astronomically vast state space, has been the subject of various research experiments with neural networks used as heuristic estimators to navigate the state-space exploration. However, prior efforts have overlooked the intriguing symmetries inherent to this domain. Drawing on geometric deep learning principles, this article introduces a novel neural architecture that explicitly leverages these symmetries, grounded in a rigorous group-theoretical analysis. The design of the proposed symmetry-invariant model is then validated empirically through an innovative universal procedure for detecting model symmetry invariance. Finally, experimental results demonstrate that the symmetry-aware neural architecture exhibits enhanced generalization and problem-solving efficacy compared with the state of the art.},
  archive      = {J_TNNLS},
  author       = {Martin Krutský and Gustav Šír},
  doi          = {10.1109/TNNLS.2025.3599009},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Geometric deep learning for the rubik’s cube group},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Joint trajectory replanning for mars ascent vehicle under propulsion system faults: A suboptimal learning-based warm-start approach. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3598120'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a suboptimal joint trajectory replanning (SJTR) method for Mars ascent vehicle (MAV) launch missions under propulsion system faults. Conventional step-by-step trajectory replanning may fail to make timely decisions, risking mission failure. The SJTR method formulates a joint convex optimization problem of target orbit and flight trajectory after a fault. By applying penalty coefficients for terminal constraints, it adheres to the orbit redecision principles, enabling a concise and rapid solution. To further enhance the convergence and the accuracy of orbit-type determination, a learning-based warm-start scheme is proposed. Offline, a deep neural network (DNN) is trained with data generated by various trajectory replanning methods following the redecision principles. Online, the DNN provides initial guesses for the time optimization variables based on the fault scenario. Numerical simulations on mass flow rate and specific impulse drops validate the reliability of the proposed method, demonstrating at least 49.5% higher computational efficiency compared with the upgrading and downgrading replanning methods.},
  archive      = {J_TNNLS},
  author       = {Kun Li and Guangtao Ran and Yanning Guo and Ju H. Park and Yao Zhang},
  doi          = {10.1109/TNNLS.2025.3598120},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Joint trajectory replanning for mars ascent vehicle under propulsion system faults: A suboptimal learning-based warm-start approach},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IRPruneDeXt: Efficient infrared small target detection via musical wavelet-regularized channel pruning. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3594958'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infrared small target detection (IRSTD) refers to detecting faint targets in infrared (IR) images, which has achieved notable progress with the advent of deep learning. However, the drive for improved detection accuracy has led to larger, intricate models with redundant parameters, causing storage and computation inefficiencies. In this pioneering study, we introduce the concept of utilizing network pruning to enhance the efficiency of IRSTD. Due to the challenge posed by low signal-to-noise ratios (SNRs) and the absence of detailed semantic information in IR images, directly applying existing pruning techniques yields suboptimal performance. To address this, we propose a novel wavelet structure-regularized multidimensional musical scale soft channel pruning (SCP) method, giving rise to the efficient IRPruneDeXt model. Our approach involves representing the weight matrix in the wavelet domain and formulating a wavelet channel pruning (WCP) strategy. We incorporate wavelet regularization to induce structural sparsity without incurring extra memory usage. Additionally, we design a multidimensional musical scale soft channel reconstruction (MMSCR) method that adapts the strategy across temporal and spatial dimensions to preserve key target information and prevent premature pruning. By leveraging interactions between criteria, it balances pruning and reconstruction through a musical scale feedback effect, achieving an optimal sparse structure while maintaining overall sparsity. Through extensive experiments on many widely used benchmarks, our IRPruneDeXt method surpasses established techniques in both model complexity and accuracy. Specifically, when employing U-net as the baseline network, IRPruneDeXt achieves a 65.68% reduction in parameters and a 51.77% decrease in floating-point operations (FLOPs) while improving intersection over union (IoU) from 73.31% to 76.17% and normalized IoU (nIoU) from 70.92% to 75.08%. The code is available at github.com/hd0013/IRPruneDet},
  archive      = {J_TNNLS},
  author       = {Mingjin Zhang and Jin Feng and Handi Yang and Jie Guo and Yunsong Li and Xinbo Gao},
  doi          = {10.1109/TNNLS.2025.3594958},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {IRPruneDeXt: Efficient infrared small target detection via musical wavelet-regularized channel pruning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust multivariate time series forecasting against intraseries and interseries transitional shift. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3593156'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The nonstationary nature of real-world multivariate time series (MTS) data presents forecasting models with a formidable challenge of the time-variant distribution of time series, referred to as distribution shift. Existing studies on the distribution shift mostly adhere to adaptive normalization techniques for alleviating temporal mean and covariance shifts or time-variant modeling for capturing temporal shifts. Despite improving model generalization, these normalization-based methods often assume a time-invariant transition between outputs and inputs but disregard specific intraseries/interseries correlations, while time-variant models overlook the intrinsic causes of the distribution shift. This limits the model’s expressiveness and interpretability in tackling the distribution shift for MTS forecasting. To mitigate such a dilemma, we present a unified Probabilistic Graphical Model to Jointly capture intraseries/interseries correlations and model the time-variant transitional distribution and instantiate a neural framework called JointPGM for nonstationary MTS forecasting. Specifically, JointPGM first employs multiple Fourier basis functions to learn dynamic time factors and designs two distinct learners: intraseries and interseries learners. The intraseries learner effectively captures temporal dynamics by utilizing temporal gates, while the interseries learner explicitly models spatial dynamics through multihop propagation, incorporating Gumbel-softmax sampling. These two types of series dynamics are subsequently fused into a latent variable, which is inversely employed to infer time factors, generate a final prediction, and perform the reconstruction. We validate the effectiveness and efficiency of JointPGM through extensive experiments on six highly nonstationary MTS datasets, achieving state-of-the-art (SOTA) forecasting performance of MTS forecasting.},
  archive      = {J_TNNLS},
  author       = {Hui He and Qi Zhang and Kun Yi and Xiaojun Xue and Shoujin Wang and Liang Hu and Longbing Cao},
  doi          = {10.1109/TNNLS.2025.3593156},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Robust multivariate time series forecasting against intraseries and interseries transitional shift},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Satellite pose set estimation by uncertainty-guided conformal keypoint detection. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3598481'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Satellite pose estimation constitutes a critical technology in the aerospace tasks. The tradeoff between accuracy and efficiency becomes paramount for successful mission execution, due to the limited computational resources of on-board systems. Existing methods predominantly provide single-point estimations, which fall short of fulfilling the uncertainty quantification requirements demanded by safety-critical space operations. To address these problems, we first propose uncertainty-guided conformal keypoint detection to predict keypoint inductive conformal prediction (IndCP) set and then design a uncertainty propagation strategy to obtain pose uncertainty set. Specifically, we build our method upon a transformer-based keypoint predictor, which directly outputs uncertainty-guided keypoints. We first propose a nonconformal function to generate keypoint IndCP set to cover the ground-truth keypoint with a certain probability. We then apply Monte Carlo to sample within the keypoint IndCP set and estimate the poses by solving the perspective-n-point (PnP) problem. The top-n poses with the smallest conformal reprojection error are used to construct a convex hull, which are defined as the pose uncertainty set. Furthermore, we take the mean of the top-n poses as the average pose. Experiments on the Spacecraft PosE Estimation challenge Dataset (SPEED) and LineMOD Occlusion (LMO) dataset show that not only the average pose demonstrates higher accuracy but also the pose uncertainty sets can cover the true pose with the certain probability.},
  archive      = {J_TNNLS},
  author       = {Jinghao Wang and Zhang Li and Cong Sun and Yulan Guo and Zi Wang and Qifeng Yu},
  doi          = {10.1109/TNNLS.2025.3598481},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Satellite pose set estimation by uncertainty-guided conformal keypoint detection},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Extrapolation convolution for data prediction on a 2-D grid: Bridging spatial and frequency domains with applications in image outpainting and compressed sensing. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3598745'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extrapolation plays a critical role in machine/deep learning (ML/DL), enabling models to predict data points beyond their training constraints, particularly useful in scenarios deviating significantly from training conditions. This article addresses the limitations of current convolutional neural networks (CNNs) in extrapolation tasks within image restoration and compressed sensing (CS). While CNNs show potential in tasks such as image outpainting and CS, traditional convolutions are limited by their reliance on interpolation, failing to fully capture the dependencies needed for predicting values outside the known data. This work proposes an extrapolation convolution (EC) framework that models missing data prediction as an extrapolation problem using linear prediction within DL architectures. The approach is applied in two domains: first, image outpainting, where EC in encoder–decoder (EnDec) networks replaces conventional interpolation methods to reduce artifacts and enhance fine detail representation; second, Fourier-based CS-magnetic resonance imaging (CS-MRI), where it predicts high-frequency signal values from undersampled measurements in the frequency domain, improving reconstruction quality and preserving subtle structural details at high acceleration factors. Comparative experiments demonstrate that the proposed EC-DecNet and FDRN outperform traditional CNN-based models, achieving high-quality image reconstruction with finer details, as shown by improved peak signal-to-noise ratio (PSNR), structural similarity index (SSIM), and kernel inception distance (KID)/Frechet inception distance (FID) scores. Ablation studies and analysis highlight the effectiveness of larger kernel sizes and multilevel semi-supervised learning in FDRN for enhancing extrapolation accuracy in the frequency domain.},
  archive      = {J_TNNLS},
  author       = {Vazim Ibrahim and Faouzi Alaya Cheikh and Vijayan K. Asari and Joseph Suresh Paul},
  doi          = {10.1109/TNNLS.2025.3598745},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Extrapolation convolution for data prediction on a 2-D grid: Bridging spatial and frequency domains with applications in image outpainting and compressed sensing},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ReCL: A plug-and-play module for enhancing generalized category discovery using transport-based method to uncover the relationship in samples. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3598594'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning systems excel in closed-set environments but face challenges in open-set settings due to mismatched label spaces between training and test data. Generalized category discovery (GCD) is one of such real-world open-set learning problems. In GCD, given a dataset, only a subset of samples is labeled. The model is expected to simultaneously classify samples from labeled and unlabeled classes. Contrastive learning plays a critical role in solving the GCD problem, used to learn discriminative features for samples. However, in contrast to labeled data, due to the absence of label information, unlabeled samples rely solely on unsupervised contrastive loss to learn discriminated features by keeping different views of the same data consistent. Unfortunately, this approach often overlooks the relationships within unlabeled samples. In this article, we propose a relationship-based contrastive learning (ReCL) module. In ReCL, we use a transport-based assignment method to find appropriate samples for each unlabeled data point. Then, a prototype-based fusion method is applied to merge these selected samples, creating a positive anchor in contrastive learning that helps pull the unlabeled samples closer to the corresponding positive anchor. Extensive experimental evaluation across different domains demonstrates that our method can be seamlessly integrated with various existing GCD models and further improve them to achieve the state-of-the-art performance across different benchmarks. Notably, we also analyze the sample selection process between our transport-based method and the cosine similarity-based method. The results show that our method provides samples that contain semantic similarity while offering greater diversity.},
  archive      = {J_TNNLS},
  author       = {Pinzhuo Tian and Qiubo Ma and Hang Yu and Jie Lu},
  doi          = {10.1109/TNNLS.2025.3598594},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {ReCL: A plug-and-play module for enhancing generalized category discovery using transport-based method to uncover the relationship in samples},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advancing generalization in PINNs through latent-space representations. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3598617'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics-informed neural networks (PINNs) have made significant strides in modeling dynamical systems governed by partial differential equations (PDEs). However, their generalization capabilities across varying scenarios remain limited. To overcome this limitation, we propose physics-informed dynamics representation learner (PiDo), a novel physics-informed neural PDE solver designed to generalize effectively across diverse PDE configurations, including varying initial conditions, PDE coefficients, and training-time horizons. PiDo exploits the shared underlying structure of dynamical systems with different properties by projecting PDE solutions into a latent space using auto-decoding. It then learns the dynamics of these latent representations, conditioned on the PDE coefficients. Despite its promise, integrating latent dynamics models within a physics-informed framework poses challenges due to the optimization difficulties associated with physics-informed losses. To address these challenges, we introduce a novel approach that diagnoses and mitigates these issues within the latent space. This strategy employs straightforward yet effective regularization techniques, enhancing both the temporal extrapolation performance and the training stability of PiDo. We validate PiDo on a range of benchmarks, including 1-D combined equations and 2-D Navier–Stokes equations. In addition, we demonstrate the transferability of its learned representations to downstream applications such as long-term integration and inverse problems.},
  archive      = {J_TNNLS},
  author       = {Honghui Wang and Yifan Pu and Shiji Song and Gao Huang},
  doi          = {10.1109/TNNLS.2025.3598617},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Advancing generalization in PINNs through latent-space representations},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A bioinspired deep learning framework for saliency-based image quality assessment. <em>TNNLS</em>, 1-11. (<a href='https://doi.org/10.1109/TNNLS.2025.3598716'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advancements in deep learning have led to significant progress in no-reference (NR) image quality assessment (NR-IQA) for evaluating the perceived quality of digital images without relying on a reference. However, existing NR-IQA models remain suboptimal in handling complex and diverse natural images. Visual saliency constitutes a critical element for enhancing the reliability of NR-IQA, but the optimal use of saliency in deep learning-based NR-IQA has not heretofore been significantly explored. In this article, we present a novel method for integrating saliency in NR-IQA, which is motivated by the saliency-based visual search mechanism that different parts of the visual input are visited by the focus of attention (FOA) in the order of decreasing saliency. By dividing saliency into the high and low levels of FOA, we build a bioinspired deep neural network–BioSIQNet–based on a multitask learning (MTL) framework. The network architecture consists of two saliency-specific tasks and one primary image quality assessment (IQA) task. The low and high saliency (HS) are separately encoded and integrated into the early and deeper layers of the IQA network, respectively, analogous to the hierarchical processing in the visual cortex of the brain that allocates low attentional resources to process the simple patterns and high resources to learn intricate representations. We demonstrate that leveraging the synergy between visual attention and image quality perception and joint learning of these interconnected visual tasks can enhance the overall learning capabilities of the primary IQA model. Experiments validate the effectiveness of our proposed BioSIQNet for NR-IQA.},
  archive      = {J_TNNLS},
  author       = {Huasheng Wang and Yueran Ma and Hongchen Tan and Xiaochang Liu and Ying Chen and Hantao Liu},
  doi          = {10.1109/TNNLS.2025.3598716},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A bioinspired deep learning framework for saliency-based image quality assessment},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CRL: An efficient autonomous exploration framework for large-scale environments with contrastive-driven reinforcement learning. <em>TNNLS</em>, 1-12. (<a href='https://doi.org/10.1109/TNNLS.2025.3597164'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous exploration in large-scale environments is impeded by two critical challenges, namely, suboptimal viewpoint selection resulting from inadequate feature extraction and the continuously rising computational costs as the environment expands. Existing methods struggle to simultaneously tackle these dual challenges within cohesive frameworks. In response, we present an efficient autonomous exploration framework with contrastive-driven reinforcement learning. Inspired by human cognitive mechanisms that reinforce crucial information recognition through contrast, our study implements contrastive constraints on nodes of varying utility levels within high-dimensional feature spaces, achieving a decoupling of their latent representations. This capability empowers decision networks to explicitly capture key regional characteristics, thereby enhancing the precision of optimal viewpoint selection. Moreover, to mitigate the issues of backtracking and redundant exploration, we design specialized training rules that enforce effective action constraints, further enhancing viewpoint selection. Additionally, we propose a novel graph rarefaction algorithm to tackle computational costs, simplifying computational complexities while maintaining performance standards. Compared to the state-of-the-art (SOTA) approaches, our method achieves 6.7% shorter path lengths, while also demonstrates robust generalization capabilities through real-world robotic experiments across multiple real-world scenarios.},
  archive      = {J_TNNLS},
  author       = {Benke Gao and Hao Chen and Quan Liu and Hanqiang Deng and Jian Huang and Yan-Jun Liu},
  doi          = {10.1109/TNNLS.2025.3597164},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {CRL: An efficient autonomous exploration framework for large-scale environments with contrastive-driven reinforcement learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Recurrent network expansion for class incremental learning. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3601373'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class incremental learning (CIL) is the key to achieving adaptive vision intelligence, and one of the main streams for CIL is network expansion (NE). However, state-of-the-art (SOTA) methods usually suffer from feature diffusion, growing parameters, feature confusion, and classifier bias. In view of this, a novel dynamic structure dubbed as recurrent NE (RNE) is proposed by establishing connections among task experts. Specifically, the previous task experts transfer features sequentially through a shared module and the new task expert makes adjustments based on received features rather than reextracted ones, thereby focusing more on the key area and avoiding feature diffusion. Furthermore, the RNE is compressed by replacing additional task experts with lightened ones, in order to significantly reduce the number of parameters while keeping the performance almost unaltered. In addition, feature confusion is alleviated by a decoupled classifier and classifier bias is corrected by pseudo-feature generation. Extensive experiments on four widely adopted benchmark datasets, i.e., CIFAR-100, ImageNet-100, Food-101, and ImageNet-1K, have demonstrated that RNE achieves SOTA performance in both ordinary and challenging CIL settings.},
  archive      = {J_TNNLS},
  author       = {Kai Jiang and Xueru Bai and Feng Zhou},
  doi          = {10.1109/TNNLS.2025.3601373},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Recurrent network expansion for class incremental learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DSPFL: A deep-layer sign sharing personalized federated learning scheme for mitigating poisoning attacks. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3601078'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rise of the smart industry, machine learning (ML) has become a popular method to improve the security of the Industrial Internet of Things (IIoT) by training anomaly detection models. Federated learning (FL) is a distributed ML scheme that facilitates anomaly detection on IIoT by preserving data privacy and breaking data silos. However, poisoning attacks pose significant threats to FL, where adversaries upload poisoned local models to the aggregation server, thereby degrading model accuracy. The prevalence of non-independent and identically distributed (non-IID) data across IIoT devices further exacerbates this threat, as it naturally leads to diverse local models, making malicious ones harder to distinguish. To address the above challenges, we propose a deep-layer sign-sharing personalized FL (DSPFL) scheme. DSPFL innovatively aggregates only the signs of stochastic gradients (SignSGD) from the deep layers of local models during training. This targeted aggregation enhances the robustness of the shared components against poisoning attacks, while shallow layers are retained locally to preserve personalization. This integrated approach improves the accuracy and resilience of personalized local models on IIoT devices under poisoning attacks. Extensive experimental results show that DSPFL consistently achieves up to 20% higher and more stable overall personalized model accuracy compared to state-of-the-art methods under specific poisoning attacks.},
  archive      = {J_TNNLS},
  author       = {Chenhao Xu and Nasrin Sohrabi and Youyang Qu and Hai Dong and Zahir Tari and Xun Yi},
  doi          = {10.1109/TNNLS.2025.3601078},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {DSPFL: A deep-layer sign sharing personalized federated learning scheme for mitigating poisoning attacks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient high-dimensional learning with adaptive gaussian RBF networks. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3601366'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radial basis function neural networks (RBFNNs) are widely applied due to their rapid modeling capabilities and efficient learning performance. However, when dealing with high-dimensional data, RBFNNs encounter two critical limitations: the hidden layer responses using Gaussian kernels suffer from ineffective activation and numeric underflow; and the estimation of output layer weights typically involves tedious parameter tuning and inefficient loading of high-dimensional feature matrices. To overcome these challenges, we first propose a dimensionality-adaptive Gaussian kernel function (DAGKF) equipped with a novel width adjustment mechanism that flexibly mitigates the numerical difficulties inherent in high-dimensional spaces. Moreover, to avoid processing entire feature matrices simultaneously, we introduce a multioutput coordinate descent (MOCD) algorithm that enables parallel computation across multioutput systems. Building upon MOCD, we further develop the joint residual MOCD (JRMOCD) algorithm, which incorporates a joint residual criterion for more effective weight estimation. The convergence of the JRMOCD algorithm is rigorously proven. Extensive experiments demonstrate the superior performance of the proposed methods, particularly in high-dimensional settings.},
  archive      = {J_TNNLS},
  author       = {Xiaoyu Gao and Xuetao Xie and Jian Wang and Sergey V. Ablameyko and Nikhil R. Pal},
  doi          = {10.1109/TNNLS.2025.3601366},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Efficient high-dimensional learning with adaptive gaussian RBF networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SSPPI: Cross-modality enhanced Protein–Protein interaction prediction from sequence and structure perspectives. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3599927'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances have shown great promise in mining multimodal protein knowledge for better protein–protein interaction (PPI) prediction by enriching the representation of proteins. However, existing solutions lack a comprehensive consideration of both local patterns and global dependencies in proteins, hindering the full exploitation of modal information. Additionally, the inherent disparities between modalities are often disregarded, which may lead to inferior modality complementarity effects. To address these issues, we propose a cross-modality enhanced PPI prediction method from the perspectives of protein sequence and structure modalities, namely SSPPI. In this framework, our main contribution is that we integrate both sequence and structural modalities of proteins and employ an alignment and fusion method between modalities to further generate more comprehensive protein representations for PPI prediction. Specifically, we design two modal representation modules (Convformer and Graphormer) tailored for protein sequence and structure modalities, respectively, to enhance the quality of modal representation. Subsequently, we introduce a Cross-modality enhancer module to achieve alignment and fusion between modalities, thereby generating more informative modal joint representations. Finally, we devise a cross-protein fusion (CPF) module to model residue interaction processes between proteins, thereby enriching the joint representation of protein pairs. Extensive experimentation on four benchmark datasets demonstrates that our proposed model surpasses all current state-of-the-art (SOTA) methods. The source codes are publicly available at the following link https://github.com/bixiangpeng/SSPPI/},
  archive      = {J_TNNLS},
  author       = {Xiangpeng Bi and Wenjian Ma and Huasen Jiang and Weigang Lu and Zhiqiang Wei and Shugang Zhang},
  doi          = {10.1109/TNNLS.2025.3599927},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {8},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {SSPPI: Cross-modality enhanced Protein–Protein interaction prediction from sequence and structure perspectives},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decentralized personalized federated learning based on a conditional “Sparse-to-sparser” scheme. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3580277'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decentralized federated learning (DFL) has gained popularity due to its robustness and elimination of centralized coordination requirements. In this paradigm, clients actively participate in training by exchanging models with neighboring nodes in their network. However, DFL introduces significant overhead in both training and communication costs. While existing methods focus primarily on reducing communication costs, they often overlook training efficiency and the challenges of data heterogeneity. We address these limitations by introducing DA-DPFL, a novel sparse-to-sparser training scheme that initializes with a subset of model parameters which progressively decrease during training through dynamic aggregation. This approach substantially reduces energy consumption while preserving adequate information during critical learning periods. Our experimental results demonstrate that DA-DPFL significantly outperforms DFL baselines in test accuracy while achieving up to 5x reduction in energy costs. We provide theoretical convergence analysis that validates the applicability of our approach in decentralized and personalized learning contexts. The code is available at: https://github.com/EricLoong/da-dpfl},
  archive      = {J_TNNLS},
  author       = {Qianyu Long and Qiyuan Wang and Christos Anagnostopoulos and Daning Bi},
  doi          = {10.1109/TNNLS.2025.3580277},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Decentralized personalized federated learning based on a conditional “Sparse-to-sparser” scheme},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DiffCL: A diffusion-based contrastive learning framework with semantic alignment for multimodal recommendations. <em>TNNLS</em>, 1-11. (<a href='https://doi.org/10.1109/TNNLS.2025.3583509'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal recommendation systems integrate diverse multimodal information into the feature representations of both items and users, thereby enabling a more comprehensive modeling of user preferences. However, existing methods are hindered by data sparsity and the inherent noise within multimodal data, which impedes the accurate capture of users’ interest preferences. Additionally, discrepancies in the semantic representations of items across different modalities can adversely impact the prediction accuracy of recommendation models. To address these challenges, we introduce a novel diffusion-based contrastive learning (DiffCL) framework for multimodal recommendation. DiffCL employs a diffusion model (DM) to generate contrastive views that effectively mitigate the impact of noise during the contrastive learning phase. Furthermore, it improves semantic consistency across modalities by aligning distinct visual and textual semantic information through stable ID embeddings. Finally, the introduction of the item-item graph (I-I graph) enhances multimodal feature representations, thereby alleviating the adverse effects of data sparsity on the overall system performance. We conduct extensive experiments on three public datasets, and the results demonstrate the superiority and effectiveness of the DiffCL.},
  archive      = {J_TNNLS},
  author       = {Qiya Song and Jiajun Hu and Lin Xiao and Bin Sun and Xieping Gao and Shutao Li},
  doi          = {10.1109/TNNLS.2025.3583509},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {DiffCL: A diffusion-based contrastive learning framework with semantic alignment for multimodal recommendations},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contrastive learning framework with cross-sensor adaptive signal representation for fault diagnosis. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3582858'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although multisource sensor (MS) signal-based mechanical fault diagnosis (MFD) can significantly improve the diagnostic performance, the existing methods often lack sufficient adaptability and generalization when retraining on single-sensor signals or inferring from partial sensor signals. Thus, a general two-stage signal representation contrastive learning fault diagnosis framework (T-SCF) is proposed to adapt the trained model to varying numbers of sensor signals. This framework enhances model robustness and data fusion by comparing sensor signal views, offering a new approach for information fusion, fault detection, and classification in MFD. In the first stage, an adaptive contrastive algorithm is proposed to generate contrastive samples (C-Ss) and contrastive labels (C-Ls) for MS signals. Then, a supervised contrastive loss (SCL) is designed to minimize the similarity between different fault MS signals while maximizing the similarity between identical ones. By designing a parallel encoder architecture, SCL enables it to merge contrasting the features of different sensor signals during training. This strategy preserves the time-domain dimension properties of different sensors during the training of the second-stage classifier, thereby improving the adaptability of the model to different sensor signals without affecting the global information. The effectiveness of the method was verified from multiple different evaluation dimensions using two public datasets and one self-built dataset.},
  archive      = {J_TNNLS},
  author       = {Wenbin He and Jianxu Mao and Yaonan Wang and Zhe Li and Hui Zhang},
  doi          = {10.1109/TNNLS.2025.3582858},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Contrastive learning framework with cross-sensor adaptive signal representation for fault diagnosis},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DVGMAE: Self-supervised dynamic variational graph masked autoencoder. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3583045'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although contrastive self-supervised learning (SSL) on dynamic graphs has made significant success, the issue of heavy reliance on data augmentation and training tricks has been a persistent pain point. Generative SSL, especially masked autoencoders (MAEs) have recently produced promising results and can avoid these issues. However, the research on MAE in dynamic graphs remains largely unexplored due to the following challenges: 1) how to design an effective masking strategy for dynamic graphs? and 2) how to design a decoder to retain temporal dependency when graphs are perturbed? In this article, we propose DVGMAE, a novel dynamic variational graph masked autoencoder model to solve these challenges. DVGMAE simultaneously captures the evolving behaviors and topological features via an innovative masking strategy and an elaborate decoder. Specifically, we first implement a temporal-aware masking strategy on the edges of each snapshot based on the updated probabilities derived from historical mask information. This strategy mitigates potential masking bias in dynamic graphs. We then design a globally enhanced decoder to recover the temporal and spatial information of each snapshot. Extensive experiments demonstrate that DVGMAE outperforms the existing state-of-the-art on various tasks across different datasets.},
  archive      = {J_TNNLS},
  author       = {Mengzhou Gao and Xinxun Zhang and Pengfei Jiao and Tianpeng Li and Zhidong Zhao},
  doi          = {10.1109/TNNLS.2025.3583045},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {DVGMAE: Self-supervised dynamic variational graph masked autoencoder},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DMAE-EEG: A pretraining framework for EEG spatiotemporal representation learning. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3581991'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalography (EEG) plays a crucial role in neuroscience research and clinical practice, but it remains limited by nonuniform data, noise, and difficulty in labeling. To address these challenges, we develop a pretraining framework named DMAE-EEG, a denoising masked autoencoder for mining generalizable spatiotemporal representation from massive unlabeled EEG. First, we propose a novel brain region topological heterogeneity (BRTH) division method to partition the nonuniform data into fixed patches based on neuroscientific priors. Second, we design a denoised pseudo-label generator (DPLG), which utilizes a denoising reconstruction pretext task to enable the learning of generalizable representations from massive unlabeled EEG, suppressing the influence of noise and artifacts. Furthermore, we utilize an asymmetric autoencoder with self-attention as the backbone in the proposed DMAE-EEG, which captures long-range spatiotemporal dependencies and interactions from unlabeled EEG data across 14 public datasets. The proposed DMAE-EEG is validated on both generative (signal quality enhancement) and discriminative tasks (motion intention recognition). In the quality enhancement, DMAE-EEG outperforms existing statistical methods with normalized mean squared error (nMSE) reduction of 27.78%–50.00% under corruption levels of 25%, 50%, and 75%, respectively. In motion intention recognition, DMAE-EEG achieves a relative improvement of 2.71%–6.14% in intrasession classification balanced accuracy across 2–6 class motor execution and imagery tasks, outperforming state-of-the-art methods. Overall, the results suggest that the pretraining framework DMAE-EEG can capture generalizable spatiotemporal representations from massive unlabeled EEG and enhance the knowledge transferability across sessions, subjects, and tasks in various downstream scenarios, advancing EEG-aided diagnosis and brain–computer communication and control, and other clinical practice.},
  archive      = {J_TNNLS},
  author       = {Yifan Zhang and Yang Yu and Hao Li and Anqi Wu and Xin Chen and Jinfang Liu and Ling-Li Zeng and Dewen Hu},
  doi          = {10.1109/TNNLS.2025.3581991},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {DMAE-EEG: A pretraining framework for EEG spatiotemporal representation learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Frobenius norm-based robust dynamic neural network for time-dependent matrix inversion. <em>TNNLS</em>, 1-7. (<a href='https://doi.org/10.1109/TNNLS.2025.3583573'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time-dependent matrix inversion (TDMI) is popularly utilized in scientific fields. Considering the low computing costs and simplified structure, this brief puts forward a Frobenius norm-based dynamic neural network (FNBDNN) model to address a TDMI problem for the first time, which achieves convergence within finite time and ensures strong robustness without using integral operations and element-wise nonlinear activation functions. Moreover, precise theoretical analyses are provided to display the property of finite-time convergence of the FNBDNN model in dealing with the TDMI problem. Simulation experiments are further conducted to verify the validity and preponderance of the FNBDNN model. Finally, an application of the devised FNBDNN model to the precise motion control of a two-axis manipulator is introduced.},
  archive      = {J_TNNLS},
  author       = {Hanyi Xu and Linyan Dai and Yinyan Zhang},
  doi          = {10.1109/TNNLS.2025.3583573},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-7},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Frobenius norm-based robust dynamic neural network for time-dependent matrix inversion},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Utilizing TOP2 class for hybrid decision-making to enhance TOP1 accuracy of ensemble models. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3579732'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the domain of deep learning for visual tasks, ensemble models combine several less accurate models to form a more precise composite model, improving overall performance. Traditionally, majority voting and average probabilities have been the main decision-making techniques in ensemble learning, focusing only on the TOP1 Class of base models, hence overlooking other significant information. This article introduces a new algorithm, TOP2 hybrid decision (TOP2 HD), which enhances the TOP1 accuracy of the ensemble model. TOP2 HD categorizes base models into hierarchies based on their TOP1 Class and uses the TOP2 Class for ranking, leading to better performance. Extensive experiments across various models and datasets demonstrate that TOP2 HD not only surpasses traditional ensemble methods, such as majority voting, average probabilities, and stacking, but also exceeds many of the latest ensemble strategies in the image domain. In addition, our experiments revealed a functional relationship between the test accuracy of the ensemble model and the number of base models. This enables us to predict the upper limit of the ensemble model’s performance using only a fraction of the models, providing a crucial reference for the performance after the deployment of the ensemble model.},
  archive      = {J_TNNLS},
  author       = {Jiqing Li and Zhendong Yin and Dasen Li and Yanlong Zhao},
  doi          = {10.1109/TNNLS.2025.3579732},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Utilizing TOP2 class for hybrid decision-making to enhance TOP1 accuracy of ensemble models},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HVLF: A holistic visual localization framework across diverse scenes. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3580405'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, integrating the multitask learning (MTL) paradigm into scene coordinate regression (SCoRe) techniques has achieved significant success in visual localization tasks. However, the feature extraction ability of existing frameworks is inherently constrained by the rigid weight activation strategy, which prevents each layer from concurrently capturing scene-universal features across diverse scenes and scene-particular attributes unique to each individual scene. In addition, the straightforward network architecture further exacerbates the issue of insufficient feature representation. To address these limitations, we introduce HVLF, a holistic framework that ensures flexible identification of both scene-universal and scene-particular attributes while integrating various attention mechanisms to enhance feature representation effectively. Technically, for the first issue, HVLF proposes a soft weight activation strategy (SWAS) equipped with polyhedral convolution to concurrently optimize scene-shared and scene-specific weights within each layer, which facilitates sufficient discernment of both scene-universal features and scene-particular attributes, thereby boosting the network’s capability for comprehensive scene perception. For the second issue, HVLF introduces a mixed attention perception module (MAPM) that incorporates channelwise, spatialwise, and elementwise attention mechanisms to perform multilevel feature fusion, hence extracting discriminative features to regress precise scene coordinates. Extensive experiments on indoor and outdoor datasets prove that HVLF realizes impressive localization performance. In addition, experiments conducted on 3-D object detection and feature matching tasks prove that the two proposed techniques are universal and can be seamlessly inserted into other methods.},
  archive      = {J_TNNLS},
  author       = {Kun Dai and Zhiqiang Jiang and Fuyuan Qiu and Dedong Liu and Tao Xie and Ke Wang and Ruifeng Li and Lijun Zhao},
  doi          = {10.1109/TNNLS.2025.3580405},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {HVLF: A holistic visual localization framework across diverse scenes},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Asynchronous boundary stabilization of stochastic markovian Reaction–Diffusion neural networks with mode-dependent delays. <em>TNNLS</em>, 1-11. (<a href='https://doi.org/10.1109/TNNLS.2025.3574214'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article tackles asynchronous control issue for a class of stochastic Markovian reaction-diffusion neural networks with mode-dependent delays (MDDs). Taking into account the spatio-temporal distribution of such networks, we propose a boundary control (BC) scheme combined with asynchronous control to reduce control implementation cost and overcome environmental constraint. By incorporating a hidden Markov model to manage the mode asynchrony, we develop an integral asynchronous boundary controller for Neumann boundary conditions, as well as an innovative one for Dirichlet boundary conditions. We then derive an exponential stability criterion specific to MDDs and introduce a novel asynchronous BC synthesis approach. Additionally, we extend our findings to the leader-follower synchronization of these neural networks. The validity, superiority, and practicality of the proposed control design approach are demonstrated via three numerical examples, respectively.},
  archive      = {J_TNNLS},
  author       = {Xin-Xin Han and Kai-Ning Wu and Xin Yuan},
  doi          = {10.1109/TNNLS.2025.3574214},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Asynchronous boundary stabilization of stochastic markovian Reaction–Diffusion neural networks with mode-dependent delays},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust spatiotemporal prototype learning for spiking neural networks. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3583747'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural networks (SNNs) leverage their spike-driven nature to achieve high energy efficiency, positioning them as a promising alternative to traditional artificial neural networks (ANNs). The spiking decoder, a crucial component for output, significantly affects the performance of SNNs. However, current rate coding schemes for decoding of SNNs often lack robustness and do not have a training framework suitable for robust learning, while alternatives to rate coding generally produce worse overall performance. To address these challenges, we propose spatiotemporal prototype (STP) learning for SNNs, which uses multiple learnable binarized prototypes for distance-based decoding. In addition, we introduce a cotraining framework that jointly optimizes prototypes and model parameters, enabling mutual adaptation of the two components. STP learning clusters feature centers through supervised learning to ensure effective aggregation around the prototypes, while maintaining enough spacing between prototypes to handle noise and interference. This dual capability results in superior stability and robustness. On eight benchmark datasets with diverse challenges, the STP-SNN model achieves performance comparable to or superior to state-of-the-art methods. Notably, STP learning demonstrates exceptional robustness and stability in multitask experiments. Overall, these findings reveal that STP learning is an effective means of improving the performance and robustness of SNNs.},
  archive      = {J_TNNLS},
  author       = {Wuque Cai and Hongze Sun and Qianqian Liao and Jiayi He and Duo Chen and Dezhong Yao and Daqing Guo},
  doi          = {10.1109/TNNLS.2025.3583747},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Robust spatiotemporal prototype learning for spiking neural networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semi-supervised anomaly detection using restricted distribution transformation. <em>TNNLS</em>, 1-12. (<a href='https://doi.org/10.1109/TNNLS.2025.3583320'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection (AD) is typically regarded as an unsupervised learning task, where the training data either do not contain any anomalous samples or contain only a few unlabeled anomalous samples. In fact, in many real scenarios such as fault diagnosis and disease detection, a small number of anomalous samples labeled by domain experts are often available during the training phase, which makes semi-supervised AD (SAD) more appealing, though the related study is quite limited. Existing semi-supervised AD methods directly add optimization terms of anomalous samples to the optimization objective of unsupervised AD (UAD), where the effects of the limited labeled anomalous data on the optimization process become trivial and they cannot fully contribute to the detection task. To cover the shortage, in this work, we propose a novel semi-supervised AD method to fully use the limited labeled anomalous data and further to boost detection performance. The proposed method learns a nonlinear transformation to project normal data into a compact target distribution and simultaneously to project exposed anomalous samples into another target distribution, where the two target distributions do not overlap each other. The goal is difficult to achieve because of the scarcity of anomalous samples. To address this problem, we propose to generate a large number of intermediate samples interpolating between normal and anomalous data and project them into a third target distribution lying between the aforementioned two target distributions. Empirical results on multiple benchmarks with varying domains demonstrate the superiority of our method over existing supervised and semi-supervised AD methods.},
  archive      = {J_TNNLS},
  author       = {Feng Xiao and Youqing Wang and S. Joe Qin and Jicong Fan},
  doi          = {10.1109/TNNLS.2025.3583320},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Semi-supervised anomaly detection using restricted distribution transformation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Highly condensed all-MLP architecture for long-term human motion prediction. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3583597'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In artificial intelligence (AI) scenarios where computational resources are constrained, such as in autonomous driving systems, it is challenging to construct a lightweight model that can accurately predict human motion overextended duration. To tackle this challenge, we introduce a highly condensed all-multilayer perceptron (HCMLP) architecture that is engineered for supreme lightweight efficiency. This design facilitates extended-range motion predictions while maintaining uncompromised performance. First, the spatiotemporal dynamic perception (STDP) block enhances operational efficiency while maintaining a simple structure. In STDP, the distinct but parallel spatial multilayer perceptron (SMLP) and temporal multilayer perceptron (TMLP) simultaneously capture the spatial correlations between pose joints and the temporal dynamics of each joint. The subsequent dynamic aggregation (DA), coupled with the channel multilayer perceptron (CMLP), dynamically consolidates and refines spatial and temporal features, leading to improved predictive accuracy. Second, the multiterm union prediction (MTUP) block directly delivers precise predictions for periods ranging from 0 to 4000 ms, eliminating the need for repetitive short-term (ST) prediction iterations. Our experimental results on the Human3.6M, AMASS, 3DPW, and CMU-Mocap datasets demonstrate that HCMLP outperforms existing state-of-the-art (SOTA) methods in ST prediction, long-term (LT) prediction, and especially in extended and extra extended LT (ELT) predictions, all while utilizing the fewest parameters.},
  archive      = {J_TNNLS},
  author       = {Sheng Liu and Shaobo Zhang and Fei Gao and Yuan Feng},
  doi          = {10.1109/TNNLS.2025.3583597},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Highly condensed all-MLP architecture for long-term human motion prediction},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust dynamic material handling via adaptive constrained evolutionary reinforcement learning. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3582299'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic material handling (DMH) involves the assignment of dynamically arriving material transporting tasks to suitable vehicles in real time for minimizing makespan and tardiness. In real-world scenarios, historical task records are usually available, which enables the training of a decision policy on multiple instances consisting of historical records. Recently, reinforcement learning (RL) has been applied to solve DMH. Due to the occurrence of dynamic events such as new tasks, adaptability is highly required. Solving DMH is challenging since constraints, including task delay, should be satisfied. A feedback is received only when all tasks are served, which leads to sparse reward. Besides, making the best use of limited computational resources and historical records for training a robust policy is crucial. The time allocated to different problem instances would highly impact the learning process. To tackle those challenges, this article proposes a novel adaptive constrained evolutionary RL (ACERL) approach, which maintains a population of actors for diverse exploration. ACERL accesses each actor for tackling sparse rewards and constraint violation to restrict the behavior of the policy. Moreover, ACERL adaptively selects the most beneficial training instances for improving the policy. Extensive experiments on eight training and eight unseen test instances demonstrate the outstanding performance of ACERL compared with several state-of-the-art algorithms. Policies trained by ACERL can schedule the vehicles while fully satisfying the constraints. Additional experiments on 40 unseen noised instances show the robust performance of ACERL. Cross validation further presents the overall effectiveness of ACREL. Besides, a rigorous ablation study highlights the coordination and benefits of each ingredient of ACERL.},
  archive      = {J_TNNLS},
  author       = {Chengpeng Hu and Ziming Wang and Bo Yuan and Jialin Liu and Chengqi Zhang and Xin Yao},
  doi          = {10.1109/TNNLS.2025.3582299},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Robust dynamic material handling via adaptive constrained evolutionary reinforcement learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deformation-resilient multigranularity learning for unaligned RGB–T semantic segmentation. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3585105'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGB–Thermal semantic segmentation (SS) aims to combine visual light and thermal images to determine the semantic category for each pixel and create an object mask. While existing methods typically rely on well-aligned RGB–T image pairs, real-world RGB–T pairs are often unaligned, and pixel-by-pixel alignment is both challenging and time-consuming. To address this critical issue, we introduce a new unaligned RGB–T SS benchmark and propose the deformation-resilient multigranularity learning (DML) method. DML explores the spatial consistency and modal complementarity of RGB–T and mitigates the interference of warped modalities by aligning multimodal features in a coarse-to-fine multigranularity strategy. Specifically, DML constructs a deformation-aware complementary feature enhancer (DCFE), which consists of deformation-aware feature alignment (DFA) and complementary feature aggregation (CFA) modules. DFA enhances the spatial alignment of RGB–T by estimating the deformation field of warped features. Then, CFA aggregates complementary contexts of modal differences across multiple scales to produce deformation-resilient and robust RGB–T feature representations. Finally, we design the multigranularity mask refinement engine (MMFE), which combines class-agnostic saliency prediction (CSP) and class-aware edge generation (CEG) auxiliary tasks to provide useful boundary and positional cues for SS decoders. The MMFE enhances semantic alignment and interclass separability, yielding object masks with sharp boundaries. Quantitative and qualitative experiments on aligned and unaligned datasets validate the effectiveness of our proposed DML, consistently outperforming existing methods designed for aligned RGB–T data. The new unaligned RGB–T SS benchmark and code are available at https://github.com/VisionVerse/Unaligned-RGBT-Semantic-Segmentation},
  archive      = {J_TNNLS},
  author       = {Heng Zhou and Zhenxi Zhang and Chengyang Li and Chunna Tian and Yongqiang Xie and Zhongbo Li and Xiao-Jun Wu},
  doi          = {10.1109/TNNLS.2025.3585105},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Deformation-resilient multigranularity learning for unaligned RGB–T semantic segmentation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DiffusionMOT: A diffusion-based multiple object tracker. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3579729'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, researchers have introduced diffusion models into multiple object tracking (MOT) tasks. However, existing diffusion-based MOT methods, such as DiffusionTrack, have significant limitations, including frequent ID switching, reduced performance when tracking nonlinear motion objects, and long inference time. To this end, we propose a more effective diffusion-based multiple object tracker named DiffusionMOT. In particular, we propose a mixed intersection over union (IoU) and Re-Identification (ReID) method for trajectory matching, which effectively reduces incorrect matches. Meanwhile, we propose a secondary calibration method for trajectory boxes, improving the accuracy of the generated detection boxes. Moreover, we introduce the parallel sampling technique from the field of image generation into object tracking and propose a parallel sampling module to enhance the model’s inference speed while maintaining tracking accuracy. Furthermore, we design a pair-based two-stage matching (PTM) pipeline to more effectively utilize potential detection information. Extensive experiments on several public MOT benchmarks, including DanceTrack, SportsMOT, MOT20, and MOT17, demonstrate that our approach achieves state-of-the-art (SOTA) performance. The code and models are available at https://github.com/sad123-yx/DiffusionMOT},
  archive      = {J_TNNLS},
  author       = {Yaxuan Hu and Jie Hua and Zhen Han and Hua Zou and Gang Wu and Zhongyuan Wang},
  doi          = {10.1109/TNNLS.2025.3579729},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {DiffusionMOT: A diffusion-based multiple object tracker},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Protecting deep learning model copyrights with adversarial example-free reuse detection. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3578664'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model reuse techniques can reduce the resource requirements for training high-performance deep neural networks (DNNs) by leveraging existing models. However, unauthorized reuse and replication of DNNs can lead to copyright infringement and economic loss to the model owner. This underscores the need to analyze the reuse relation between DNNs and develop copyright protection techniques to safeguard intellectual property rights. Existing DNN copyright protection approaches suffer from several inherent limitations hindering their effectiveness in practical scenarios. For instance, existing white-box fingerprinting approaches cannot address the common heterogeneous reuse case where the model architecture is changed, and DNN fingerprinting approaches heavily rely on generating adversarial examples with good transferability, which is known to be challenging in the black-box setting. To bridge the gap, we propose a neuron functionality analysis-based reuse detector (NFARD), a neuron functionality (NF) analysis-based reuse detector, which only requires normal test samples to detect reuse relations by measuring the models’ differences on a newly proposed model characterization, i.e., NF. A set of NF-based distance metrics is designed to make NFARD applicable to both white-box and black-box settings. Moreover, we devise a linear transformation method to handle heterogeneous reuse cases by constructing the optimal projection matrix for dimension consistency, significantly extending the application scope of NFARD. To the best of our knowledge, this is the first adversarial example-free method that exploits NF for DNN copyright protection. As a side contribution, we constructed a reuse detection benchmark named Reuse Zoo that covers various practical reuse techniques and popular datasets. Extensive evaluations on this comprehensive benchmark show that NFARD achieves $F1$ scores of 0.984 and 1.0 for detecting reuse relationships in black-box and white-box settings, respectively, while generating test suites $2{\sim } 99$ times faster than previous methods.},
  archive      = {J_TNNLS},
  author       = {Xiaokun Luan and Xiyue Zhang and Jingyi Wang and Meng Sun},
  doi          = {10.1109/TNNLS.2025.3578664},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Protecting deep learning model copyrights with adversarial example-free reuse detection},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Branch-tuning: Balancing stability and plasticity for continual self-supervised learning. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3579928'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The self-supervised learning (SSL) has emerged as an effective paradigm for deriving general representations from vast amounts of unlabeled data. However, as real-world applications continually integrate new content, the high computational and resource demands of SSL necessitate continual learning (CL) rather than complete retraining. This poses a challenge in balancing between stability and plasticity when adapting to new information. In this article, we employ centered kernel alignment (CKA) for quantitatively analyzing model stability and plasticity, revealing the critical roles of batch normalization (BN) layers for stability and convolutional layers for plasticity. Motivated by this, we propose branch-tuning (BT), an efficient and straightforward method that achieves a balance between stability and plasticity in continual SSL. BT consists of branch expansion and compression and can be easily applied to various SSL methods without the need of modifying the original methods, retaining old data or models. We validate our method through experiments on various benchmark datasets, demonstrating its effectiveness and practical value in real-world scenarios. We hope our work offers new insights for future continual SSL research. The code will be made publicly available.},
  archive      = {J_TNNLS},
  author       = {Wenzhuo Liu and Fei Zhu and Cheng-Lin Liu},
  doi          = {10.1109/TNNLS.2025.3579928},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Branch-tuning: Balancing stability and plasticity for continual self-supervised learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prescribed-time human-in-the-loop optimal synchronization control for multiagent systems under DoS attacks via reinforcement learning. <em>TNNLS</em>, 1-11. (<a href='https://doi.org/10.1109/TNNLS.2025.3583248'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prescribed-time (PT) human-in-the-loop (HiTL) optimal synchronization control problem for multiagent systems (MASs) under link-based denial-of-service (DoS) attacks is investigated. First, the HiTL framework enables the human operator to govern the MASs by transmitting commands to the leader. The link-based DoS attacks cause communication blockages between agents, resulting in topology switching. Under the switching communication topology, a fully distributed observer is proposed for each follower, which simultaneously integrates a prescribed finite-time function to estimate the leader’s output within the PT. This observer is characterized by a bounded gain at the PT point and guarantees global practical PT convergence, while avoiding the use of global topology information. By combining the follower dynamics with the proposed observer, an augmented system is developed. Subsequently, the model-free Q-learning algorithm is used to learn the optimal synchronization policy directly from real system data. To reduce computational burden, the Q-learning algorithm is implemented using a single critic neural network (NN) structure, with the least-squares method applied to train the NN weights. The convergence of the Q-functions generated by the proposed Q-learning algorithm is proven. Finally, simulation results verify the effectiveness of the proposed control scheme.},
  archive      = {J_TNNLS},
  author       = {Zongsheng Huang and Tieshan Li and Yue Long and Hongjing Liang},
  doi          = {10.1109/TNNLS.2025.3583248},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Prescribed-time human-in-the-loop optimal synchronization control for multiagent systems under DoS attacks via reinforcement learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fed-HeLLo: Efficient federated foundation model fine-tuning with heterogeneous LoRA allocation. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3580495'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) has recently been used to collaboratively fine-tune foundation models (FMs) across multiple clients. Notably, federated low-rank adaptation (LoRA)-based fine-tuning methods have recently gained attention, which allows clients to fine-tune FMs with a small portion of trainable parameters locally. However, most existing methods do not account for the heterogeneous resources of clients or lack an effective local training strategy to maximize global fine-tuning performance under limited resources. In this work, we propose federated LoRA-based fine-tuning framework with heterogeneous LoRA allocation (Fed-HeLLo), a novel federated LoRA-based fine-tuning framework that enables clients to collaboratively fine-tune an FM with different local trainable LoRA layers. To ensure its effectiveness, we develop several heterogeneous LoRA allocation (HLA) strategies that adaptively allocate local trainable LoRA layers based on clients’ resource capabilities and the layer importance. Specifically, based on the dynamic layer importance, we design a Fisher information matrix score-based HLA (FIM-HLA) that leverages dynamic gradient norm information. To better stabilize the training process, we consider the intrinsic importance of LoRA layers and design a geometrically defined HLA (GD-HLA) strategy. It shapes the collective distribution of trainable LoRA layers into specific geometric patterns, such as triangle, inverted triangle, bottleneck, and uniform. Moreover, we extend GD-HLA into a randomized version, named randomized GD-HLA (RGD-HLA), for enhanced model accuracy with randomness. By codesigning the proposed HLA strategies, we incorporate both the dynamic and intrinsic layer importance into the design of our HLA strategy. To thoroughly evaluate our approach, we simulate various complex federated LoRA-based fine-tuning settings using five datasets and three levels of data distributions ranging from independent identically distributed (i.i.d.) to extreme non-i.i.d. The experimental results demonstrate the effectiveness and efficiency of Fed-HeLLo with the proposed HLA strategies. The code is available at https://github.com/ TNI-playground/Fed_HeLLo},
  archive      = {J_TNNLS},
  author       = {Zikai Zhang and Ping Liu and Jiahao Xu and Rui Hu},
  doi          = {10.1109/TNNLS.2025.3580495},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Fed-HeLLo: Efficient federated foundation model fine-tuning with heterogeneous LoRA allocation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identifying outliers via local granular-ball density. <em>TNNLS</em>, 1-12. (<a href='https://doi.org/10.1109/TNNLS.2025.3578074'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing density-based outlier detection methods process data at the single-granularity level of individual samples, requiring pairwise distance calculations between all samples and exhibiting high sensitivity to noise. The single-granularity-based processing paradigm fails to mine the information at multiple levels of granularity in data, and most of these methods ignore the potential uncertainty information in data, such as fuzziness, resulting in an inability to effectively detect potential outliers in data. As a novel granular computing method, Granular-Ball Computing (GBC) is characterized by its multi-granularity and robustness, which makes it able to make up for the above drawbacks well. In this study, we propose local Granular-Ball Density-based Outlier (GBDO) detection to improve the performance of the density-based methods. In GBDO, we first identify the $k\text {-}$ similarity Granular-Ball (GB) neighborhoods of each GB via the fuzzy relations among them. Subsequently, the local reachability similarity density of the GBs is calculated through the reachability similarity we defined. Finally, the local GB outlier factors of the samples are calculated based on the local reachability similarity density of the GBs. We adopt a multi-granularity processing paradigm using GBs as the basic units, which reduces computational complexity and improves robustness to noisy data by leveraging the multi-granularity nature of GBs. The experimental results demonstrate the effectiveness of GBDO by comparing it with state-of-the-art methods. The source code and datasets are publicly available at https://github.com/Mxeron/GBDO.},
  archive      = {J_TNNLS},
  author       = {Xinyu Su and Xiwen Wang and Dezhong Peng and Xiaomin Song and Huiming Zheng and Zhong Yuan},
  doi          = {10.1109/TNNLS.2025.3578074},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Identifying outliers via local granular-ball density},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolutionary neural architecture search for remote sensing image classification. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3579517'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote sensing scene classification is a vital task in remote sensing image analysis with significant application potential. In recent years, convolutional neural network (CNN)-based methods have shown remarkable promise in classifying remote sensing scene images. However, these methods often require extensive trial and error and rely heavily on expert knowledge. To address these challenges, this article proposes a novel neural architecture search (NAS) approach that automatically designs CNNs for remote sensing scene classification. Specifically, an evolutionary algorithm (EA) is employed to search for well-structured basic modules, which are then combined to construct a new architecture. To further enhance the search process, a new population generation strategy is introduced to promote diversity and mitigate premature convergence. Additionally, a random forest-based selection mechanism is utilized to identify high-quality individuals based on estimated fitness values, effectively reducing computational complexity. The proposed approach is evaluated on three benchmark remote sensing scene datasets and compared with several widely used CNNs. The experimental results demonstrate that the proposed approach can discover CNN architectures that not only surpass state-of-the-art performance but also achieve this with fewer parameters and lower search cost.},
  archive      = {J_TNNLS},
  author       = {Jing Liang and Genyue Liu and Ying Bi and Mingyuan Yu and Mengnan Liu and Yaochu Jin},
  doi          = {10.1109/TNNLS.2025.3579517},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Evolutionary neural architecture search for remote sensing image classification},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing graph neural networks for out-of-distribution graph detection. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3584090'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have shown promise in graph classification tasks, but they struggle to identify out-of-distribution (OOD) graphs often encountered in real-world scenarios, posing a significant obstacle for their open-world deployment. Due to the unpredictable nature of the various distributions to which OOD graphs adhere, the challenge of OOD graph detection lies in enabling models to capture distribution differences between in-distribution (ID) and OOD graphs. Current methods often introduce a subset of OOD patterns, such as synthetic OOD graphs, to facilitate learning the discrimination between ID and OOD graphs. However, these OOD patterns may not sufficiently encapsulate the entire range of OOD graphs, leading to inadequate learning of the distribution differences between ID and OOD graphs. In this article, we propose a novel OOD graph detection algorithm, ODGNN. The ODGNN does not expose GNNs to any OOD patterns during model training, thus reducing bias toward specific types of OOD graph samples and enhancing OOD graph detection. The algorithm differentiates graphs by evaluating whether the input graphs conform to established ID graph class-conditioned distributions. Specifically, during model training, the ODGNN integrates a Gaussian encoder into GNNs to characterize ID graph classes using distinct class-conditioned distributions. During inference, OOD graphs are mapped to a representation space distant from ID graphs due to their divergence from any known class-conditioned distribution. Extensive experiments conducted on real-world datasets validate the effectiveness of the ODGNN in enhancing OOD detection performance across various GNN-based graph classification models. The ODGNN also demonstrates superior performance compared to state-of-the-art OOD graph detection competitors.},
  archive      = {J_TNNLS},
  author       = {Ge Zhang and Zhenyu Yang and Jia Wu and Pengfei Jiao and Jian Yang},
  doi          = {10.1109/TNNLS.2025.3584090},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Enhancing graph neural networks for out-of-distribution graph detection},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DSFuse: A dual-diffusion structure for feature fidelity infrared and visible image fusion. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3584834'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image fusion aims to combine the complementary features of different modalities to produce an informative fused image. Due to the different imaging mechanisms, information conflicts may arise from infrared and visible source images. Existing infrared and visible fusion methods are devoted to preserving the features of source images as much as possible. However, handling conflicting information is often overlooked. Thus, we leverage the powerful generative priors of diffusion and propose a dual-diffusion structure, termed DSFuse, to handle conflicting information and achieve feature fidelity during image fusion processing. Diffusion modules are introduced to guide the fusion network to understand the meaningful information of the source image easily. First, the fusion network is used to retain features in the fused image as much as possible. Then, diffusion modules are used to reconstruct source images from noise based on the output of the fusion network. Finally, feedback from the diffusion modules forces the fusion network to aggregate modality information to ensure fidelity; the high quality of the fusion result is also profitable for a better reconstruction of diffusion modules, forming a positive feedback loop. In addition, we release a new dataset for infrared/visible fusion to support the fusion network training and evaluation, named the multiscene infrared and visible (MSIV) images dataset. Extensive experiments demonstrate that DSFuse outperforms other state-of-the-art (SOTA) fusion methods.},
  archive      = {J_TNNLS},
  author       = {Zhijia Yang and Kun Gao and Yanzheng Zhang and Xiaodian Zhang and Zibo Hu and Junwei Wang and Jingyi Wang and Wei Li},
  doi          = {10.1109/TNNLS.2025.3584834},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {DSFuse: A dual-diffusion structure for feature fidelity infrared and visible image fusion},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust multi-agent reinforcement learning by mutual information regularization. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3577259'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In cooperative multi-agent reinforcement learning (MARL), ensuring robustness against cooperative agents making unpredictable or worst-case adversarial actions is crucial for real-world deployment. In multi-agent settings, each agent may be perturbed or unperturbed, leading to an exponential increase in potential threat scenarios as the number of agents grows. Existing robust MARL methods either enumerate, or approximate all possible threat scenarios, leading to intense computation and insufficient robustness. In contrast, humans develop robust behaviors by maintaining a general level of caution rather than preparing for every possible threat. Inspired by human decision making, we frame robust MARL as a control-as-inference problem, and optimize worst-case robustness across all threat scenarios implicitly optimized through off-policy evaluation. Specifically, we introduce mutual information regularization as robust regularization (MIR3), which maximizes a lower bound on robustness during routine training, serving as a kind of caution for MARL without adversarial inputs. Further insights show that MIR3 acts as an information bottleneck, preventing agents from over-reacting to others and aligning policies with robust action priors. In the presence of worst-case adversaries, our MIR3 significantly surpasses baseline methods in robustness and training efficiency, and maintaining cooperative performance in StarCraft II, quadrotor swarm control, and robot swarm control. When deploying the robot swarm control algorithm in the real world, our method also outperforms the best baseline by 14.29% in reward. See code and demo videos at https://github.com/DIG-Beihang/MIR3},
  archive      = {J_TNNLS},
  author       = {Simin Li and Ruixiao Xu and Jingqiao Xiu and Yuwei Zheng and Pu Feng and Yuqing Ma and Bo An and Yaodong Yang and Xianglong Liu},
  doi          = {10.1109/TNNLS.2025.3577259},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Robust multi-agent reinforcement learning by mutual information regularization},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pose error prediction, compensation method, and applicable condition determination of parallel motion platform based on transfer learning. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3586458'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collecting a large amount of measured configuration data for robots entails high costs and time, which restricts the widespread use of neural networks for robot error prediction and compensation. In this study, a “transfer network” is established by taking the motion transmission characteristics inherent in the ideal kinematic model as prior knowledge and transferring it to a network trained based on the actual poses. Compared with the traditional back propagation (BP) neural network trained by actual poses alone, the transfer network shows significant performance advantages, effectively solving the problems of low prediction accuracy and weak generalization ability in the case of the small-sample measured data. Considering this, a method for determining the applicability of transfer learning is proposed. This method is achieved by evaluating the similarity between the learning tasks and then revealing the coupling effect of task similarity and the sample number of actual poses on the performance of the transfer network. Experiments are conducted on a six degrees of freedom (6-DOF) parallel robot. The results verify the superiority of transfer learning applied in robot precision compensation and the effectiveness of the proposed determination method.},
  archive      = {J_TNNLS},
  author       = {Wenjie Tian and Xu Guo and Min Xu and Xiangpeng Zhang},
  doi          = {10.1109/TNNLS.2025.3586458},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Pose error prediction, compensation method, and applicable condition determination of parallel motion platform based on transfer learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DefectSAM: Hierarchically adapting SAM for pixel-wise surface defect detection. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3585887'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Segment anything model (SAM) has recently demonstrated powerful segmentation ability for natural scene images (NSIs). However, the SAM exhibits limited performance in defect detection owing to the weak appearance of defects and cluttered backgrounds in industrial images. In this article, we propose a hierarchically adapting SAM for pixel-wise surface defect detection, named DefectSAM, which effectively modulates and decodes multilevel features of the encoder to capture defect information. Specifically, we introduce a learnable feature adaptation component between the image encoder and the decoder to modulate each level of features via the dual-feature adaptation unit. The dual-feature adaptation unit mainly includes the correlation-gated feature adaptation (CGFA) module and the mask-guided feature adaptation (MGFA) module. The CGFA exploits cross correlation spatial gating maps to adaptively incorporate a convolutional feature pyramid and Transformer features during feature adaptation, which is beneficial for capturing defect details. Moreover, the MGFA utilizes the mask prediction of high-level features as semantic guidance to select top-confidence foreground and background tokens for feature adaptation, focusing more on defect details and suppressing background noise. Extensive experiments on three defect detection datasets (i.e., MVTec AD, CrackSeg9k, ZJU-Leaper, and Magnetic tile) demonstrate that the proposed method achieves state-of-the-art performance with few learnable parameters, which greatly improves the generalization of SAM in defect detection.},
  archive      = {J_TNNLS},
  author       = {Feng Yan and Xiaoheng Jiang and Yang Lu and Jiale Cao and Mingliang Xu},
  doi          = {10.1109/TNNLS.2025.3585887},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {DefectSAM: Hierarchically adapting SAM for pixel-wise surface defect detection},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HierSpeech++: Bridging the gap between semantic and acoustic representation of speech by hierarchical variational inference for zero-shot speech synthesis. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3584944'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language model (LLM)-based speech synthesis has been widely adopted in zero-shot speech synthesis. However, they require a large-scale data and possess the same limitations as previous autoregressive speech models, including slow inference speed and lack of robustness. This article proposes HierSpeech++, a fast and strong zero-shot speech synthesizer for text-to-speech (TTS) and voice conversion (VC). We verified that hierarchical speech synthesis frameworks could significantly improve the robustness and expressiveness of the synthetic speech. Furthermore, we significantly improve the naturalness and speaker similarity of synthetic speech even in zero-shot speech synthesis scenarios. For TTS, we adopt the text-to-vec (TTV) framework, which generates a self-supervised speech representation and an F0 representation based on text representations and prosody prompts. Then, HierSpeech++ generates speech from the generated vector, F0, and voice prompt. We further introduce a high-efficient speech super-resolution (SpeechSR) framework from 16 to 48 kHz. The experimental results demonstrated that the hierarchical variational autoencoder could be a strong zero-shot speech synthesizer given that it outperforms LLM-based and diffusion-based models. Moreover, we achieved the first human-level quality zero-shot speech synthesis. Audio samples and source code are available at https://github.com/hierspeechpp/code},
  archive      = {J_TNNLS},
  author       = {Sang-Hoon Lee and Ha-Yeong Choi and Seung-Bin Kim and Seong-Whan Lee},
  doi          = {10.1109/TNNLS.2025.3584944},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {HierSpeech++: Bridging the gap between semantic and acoustic representation of speech by hierarchical variational inference for zero-shot speech synthesis},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiview temporal graph clustering. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3584384'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an emerging task, temporal graph clustering (TGC) is committed to clustering nodes on temporal graphs through interaction sequence-based batch-processing patterns. These patterns allow for more flexibility in finding a balance between time and space requirements than adjacency matrix-based static graph clustering. However, as a new task, TGC still has important unresolved challenges, such as insufficient information. This challenge manifests itself in a variety of problems in real-world datasets, including missing features (eigenvalues are missing or even nonexistent), long-tail nodes (most inactive nodes have little interaction), and noisy data (data is subject to anomalies, errors, and sparsity). These problems occur before training, making it difficult for the model to train well with insufficient information. To solve the challenge, we propose a method that introduces multiview clustering (MVC) into TGC, called MVTGC. Our method aims to perform data augmentation on the temporal graph by constructing multiple views to increase the information richness. In particular, we utilize different techniques to model a certain part of the temporal graph to generate enhanced views focusing on different angles. These views are combined into training through early fusion and late fusion and ultimately enhance the model’s receptive field and information richness. Comparative experiments and a case study on real-world datasets demonstrate the significance and effectiveness of MVTGC, which achieves at most 10.48% performance improvement. The code and data are available at https://github.com/MGitHubL/MVTGC},
  archive      = {J_TNNLS},
  author       = {Meng Liu and Ke Liang and Hao Yu and Lingyuan Meng and Siwei Wang and Sihang Zhou and Xinwang Liu},
  doi          = {10.1109/TNNLS.2025.3584384},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Multiview temporal graph clustering},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Alpha and prejudice: Improving α-sized worst case fairness via intrinsic reweighting. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3586609'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Achieving worst case group fairness typically relies on maximizing the utility of the worst-off demographic group. However, in practice, demographic information is often unavailable, making direct max-min formulations infeasible. To address this, recent work introduces a relaxed setting, using a lower bound $\alpha $ on the minimal group size—referred to as “ $\alpha $ -sized worst case fairness” in this article. We first motivate the importance of this setting by highlighting its relevance to data privacy, a critical yet underexplored perspective. Rather than simply retraining on worst-off samples, we propose a reweighting approach that assigns sample weights based on their intrinsic contributions to fairness. To handle the global nature of worst case objectives efficiently, we develop a stochastic learning algorithm that simplifies training without sacrificing performance. We also address the impact of outliers by introducing a robust variant of our method. Through theoretical analysis and extensive experiments on standard fairness benchmarks, we show that our methods not only connect naturally to existing fairness-through-reweighting approaches but also outperform strong baselines.},
  archive      = {J_TNNLS},
  author       = {Jing Li and Yinghua Yao and Yuangang Pan and Xuanqian Wang and Ivor W. Tsang and Xiuju Fu},
  doi          = {10.1109/TNNLS.2025.3586609},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Alpha and prejudice: Improving α-sized worst case fairness via intrinsic reweighting},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EMWQ: An efficient mixed precision weight quantization method for large language models. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3585677'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) have gained a lot of attention and achievements recently because of their significant comprehension and generative abilities. However, the large-scale parameters of LLMs require considerable computational resources in the training and inference process, which restricts their wide application. To overcome this challenge, we propose an efficient mixed precision weight quantization (EMWQ) method for LLMs in this article. Specifically, we introduce a new outlier detection method by analyzing the weight distribution instead of the conventional weight magnitude. Then, we propose a dual-quantization strategy that quantizes both the outlier critical columns and the residual matrices with different precision. Besides, we introduce two effective EMWQ-based application frameworks, the EMWQ-R and EMWQ-O in our study. Comprehensive experiments are conducted on the Penn Treebank (PTB), C4, ARC-Easy datasets, and MMLU benchmark across various tasks. The comparison results demonstrate that the proposed EMWQ achieves state-of-the-art performance in mixed precision quantization and further reduces computational memory cost. Besides, it has higher generalizability compared with conventional methods.},
  archive      = {J_TNNLS},
  author       = {Yuning Yang and Xiurui Xie and Guowei Peng and Malu Zhang and Guangchun Luo and Yang Yang and Guisong Liu},
  doi          = {10.1109/TNNLS.2025.3585677},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {EMWQ: An efficient mixed precision weight quantization method for large language models},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semantic-aligned code summarization: Bridging the gap between code and natural language through data flow analysis. <em>TNNLS</em>, 1-16. (<a href='https://doi.org/10.1109/TNNLS.2025.3581792'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Code summarization is designed to generate descriptive natural language for code snippets, facilitating understanding and increasing productivity for developers. Previous research often overlooks the semantic connection between code and its natural language description, resulting in a noticeable gap and suboptimal solution. To address this issue, we introduce a semantic-aligned code summarization framework that leverages crucial data flow information from code for semantic analysis, ensuring alignment between code and summaries. Specifically, we utilize a semantic extraction module (SEM) to decipher the meaning of code and align it with natural language through a semantic alignment module. In the SEM, we construct a code graph that includes data flow edges using static program analysis techniques. Then, on this well-constructed code graph, we innovatively adopt a walking algorithm guided by data flow to extract the semantics of the code. This walking algorithm understands code semantics by analyzing the information transfer between variables during the program execution process. In the semantic alignment module, we integrate a contrastive learning loss mechanism for semantic alignment, which cohesively maps the semantic domains of code and natural language into a unified vector space. We further theoretically analyzed that the data-flow-guided walking algorithm can ensure capturing semantically highly related nodes in shorter paths. Extensive experiments on two benchmark datasets demonstrate the efficacy and broad applicability of the framework.},
  archive      = {J_TNNLS},
  author       = {Yuze Zhao and Zhenya Huang and Kai Zhang and Weibo Gao and Qi Liu and Xukai Liu and Fangzhou Yao and Enhong Chen},
  doi          = {10.1109/TNNLS.2025.3581792},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Semantic-aligned code summarization: Bridging the gap between code and natural language through data flow analysis},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multilevel reliable guidance for unpaired multiview clustering. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3586306'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we address the challenging problem of unpaired multiview clustering (UMC), which aims to achieve effective joint clustering using unpaired samples observed across multiple views. Traditional incomplete multiview clustering (IMC) methods typically rely on paired samples to capture complementary information between views. However, such strategies become impractical in the UMC due to the absence of paired samples. Although some researchers have attempted to address this issue by preserving consistent cluster structures across views, effectively mining such consistency remains challenging when the cluster structures with low confidence. Therefore, we propose a novel method, multilevel reliable guidance for UMC (MRG-UMC), which integrates multilevel clustering and reliable view guidance to learn consistent and confident cluster structures from three perspectives. Specifically, inner view multilevel clustering exploits high-confidence sample pairs across different levels to reduce the impact of boundary samples, resulting in more confident cluster structures. Synthesized-view alignment leverages a synthesized view to mitigate cross-view discrepancies and promote consistency. Cross-view guidance employs a reliable view guidance strategy to enhance the clustering confidence of poorly clustered views. These three modules are jointly optimized across multiple levels to achieve consistent and confident cluster structures. Furthermore, theoretical analyses verify the effectiveness of MRG-UMC in enhancing clustering confidence. Extensive experimental results show that MRG-UMC outperforms state-of-the-art UMC methods, achieving an average NMI improvement of 12.95% on multiview datasets. The source code is available at https://anonymous.4open.science/r/MRG-UMC-5E20},
  archive      = {J_TNNLS},
  author       = {Like Xin and Wanqi Yang and Lei Wang and Ming Yang},
  doi          = {10.1109/TNNLS.2025.3586306},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Multilevel reliable guidance for unpaired multiview clustering},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LCwmcaR: Learning cross-window cross-modality correlation-aware representation for human activity recognition. <em>TNNLS</em>, 1-16. (<a href='https://doi.org/10.1109/TNNLS.2025.3581226'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL)-based human activity recognition (HAR) has attracted considerable attention owing to its vast potential across various applications. Currently, HAR still faces two challenges. For one thing, existing methods neglect the spatial distribution information embedded in HAR signals and lack the ability to comprehensively model the spatial–temporal (ST) dependencies within HAR data, restricting them from effectively decoding human activity. For another thing, previous models generate feature representations for a sliding window of the sequence solely based on this window itself, without cross-window interaction learning, posing challenges to classifiers, such as perceptual aliasing or feature inconsistency issues. For that, we propose a novel cross-window and cross-modality correlation-aware framework, namely LCwmcaR, which is a dual-branch network that simultaneously models temporal- and spatial-level information using Mamba and convolutional neural network (CNN), respectively. Additionally, a learnable temporal 2-dimensionalization (LT2D) strategy is designed to encode low-level temporal patterns into high-level learnable image-liked 2-D space representations that integrate both local and global ST dependencies. Moreover, a cross-window correlation-aware feature representation generation (CrwcaFRGen) module, which correlates multiple windows representations within a batch at the attention level, is introduced to produce more robust features for the classifier. Experimental results on four public datasets demonstrate that the LCwmcaR outperforms state-of-the-art (SOTA) methods by a large margin.},
  archive      = {J_TNNLS},
  author       = {Zhuang Li and Jing Tao and Xintao Liu and Dahua Shou},
  doi          = {10.1109/TNNLS.2025.3581226},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {LCwmcaR: Learning cross-window cross-modality correlation-aware representation for human activity recognition},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The risk of federated learning to skew fine-tuning features and underperform robustness. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3585063'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To tackle the scarcity and privacy issues associated with domain-specific datasets, the integration of federated learning in conjunction with fine-tuning (FT) has emerged as a practical solution. However, our findings reveal that federated learning has the risk of skewing FT features and compromising the out-of-distribution (OOD) robustness of pretrained models. By introducing three robustness indicators and conducting experiments across diverse robust datasets, we elucidate these phenomena by scrutinizing the ability of data representations, transferability, and deviations within the model. To mitigate the negative impact of practical federated learning on model robustness, we introduce a general noisy projection (GNP)-based robust algorithm, ensuring no deterioration of accuracy on the target distribution. Specifically, the key strategy for enhancing model robustness entails the transfer of robustness from the pretrained model to the fine-tuned model, coupled with adding a small amount of Gaussian noise to augment the representative capacity of the model. The comprehensive experimental results demonstrate that our approach markedly enhances the robustness across diverse scenarios, encompassing various parameter-efficient FT (PEFT) methods and confronting different levels of label distribution skew and quantity distribution skew.},
  archive      = {J_TNNLS},
  author       = {Mengyao Du and Miao Zhang and Yuwen Pu and Qingming Li and Shouling Ji and Quanjun Yin},
  doi          = {10.1109/TNNLS.2025.3585063},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {The risk of federated learning to skew fine-tuning features and underperform robustness},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distance-aware attention reshaping for enhancing generalization of neural solvers. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3588209'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural solvers (NSs) based on the attention mechanism have demonstrated remarkable effectiveness in solving routing problems like traveling salesman problems (TSPs) and vehicle routing problems (VRPs). However, in the generalization process, we find a phenomenon of the dispersion of attention scores in existing NSs, which leads to poor performance. To improve the generalization ability of NSs, this article proposes a distance-aware attention reshaping (DAR) method. Specifically, without increasing any parameter of the neural network (NN), we utilize the distance information between nodes to adjust attention scores. This enables an NS trained on small-scale instances with a certain distribution to make rational choices when solving large-scale problems with different distributions. Its effectiveness is verified both theoretically and empirically. Extensive experiments on the TSP, asymmetric TSP (ATSP), capacitated VRP (CVRP), VRP with time windows (VRPTW), capacitated arc routing problem (CARP), and knapsack problem (KP) demonstrate the advantages of our method. Our code is available at https://github.com/ftwangyang/DAR},
  archive      = {J_TNNLS},
  author       = {Yang Wang and Ya-Hui Jia and Wei-Neng Chen and Yi Mei},
  doi          = {10.1109/TNNLS.2025.3588209},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Distance-aware attention reshaping for enhancing generalization of neural solvers},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated fine-tuning on heterogeneous LoRAs with error-compensated aggregation. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3586545'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) has recently been applied to the parameter-efficient fine-tuning (PEFT) of large language models (LLMs). While promising, client resource heterogeneity has imposed the challenge of the “bucket effect” to FL, where model configuration must cater to the client with the fewest resources. To tackle this issue, heterogeneous low-rank adaptation (LoRA) has recently emerged in FL, which enables clients to do local fine-tuning with different LoRA ranks. However, existing works in this area typically adopt zero-padding, stacking, or singular value decomposition (SVD) for LoRA aggregation, which often incur precision loss or significant overhead, limiting their practicality. In this article, we propose ECLoRA, a novel method for federated fine-tuning with heterogeneous LoRA settings across clients. ECLoRA employs randomized SVD (RSVD) to dramatically reduce aggregation overhead while introducing an error compensation (EC) mechanism that incorporates the decomposition error from previous rounds to improve aggregation precision. Extensive experiments on four widely used foundation models across six public tasks demonstrate the effectiveness of ECLoRA. Specifically, ECLoRA is: (1) accurate, significantly improving the final model performance; (2) fast, accelerating convergence with an average speedup of $1.54\times $ to $3.01\times $ ; and (3) practical, reducing aggregation time by approximately $40\times $ compared to classical SVD.},
  archive      = {J_TNNLS},
  author       = {Wanyi Ning and Jingyu Wang and Qi Qi and Haifeng Sun and Daixuan Cheng and Cong Liu and Lei Zhang and Zirui Zhuang and Jianxin Liao},
  doi          = {10.1109/TNNLS.2025.3586545},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Federated fine-tuning on heterogeneous LoRAs with error-compensated aggregation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decentralized consensus inference-based hierarchical reinforcement learning for multiconstrained UAV pursuit-evasion game. <em>TNNLS</em>, 1-16. (<a href='https://doi.org/10.1109/TNNLS.2025.3582909'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple quadrotor uncrewed aerial vehicles (UAVs) systems have garnered widespread research interest and fostered tremendous interesting applications, especially in multiconstrained pursuit-evasion games (MC-PEGs). The cooperative evasion and formation coverage (CEFC) task, where the UAV swarm aims to maximize formation coverage across multiple target zones while collaboratively evading predators, belongs to one of the most challenging issues in MC-PEGs, especially under communication-limited constraints. This multifaceted problem, which intertwines responses to obstacles, adversaries, target zones, and formation dynamics, brings up significant high-dimensional complications in locating a solution. In this article, we propose a novel two-level framework [i.e., consensus inference-based hierarchical reinforcement learning (CI-HRL)], which delegates target localization to a high-level policy, while adopting a low-level policy to manage obstacle avoidance, navigation, and formation. Specifically, in the high-level policy, we develop a novel multiagent reinforcement learning (RL) module, consensus-oriented multiagent communication (ConsMAC), to enable agents to perceive global information and establish consensus from local states by effectively aggregating neighbor messages. Meanwhile, we leverage an alternative training-based MAPPO (AT-M) and policy distillation to accomplish the low-level control. The experimental results, including the high-fidelity software-in-the-loop (SITL) simulations, validate that CI-HRL provides a superior solution with enhanced swarm’s collaborative evasion and task completion capabilities.},
  archive      = {J_TNNLS},
  author       = {Yuming Xiang and Sizhao Li and Rongpeng Li and Zhifeng Zhao and Honggang Zhang},
  doi          = {10.1109/TNNLS.2025.3582909},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Decentralized consensus inference-based hierarchical reinforcement learning for multiconstrained UAV pursuit-evasion game},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncertain interruptibility multiobjective flexible job shop via deep reinforcement learning based on heterogeneous graph self-attention. <em>TNNLS</em>, 1-18. (<a href='https://doi.org/10.1109/TNNLS.2025.3578368'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although an increasing number of studies have focused on the flexible job shop problem, there has been insufficient consideration of realistic constraints, such as the working hours of employees and the noninterruptible nature of certain operations. To address this issue, here an improved deep reinforcement learning (DRL) approach is presented that utilizes end-to-end multidecision-intelligent body proximal policy optimization (m-PPO). In the proposed framework, a heterogeneous graph self-attention neural network (HGAN) model is embedded, which efficiently extracts valuable features from the original state in heterogeneous graphs to capture intricate relationships. Within this framework, agents are divided into five rule-driven job decision agents and data-driven operation-machine ( $\mathcal {O}\text {-}\mathcal {M}$ ) pair decision agents, which incorporate problem-specific knowledge. To optimize the makespan, total costs, and total lateness concurrently, the weight parameters for the objectives are generated by the network and self-updated based on the current state. Numerical experiments demonstrate the effectiveness of the proposed method.},
  archive      = {J_TNNLS},
  author       = {Zunxun Wang and Junqing Li and Xiaolong Chen and Peiyong Duan and Jiake Li},
  doi          = {10.1109/TNNLS.2025.3578368},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-18},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Uncertain interruptibility multiobjective flexible job shop via deep reinforcement learning based on heterogeneous graph self-attention},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A self-supervised heterogeneous graph attention model based on adaptable step-size metapaths. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3587020'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graphs are widely used to model networks in real-world applications, with heterogeneous graph neural networks gaining increasing attention in recent years. Existing methods generally rely on first-order or high-order neighbors to capture semantic relationships, where metapath-based approaches are the most popular ones. However, existing metapath-based models not only require predefined metapaths based on prior knowledge, but also lack the consideration of metapath sequence modeling. Additionally, labeled data are scarce in massive graph data, and existing self-supervised or semisupervised models heavily rely on data enhancement strategies and complex frameworks. To address these limitations, we propose a self-supervised heterogeneous graph attention model (HGAM) based on adaptable step-size metapaths. Our model requires no prior knowledge to select the type of metapath and can adaptively capture the specific step-size metapath with high importance. The adaptable step-size metapaths module not only considers the attention weight in different step sizes, but also pays attention to the changing trend of attention, which expands the receptive field of the model and integrates global information preferably. To alleviate labeled data scarcity, our model employs a dual contrastive learning strategy. HGAM learns global representations by contrasting a high-order meta-graph against nodes, while preserving local structure through a cross-view comparison of first-order and high-order semantics. Extensive experiments on three different types of tasks, including node classification, clustering, and link prediction, are conducted on real-world datasets. Experimental results demonstrate that HGAM achieves superior performance compared to state-of-the-art methods.},
  archive      = {J_TNNLS},
  author       = {Xiangyi Teng and Minghao Zhong and Jing Liu},
  doi          = {10.1109/TNNLS.2025.3587020},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A self-supervised heterogeneous graph attention model based on adaptable step-size metapaths},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RealignDiff: Boosting text-to-image diffusion model with coarse-to-fine semantic realignment. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3584554'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in text-to-image diffusion models have achieved remarkable success in generating high-quality, realistic images from textual descriptions. However, these approaches have faced challenges in precisely aligning the generated visual content with the textual concepts described in the prompts. In this article, we propose a two-stage coarse-to-fine semantic realignment method, named RealignDiff, aimed at improving the alignment between text and images in text-to-image diffusion models. In the coarse semantic realignment phase, a novel caption reward, leveraging the BLIP-2 model, is proposed to evaluate the semantic discrepancy between the generated image caption and the given text prompt. Subsequently, the fine semantic realignment stage uses a local dense caption generation module and a reweighting attention modulation module to refine the previously generated images from a local semantic view. Experimental results on the MS-COCO and ViLG-300 datasets demonstrate that the proposed two-stage coarse-to-fine semantic realignment method outperforms other baseline realignment techniques by a substantial margin in both visual quality and semantic similarity with the input prompt.},
  archive      = {J_TNNLS},
  author       = {Zutao Jiang and Guian Fang and Jianhua Han and Guansong Lu and Hang Xu and Shengcai Liao and Xiaojun Chang and Xiaodan Liang},
  doi          = {10.1109/TNNLS.2025.3584554},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {RealignDiff: Boosting text-to-image diffusion model with coarse-to-fine semantic realignment},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward open-world domain adaptation via iteratively contrastive learning and clustering. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3584072'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The open-set domain adaptation (DA) aims to address both covariate shift and category shift between a labeled source domain and an unlabeled target domain. Nevertheless, existing open-set DA methods always ignore the demand for discovering novel classes that are not present in the source domain and simply reject them as “unknown” sets without further exploration, which motivates us to understand the unknown sets more specifically. In this article, we present a more challenging open-world DA problem that recognizes seen classes while discovering novel classes in the target domain. To address this problem, we propose a novel framework that converts this problem into a clustering task via contrastive learning to learn pairwise relationships among the instances. More specifically, our method consists of two iterative steps. The semi-supervised clustering step clusters the unlabeled target data and separates it into seen and novel classes. In the contrastive learning step, based on the cluster assignments, we design tailored contrastive losses that learn pairwise relationships to reduce domain discrepancy and discover novel classes. Our method can be optimized as an example of expectation maximization (EM). We establish several baselines by extending related work. Our method obtains the superior performance on five public datasets, benchmarking this challenging setting for future research.},
  archive      = {J_TNNLS},
  author       = {Jingzheng Li and Hailong Sun and Jiyi Li and Pengpeng Chen and Shikui Wei},
  doi          = {10.1109/TNNLS.2025.3584072},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Toward open-world domain adaptation via iteratively contrastive learning and clustering},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ODMTCNet: An interpretable multiview deep neural network architecture for feature representation. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3588327'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, deep cascade architecture-based algorithms have attracted wide attention and have been applied to numerous application domains successfully. Nevertheless, the black-box structure of such algorithms has always been considered the Achilles’ heel by the machine learning community. Moreover, due to its data-driven nature, the deep cascade architecture likely causes over-fitting problems when there is no sufficient data available. In order to solve these pressing issues, this work proposes a novel multiview deep neural network (DNN) model, namely, optimal discriminant multiview tensor convolutional network (ODMTCNet), which integrates statistics-guided optimization (SGO) principles with the DNN architecture. Specifically, a discriminant multiview tensor convolution strategy is proposed and integrated with a deep cascade architecture. Different from the traditional DNN models, the parameters of the convolutional layers in ODMTCNet are determined by solving SGO problems. Based on the SGO principles, the relation between the optimal performance and parameters (e.g., the number of convolutional filters) can be analytically predicted, with each layer generating justified knowledge representations. In addition, information quality (IQ) is adopted to further improve multiview feature representation. Because of its unique design, ODMTCNet is able to handle different types of features (e.g., raw, hand-crafted, prior knowledge-based, and DNN-generated features), forming a general platform for multiview feature representation. To validate the genericness and effectiveness of the ODMTCNet model, we conducted experiments on five datasets of different scales: The Olivetti Research Lab (ORL) database, the Facial Recognition Technology (FERET) database, the ETH-80 database, the Caltech 256 database, and the nanyang technological university (NTU) red green blue-depth (RGB+D) 120 database. Experimental results show the superiority of the presented solution over the state-of-the-art. Implementation codes will be made available in the final version.},
  archive      = {J_TNNLS},
  author       = {Lei Gao and Zheng Guo and Ling Guan},
  doi          = {10.1109/TNNLS.2025.3588327},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {ODMTCNet: An interpretable multiview deep neural network architecture for feature representation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NACHOS: Neural architecture search for hardware-constrained early-exit neural networks. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3588558'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early-exit neural networks (EENNs) endow a standard deep neural network (DNN) with early-exit classifiers (EECs) to provide predictions at intermediate points of the processing when enough confidence in classification is achieved. This leads to many benefits in terms of effectiveness and efficiency. Currently, the design of EENNs is carried out manually by experts, a complex and time-consuming task that requires accounting for many aspects, including the correct placement, the thresholding, and the computational overhead of the EECs. For this reason, the research is exploring the use of neural architecture search (NAS) to automate the design of EENNs. Currently, few comprehensive NAS solutions for EENNs have been proposed in the literature, and a fully automated, joint design strategy taking into consideration both the backbone and the EECs remains an open problem. To this end, this work presents neural architecture search for hardware-constrained early exit neural networks (NACHOS), the first NAS framework for the design of optimal EENNs satisfying constraints on the accuracy and the number of multiply and accumulate (MAC) operations performed by the EENNs at inference time. In particular, this provides the joint design of backbone and EECs to select a set of admissible (i.e., respecting the constraints) Pareto optimal solutions in terms of the best trade-off between the accuracy and the number of MACs. The results show that the models designed by NACHOS are competitive with the state-of-the-art EENNs. Additionally, this work investigates the effectiveness of two novel regularization terms designed for the optimization of the auxiliary classifiers of the EENN.},
  archive      = {J_TNNLS},
  author       = {Matteo Gambella and Jary Pomponi and Simone Scardapane and Manuel Roveri},
  doi          = {10.1109/TNNLS.2025.3588558},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {NACHOS: Neural architecture search for hardware-constrained early-exit neural networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Copula density neural estimation. <em>TNNLS</em>, 1-8. (<a href='https://doi.org/10.1109/TNNLS.2025.3585755'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probability density estimation from observed data constitutes a central task in statistics. In this brief, we focus on the problem of estimating the copula density associated with any observed data, as it fully describes the dependence between random variables. We separate univariate marginal distributions from the joint dependence structure in the data, the copula itself, and we model the latter with a neural network-based method referred to as copula density neural estimation (CODINE). Results show that the novel learning approach is capable of modeling complex distributions and can be applied for mutual information estimation and data generation.},
  archive      = {J_TNNLS},
  author       = {Nunzio A. Letizia and Nicola Novello and Andrea M. Tonello},
  doi          = {10.1109/TNNLS.2025.3585755},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-8},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Copula density neural estimation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ChebMixer: Efficient graph representation learning with MLP mixer. <em>TNNLS</em>, 1-12. (<a href='https://doi.org/10.1109/TNNLS.2025.3589316'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have achieved remarkable success in learning graph representations, especially graph Transformers, which have recently shown superior performance on various graph mining tasks. However, the graph Transformer generally treats nodes as tokens, which results in quadratic complexity regarding the number of nodes during self-attention computation. The graph multilayer perceptron (MLP) mixer addresses this challenge using the efficient MLP Mixer technique from computer vision. However, the time-consuming process of extracting graph tokens limits its performance. In this article, we present a novel architecture named ChebMixer, a newly proposed graph MLP Mixer that uses fast Chebyshev polynomials-based spectral filtering to extract a sequence of tokens. First, we produce multiscale representations of graph nodes via fast Chebyshev polynomial-based spectral filtering. Next, we consider each node’s multiscale representations as a sequence of tokens and refine the node representation with an effective MLP Mixer. Finally, we aggregate the multiscale representations of nodes through Chebyshev interpolation. Owing to the powerful representation capabilities and fast computational properties of the MLP Mixer, we can quickly extract more informative node representations to improve the performance of downstream tasks. The experimental results prove our significant improvements in various scenarios, ranging from homogeneous and heterophilic graph node classification to medical image segmentation. Compared with NAGphormer, the average performance improved by 1.45% on homogeneous graphs and 4.15% on heterophilic graphs. And the average performance improved by 1.39% on medical image segmentation tasks compared with VM-UNet. We will release the source code after this article is accepted.},
  archive      = {J_TNNLS},
  author       = {Xiaoyan Kui and Haonan Yan and Qinsong Li and Min Zhang and Liming Chen and Beiji Zou},
  doi          = {10.1109/TNNLS.2025.3589316},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {ChebMixer: Efficient graph representation learning with MLP mixer},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). D2Fed: Federated semi-supervised learning with dual-role additive local training and dual-perspective global aggregation. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3587942'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated semi-supervised learning (FSSL) has recently emerged as a promising approach for enhancing the performance of federated learning (FL) using ubiquitous unlabeled data. However, this approach encounters challenges when learning a global model using both fully labeled and fully unlabeled clients. Previous works overlook the dissimilarities between labeled and unlabeled clients, predominantly using shared parameters for local training across these two types of clients, thereby inducing intertask interference during local training. Moreover, these works typically adopt a single-perspective aggregation strategy, primarily focusing on data-volume-aware aggregation (i.e., FedAvg), leading to a lack of comprehensive consideration in model aggregation. In this article, we propose a novel FSSL method termed $\text {D}^{{2}}\text {Fed}$ , which addresses these issues by rethinking the roles of labeled clients and unlabeled ones to mitigate intertask interference during local training and by integrating client-type-aware with data-volume-aware to provide a more comprehensive perspective for model aggregation. Specifically, in local training, our proposed $\text {D}^{{2}}\text {Fed}$ distinguishes between the primary and accessory roles of labeled and unlabeled clients, respectively, performing dual-role additive local training (DALT) accordingly. In global aggregation, $\text {D}^{{2}}\text {Fed}$ uses a dual-perspective global aggregation (DGA) strategy, transitioning from data-volume-aware aggregation to client-type-aware aggregation. The proposed method simultaneously improves both local training and global model aggregation for FSSL without compromising privacy. We demonstrate the effectiveness and robustness of the proposed method through extensive experiments and elaborate ablation studies conducted on the CIFAR-10/100, SVHN, FMNIST, and STL-10 datasets. Experimental results show that $\text {D}^{{2}}\text {Fed}$ outperforms state-of-the-arts on five datasets under diverse data settings.},
  archive      = {J_TNNLS},
  author       = {Jingxin Mao and Yu Yang and Zhiwei Wei and Yanlong Bi and Rongqing Zhang},
  doi          = {10.1109/TNNLS.2025.3587942},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {D2Fed: Federated semi-supervised learning with dual-role additive local training and dual-perspective global aggregation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Long short-term financial time series forecasting based on residual multiscale TCN sparse expert network and informer. <em>TNNLS</em>, 1-10. (<a href='https://doi.org/10.1109/TNNLS.2025.3584369'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the inherent high volatility and complexity of financial markets, traditional time series forecasting models face numerous challenges in handling both short- and long-term predictions in the stock market. Most traditional neural network-based financial prediction models are limited to short-term forecasting and struggle to capture long-term trends and global dependencies in the market fully. To address this, we propose a novel network architecture called ResMMoT-Informer. This model combines the strengths of the residual multiscale temporal convolutional network (TCN) sparse expert network (ResMMoT) and the Informer, enabling it to effectively capture multiscale local features and global dependencies in the stock market. ResMMoT achieves stable training through a residual structure and a sparse multiscale TCN expert network, allowing it to flexibly model complex temporal features and learn trends across different time-step scales. Meanwhile, the Informer optimizes long-sequence forecasting performance through an improved self-attention mechanism. Additionally, we introduce the wavelet noise reduction (WNR) method, further enhancing the model’s robustness and prediction accuracy. In the experimental section, ablation experiments first validate the effectiveness and necessity of the proposed strategies and network structure. Subsequent comparison experiments on the NASDAQ100 dataset demonstrate that ResMMoT-Informer excels in both long- and short-term time series forecasting tasks in the stock market, with significantly better prediction accuracy and generalization ability than existing models. Compared to other popular neural network-based financial forecasting models, ResMMoT-Informer leads in prediction accuracy, time robustness, and interpretability, showcasing its cutting-edge advantage in contemporary research.},
  archive      = {J_TNNLS},
  author       = {Wuzhida Bao and Yuting Cao and Yin Yang and Shiping Wen},
  doi          = {10.1109/TNNLS.2025.3584369},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Long short-term financial time series forecasting based on residual multiscale TCN sparse expert network and informer},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Domain information mining and state-guided adaptation network for multispectral image segmentation. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3589574'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Segment anything model (SAM), as a prompt-based image segmentation foundation model, demonstrates strong task versatility and domain generalization (DG) capabilities, providing a new direction for solving cross-scene segmentation tasks. However, SAM still has limitations in multispectral cross-domain segmentation tasks, mainly reflected in: 1) insufficient information utilization, which is reflected in the neglect of nonvisible spectral information and the shift information contained in source domain (SD) samples and target domain (TD) samples; and 2) lack of cross-domain strategies, which leads to insufficient cross-domain adaptation (DA) ability in downstream tasks. To address these challenges, we combine the respective advantages of masked autoencoder (MAE) and cross-domain strategies, propose an improved SAM DA network structure called domain information mining and state-guided adaptation network (DSAnet), aiming to enhance SAM’s performance in multispectral cross-domain segmentation tasks from both data and task levels. At the data level, DSAnet incorporates a style masking learning component, which randomly masks image features and replaces them with domain-specific learnable tokens, integrated with the image reconstruction task, to mine the style information and domain invariance of the image itself. At the task level, DSAnet introduces domain state learning and style-guided segmentation: domain state learning, through a state sequence modeling approach, designs specific state representations for SD and TD to capture interdomain differences, thereby reducing task shift. Meanwhile, the learned domain state information can be directly applied to the inference stage. Style prompt segmentation guides the segmentation training process of SD images with TD style prompts, improving SAM’s adaptability in cross-domain multispectral segmentation downstream tasks. Extensive experiments on three multitemporal multispectral image (MSI) datasets demonstrate the superiority of the proposed method compared to state-of-the-art cross-domain strategies and SAM variant methods.},
  archive      = {J_TNNLS},
  author       = {Boyu Zhao and Mengmeng Zhang and Wei Li and Yunhao Gao and Junjie Wang},
  doi          = {10.1109/TNNLS.2025.3589574},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Domain information mining and state-guided adaptation network for multispectral image segmentation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive neighborhood-resonated graph convolution network for undirected weighted graph representation. <em>TNNLS</em>, 1-12. (<a href='https://doi.org/10.1109/TNNLS.2025.3589224'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An undirected weighted graph (UWG) is the fundamental data representation in various real applications. A graph convolution network is frequently utilized for representation learning to a UWG. Nevertheless, existing graph convolutional networks (GCNs) only consider a node’s neighborhood during the embedding propagation, which regrettably decreases its representation learning capability due to the information loss in the modeling phase. Motivated by this discovery, this study proposes an adaptive neighborhood-resonated graph convolution network (ANR-GCN) with the following ideas: 1) establishing the weighted embedding propagation with the consideration of link weights in a UWG, thereby incorporating the interaction strength of each node pair into the ANR-GCN model; 2) building the neighborhood-regularization (NR) to make each node resonate with its neighborhoods, thus reinforcing the informative neighborhood information for improving the ANR-GCN’s representation capability to the complex topology of the target UWG; and 3)diversifying the NR effects following the attention principle for guaranteeing the ANR-GCN’s learning capacity. The proposed ANR-GCN’s representation learning ability to a UWG is theoretically guaranteed from the perspectives of bounded generalization error and uniform stability. Extensive experiments on four UWG datasets illustrate that the proposed ANR-GCN significantly outperforms state-of-the-art GCNs in missing edge detection in a UWG, which evidently demonstrates its superior performance.},
  archive      = {J_TNNLS},
  author       = {Jiufang Chen and Ye Yuan and Xin Luo and Xinbo Gao},
  doi          = {10.1109/TNNLS.2025.3589224},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {An adaptive neighborhood-resonated graph convolution network for undirected weighted graph representation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Video prediction of dynamic physical simulations with pixel-space spatiotemporal transformers. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3585949'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by the performance and scalability of autoregressive large language models (LLMs), transformer-based models have seen recent success in the visual domain. This study investigates a transformer adaptation for video prediction with a simple end-to-end approach, comparing various spatiotemporal self-attention layouts. Focusing on causal modeling of physical simulations over time; a common shortcoming of existing video-generative approaches, we attempt to isolate spatiotemporal reasoning via physical object tracking metrics and unsupervised training on physical simulation datasets. We introduce a simple yet effective pure transformer model for autoregressive video prediction, utilizing continuous pixel-space representations for video prediction. Without the need for complex training strategies or latent feature-learning components, our approach significantly extends the time horizon for physically accurate predictions by up to 50% when compared with existing latent-space approaches, while maintaining comparable performance on common video quality metrics. In addition, we conduct interpretability experiments to identify network regions that encode information useful to perform accurate estimations of PDE simulation parameters via probing models, and find that this generalizes to the estimation of out-of-distribution simulation parameters. This work serves as a platform for further attention-based spatiotemporal modeling of videos via a simple, parameter efficient, and interpretable approach.},
  archive      = {J_TNNLS},
  author       = {Dean L. Slack and G. Thomas Hudson and Thomas Winterbottom and Noura Al Moubayed},
  doi          = {10.1109/TNNLS.2025.3585949},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Video prediction of dynamic physical simulations with pixel-space spatiotemporal transformers},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PolicyMamba: Localized policy attention with state space model for land cover classification. <em>TNNLS</em>, 1-12. (<a href='https://doi.org/10.1109/TNNLS.2025.3586836'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multihead self-attention and cross-attention mechanisms often suffer from computational inefficiencies, limited scalability, and suboptimal contextual understanding, particularly in hyperspectral image (HSI) classification. These mechanisms struggle to effectively capture long-range dependencies while maintaining computational feasibility due to the quadratic complexity of self-attention. To address these challenges, this work proposes PolicyMamba, a spectral–spatial mamba model enhanced with a localized policy attention mechanism. This mechanism reduces computational overhead by restricting attention to nonoverlapping localized regions and enforcing sparsity constraints, ensuring that only the most informative interactions are retained. A hierarchical aggregation strategy further integrates patch-wise attention outputs, preserving spectral–spatial correlations across scales. In addition, a sliding window patch process enhances local feature continuity while mitigating information loss. The PolicyMamba framework integrates spectral–spatial token generation, token enhancement, localized attention, and state transition modules, significantly improving HSI feature representation. Extensive experiments demonstrate that PolicyMamba achieves superior classification accuracy, outperforming conventional and state-of-the-art methods in land cover classification (LCC) by efficiently modeling intricate dependencies in HSI data.},
  archive      = {J_TNNLS},
  author       = {Muhammad Ahmad and Manuel Mazzara and Salvatore Distefano and Adil Mehmood Khan and Muhammad Hassaan Farooq Butt and Danfeng Hong},
  doi          = {10.1109/TNNLS.2025.3586836},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {PolicyMamba: Localized policy attention with state space model for land cover classification},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Progressive training for learning from label proportions. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3590131'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning from label proportions (LLPs), which aims to learn an instance-level classifier using proportion-based grouped training data, has garnered increasing attention in the field of machine learning. Existing deep learning-based LLP methods employ end-to-end pipelines to derive proportional loss functions via the Kullback–Leibler (KL) divergence between bag-level prior and posterior class distributions. However, the optimal solutions of these methods often struggle to conform to the given proportions, inevitably leading to degradation in the final classification performance. In this article, we address this issue by proposing a novel progressive training method for LLP, termed PT-LLP, which strives to meet the proportion constraints from the bag level to the instance level. Specifically, we first train a model by using the existing KL-divergence-based LLP methods that are consistent with bag-level proportion information. Then, we impose additional constraints on strict proportion consistency to the classifier to further move toward a more ideal solution by reformulating it as a constrained optimization problem, which can be efficiently solved using optimal transport (OT) algorithms. In particular, the knowledge distillation is employed as a transition stage to transfer the bag-level information to the instance level using a teacher–student framework. Finally, our framework is model-agnostic and demonstrates significant performance improvements through extensive experiments on different datasets when incorporated into other deep LLP methods as the first training stage.},
  archive      = {J_TNNLS},
  author       = {Jiabin Liu and Bo Wang and Yuping Zhang and Huadong Wang and Biao Li and Xin Shen and Gang Kou},
  doi          = {10.1109/TNNLS.2025.3590131},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Progressive training for learning from label proportions},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The diversity bonus: Learning from dissimilar clients in personalized federated learning. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3585927'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized federated learning (PFL) allows clients to collaboratively train their personalized models to handle situations where data from different clients are not independent and identically distributed (non-IID). Previous PFL research implicitly assumes that clients benefit most from those with similar data distributions. Correspondingly, methods such as personalized weight aggregation assign higher weights to similar clients during aggregation. We pose a question: can a client benefit from other clients with dissimilar data distributions, and if so, how? This question is particularly relevant in scenarios with a high degree of non-IID, where clients have widely different distributions, and learning from only similar clients will result in a loss of knowledge from many other clients. We note that when dealing with clients with similar distributions, current methods tend to enforce their models to be close in the parameter space. It is reasonable to conjecture that a client can benefit from dissimilar clients if we allow their models to depart from each other. Based on this idea, we propose DiversiFed, which allows each client to learn from clients with diversified distribution. DiversiFed pushes personalized models of clients with dissimilar distributions apart in the parameter space while pulling together those with similar distributions. In addition, to achieve the above effect without using prior knowledge of distribution, we design a loss function that leverages model similarity to determine the degree of attraction and repulsion between any two models. Experiments on benchmark and medical datasets show that DiversiFed can outperform the state-of-the-art (SOTA) methods by up to 3.19%.},
  archive      = {J_TNNLS},
  author       = {Xinghao Wu and Jianwei Niu and Xuefeng Liu and Guogang Zhu and Shaojie Tang and Wanyu Lin and Jiannong Cao},
  doi          = {10.1109/TNNLS.2025.3585927},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {The diversity bonus: Learning from dissimilar clients in personalized federated learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey on text-guided 3-D visual grounding: Elements, recent advances, and future directions. <em>TNNLS</em>, 1-22. (<a href='https://doi.org/10.1109/TNNLS.2025.3584895'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text-guided 3-D visual grounding (T-3DVG), which aims to locate a specific object that semantically corresponds to a language query from a complicated 3-D scene, has drawn increasing attention in the 3-D research community over the past few years. Compared to 2-D visual grounding, this task presents great potential and challenges due to its closer proximity to the real world, the complexity of data collection, and 3-D point cloud source processing. In this survey, we attempt to provide a comprehensive overview of the T-3DVG progress, including its fundamental elements, recent research advances, and future research directions. To the best of our knowledge, this is the first systematic survey on the T-3DVG task. Specifically, we first provide a general structure of the T-3DVG pipeline with detailed components in a tutorial style, presenting a complete background overview. Then, we summarize the existing T-3DVG approaches into different categories and analyze their strengths and weaknesses. We also present the benchmark datasets and evaluation metrics to assess their performances. Finally, we discuss the potential limitations of existing T-3DVG and share some insights on several promising research directions.},
  archive      = {J_TNNLS},
  author       = {Daizong Liu and Yang Liu and Wencan Huang and Wei Hu},
  doi          = {10.1109/TNNLS.2025.3584895},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-22},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A survey on text-guided 3-D visual grounding: Elements, recent advances, and future directions},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Off-OAB: Off-policy policy gradient method with optimal action-dependent baseline. <em>TNNLS</em>, 1-12. (<a href='https://doi.org/10.1109/TNNLS.2025.3588881'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The policy-based methods have achieved remarkable success in solving challenging reinforcement learning (RL) problems. Among these methods, the off-policy policy gradient (OPPG) methods are particularly important because they can benefit from off-policy data. However, these methods suffer from the high variance of the OPPG estimator, which results in poor sample efficiency during training. In this article, we propose an off-policy policy gradient method with the optimal action-dependent baseline (Off-OAB) to mitigate this variance issue. Specifically, this baseline maintains the OPPG estimator’s unbiasedness while theoretically minimizing its variance. To enhance practical computational efficiency, we design an approximated version of this optimal baseline. Utilizing this approximation, our method (Off-OAB) aims to decrease the OPPG estimator’s variance during policy optimization. We evaluate the proposed Off-OAB method on six representative tasks from OpenAI Gym and MuJoCo, where it demonstrably surpasses the state-of-the-art methods on the majority of these tasks.},
  archive      = {J_TNNLS},
  author       = {Wenjia Meng and Qian Zheng and Long Yang and Yilong Yin and Gang Pan},
  doi          = {10.1109/TNNLS.2025.3588881},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Off-OAB: Off-policy policy gradient method with optimal action-dependent baseline},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). OS-RRG: Observation state-aware radiology report generation with balanced diagnosis and attention intervention. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3589103'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radiology report generation (RRG) aims to automatically generate detailed textual descriptions and diagnoses for clinical radiography, alleviating radiologists’ workloads, aiding inexperienced radiologists, and minimizing errors. RRG is challenging due to the need to generate coherent and clinically accurate multisentence reports that describe various medical conditions. Although previous diagnosis-guided methods achieve impressive diagnostic accuracy by explicitly converting the identified observation states (OSs) (e.g., positive, negative, and uncertain) to descriptions, these methods still struggle in accurate observation-state identification and establishing precise state-to-description alignment. These challenges largely stem from the two aspects of imbalance (interclass and intraclass) inherent in observation states. In this article, we introduce a novel framework, observation state-aware radiology report generator (OS-RRG), designed to improve both the identification of states and their alignment with clinical descriptions. Our approach includes a state-aware balancing diagnosis (SBD) module to address both interclass and intraclass imbalances, an issue that previous methods have overlooked, resulting in suboptimal identification performance. In addition, we propose a novel technique called state-guided attention intervention (SAI), which dynamically adjusts focus on critical diagnostic features through a targeted filtering and enhancement mechanism. Furthermore, we propose a task-specific learning paradigm that decouples the identification and alignment processes into independent pathways, significantly enhancing the overall performance. Experiments on the MIMIC-CXR and IU-Xray benchmarks demonstrate the superior diagnostic accuracy of our method, which outperforms existing state-of-the-art techniques. The code will be made publicly available at https://github.com/xmed-lab/OS_RRG},
  archive      = {J_TNNLS},
  author       = {Honglong Yang and Hui Tang and Shanshan Song and Xiaomeng Li},
  doi          = {10.1109/TNNLS.2025.3589103},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {OS-RRG: Observation state-aware radiology report generation with balanced diagnosis and attention intervention},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Game-theoretic constrained policy optimization for safe reinforcement learning. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3586603'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Safe reinforcement learning (RL) aims to optimize the task performance with safety guarantees. One common modeling scheme to study safe RL problems is the constrained Markov decision process (CMDP). However, current safe RL methods within the CMDP framework face challenges in tradeoffs among various objectives and gradient conflicts of policy updating. To cope with these challenges, this article presents a novel safe RL approach called game-theoretic constrained policy optimization (GCPO). The proposed approach formulates the CMDP problem as a general-sum Markov game with multiple players, where a task player seeks to maximize the reward objective, while constraint players aim to minimize constraint objectives until they are fulfilled. By doing so, GCPO adopts the learning mode with multiple subpolicies, each aligned with a distinct objective, that collectively constitute the overall behavior of the agent. The learning convergence of the GCPO can be ensured with the contraction mapping to the Nash equilibrium. Furthermore, a novel dominant timescale update rule is presented for multiplayer policy learning to guarantee constraint satisfaction. The learning convergence and constraint satisfaction of GCPO are theoretically analyzed. Consequently, GCPO eliminates the necessity of tuning tradeoff parameters and mitigates gradient conflicts during multiobjective policy updating. Experimental results show that GCPO outperforms state-of-the-art safe RL algorithms in a quadrotor trajectory tracking task and various high-dimensional robot locomotion benchmarks. Moreover, GCPO exhibits robustness to diverse scales of task rewards and constraint costs without the need for intricate tradeoffs.},
  archive      = {J_TNNLS},
  author       = {Changxin Zhang and Xinglong Zhang and Yixing Lan and Hao Gao and Xin Xu},
  doi          = {10.1109/TNNLS.2025.3586603},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Game-theoretic constrained policy optimization for safe reinforcement learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing graph reconstruction: Uniting dual-level graph structure with graph reinforcement learning. <em>TNNLS</em>, 1-11. (<a href='https://doi.org/10.1109/TNNLS.2025.3585906'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A combinatorial optimization problem is typically regarded as a 1-D sorting problem in most existing research. The representation ignores some information about the problem because of dimension compression. When applying reinforcement learning (RL) to this problem, convolutional neural networks (CNNs) used in conventional RL cannot directly extract the connection information between two elements in the feature matrix. A typical class of combinatorial optimization problems, the job shop scheduling problem (JSSP), is used in this article as an example. Considering the limitations in previous research, this article reexamines the task from the perspective of graph reconstruction and proposes a graph RL (GRL) method that combines a double deep Q-network (DDQN) and graph attention network (GAT) to achieve breakthroughs beyond the constraints of CNN performance. Moreover, a dual-level graph representation structure is constructed to comprehensively learn the features of scheduling information and overcome the difficulty of learning dynamic graphs. Experiments show that the quality of the obtained solution and generalization performance are both improved compared with models based on original deep RL (DRL) algorithms.},
  archive      = {J_TNNLS},
  author       = {Dazi Li and Yanyang Bao and Xin Xu},
  doi          = {10.1109/TNNLS.2025.3585906},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Enhancing graph reconstruction: Uniting dual-level graph structure with graph reinforcement learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online adaptable offline RL with guidance model. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3589418'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning (RL) has emerged as a promising approach across various applications, yet its reliance on repeated trial-and-error learning to develop effective policies from scratch poses significant challenges for deployment in scenarios where interaction is costly or constrained. In this work, we investigate the offline-to-online RL paradigm, wherein policies are initially pretrained using offline historical datasets and subsequently fine-tuned with a limited amount of online interaction. Previous research has suggested that efficient offline pretraining is crucial for achieving optimal final performance. However, it is challenging to incorporate appropriate conservatism to prevent the overestimation of out-of-distribution (OOD) data while maintaining adaptability for online fine-tuning. To address these issues, we propose an effective offline RL algorithm that integrates a guidance model to introduce suitable conservatism and ensure seamless adaptability to online fine-tuning. Our rigorous theoretical analysis and extensive experimental evaluations demonstrate better performance of our novel algorithm, underscoring the critical role played by the guidance model in enhancing its efficacy.},
  archive      = {J_TNNLS},
  author       = {Xun Wang and Jingmian Wang and Zhuzhong Qian and Bolei Zhang},
  doi          = {10.1109/TNNLS.2025.3589418},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Online adaptable offline RL with guidance model},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A switched system model for exponential stability and dissipativity of delayed neural networks. <em>TNNLS</em>, 1-10. (<a href='https://doi.org/10.1109/TNNLS.2025.3590251'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates the problems of exponential stability and dissipativity for neural networks with time-varying delays. To capture more information on the delay and its derivative in constructing Lyapunov–Krasovskii functionals (LKFs), the original delayed neural network (DNN) is modeled as a switching system with two modes, corresponding to cases where the delay derivative is positive or negative. This model provides extra freedom in constructing a proper LKF, allowing for the selection of different Lyapunov matrices in each mode. By applying the average dwell time (ADT) technique, several criteria for exponential stability and exponential dissipativity are obtained for DNNs. Two extensively studied benchmark examples and a quadruple-tank process control system are provided to demonstrate the superiority of the proposed criteria over some existing methods and to verify the practical applicability of the approach.},
  archive      = {J_TNNLS},
  author       = {Hong-Bing Zeng and Zong-Jun Zhu and Shen-Ping Xiao and Xian-Ming Zhang},
  doi          = {10.1109/TNNLS.2025.3590251},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A switched system model for exponential stability and dissipativity of delayed neural networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HCG: Streaming DCNN accelerator with a hybrid computational granularity scheme on FPGA. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3587694'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growth of field-programmable gate array (FPGA) hardware resources, streaming DCNN accelerators leverage interconvolutional-layer parallelism to enhance throughput. In existing streaming accelerators, convolution nodes typically adopt layer- or column-based tiling methods, where the tiled input feature map (Ifmap) encompasses all input channels. This approach facilitates the comprehensive calculation of the output feature map (Ofmap) and maximizes interlayer parallelism. The computational granularity, defined in this study as the calculated rows or columns of Ofmap based on each tiled Ifmap data, significantly influences on-chip Ifmap storage and off-chip weight bandwidth (BW). The uniform application of computational granularity across all nodes inevitably impacts the memory-BW tradeoff. This article introduces a novel streaming accelerator with a hybrid computational granularity (HCG) scheme. Each node employs an independently optimized computational granularity, enabling a more flexible memory-BW tradeoff and more effective utilization of FPGA resources. However, this hybrid scheme can introduce pipeline bubbles and increase system pipeline complexity and control logic. To address these challenges, this article theoretically analyzes the impact of computational granularity on individual computing nodes and the overall system, aiming to establish a seamless system pipeline without pipeline bubbles and simplify system design. Furthermore, the article develops a hardware overhead model and employs a heuristic algorithm to optimize computational granularity for each computing node, achieving optimal memory-BW tradeoff and higher throughput. Finally, the effectiveness of the proposed design and optimization methodology is validated through the implementation of a 3-TOPS ResNet-18 accelerator on the Alveo U250 development board under BW constraints of 25, 20, and 15 GB/s. Additionally, accelerators for 4-TOPS VGG-16, 4-TOPS ResNet-34, 5-TOPS ResNet-50, 3-TOPS MobileNetV1, 4-TOPS ConvNeXt-T, and 4-TOPS ResNeXt-50 are implemented, surpassing the performance of most existing works.},
  archive      = {J_TNNLS},
  author       = {Wenjin Huang and Conghui Luo and Baoze Zhao and Han Jiao and Yihua Huang},
  doi          = {10.1109/TNNLS.2025.3587694},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {HCG: Streaming DCNN accelerator with a hybrid computational granularity scheme on FPGA},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). VB-adapter: Variational bayesian adapter for cross-domain speech representation learning. <em>TNNLS</em>, 1-12. (<a href='https://doi.org/10.1109/TNNLS.2025.3589086'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To leverage the abundant speech data available for pretraining, current models excel in generalization across diverse tasks. Nevertheless, real-world challenges emerge when addressing unfamiliar speech scenarios far from the pretrained speech, owing to the domain shift between pretraining (source) and fine-tuning (target) data. To overcome this barrier, we propose a variational Bayesian adapter (VB-Adapter) for cross-domain speech representation learning during fine-tuning. First, we establish a latent variable model to construct a desired posterior distribution after incorporating domain-specific knowledge to bridge the gap between the source and target domains. Then, an adaptive objective is presented to maximize the mutual information of the latent variables with and without domain-specific knowledge to facilitate model adaptation. Finally, we introduce contrastive learning on samples to optimize the lower bound of the above adaptive objective. Our experiments apply the VB-Adapter on transformers for dysarthric speech recognition (DSR) and the integration of Whisper-encoder and Llama for Mandarin speech recognition (MSR). The results reveal the effectiveness of VB-Adapter in modeling the uncertainties arising from domain shift and enhancing the robustness of speech representations.},
  archive      = {J_TNNLS},
  author       = {Jing Zhao and Qimin Huang and Shanhu Wang and Shiliang Sun},
  doi          = {10.1109/TNNLS.2025.3589086},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {VB-adapter: Variational bayesian adapter for cross-domain speech representation learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DAWN+: Wavelet-based image deraining meets direction-aware attention and mutual representation. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3587248'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The single-image deraining aims to restore clean scenes from rainy inputs by eliminating precipitation artifacts. Current methods often neglect the directional nature of rain streaks—a critical oversight that causes heterogeneous degradation, particularly in texture regions aligned with rain orientations. To address this issue and advance image deraining, we propose a novel direction-aware attention wavelet network (DAWN) for rain streaks removal. DAWN has several key distinctions and innovative features compared with existing wavelet transform-based methods: 1) introducing vector decomposition to parameterize rain distribution through vertical (V) and horizontal (H) component decomposition, enabling explicit direction-aware representation; 2) devising a novel direction-aware attention module (DAM) to learn projection/transformation parameters via coordinate attention mechanisms for precise rain removal and texture preservation; and 3) exploring practical composite constraints to jointly optimize structural coherence, detail fidelity, and chrominance accuracy. Building upon the conference version (DAWN), we devise DAWN+ with enhanced capabilities: 1) decoupling diagonal coefficient learning to eliminate frequency aliasing by characterizing diagonal components with dedicated projection parameters; 2) dividing vector decomposition and parameter fitting into multiple stages to reduce error accumulation; and 3) applying cross-frequency mutual representation to boost training and performance. Experiments across six tasks (deraining, raindrop/rainhaze removal, dehazing, and low-light/underwater enhancement) demonstrate the portability and reusability of these strategies. Meanwhile, DAWN+ delivers significant performance gains over DAWN, achieving an average peak signal to noise ratio (PSNR) increase of 1.17 dB with an acceptable complexity increase. Meanwhile, DAWN+ achieves the competitive performance to the state-of-the-art DRSformer (gaining 0.15 dB in PSNR) while saving 94.4% and 95% model parameters and inference time, respectively.},
  archive      = {J_TNNLS},
  author       = {Kui Jiang and Junjun Jiang and Zheng Wang and Zihan Geng and Xianming Liu},
  doi          = {10.1109/TNNLS.2025.3587248},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {DAWN+: Wavelet-based image deraining meets direction-aware attention and mutual representation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Find hidden modality divergence: Adversarial aware learning for unsupervised Visible–Infrared person re-identification. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3591116'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised visible–infrared person re-identifi-cation (Unsupervised VI-ReID) aims to learn discriminative identity features under the large modality gap without any labeled data. Currently, the state-of-the-art methods optimize cross-modality differences by using contrastive learning as the underlying paradigm. However, they neglect the problem of modality divergence during the cross-modality optimization process. This problem means that the interclass instances between the cross-modality intraclass gaps can make cross-modality intraclass instances difficult to get closer to each other in the feature space due to the effect of contrastive learning on these interclass instances. To alleviate the negative impact of the modality divergence problem, we propose an adversarial aware learning (ADAL) framework to explore the instances that generate modal divergence and adversarially optimize these explored instances. Specifically, on the one hand, we explore the optimization directions of each cluster during the cross-modality optimization process, and the cluster centroids generating positive optimization are facilitated, while the others generating negative optimization are penalized. On the other hand, we further consider the instance-level optimization process, which increases the affinities of the positive instance pairs with large cross-modality gaps to further improve the centroid-level optimization. Extensive experiments conducted on the visible–infrared person Re-ID datasets show that the proposed method is used as a universally applicable plug-in module to add the existing unsupervised VI-ReID methods, which outperforms the existing state-of-the-art approaches.},
  archive      = {J_TNNLS},
  author       = {Yuxuan Liu and Hongwei Ge and Yong Luo and Chunguo Wu},
  doi          = {10.1109/TNNLS.2025.3591116},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Find hidden modality divergence: Adversarial aware learning for unsupervised Visible–Infrared person re-identification},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An advanced optimal tracking control for nonlinear discrete-time systems based on (N + 1)-step gradient learning. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3588259'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, to address the issue of accelerating convergence performance and eliminating the tracking error, an advanced optimal control method for nonlinear discrete-time systems is investigated based on an improved N-step [( ${N} +1$ )-step] gradient learning algorithm. Independent of the discount factor, this article introduces a novel tracking error index without quadratic input terms for the steady-state and convergence performances, which obtains the optimal control policy without calculating the reference control input. Compared with classic N-step gradient learning algorithms with infinite future reward assumption, the proposed algorithm investigates the (N +1)-step return with a fixed N and a step forward for finite tracking problems based on a long-term weighting parameter. Based on the above theory, value iteration (VI) and policy iteration (PI) methods are utilized to derive the convergence, monotonicity, optimality, and stability properties of the proposed algorithm, which can be conducted without the traditional assumption of zero initial functions. In the implementation of the algorithms, the actor–critic structure, constructed by four neural networks, is established to approximate the states, the value functions, and the control policy, respectively. Three simulation experiments on a helicopter system validate the efficacy and practicality of the control methods in addressing nonlinear optimal tracking challenges.},
  archive      = {J_TNNLS},
  author       = {Zeyu Zhou and Yuhui Wang and Qingxian Wu},
  doi          = {10.1109/TNNLS.2025.3588259},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {An advanced optimal tracking control for nonlinear discrete-time systems based on (N + 1)-step gradient learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decoupling neural networks to leverage uniform representation and balance personalization and collaboration in federated learning. <em>TNNLS</em>, 1-11. (<a href='https://doi.org/10.1109/TNNLS.2025.3586600'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL), a distributed learning paradigm focused on preserving data privacy, faces challenges due to varying data distributions among clients, impacting global model performance. To mitigate data heterogeneity, we propose FedUB—a personalized FL framework leveraging uniform feature representation and balancing personalization and collaboration in the classifier. Specifically, the uniform representation (UR) in FedUB provides all clients with a shared feature extractor and a common representation centroid (RC). Achieving this uniformity involves incorporating a regularization term to reduce the gap between global and local RCs. Additionally, an importance estimation of the parameters in the classifier is provided to partition the parameters into two parts: the personalized component and the collaborated component. Specifically, the personalized component adapts to local data, while the collaborated component prevents the classifier from overfitting local data. Theoretically, we establish the existence of the UR, demonstrating its effectiveness in reducing the average generalization bound. Experiments on benchmark datasets consistently demonstrate the performance gains and improved generalization behavior of FedUB.},
  archive      = {J_TNNLS},
  author       = {Zhangmin Huang and Pengcheng Wang and Shaojie Tang and Bo Lyu and Lingfang Zeng},
  doi          = {10.1109/TNNLS.2025.3586600},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Decoupling neural networks to leverage uniform representation and balance personalization and collaboration in federated learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A-SDM: Accelerating stable diffusion through model assembly and feature inheritance strategies. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3587724'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The stable diffusion model (SDM) is a prevalent and effective model for text-to-image (T2I) and image-to-image (I2I) generation. Despite various attempts at sampler optimization, model distillation, and network quantification, these approaches typically maintain the original network architecture. The extensive parameter scale and substantial computational demands have limited research into adjusting the model architecture. This study focuses on reducing redundant computation in SDM and optimizes the model through both tuning and tuning-free methods: 1) for the tuning method, we design a model assembly strategy to reconstruct a lightweight model while preserving performance and ensuring semantic stability through distillation and 2) for the tuning-free method, we propose a feature inheritance strategy to accelerate inference by skipping local computations at the block, layer, or unit level within the network structure. We also examine multiple sampling modes for feature inheritance at the time-step level. Experiments demonstrate that both the proposed tuning and the tuning-free methods can improve the speed and performance of the SDM. The lightweight model reconstructed by the model assembly strategy increases generation speed by 22.4%, while the feature inheritance strategy enhances the SDM generation speed by 40.0%.},
  archive      = {J_TNNLS},
  author       = {Jinchao Zhu and Yuxuan Wang and Siyuan Pan and Pengfei Wan and Di Zhang and Gao Huang},
  doi          = {10.1109/TNNLS.2025.3587724},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A-SDM: Accelerating stable diffusion through model assembly and feature inheritance strategies},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SimAD: A simple dissimilarity-based approach for time-series anomaly detection. <em>TNNLS</em>, 1-12. (<a href='https://doi.org/10.1109/TNNLS.2025.3590220'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the prevalence of reconstruction-based deep learning methods, time-series anomaly detection (TSAD) remains a tremendous challenge. Existing approaches often struggle with limited temporal contexts, insufficient representation of normal patterns, and flawed evaluation metrics, all of which hinder their effectiveness in detecting anomalous behavior. To address these issues, we introduce a simple dissimilarity-based approach for time-series anomaly detection (SimAD). Specifically, SimAD first incorporates a patching-based feature extractor capable of processing extended temporal windows and employs the EmbedPatch encoder to fully integrate normal behavioral patterns. Second, we design an innovative ContrastFusion module in SimAD, which strengthens the robustness of anomaly detection by highlighting the distributional differences between normal and abnormal data. Third, we introduce two robust enhanced evaluation metrics, unbiased affiliation (UAff) and normalized affiliation (NAff), designed to overcome the limitations of existing metrics by providing better distinctiveness and semantic clarity. The reliability of these two metrics has been demonstrated by both theoretical and experimental analyses. Experiments conducted on seven diverse time-series datasets clearly demonstrate SimAD’s superior performance compared with state-of-the-art (SOTA) methods, achieving relative improvements of 19.85% on ${F}1$ , 4.44% on Aff-F1, 77.79% on NAff-F1, and 9.69% on AUC on six multivariate datasets. Code and pretrained models are available at https://github.com/EmorZz1G/SimAD},
  archive      = {J_TNNLS},
  author       = {Zhijie Zhong and Zhiwen Yu and Xing Xi and Yue Xu and Wenming Cao and Yiyuan Yang and Kaixiang Yang and Jane You},
  doi          = {10.1109/TNNLS.2025.3590220},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {SimAD: A simple dissimilarity-based approach for time-series anomaly detection},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solving scalable multiagent routing problems with reinforcement learning. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3591311'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiagent routing problems, arising from practical applications, such as logistics, transportation, and emergency response, face challenges due to the exponential growth of the search space with increasing problem scales. This article proposes RouteMaker to address the often-overlooked multiagent routing problems involving dedicated multiple depots. RouteMaker leverages role-interaction-based graph neural network (RIGNN) to realize effective locations assignments and integrates an advanced planner to plan travel path for each agent. RouteMaker is trained on small-scale problems and can produce comparable or superior approximate optimal solutions compared with the best heuristic baselines. Notably, the learned RouteMaker generalizes seamlessly to large-scale problems and real-world problems without the need for fine-tuning, delivering significantly higher quality solutions in relatively less time. For scenarios involving 40 agents and 1000 locations, RouteMaker achieves over $600\times $ speed improvement and more than 88% cost reduction, compared with the representative classical heuristic solver (ORTools).},
  archive      = {J_TNNLS},
  author       = {Yujiao Hu and Yuan Yao and Jinchao Chen and Zhihao Wang and Qingmin Jia and Yan Pan},
  doi          = {10.1109/TNNLS.2025.3591311},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Solving scalable multiagent routing problems with reinforcement learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SpeGCL: Self-supervised graph spectrum contrastive learning without positive samples. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3589861'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph contrastive learning (GCL) has emerged as a powerful method for dealing with noise and fluctuations in graph-structured data, and can be applied to social networks and knowledge graphs. Although various graph augmentation strategies have emerged in the field of GCL, traditional graph convolutional network (GCN) mainly tends to preserve smooth features and has difficulty capturing fine-grained changes between different views. To address the above issue, we first construct Fourier graph neural network (FourierGNN) from the perspective of graph spectrum learning, which captures different frequency components by stacking multiple Fourier graph operations (FGO) layers in Fourier space. Then, we find that the difference between the high-frequency information of two augmented graphs should be larger than the difference between the low-frequency information. Next, we theoretically prove that focusing only on pushing negative pairs farther away can more effectively achieve performance advantages. By leveraging these discoveries, we propose a novel self-supervised graph spectrum contrastive learning framework, i.e., SpeGCL, and design an effective contrastive strategy to optimize this goal. We also provide a theoretical justification for the efficacy of using only negative samples in SpeGCL. Extensive experiments have been conducted on unsupervised, transfer, and semi-supervised learning tasks to show that SpeGCL outperforms existing state-of-the-art (SOTA) GCL methods.},
  archive      = {J_TNNLS},
  author       = {Yuntao Shou and Xiangyong Cao and Deyu Meng},
  doi          = {10.1109/TNNLS.2025.3589861},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {SpeGCL: Self-supervised graph spectrum contrastive learning without positive samples},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust fault-aware extreme learning machine based on maximum correntropy. <em>TNNLS</em>, 1-9. (<a href='https://doi.org/10.1109/TNNLS.2025.3590097'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extreme learning machine (ELM) is an effective and efficient neural model for universal approximation. However, its practical performance can degrade due to weight noise, node faults, and outliers. This brief introduces a robust ELM algorithm designed to address these issues and enhance network robustness. We first analyze the square error of the classic ELM, considering both weight noise and node faults. By integrating an outlier-resistant method, the maximum correntropy criterion (MCC), we derive a new objective function to bolster network resilience. This leads to the development of the robust fault-aware ELM (RFAELM) algorithm. The convergence property of RFAELM is rigorously proven. For validation, the proposed algorithm is evaluated in various noise and fault levels using eight different benchmark datasets. The simulation results, encompassing all imperfect conditions and datasets, verify the robustness and generalization of this new algorithm. Also, the new algorithm is compared with other robust ELM algorithms using different statistical measurements. The superior performance of RFAELM substantiates its significant improvement over existing algorithms.},
  archive      = {J_TNNLS},
  author       = {Yuqi Xiao and Muideen Adegoke and Chi-Sing Leung and Kwok Wa Leung},
  doi          = {10.1109/TNNLS.2025.3590097},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-9},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Robust fault-aware extreme learning machine based on maximum correntropy},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SMTLNet: Domain prior-inspired tooth segmentation based on self-supervised manifold transfer learning. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3591003'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate identification and delineation of teeth in cone-beam computed tomography (CBCT) images are crucial in the advancement of digital dentistry technology. Teeth exhibit high interclass similarity and often have fuzzy boundaries. In addition, it is difficult to obtain teeth samples due to the time-consuming annotation process. However, existing methods typically fail to incorporate this domain-specific prior information under limited labeled samples, which limits the improvement of segmentation performance. Based on the intrinsic characteristics of the tooth CBCT images, a self-supervised manifold transfer learning network (SMTLNet) is proposed to improve segmentation accuracy. Initially, an object-oriented self-supervised pretraining approach is designed to fully explore valuable image representations from unannotated images, and this helps reduce dependence on labeled samples. Furthermore, a manifold optimization strategy is employed to regularize the segmentation model to separate interclass samples while compacting intraclass neighbors. Finally, to address the issue of blurred tooth boundaries, a multiscale boundary constraint module is developed to extract multiscale boundary-aware features, and more discriminative tooth descriptions can be acquired in this way. The proposed SMTLNet method is evaluated on clinical datasets containing diverse challenging cases (e.g., impacted wisdom teeth, crowded dentition), and it achieves state-of-the-art performance with dice similarity coefficients (DSCs) of 91.8%/89.08% and Jaccard similarities (JSs) of 86.71%/82.87% under full (100%) and limited (20%) training data regimes, respectively. The method maintains anatomical precision with Hausdorff distances (HDs) of 1.41 mm (high-resource) and 2.35 mm (low-resource), demonstrating strong clinical applicability in digital dentistry workflows.},
  archive      = {J_TNNLS},
  author       = {Yue Zhao and Ruoyu Wu and Pengyu Dai and Hong Huang and Yang Liu},
  doi          = {10.1109/TNNLS.2025.3591003},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {SMTLNet: Domain prior-inspired tooth segmentation based on self-supervised manifold transfer learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning granularity-aware affordances from human-object interaction for tool-based functional dexterous grasping. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3591538'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To enable robots to use tools, the initial step is teaching robots to employ dexterous gestures for touching specific areas precisely where tasks are performed. Affordance features of objects serve as a bridge in the functional interaction between agents and objects. However, leveraging these affordance cues to help robots achieve functional tool grasping remains unresolved. To address this, we propose a granularity-aware affordance feature extraction method for locating functional affordance areas and predicting dexterous coarse gestures. We study the intrinsic mechanisms of human tool use. On the one hand, we use fine-grained affordance features of object-functional finger contact areas to locate functional affordance regions. On the other hand, we use highly activated coarse-grained affordance features in hand–object interaction regions to predict grasp gestures. Additionally, we introduce a model-based postprocessing module that transforms affordance localization and gesture prediction into executable robotic actions. This forms GAAF-Dex, a complete framework that learns granularity-aware affordances from human–object interaction to enable tool-based functional grasping with dexterous hands. Unlike fully supervised methods that require extensive data annotation, we employ a weakly supervised approach to extract relevant cues from exocentric (Exo) images of hand–object interactions to supervise feature extraction in egocentric (Ego) images. To support this approach, we have constructed a small-scale dataset, functional affordance hand (FAH)-object interaction dataset, which includes nearly 6k images of functional hand–object interaction Exo images and Ego images of 18 commonly used tools performing six tasks. Extensive experiments on the dataset demonstrate that our method outperforms state-of-the-art methods, and real-world localization and grasping experiments validate the practical applicability of our approach. The source code and the established dataset are available at https://github.com/yangfan293/GAAF-DEX},
  archive      = {J_TNNLS},
  author       = {Fan Yang and Wenrui Chen and Kailun Yang and Haoran Lin and Dongsheng Luo and Conghui Tang and Zhiyong Li and Yaonan Wang},
  doi          = {10.1109/TNNLS.2025.3591538},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Learning granularity-aware affordances from human-object interaction for tool-based functional dexterous grasping},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interpretable cross-modal alignment network for EEG visual decoding with algorithm unrolling. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3592646'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate decoding in electroencephalography (EEG) technology, particularly for rapid visual stimuli, remains challenging due to the low signal-to-noise ratio (SNR). Additionally, existing neural networks struggle with issues related to generalization and interpretability. This article proposes a cross-modal aligned network, E2IVAE, which leverages shared information from multiple modalities for self-supervised alignment of EEG to images for extracting visual perceptual information and features a novel EEG encoder, ISTANet, based on algorithm unrolling. This network framework significantly enhances the accuracy and stability of EEG decoding for object recognition in novel classes while reducing the extensive neural data typically required for training neural decoders. The proposed ISTANet employs algorithm unrolling to transform the multilayer sparse coding algorithm into an end-to-end format, extracting features from noisy EEG signals while incorporating the interpretability of traditional machine learning. The experimental results demonstrate that our method achieves SOTA top-1 accuracy of 62.39% and top-5 accuracy of 88.98% on a comprehensive rapid serial visual presentation (RSVP) dataset for public comparison in a 200-class zero-shot neural decoding task. Additionally, ISTANet enables visualization and analysis of multiscale atom features and overall reconstruction features, exploring biological plausibility across temporal, spatial, and spectral dimensions. On another more challenging RSVP large-scale dataset, the proposed framework also achieves significantly above chance-level performance, proving its robustness and generalization. This research provides critical insights into neural decoding and brain–computer interfaces (BCIs) within the fields of cognitive science and artificial intelligence.},
  archive      = {J_TNNLS},
  author       = {Daowen Xiong and Liangliang Hu and Jiahao Jin and Yikang Ding and Congming Tan and Jing Zhang and Yin Tian},
  doi          = {10.1109/TNNLS.2025.3592646},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Interpretable cross-modal alignment network for EEG visual decoding with algorithm unrolling},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward disentangled and controllable deep metric learning with human-like concept decomposition. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3587907'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep metric learning (DML) has shown significant advancements in learning discriminative embeddings for images, playing a crucial role in various vision tasks. However, existing methods typically rely on deep neural networks to extract holistic embeddings, which are challenging to disentangle and interpret. To address this issue, we take inspiration from human cognition, where objects are decomposed into distinct concepts for better understanding. Specifically, we propose the concept metrics network (CMNs) to achieve disentangled and controllable DML. CMN begins by initializing learnable concept vectors to represent various visual concepts. These vectors are then associated with regional visual features via cross-attention mechanism, ensuring each vector corresponds to specific visual properties. Finally, the concept values, determined by their presence in the image, form the output embedding. Comprehensive experiments demonstrate that CMN effectively disentangles visual concepts, with each embedding dimension corresponding to a specific concept. Our method not only outperforms existing state-of-the-art methods in conventional DML application (i.e., image retrieval), but also enables more flexible and controllable application. The code is available at https://github.com/shchen0001/CMN},
  archive      = {J_TNNLS},
  author       = {Shuhuang Chen and Shiming Chen and Shuo Ye and Yuetian Wang and Xinge You},
  doi          = {10.1109/TNNLS.2025.3587907},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Toward disentangled and controllable deep metric learning with human-like concept decomposition},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SAM-Med3D: A vision foundation model for general-purpose segmentation on volumetric medical images. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3586694'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing volumetric medical image segmentation models are typically task-specific, excelling at specific targets but struggling to generalize across anatomical structures or modalities. This limitation restricts their broader clinical use. In this article, we introduce segment anything model (SAM)-Med3D, a vision foundation model (VFM) for general-purpose segmentation on volumetric medical images. Given only a few 3-D prompt points, SAM-Med3D can accurately segment diverse anatomical structures and lesions across various modalities. To achieve this, we gather and preprocess a large-scale 3-D medical image segmentation dataset, SA-Med3D-140K, from 70 public datasets and 8K licensed private cases from hospitals. This dataset includes 22K 3-D images and 143K corresponding masks. SAM-Med3D, a promptable segmentation model characterized by its fully learnable 3-D structure, is trained on this dataset using a two-stage procedure and exhibits impressive performance on both seen and unseen segmentation targets. We comprehensively evaluate SAM-Med3D on 16 datasets covering diverse medical scenarios, including different anatomical structures, modalities, targets, and zero-shot transferability to new/unseen tasks. The evaluation demonstrates the efficiency and efficacy of SAM-Med3D, as well as its promising application to diverse downstream tasks as a pretrained model. Our approach illustrates that substantial medical resources can be harnessed to develop a general-purpose medical AI for various potential applications. Our dataset, code, and models are available at: https://github.com/uni-medical/SAM-Med3D},
  archive      = {J_TNNLS},
  author       = {Haoyu Wang and Sizheng Guo and Jin Ye and Zhongying Deng and Junlong Cheng and Tianbin Li and Jianpin Chen and Yanzhou Su and Ziyan Huang and Yiqing Shen and Bin Fu and Shaoting Zhang and Junjun He},
  doi          = {10.1109/TNNLS.2025.3586694},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {SAM-Med3D: A vision foundation model for general-purpose segmentation on volumetric medical images},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Vector quantization-based clustered federated learning with global feature anchors for improved representation and generalization. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3589186'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustered federated learning (CFL) addresses the challenge of data heterogeneity in federated learning (FL) by customizing models for different groups of clients. However, existing CFL methods heavily rely on indirect metrics, such as model parameters, gradient information, or loss function values, for client clustering. These approaches often fail to fully capture the diversity and intrinsic characteristics of client data distributions, leading to inaccurate representations of client data features. To address this issue, we propose a novel CFL framework called vector quantization-based CFL (VQCFL). First, we introduce a vector quantization network (VQNet), which effectively captures the intrinsic structure of client data by mapping the local feature space into discrete feature dictionary vectors. In addition, to prevent drift in the feature dictionary vectors, we propose a global feature anchor strategy that aligns feature dictionary vectors across clients, ensuring consistent updates within the same feature space. Furthermore, we present a novel cross-cluster knowledge-sharing mechanism that integrates feature information from different clusters through global aggregation of feature dictionary vectors. Combined with a personalized cross-cluster classifier weight adjustment strategy, this mechanism significantly enhances the model’s generalization performance in the presence of mixed data heterogeneity. Experimental results under various settings demonstrate that VQCFL achieves superior local personalization and global generalization performance.},
  archive      = {J_TNNLS},
  author       = {Xiaohong Chen and Yuhang Zhang and Xuesong Xu and Dongbin Hu and Guanying Xu},
  doi          = {10.1109/TNNLS.2025.3589186},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Vector quantization-based clustered federated learning with global feature anchors for improved representation and generalization},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AQE-RF: An adaptive quantifier extension and rule-filtering graph network for logical reasoning of text. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3588525'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Logical reasoning of text requires neural models to possess strong contextual comprehension and logical reasoning ability to draw conclusions from limited information. To improve the logical reasoning capabilities of pretrained language models (PLMs), existing approaches can be broadly categorized into neural architecture-based methods and large language model (LLM)-driven strategies. While neural methods struggle with fine-grained logic that fails to capture detailed semantic roles and constraints, LLM-driven approaches, despite generating multistep reasoning sequences, lack explicit inference control and suffer from error accumulation due to their implicit and stochastic nature. Some works have tried using logical expressions, like first-order logic, but these approaches often fail to handle quantifiers systematically or support clear reasoning processes. Inspired by first-order logic and generalized quantifier (GQ) theory, we propose AQE-RF, a model based on an adaptive quantifier extension and rule-filtering graph network to address this challenge. The first component constructs a fine-grained text logical graph (FTLG) and then performs GQ instantiation based on option attention. The second component performs rule-filtered deductive reasoning, using conflict scores and dynamic programming (DP) to select coherent, interpretable inference paths. Extensive experiments on the LogiQA, ReClor, and AR-LSAT datasets demonstrate the effectiveness and robustness of AQE-RF.},
  archive      = {J_TNNLS},
  author       = {Meng Wang and Jinshuo Liu and Víctor Gutiérrez-Basulto and Lina Wang and Jeff Z. Pan},
  doi          = {10.1109/TNNLS.2025.3588525},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {AQE-RF: An adaptive quantifier extension and rule-filtering graph network for logical reasoning of text},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AFSPrompt: An axiomatic fuzzy set prompt pipeline for knowledge-based VQA. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3573267'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the impressive few-shot performance of in-context learning (ICL) in knowledge-based visual question answering (VQA), existing research often prioritizes addressing the image information gap in VQA, while placing less emphasis on organizing appropriate demonstrations (e.g., in-context examples) to support this task. Recent studies, however, have shown that ICL performance is sensitive to the organization of demonstrations. To address this, we introduce axiomatic fuzzy set (AFS) theory into knowledge-based VQA, leveraging its unsupervised and interpretable nature to effectively organize demonstrations by describing each candidate with semantic concepts, thereby enhancing both the understanding and trustworthiness of the decision-making process. In this article, we propose AFSPrompt, a train-free example selection and ranking framework based on AFS theory for knowledge-based VQA tasks. After filtering irrelevant examples using multimodal embeddings, we apply AFS logic to integrate comparison information from candidates with multidimensional features. Furthermore, to reduce reliance on large-scale language model APIs such as OpenAI and facilitate model deployment, we employ a smaller 7B LLM as the knowledge engine to answer questions based on the optimized prompt. Through extensive evaluations of two datasets, we demonstrate the effectiveness of AFSPrompt within a lightweight pipeline for knowledge-based VQA tasks. Our code is publicly available at https://github.com/afs001/AFSPrompt},
  archive      = {J_TNNLS},
  author       = {Zhiwei Wang and Qi Lang and Xiaodong Liu and Hao Zhang},
  doi          = {10.1109/TNNLS.2025.3573267},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {AFSPrompt: An axiomatic fuzzy set prompt pipeline for knowledge-based VQA},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust rank-one matrix completion via explicit regularizer. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3571594'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In robust matrix completion (MC), the Welsch function, also referred to as the maximum correntropy criterion with Gaussian kernel, has been widely employed. However, it suffers from the drawback of down-weighing normal data. This work is the first to uncover the explicit regularizer (ER) for the Welsch function based on the multiplicative form of half-quadratic (HQ) minimization. Leveraging this discovery, we develop a new function called t-Welsch, also with ER, which provides unity weight to normal data and exhibits stronger robustness against large-magnitude outliers compared to Huber’s weight. We apply the t-Welsch to rank-one matching pursuit, enabling accurate and robust low-rank matrix recovery without the need of rank information and singular value decomposition (SVD). The resultant MC algorithm is realized via block coordinate descent (BCD), whose analyses of convergence and computational complexity are produced. Experiments are conducted using synthetic random data, as well as real-world images with salt-and-pepper noise and multiple-input multiple-output (MIMO) radar signals in the presence of Gaussian mixture disturbances. In all three scenarios, the proposed algorithm outperforms the state-of-the-art robust MC methods in terms of recovery accuracy. The code is available at https://github.com/ShuDun23/t-Welsch-and-RAR1MC.},
  archive      = {J_TNNLS},
  author       = {Hao Nan Sheng and Zhi-Yong Wang and Hing Cheung So},
  doi          = {10.1109/TNNLS.2025.3571594},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Robust rank-one matrix completion via explicit regularizer},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time network latency estimation with pretrained generative models. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3573200'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network latency estimation is critical for network performance monitoring and management. However, with the escalating demand for real-time performance monitoring and rapid network adjustments in contemporary networks, existing latency estimation methodologies fall short of meeting the need for instantaneous estimation. In this article, we propose a pretrained generative model-based scheme (PGM) for real-time network latency estimation. PGM operates in two stages. First, we employ a pretrained generative model to relax the low-rank constraint typically associated with latency matrix completion (MC). The pretrained generative model well learns the low-rank characteristics of latency matrices in the pretraining stage and can map a condensed latent representation to the matrix space. Second, instead of directly optimizing the matrix, we turn to optimizing the latent representation. Leveraging the low-rank structure achieved by the pretrained generative model simplifies our optimization process, enabling real-time estimation. We also provide a theoretical recovery guarantee to reveal the error bound of PGM. Experimental results on real-world datasets show that the proposed scheme can achieve accurate latency estimation within 50 ms while maintaining the relative squared error (RSE) of estimation at no more than 0.11 (as evidenced using the PlanetLab dataset).},
  archive      = {J_TNNLS},
  author       = {Lei Deng and Xiao-Yang Liu and Danny H. K. Tsang},
  doi          = {10.1109/TNNLS.2025.3573200},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Real-time network latency estimation with pretrained generative models},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SRViT: Self-supervised relation-aware vision transformer for hyperspectral unmixing. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3571798'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision transformer (ViT) has recently been a popular topic in the foundation model field, taking advantage of its strong scalability and outstanding representation capabilities. As a deep model, ViT introduces a new architecture for achieving hyperspectral image (HSI) unmixing. However, traditional ViTs overlook pixel-level spatial continuity by partitioning the input image into nonoverlapping fixed-size patches. This approach disrupts local structural relationships and hinders the model’s ability to capture fine-grained spatial dependencies, resulting in suboptimal feature representation for dense prediction tasks in unmixing. To address these challenges, this article proposes the development of a self-supervised relation-aware ViT (SRViT). SRViT incorporates a self-embedded module comprising encoders, a pixel-level position encoder (PLPE), a self-supervised contrastive mechanism (SCM), and a decoder. The self-embedded module and PLPE preserve local correlations in HSI across different views, facilitating cross-view learning through SCM to ensure generalization. In addition, the decoder incorporates Kronecker-factored approximate curvature (K-FAC) to capture the local geometric structure of spectral information. Ultimately, SRViT learns endmembers and fractional abundance as the unmixing result. The effectiveness and competitiveness of SRViT have been systematically validated through comparative experiments, demonstrating its superior performance. The source code is available at the following link: https://github.com/yuanchaosu/TNNLS-SRViT},
  archive      = {J_TNNLS},
  author       = {Yuanchao Su and Lianru Gao and Antonio Plaza and Xu Sun and Mengying Jiang and Guang Yang},
  doi          = {10.1109/TNNLS.2025.3571798},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {SRViT: Self-supervised relation-aware vision transformer for hyperspectral unmixing},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Retrieval-augmented few-shot medical image segmentation with foundation models. <em>TNNLS</em>, 1-9. (<a href='https://doi.org/10.1109/TNNLS.2025.3568479'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image segmentation is crucial for clinical decision-making, but the scarcity of annotated data presents significant challenges. Few-shot segmentation (FSS) methods show promise but often require training on the target domain and struggle to generalize across different modalities. Similarly, adapting foundation models such as the segment anything model (SAM) for medical imaging has limitations, including the need for fine-tuning and domain-specific adaptation. To address these issues, we propose a novel method that adapts DINOv2 and SAM2 for retrieval-augmented few-shot medical image segmentation. Our approach uses DINOv2’s feature as query to retrieve similar samples from limited annotated data, which are then encoded as memories and stored in memory bank. With the memory attention mechanism of SAM 2, the model leverages these memories as conditions to generate accurate segmentation of the target image. We evaluated our framework on three medical image segmentation tasks, demonstrating superior performance and generalizability across various modalities without the need for any retraining or fine-tuning. Overall, this method offers a practical and effective solution for few-shot medical image segmentation and holds significant potential as a valuable annotation tool in clinical applications.},
  archive      = {J_TNNLS},
  author       = {Lin Zhao and Xiao Chen and Eric Z. Chen and Yikang Liu and Terrence Chen and Shanhui Sun},
  doi          = {10.1109/TNNLS.2025.3568479},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-9},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Retrieval-augmented few-shot medical image segmentation with foundation models},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reachable polyhedral marching (RPM): An exact analysis tool for deep-learned control systems. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3571720'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks are increasingly used in robotics as policies, state transition models, state estimation models, or all of the above. With these components being learned from data, it is important to be able to analyze what behaviors were learned and how this affects closed-loop performance. In this article, we take steps toward this goal by developing methods for computing control invariant sets and regions of attraction (ROAs) of dynamical systems represented as neural networks. We focus our attention on feedforward neural networks with the rectified linear unit (ReLU) activation, which are known to implement continuous piecewise-affine (PWA) functions. We describe the reachable polyhedral marching (RPM) algorithm for enumerating the affine pieces of a neural network through an incremental connected walk. We then use this algorithm to compute exact forward and backward reachable sets, from which we provide methods for computing control invariant sets and ROAs. Our approach is unique in that we find these sets incrementally, without Lyapunov-based tools. In our examples, we demonstrate the ability of our approach to find nonconvex control invariant sets and ROAs on tasks with learned van der Pol oscillator and pendulum models. Further, we provide an accelerated algorithm for computing ROAs that leverages the incremental and connected enumeration of affine regions that RPM provides. We show this acceleration to lead to a $15\times $ speedup in our examples. Finally, we apply our methods to find a set of states that are stabilized by an image-based controller for an aircraft runway control problem.},
  archive      = {J_TNNLS},
  author       = {Joseph A. Vincent and Mac Schwager},
  doi          = {10.1109/TNNLS.2025.3571720},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Reachable polyhedral marching (RPM): An exact analysis tool for deep-learned control systems},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NetEventCause: Event-driven root cause analysis for large network system without topology. <em>TNNLS</em>, 1-12. (<a href='https://doi.org/10.1109/TNNLS.2025.3574316'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Root cause analysis (RCA) is a crucial technique in network systems for uncovering the abnormal nodes that lead to the network alarm flood. Within private cloud network systems, the calling chains and topologies among entities, such as hosts, routes, and services, are always incomplete due to nonstandardized management. Existing topology-free RCA techniques, which rely on the casual discovery, are inapplicable when the scale of the network system is extremely large or the number of triggered alarms is sparse. This article proposes NetEventCause (NEC), an event-driven, unsupervised, and nonintrusive RCA algorithm for large network systems, where the network topology is unknown. NEC learns from historical alarm events to model the occurrences of various alarm types using a multivariate neural temporal point process (TPP). Based on the conditional intensity predicted by the learned TPP, NEC can identify the root alarms from a cascade of alarm events and locate the causal alarms of derivative alarms using the attribution method. The experimental section evaluates the NEC using both a synthetic event dataset and a large real-world dataset. The real-world dataset is exported from the Huawei Shennong Intelligent Maintenance and Operation Center (IMOC), a platform deployed at one of China’s largest airports and manages over 200000 entities. Results obtained from the two datasets demonstrate that NEC outperforms most state of the art (SOTA) TPP models in modeling alarm events and surpasses general RCA methods in terms of identifying root alarms and recovering transmission chains of anomalies.},
  archive      = {J_TNNLS},
  author       = {Zhaolin Yuan and Long Ma and Wenjia Wei and Xia Zhu and Mingjie Sun and Duxin Chen and Xiaojuan Ban},
  doi          = {10.1109/TNNLS.2025.3574316},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {NetEventCause: Event-driven root cause analysis for large network system without topology},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). End-to-end abnormal subgraph detection via subgraph-level contrastive learning. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3573922'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abnormal subgraph (AS) detection plays a significant role in ensuring the security of many high-impact domains. Unlike node anomaly detection, identifying subgraph anomalies is extremely challenging due to the exponentially large subgraph space caused by various combinations of nodes and edges. Moreover, in the absence of supervisory signals, how to quantify the abnormality of subgraphs poses another pressing challenge. Traditional methods typically rely on handcrafted subgraph anomaly measures, making it hard to handle potential unknown anomalies with limited prior knowledge. Recent deep learning-based techniques are predominantly designed to discover individual node anomalies, which could be suboptimal for AS detection due to the inconsideration of collaborative behaviors between nodes in the subgraph. In fact, existing studies have put very little effort into this task, and even dedicated performance evaluation metrics are not yet available. To address the above challenges and promote related research, in this article, we propose a end-to-end unsupervised subgraph anomaly detection framework (EndSubG), which jointly models subgraph partition and AS detection as a whole instead of treating them as two separate stages. Specifically, EndSubG uncovers potential AS boundaries that violate the Homophily assumption by modeling the edge existence probability, then achieves anomaly-aware graph embedding and subgraph partition based on the refined topology. By forming a coarsened subgraph network, EndSubG picks out subgraph anomalies by learning the “subgraph-vicinity” matching patterns. Additionally, we design an evaluation metric weighted normalized mutual information centered on AS (AS-WNMI) specifically for subgraph anomaly detection, which is a variant of vanilla NMI and quantifies detection performance from both subgraph partition and anomaly recognition. The experimental results on synthetic and real-world datasets corroborate the superiority of end-to-end unsupervised subgraph anomaly detection framework (EndSubG) in terms of area under the curve (AUC), average precision (AP), and AS-WNMI. We also provide an intuitive analysis of the detected subgraphs through visualization for better understanding.},
  archive      = {J_TNNLS},
  author       = {Zhen Peng and Yunfan Wang and Qika Lin and Bin Shi and Chen Chen and Bo Dong and Chao Shen},
  doi          = {10.1109/TNNLS.2025.3573922},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {End-to-end abnormal subgraph detection via subgraph-level contrastive learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fine-grained entity recognition via large language models. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3574197'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained entity recognition (FGER) attracts increasing attention in information extraction and many other natural language understanding applications. However, it is a quite challenging problem for a specific domain due to the lack of specific-domain labeled data. To address this challenge, recent advancements in language modeling such as generative pretrained transformer (GPT) offer promising alternatives. Since large language models (LLMs) can be used for various tasks, such as text generation, summarization, and information extraction without labeled data, we incorporated them into the FGER field. Nonetheless, when too many verbose labels are fed to LLMs simultaneously, LLMs occasionally generate content that diverges from user input, contradicts previously generated context, or misaligns with established world knowledge, also called the “hallucination” phenomenon. In this article, we propose a new method called FGER-GPT to address these issues. Our approach leverages multiple inference chains and incorporates a hierarchical strategy for recognizing fine-grained entities, resulting in a significant performance boost. Importantly, neither coarse-grained nor fine-grained entity annotations are used in our proposed approach, which avoids the heavy labor consumption of labeling. Extensive experiments conducted on widely used datasets have demonstrated that the proposed FGER-GPT achieves competitive performance compared to state-of-the-art approaches in low-resource scenarios, highlighting its feasibility for real-world applications.},
  archive      = {J_TNNLS},
  author       = {Xue Qiao and Shuang Gu and Jiayuan Cheng and Chen Peng and Zhiwei Xiong and Hong Shen and Gan Jiang},
  doi          = {10.1109/TNNLS.2025.3574197},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Fine-grained entity recognition via large language models},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pixel-level noise mining for weakly supervised salient object detection. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3575255'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Training a deep model for visual saliency detection requires the collection and labor-intensive annotation of overwhelmingly large data. We propose to learn saliency detection in a weakly supervised manner from single noisy label, which is easy to obtain from unsupervised handcrafted feature-based methods. However, deep networks tend to overfit such noises leading to a dramatic drop in accuracy. Given our goal, we address a natural question: can we identify outliers during network prediction and rectify the label noises? To this end, we propose a pixel-level noise mining framework for robust salient object detection (SOD) by exploiting its own knowledge, and without the need for external models. Specifically, during the early training stage, we progressively identify the outliers from a novel perspective during saliency detection, before the network overfits to the noisy labels, and generate a selection matrix in each iteration. Next, we adaptively rectify the label noises under the guidance of the selection matrix for better supervision in the later training stage. Extensive experiments on multiple benchmark datasets demonstrate the superiority of our method showing its ability to learn saliency detection comparable to state-of-the-art fully supervised methods. Furthermore, our approach outperforms existing weakly supervised methods utilizing single noisy label and surpasses the half of existing weakly supervised methods employing multiple noisy labels. Our approach, which trains with multiple noisy labels, outperforms all other methods employing multiple noisy labels across four major datasets. Furthermore, we also evaluate the generalization ability of our method on the multiclass semantic segmentation (SS) task. Our code is available at https://github.com/kendongdong/NoiseMining},
  archive      = {J_TNNLS},
  author       = {Kendong Liu and Mingtao Feng and Wei Zhao and Jingtao Sun and Weisheng Dong and Yaonan Wang and Ajmal Mian},
  doi          = {10.1109/TNNLS.2025.3575255},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Pixel-level noise mining for weakly supervised salient object detection},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Facilitating multiagent coordination relying on graph information representation. <em>TNNLS</em>, 1-12. (<a href='https://doi.org/10.1109/TNNLS.2025.3575196'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The popular multiagent reinforcement learning (MARL) methods primarily focus on exploring the capability of value functions to facilitate multiagent coordination. These MARL methods, following the centralized training with decentralized execution (CTDE) paradigm, tend to design ingenious network architectures while overlooking the impact of coordination through expanding local observation information. To tackle this deficiency, we model the multiagent systems (MASs) as a graph and use a graph neural network (GNN) to extract rich information between one agent and the others efficiently. Moreover, we propose a multigraph-neural-network information representation (MGIR) method that uses the power of GNN in local observation information extraction, enabling the acquisition of higher quality information. Specifically, multiple GNNs are used during centralized training to characterize the MAS from different perspectives and extract representations of latent variables. During distributed execution, these latent variables are leveraged to expand local observation information. Extensive comparative experiments substantiate that our proposed MGIR demonstrates superior coordination performance when compared with baseline methods. In addition, it can be flexibly integrated into various value function decomposition methods of MARL.},
  archive      = {J_TNNLS},
  author       = {Ye Wang and Jingjing Wang and Ruijie Zhu and Hang Fu and Jianrui Chen and C. L. Philip Chen},
  doi          = {10.1109/TNNLS.2025.3575196},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Facilitating multiagent coordination relying on graph information representation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MOOD: Leveraging out-of-distribution data to enhance imbalanced semi-supervised learning. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3573963'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The imbalanced semi-supervised learning (SSL) has emerged as a critical research area due to the prevalence of class imbalanced and partially labeled data in real-world scenarios. As the requirement for data volume increases, naturally collected datasets inevitably contain out-of-distribution (OOD) samples. However, the performance of existing imbalanced SSL methods experiences a marked deterioration with OOD data. In this article, we propose an imbalanced SSL method called mixup-OOD (MOOD) to address this issue. The core idea is to “turn waste into treasure,” exploring the potential of leveraging seemingly detrimental OOD data to expand the feature space, particularly for tail classes. Specifically, we first filter OOD data from unlabeled data, and then fuse it with labeled data to boost feature diversity for the tail classes. To avoid feature overlapping with OOD data, we develop a push-and-pull (PaP) loss to attract in-distribution (ID) instances toward respective class centroids while repelling OOD samples from them. Extensive experiments show that MOOD achieves superior performance compared with other state-of-the-art methods and exhibits robustness across data with different imbalanced ratios and OOD proportions. The source code is available at: https://github.com/xlhuang132/MOODv2},
  archive      = {J_TNNLS},
  author       = {Yang Lu and Xiaolin Huang and Yizhou Chen and Mengke Li and Yan Yan and Chen Gong and Hanzi Wang},
  doi          = {10.1109/TNNLS.2025.3573963},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {MOOD: Leveraging out-of-distribution data to enhance imbalanced semi-supervised learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A decentralized Actor–Critic algorithm with entropy regularization and its finite-time analysis. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3573801'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decentralized actor-critic (AC) is one of the most dominant algorithms for dealing with multiagent reinforcement learning (MARL) problems. However, exploration-efficient, sample-efficient, and communication-efficient are difficult to achieve simultaneously by existing decentralized AC methods. For this reason, this article develops a decentralized multiagent AC algorithm by incorporating entropy regularization to improve exploration with theoretical guarantees, referred to as multi-agent AC algorithm with entropy regularization (MACE). Moreover, we rigorously prove that MACE can achieve sample complexity $\mathcal {O}(\epsilon ^{-2}\ln \epsilon ^{-1})$ and communication complexity of $\mathcal {O}(\epsilon ^{-1}\ln \epsilon ^{-1})$ , which match the best complexities at present. Finally, the performance of MACE is also evaluated on reinforcement learning (RL) tasks. The experimental results show that the proposed algorithm achieves better exploration efficiency than state-of-the-art decentralized AC-type algorithms.},
  archive      = {J_TNNLS},
  author       = {Tao Mao and Junlong Zhu and Mingchuan Zhang and Quanbo Ge and Ruijuan Zheng and Qingtao Wu},
  doi          = {10.1109/TNNLS.2025.3573801},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A decentralized Actor–Critic algorithm with entropy regularization and its finite-time analysis},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiattentive perception and multilayer transfer network using knowledge distillation for RGB-D indoor scene parsing. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3575088'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scene parsing has gained wide attention in the field of computer vision, with emerging methods and techniques providing superior solutions. Although some methods have improved performance, they tend to neglect the number of model parameters and computational size, which makes achieving real-time operation in practical applications challenging. To address these limitations, we propose a multiattentive perception and multilayer transfer network that employs knowledge distillation (MPMTNet-KD), which is generated by a student network (MPMTNet-S) under the guidance of a teacher network (MPMTNet-T) with the aid of our proposed multilayer transfer knowledge distillation (KD) methods. To capture complete information from different modalities, a multiattentive perception module (MAPM) is introduced to mine features from various perspectives, and hetero-oriented sensing (HOS) convolution is utilized to integrate cross-layer features in a single and holistic manner. Importantly, we introduce multilayer transfer KD to explore the different knowledge types between layers, as well as intraclass and interclass correlations. In addition, we use the discrete cosine transform (DCT) approach combined with filtering during the KD process to mitigate noise that may be induced by the depth map, thereby improving the depth information and further enhancing the knowledge transfer effect. We conducted comprehensive experiments on two challenging indoor benchmark datasets, namely NYUDv2 and SUN RGB-D. Compared with existing methods, the proposed MPMTNet-KD reduces the number of parameters from 125.8 M in MPMTNet-T to 28.3 M in MPMTNet-S, achieving a mean intersection over union (mIoU) of 54.9% in the indoor scene parsing task. MPMTNet-KD was also evaluated on two additional public datasets, namely MFNet and PST900, to demonstrate its generalization capacity. The source code is available at https://github.com/XUEXIKUAIL/MPMTNet},
  archive      = {J_TNNLS},
  author       = {Wujie Zhou and Bitao Jian and Yuanyuan Liu and Qiuping Jiang},
  doi          = {10.1109/TNNLS.2025.3575088},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Multiattentive perception and multilayer transfer network using knowledge distillation for RGB-D indoor scene parsing},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed model-free adaptive learning control of discrete-time nonlinear multiagent systems. <em>TNNLS</em>, 1-10. (<a href='https://doi.org/10.1109/TNNLS.2025.3575423'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates the distributed control problem for nonlinear multiagent systems (MASs) with unknown system models. A novel distributed model-free adaptive learning algorithm is developed to learn a controller from the online system data. Notably, a significant advancement over conventional methods is that the proposed algorithm requires only local interaction data from neighboring agents, eliminating dependencies on both a priori system structural knowledge and global topology information. Comprehensive simulations validate the theoretical results and demonstrate the superior efficacy of the devised algorithm.},
  archive      = {J_TNNLS},
  author       = {Yong-Sheng Ma and Wei-Wei Che and Shi-Xu Xu and Chao Deng and Zheng-Guang Wu},
  doi          = {10.1109/TNNLS.2025.3575423},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Distributed model-free adaptive learning control of discrete-time nonlinear multiagent systems},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multigranularity information fused contrastive learning with multiview clustering. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3574885'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contrastive multiview clustering (MVC) has emerged as a mainstream approach in MVC due to its superior representation learning capabilities. Traditional contrastive multiview learning methods extract both low- and high-level information from raw data. However, only high-level information is utilized for clustering. Since both types of information are essential for effective clustering, this limitation hampers performance. Moreover, effectively quantifying the importance of different views remains a critical challenge in contrastive MVC. Additionally, the absence of structural information during clustering further weakens clustering performance. To address these issues, this article proposes a multigranularity (MG) information fused contrastive learning with MVC (MGCMVC). Inspired by the concept of MG, low- and high-level features are reconstructed into fine- and coarse-granularity features. First, an MG adaptive weighting sample-level contrastive learning mechanism is introduced to fuse MG features to enhance clustering performance and mitigate clustering performance degradation caused by variations in view quality. Second, a structure-oriented cluster-level contrastive learning approach is designed to preserve structural information and enforce cross-view clustering consistency. Extensive and comprehensive experiments on ten widely used datasets demonstrate that MGCMVC achieves the state-of-the-art performance. The source code is available at https://github.com/Luyangabc/MGCMVC},
  archive      = {J_TNNLS},
  author       = {Hengrong Ju and Yang Lu and Weiping Ding and Wei Zhang and Xibei Yang},
  doi          = {10.1109/TNNLS.2025.3574885},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Multigranularity information fused contrastive learning with multiview clustering},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep reinforcement learning approach for dynamic distribution network reconfiguration based on sequential masking. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3574208'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic distribution network reconfiguration (DDNR) is a widely used technique for the secure and economic operation of power distribution networks (PDNs), especially in the presence of high-penetration renewable energy sources (RESs). DDNR is realized by controlling the on/off status of remotely controlled switches (RCSs) equipped at power lines in PDNs to optimize power flows. Thanks to the enhanced data availability of PDNs, data-driven solutions to DDNR, such as deep reinforcement learning (DRL), have gained growing attention recently. However, DDNR solves a sequence of combinatorial problems featuring a vast and sparse action space incurred by a so-called “radiality constraint,” which is highly challenging for DRLs to handle. Existing DRL methods are either unscalable to large-scale problems or potentially restrict optimality. Hence, we propose a sequential masking strategy to decompose its complex action space into a sequence of maskable sub-action spaces. A gated recurrent unit (GRU)-based agent and an adapted soft actor critic (SAC) algorithm are designed accordingly, producing a data-efficient, safety-guaranteed, and scalable DRL solution to the DDNR problem. Comprehensive comparisons with existing data-driven methods and model-based benchmarks are conducted via various case studies, demonstrating the advantages of the proposed method in both algorithmic performance and scalability.},
  archive      = {J_TNNLS},
  author       = {Ruoheng Wang and Xiaowen Bi and Siqi Bu and Zhixian Tang},
  doi          = {10.1109/TNNLS.2025.3574208},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Deep reinforcement learning approach for dynamic distribution network reconfiguration based on sequential masking},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online self-triggered transmission control with critic learning for discrete nonlinear systems. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3574484'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, a novel online self-triggered transmission control (STTC) framework is constructed based on the critic learning technique, which aims at tackling the optimal regulation issue of discrete-time nonlinear systems. On the premise of ensuring the system stability, a self-sampling function is designed only related to the sampling state, so that the next triggering moment can be determined. This not only effectively reduces the computational burden, but also avoids continuous judgment for the triggering condition similar to traditional event-based methods. Furthermore, the developed control method can be found to possess excellent triggering performance through theoretical analysis. Then, the model, critic, and action networks are established to execute the online critic learning algorithm, which make the control policy is adjusted in real-time to the optimal level. Finally, an experimental plant with nonlinear characteristics is given to illustrate the overall performance of the proposed online STTC method.},
  archive      = {J_TNNLS},
  author       = {Lingzhi Hu and Ding Wang and Jin Ren and Junfei Qiao},
  doi          = {10.1109/TNNLS.2025.3574484},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Online self-triggered transmission control with critic learning for discrete nonlinear systems},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MoNetV2: Enhanced motion network for freehand 3-D ultrasound reconstruction. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3573210'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-dimensional ultrasound (US) aims to provide sonographers with the spatial relationships of anatomical structures, playing a crucial role in clinical diagnosis. Recently, deep-learning-based freehand 3-D US has made significant advancements. It reconstructs volumes by estimating transformations between images without external tracking. However, image-only reconstruction poses difficulties in reducing cumulative drift and further improving reconstruction accuracy, particularly in scenarios involving complex motion trajectories. In this context, we propose an enhanced motion network (MoNetV2) to enhance the accuracy and generalizability of reconstruction under diverse scanning velocities and tactics. First, we propose a sensor-based temporal and multibranch structure (TMS) that fuses image and motion information from a velocity perspective to improve image-only reconstruction accuracy. Second, we devise an online multilevel consistency constraint (MCC) that exploits the inherent consistency of scans to handle various scanning velocities and tactics. This constraint exploits scan-level velocity consistency (SVC), path-level appearance consistency (PAC), and patch-level motion consistency (PMC) to supervise interframe transformation estimation. Third, we distill an online multimodal self-supervised strategy (MSS) that leverages the correlation between network estimation and motion information to further reduce cumulative errors. Extensive experiments clearly demonstrate that MoNetV2 surpasses existing methods in both reconstruction quality and generalizability performance across three large datasets.},
  archive      = {J_TNNLS},
  author       = {Mingyuan Luo and Xin Yang and Zhongnuo Yan and Yan Cao and Yuanji Zhang and Xindi Hu and Jin Wang and Haoxuan Ding and Wei Han and Litao Sun and Dong Ni},
  doi          = {10.1109/TNNLS.2025.3573210},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {MoNetV2: Enhanced motion network for freehand 3-D ultrasound reconstruction},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward fine-grained 3-D visual grounding through referring textual phrases. <em>TNNLS</em>, 1-12. (<a href='https://doi.org/10.1109/TNNLS.2025.3571959'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent progress in 3-D scene understanding has explored visual grounding [3D visual grounding (3DVG)] to localize a target object through a language description. However, existing methods only consider the dependency between the entire sentence and the target object, ignoring fine-grained relationships between contexts and nontarget ones. In this article, we extend 3DVG to a more fine-grained task, called 3D phrase-aware grounding (3DPAG). The 3DPAG task aims to localize the target objects in a 3-D scene by explicitly identifying all phrase-related objects and then conducting the reasoning according to contextual phrases. To tackle this problem, we manually labeled about 227 K phrase-level annotations using a self-developed platform, from 88 K sentences of widely used 3DVG datasets, i.e., Natural Reference in 3-D (Nr3D), Spatial Reference in 3-D (Sr3D), and ScanRefer. By tapping on our datasets, we can extend previous 3DVG methods to the fine-grained phrase-aware scenario. It is achieved through the proposed novel phrase-object alignment (POA) optimization and phrase-specific pretraining (PSP), boosting conventional 3DVG performance as well. Extensive results confirm significant improvements, i.e., previous state-of-the-art method achieves 3.9%, 3.5%, and 4.6% overall accuracy gains on Nr3D, Sr3D, and ScanRefer, respectively. Our datasets and platform are released in https://github.com/CurryYuan/PhraseRefer},
  archive      = {J_TNNLS},
  author       = {Zhihao Yuan and Xu Yan and Zhuo Li and Xuhao Li and Yao Guo and Shuguang Cui and Zhen Li},
  doi          = {10.1109/TNNLS.2025.3571959},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Toward fine-grained 3-D visual grounding through referring textual phrases},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dynamics theory of RMSProp-based implicit regularization in deep low-rank matrix factorization. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3574683'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Implicit regularization induced by gradient optimization is an important way to understand generalization in neural networks. Recent theory explains implicit regularization over the deep matrix factorization (DMF) model and analyzes the trajectory of discrete gradient dynamics in the optimization process. These discrete gradient dynamics can mathematically characterize the practical learning rate of adaptive gradient (AdaGrad) optimization, such as root-mean-square propagation (RMSProp). Discrete gradient dynamics analysis has been successfully applied to shallow networks but encounters difficulty in complex computation for deep networks. In this work, we introduce another discrete gradient dynamics, landscape analysis, to theoretically and experimentally explain the implicit regularization of RMSProp-based deep networks. It mainly focuses on gradient regions like saddle points and local minima. We investigate the benefits of increasing learning rates in saddle point escaping (SPE) stages. We prove that, for a rank-R matrix reconstruction, DMF will converge to a second-order critical point after R stages of SPE. Besides, we analyze the time it takes to escape from the plateau of the SPE stage. These conclusions are further experimentally verified on low-rank matrix, image reconstruction, and Hankel matrix reconstruction problems. Our proof is also applicable to gradient descent (GD) and adaptive moment estimation (Adam) but cannot apply to AdaGrad, further showing experimentally that the implicit regularization capability of RMSProp is stronger than GD and AdaGrad and weaker than Adam.},
  archive      = {J_TNNLS},
  author       = {Jian Cao and Chen Qian and Yihui Huang and Dicheng Chen and Yuncheng Gao and Jiyang Dong and Di Guo and Xiaobo Qu},
  doi          = {10.1109/TNNLS.2025.3574683},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A dynamics theory of RMSProp-based implicit regularization in deep low-rank matrix factorization},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A trust-region projection neural network for nonlinear programming. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3576600'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The trust-region method and projection neural networks are two branches of optimization approaches with different operational principles and characteristics. In this article, a trust-region projection neural network (TRPNN) is proposed by integrating the trust-region method and projection neural networks. TRPNN is a discrete-time neurodynamic optimization model that inherits the exploration–exploitation capability of the trust-region method and the local search capability of projection neural networks. TRPNN is theoretically proven to be convergent to a Karush–Kuhn–Tuchker (KKT) point of nonlinear programming problems. The efficacy of TRPNNs leveraged in a collaborative neurodynamic framework is numerically demonstrated for global optimization in the presence of nonconvexity in objective functions or constraints.},
  archive      = {J_TNNLS},
  author       = {Haoen Huang and Zhigang Zeng and Jun Wang},
  doi          = {10.1109/TNNLS.2025.3576600},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A trust-region projection neural network for nonlinear programming},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Chain-of-situation aware progressive inference learning. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3576486'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The grounded situation recognition (GSR) task aims to recognize the structured semantics of an image to achieve “human-like” event understanding. Most previous studies primarily focus on the visual features of the situation, overlooking the step-by-step cognitive reasoning process that humans employ in complex task settings. Recently, the emergence of multimodal large language models (MLLMs) has provided novel directions for addressing complex problems. However, directly deploying MLLMs on the GSR task is suboptimal due to their tendency to exhibit “hallucination” issues. Additionally, fine-tuning MLLMs for the GSR task incurs high training costs. To address these challenges, inspired by human cognitive theory and the chain-of-thought (CoT) strategy, we propose the chain-of-situation progressive inference learning (CoS-PIL) framework, a lightweight approach that progressively completes verb prediction, noun prediction, and role grounding. The prediction of each step depends on the historical information of the previous step. Specifically, we first design situation prompts tailored to the GSR task and utilize MLLMs to analyze the input image and language prompts, generating heuristic response text for the current situation in the image. Instead of fine-tuning the MLLM, we activate the reasoning capabilities of the frozen MLLM and adapt its generated responses into three lightweight modules: CoS-Verb, CoS-Noun, and CoS-Ground. Considering that MLLMs may generate redundant content, we carefully design the chain-of-interest predictor (CoI-Predictor) to extract key information from the extensive response text and inject it into the model as prompts to enhance the performance. Extensive experiments on the challenging SWiG benchmark demonstrate that CoS-PIL outperforms other state-of-the-art methods. The code is publically available at https://github.com/XDLiuyyy/CoS-PIL},
  archive      = {J_TNNLS},
  author       = {Yang Liu and Fang Liu and Licheng Jiao and Qianyue Bao and Shuo Li and Lingling Li and Xu Liu and Puhua Chen and Wenping Ma},
  doi          = {10.1109/TNNLS.2025.3576486},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Chain-of-situation aware progressive inference learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bayesian neural networks with physics-informed priors with application to boundary layer velocity. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3577508'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most popular recent areas of machine learning predicates the use of neural networks (NNs) augmented by information about the underlying process in the form of partial differential equations (PDEs). These physics-informed NNs (PINNs) are obtained by penalizing the inference with a PDE and have been cast as a minimization problem currently lacking a formal approach to quantify the uncertainty. In this work, we propose a novel model-based framework that regards the PDE as a prior information of a deep Bayesian NN (BNN), physics-informed prior (PIP)-BNN. The prior is calibrated without data to resemble the PDE solution in the prior mean, while our degree of confidence in the PDE with respect to the data is expressed in terms of the prior variance. The information embedded in the PDE are then propagated to the posterior yielding physics-informed forecasts with uncertainty quantification. We apply our approach to a simulated viscous fluid and to an experimentally obtained turbulent boundary layer velocity in a water tunnel using an appropriately simplified Navier–Stokes (NS) equation. Our approach requires very few observations to produce physically consistent forecasts as opposed to nonphysical forecasts stemming from noninformed priors, thereby allowing forecasting complex systems, where some amount of data as well as some contextual knowledge is available.},
  archive      = {J_TNNLS},
  author       = {Luca Menicali and David H. Richter and Stefano Castruccio},
  doi          = {10.1109/TNNLS.2025.3577508},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Bayesian neural networks with physics-informed priors with application to boundary layer velocity},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EEG-based emotion monitoring and regulation system by learning the discriminative brain network manifold. <em>TNNLS</em>, 1-16. (<a href='https://doi.org/10.1109/TNNLS.2025.3576182'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion recognition based on electroencephalogram (EEG) is fundamentally associated with human-like intelligence system. However, due to the noise-sensitive characteristics of EEGs and the individual variability of emotions, it is very challenging to extract inherent emotion dependent patterns from emotional EEG signals. In this work, we propose a L1-norm space defined discriminative brain network manifold learning model (L1-SGL), in which the EEG noise outliers can be effectively separated and the pseudolabeled samples caused by subjective feelings can be automatically corrected. Off-line experimental results consistently indicate that the L1-SGL can effectively suppress the influence of noise and achieve an incomparable superiority performance over other existing methods in EEG emotion recognition. Besides, benefiting from the time efficiency of the L1-SGL, an online emotion monitoring and regulation system is further implemented in this work. On-line emotion decoding experimental results (86.30%) of 25 participants prove that the L1-SGL can effectively satisfy the real-time requirements of on-line emotional monitoring applications, and the significant negative emotion regulation experimental results ( $p \lt 0.001$ ) further confirm the feasibility and effectiveness of L1-SGL model in real-time emotion regulation and interactive applications. Overall, the L1-SGL provides a promising solution for the real-time online affective brain-computer interfaces (aBCIs) and the intelligent clinical closed-loop treatments.},
  archive      = {J_TNNLS},
  author       = {Cunbo Li and Zehong Cao and Yue Pan and Pengcheng Zhu and Peiyang Li and Fali Li and Huafu Chen and Bao-Liang Lu and Feng Wan and Dezhong Yao and Peng Xu},
  doi          = {10.1109/TNNLS.2025.3576182},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {EEG-based emotion monitoring and regulation system by learning the discriminative brain network manifold},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Variational hierarchical N-BEATS model for long-term time-series forecasting. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3571039'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long-term time-series forecasting (LTSF) is gaining increasing attention due to its significant challenges and real-world applications. However, existing studies underexplore the role of hierarchical timestamp information in LTSF. We find this information crucial, as neglecting it may lead to the loss of broader perspectives necessary for understanding hierarchical effects, such as weekly and yearly patterns. Therefore, we propose VH-NBEATS, an interpretable variational hierarchical model that extends the N-BEATS architecture to address the challenges outlined above. VH-NBEATS consists of two blocks: the hierarchical timestamp block and the harmonic seasonal block, which are designed to capture hierarchical seasonal and trending effects. To tackle the high variability often observed in time series, VH-NBEATS incorporates a variational autoencoder (VAE), significantly enhancing the standard deterministic approach. The experimental results are evaluated on seven real-world datasets, demonstrating state-of-the-art (SOTA) performance for LTSF. We also prove that the hierarchical timestamp block can enable plug-and-play with any methods, such as PatchTST, Informer, and DLinear, for better performance.},
  archive      = {J_TNNLS},
  author       = {Runze Yang and Longbing Cao and Jianxun Li and Jie Yang},
  doi          = {10.1109/TNNLS.2025.3571039},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Variational hierarchical N-BEATS model for long-term time-series forecasting},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PADiff: Reconstruction from patch to pixel with normality-guided diffusion model for unsupervised anomaly localization. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3572438'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly localization (AL) is an indispensable and challenging task in manufacturing. Recently, diffusion models have been widely used to localize anomalies through discrepancies between original and reconstructed representations, which is based on the hypothesis that diffusion models regard anomalies as noise and reconstruct them to normal representations. However, anomalies usually deviate from prior standard Gaussian distribution and diffusion models cannot reconstruct anomaly parts as normal patterns well due to powerful generalization. These issues hinder the application of diffusion models in AL and lead to suboptimal performance. As a remedy, we present a novel framework for AL based on the diffusion model, dubbed PADiff. To enable the diffusion model to reconstruct abnormal regions to normal regions in an anomaly image, we propose to guide the diffusion model in the reconstruction process using its normal counterpart. High-quality guided normal counterpart plays a key role in our method. Therefore, we propose a patch-substitution strategy to obtain a high-quality-guided normal counterpart. Specifically, we first construct a normal patch memory bank using normal training samples. With a normal memory bank, we find potential anomaly patches in testing images and substitute them with most similar normal patches in the memory bank. After substitution, pseudo-normal images are generated to guide the diffusion model. To make our method more data-efficient, we divide an image into patches and propose patch-wise training and reconstruction. As one of our innovations, we propose to encode each patch into positional embedding and add it on time embedding, which introduces patch-level representation and position information in the diffusion model. Extensive experiments are conducted on three commonly used anomaly detection datasets (MVTec-AD, VisA, and BTAD) to showcase the state-of-the-art (SOTA) performance of the proposed PADiff. The source code is publicly available at https://github.com/Jay-zzcoder/padiff},
  archive      = {J_TNNLS},
  author       = {Zuo Zuo and Jiahao Dong and Yao Wu and Yanyun Qu and Zongze Wu},
  doi          = {10.1109/TNNLS.2025.3572438},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {PADiff: Reconstruction from patch to pixel with normality-guided diffusion model for unsupervised anomaly localization},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised multimanifold cross-guided diffusion deformable registration for cardiac MRI. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3577483'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffusion networks demonstrate remarkable robustness in extracting complex structural features across various domains of medical image processing. In the task of cardiac image registration, diffusion networks excel at reconstructing intricate structural details, thereby enabling effective representation of cardiac anatomical motion. In this article, we propose an unsupervised diffusion registration framework named MCG-Reg for 3-D cardiac magnetic resonance (MR) image registration, employing a multimanifold cross-fusion strategy. MCG-Reg comprises two components: the multimanifold cross-fusion (MCF) module and the weighted fusion codec (WFC) module. MCF module decouples the cardiac image, leveraging multifrequency and multiscale features for cross-attention (CA) calculation, and fuses with the edge image to enable adaptive focus gathering and edge perception capabilities in the model, thereby enhancing the effective aggregation of local and global features. WFC module further processes cardiac features by utilizing offset attention to capture large displacement information, while employing feature energy maps for residual connections to enhance the model’s attention perception ability, thus facilitating better topology maintenance and boundary constraint realization. The registration accuracy and model generalization of the proposed MCG-Reg are validated in publicly available ACDC, M&Ms, and CAP datasets. The experimental results verify that it achieves state-of-the-art performance in comparison to related methods, highlighting the significant potential of the proposed framework in cardiac image analysis applications.},
  archive      = {J_TNNLS},
  author       = {Qifeng Zhao and Xuchu Wang},
  doi          = {10.1109/TNNLS.2025.3577483},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Unsupervised multimanifold cross-guided diffusion deformable registration for cardiac MRI},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ChatABL: Abductive learning via natural language interaction with ChatGPT. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3567945'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) such as ChatGPT have recently demonstrated significant potential in mathematical abilities, providing a valuable reasoning paradigm consistent with human natural language. However, LLMs currently have difficulty in bridging perception, language understanding, and reasoning (PLR) capabilities due to incompatibility of the underlying information flow among them, making their reasoning ability not fully elicited and challenging to accomplish complicated reasoning tasks autonomously. To resolve the above problem, a novel method called ChatABL is proposed by integrating LLMs into an abductive learning (ABL) framework, capable of unifying the three abilities effectively in a more user-friendly and understandable manner. Initially, the proposed method uses LLMs to correct the incomplete logical facts for optimizing the perception module, by summarizing and reorganizing domain knowledge represented in natural language format. Then, the perception module also provides necessary logical reasoning materials for feeding LLMs. Finally, these parts are integrated into a dynamic closed-loop system by introducing the feedback form and automatic learning strategies to mutually promote their performance. As a testbed, the variable-length handwritten equation decipherment (HED), an abstract expression of the Mayan calendar decoding, is used to demonstrate that ChatABL has reasoning ability beyond most existing state-of-the-art methods, which has been well-supported by comparative studies. To the best of authors’ knowledge, the proposed ChatABL is the first attempt to explore a possible and novel avenue to approaching human-level cognitive ability via natural language interaction by means of ChatGPT.},
  archive      = {J_TNNLS},
  author       = {Tianyang Zhong and Yi Pan and Yutong Zhang and Yaonai Wei and Li Yang and Zhengliang Liu and Xiaozheng Wei and Wenjun Li and Junjie Yao and Chong Ma and Xi Jiang and Dinggang Shen and Junwei Han and Tuo Zhang},
  doi          = {10.1109/TNNLS.2025.3567945},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {ChatABL: Abductive learning via natural language interaction with ChatGPT},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Layer-wise training of graph neural networks with self-supervised learning. <em>TNNLS</em>, 1-11. (<a href='https://doi.org/10.1109/TNNLS.2025.3577702'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Training graph neural networks (GNNs) on large graphs is challenging due to both the high memory and computational costs of end-to-end training and the scarcity of detailed node-level annotations. To address these challenges, we propose layer-wise regularized graph infomax (LRGI), a self-supervised learning algorithm inspired by predictive coding, a biologically motivated principle in which each layer is trained locally to predict its future inputs. LRGI trains GNNs layer by layer, decoupling their memory and time complexity from the network depth, thereby enabling scalable training on large graphs. In LRGI, each layer learns to predict the features propagated from its neighbors, allowing independent training of each layer. This approach, combined with regularization that promotes diverse representations, also helps mitigate oversmoothing in deep GNNs. Experiments on large inductive graph benchmarks demonstrate that LRGI achieves competitive performance compared to state-of-the-art end-to-end methods, while substantially improving efficiency.},
  archive      = {J_TNNLS},
  author       = {Oscar Pina and Verónica Vilaplana},
  doi          = {10.1109/TNNLS.2025.3577702},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Layer-wise training of graph neural networks with self-supervised learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncovering large language model weaknesses in character and word understanding and manipulating. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3575818'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, large language models (LLMs) have showcased remarkable capabilities across a diverse range of applications, including general natural language processing (NLP) and domain-specific tasks. Empirical evidence indicates that LLMs have matched or even surpassed human performance in various areas, such as language translation, reading comprehension, and logical reasoning. However, preliminary research reveals that LLMs struggle with basic character and word editing, which is crucial for practical tasks such as creating 1000-word articles or modifying specific text information. To comprehensively assess the capabilities of LLMs in character and word understanding and manipulation (CWUM), we introduce the CWUM benchmark in Chinese and English. CWUM comprises 23 tasks focusing on text editions, including counting, identification, insertion, and reversal. A comprehensive evaluation of nine advanced LLMs on CWUM is conducted, which highlights significant failures of existing LLMs on CWUM tasks that humans can solve perfectly with 100% accuracy. Meanwhile, specific deficiencies of LLMs in basic language understanding and manipulation are revealed by performing quality and quantity analysis. Furthermore, in the experiment part, various methods are investigated to improve model performance, demonstrating the effectiveness of supervised fine-tuning (SFT) in enhancing model performance on CWUM while maintaining generalization abilities on unseen tasks.},
  archive      = {J_TNNLS},
  author       = {Yidan Zhang and Zhenan He and Gary G. Yen},
  doi          = {10.1109/TNNLS.2025.3575818},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Uncovering large language model weaknesses in character and word understanding and manipulating},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multihop reconstruction for generalized zero-shot node classification. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3574252'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graphs in the real world keep evolving with the integration of new nodes, and it is often infeasible to manually label all the new nodes promptly. In this case, graph learning algorithms can come in handy and perform classification on these newly emerging nodes. Typically, if unseen classes exist (i.e., no training samples from these classes), one can perform zero-shot learning (ZSL) or generalized ZSL (GZSL). During testing, ZSL aims to classify samples within unseen classes, whereas GZSL aims to classify samples within both seen and unseen classes, which is even more challenging. In our previous work, we proposed a decomposed graph prototype network (DGPN) to decompose the graph convolution operation for handling the zero-shot node classification (ZNC) problem. However, DGPN is not well-suited for the generalized ZNC (GZNC) problem. To this end, in this article, we propose a novel graph generative model, multihop reconstruction graph autoencoder (MHR-GAE). Unlike DGPN, MHR-GAE utilizes a multihop encoder with class semantic descriptions (CSDs) (as condition signals) to reconstruct the information and generate nodes of unseen classes. Thus, it can handle both the ZNC and GZNC problems and obtain competitive performance. We evaluate our model on real-world datasets, and the experimental results demonstrate that MHR-GAE outperforms other baseline methods.},
  archive      = {J_TNNLS},
  author       = {Jialong Wang and Zheng Wang and Zhiguo Gong},
  doi          = {10.1109/TNNLS.2025.3574252},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Multihop reconstruction for generalized zero-shot node classification},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FX-DARTS: Designing topology-unconstrained architectures with differentiable architecture search and entropy-BasedSuper-network shrinking. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3575505'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Strong priors are imposed on the search space of differentiable architecture search (DARTS), such that cells of the same type share the same topological structure and each intermediate node retains two operators from distinct nodes. While these priors reduce optimization difficulties and improve the applicability of searched architectures, they hinder the subsequent development of automated machine learning (auto-ML) and prevent the optimization algorithm from exploring more powerful neural networks through improved architectural flexibility. This article aims to reduce these prior constraints by eliminating restrictions on cell topology and modifying the discretization mechanism for super-networks. Specifically, the flexible DARTS (FX-DARTS) method, which leverages an entropy-based super-network shrinking (ESS) framework, is presented to address the challenges arising from the elimination of prior constraints. Notably, FX-DARTS enables the derivation of neural architectures without strict prior rules while maintaining the stability in the enlarged search space. Experimental results on image classification benchmarks demonstrate that FX-DARTS is capable of exploring a set of neural architectures with competitive trade-offs between performance and computational complexity within a single search procedure.},
  archive      = {J_TNNLS},
  author       = {Xuan Rao and Bo Zhao and Derong Liu and Cesare Alippi},
  doi          = {10.1109/TNNLS.2025.3575505},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {FX-DARTS: Designing topology-unconstrained architectures with differentiable architecture search and entropy-BasedSuper-network shrinking},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online self-training driven attention-guided self-mimicking network for semantic segmentation. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3577327'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the realm of semantic segmentation tasks, knowledge distillation (KD) has emerged as a prominent strategy, leveraging the transfer of mature knowledge from large teacher networks to enhance the performance of smaller student networks. However, existing methods often rely heavily on high-quality yet cumbersome teacher networks, leading to a complex training process. To address this challenge, we introduce a novel approach termed self-training driven attention-guided self-mimicking online ensemble network. Our proposed method begins by employing intermediate channel-joint attention maps to guide image augmentation. Both the original and augmented images are then input into the networks. Leveraging intermediate feature maps and predictive predictions generated from the two images, we employ KD to uncover invariant features. To further harness representation potential through learning from credible predictions, we introduce a self-training mechanism. This mechanism utilizes an exponential moving average (EMA)-teacher network constructed using the exponential moving average technique to generate feature maps and predicted posterior probabilities. The knowledge of the EMA-teacher is subsequently transferred to the student network through distillation. Extensive experiments and visualization analyses conducted on multiple benchmark datasets, including Cityscapes, Pascal VOC, CamVid, and ADE20k, validate the effectiveness of self-training driven attention-guided self-mimicking network (ST-ASMNet). The interpretability of our method is further validated through visualization and analysis. Our code will be publicly available.},
  archive      = {J_TNNLS},
  author       = {Shuchang Lyu and Qi Zhao and Hong Zhang and Guangliang Cheng and Chenguang Yang},
  doi          = {10.1109/TNNLS.2025.3577327},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Online self-training driven attention-guided self-mimicking network for semantic segmentation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ABNN: Adaptive-gating binary neural network with dynamic activation quantization for industrial health status prediction. <em>TNNLS</em>, 1-12. (<a href='https://doi.org/10.1109/TNNLS.2025.3577620'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex industrial equipment plays a critical role in specific tasks within industrial edge scenarios. Predicting their health status accurately is essential to ensuring safety and reliability in the production process. However, real-world industrial edge scenarios often have limited resources and stringent real-time requirements, making it difficult to deploy high-precision deep learning models directly at the edge. To address this issue, this article proposes an efficient adaptive-gating binary neural network (ABNN). First, a trend-aware encoder (TAE) is proposed to optimize the binarization process of the input layer. Next, a learnable precision indicator (LPI) is proposed to adjust the inference precision level. Finally, an adaptive-gating convolution is proposed to improve the representational capabilities while maintaining the fitting ability without significantly increasing the computational cost. Additionally, a field-programmable gate array (FPGA) hardware accelerator is designed for the proposed network. ABNN achieves approximately a 7% improvement in accuracy and a 45% gain in efficiency compared to the baseline model.},
  archive      = {J_TNNLS},
  author       = {Lei Ren and Shixiang Li and Haiteng Wang and Yuanjun Laili},
  doi          = {10.1109/TNNLS.2025.3577620},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {ABNN: Adaptive-gating binary neural network with dynamic activation quantization for industrial health status prediction},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Near-optimal algorithms for instance-level constrained k-center clustering. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3574268'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many practical applications impose a new challenge of utilizing instance-level background knowledge (e.g., subsets of similar or dissimilar data points) within their input data to improve clustering results. In this work, we build on the widely adopted k-center clustering, modeling its input instance-level background knowledge as must-link (ML) and cannot-link (CL) constraint sets, and formulate the constrained k-center problem. Given the long-standing challenge of developing efficient algorithms for constrained clustering problems, we first derive an efficient approximation algorithm for constrained k-center at the best possible approximation ratio of 2 with linear programming (LP)-rounding technology. Recognizing the limitations of LP-rounding algorithms including high runtime complexity and challenges in parallelization, we subsequently develop a greedy algorithm that does not rely on the LP and can be efficiently parallelized. This algorithm also achieves the same approximation ratio 2 but with lower runtime complexity. Lastly, we empirically evaluate our approximation algorithm against baselines on various real datasets, validating our theoretical findings and demonstrating significant advantages of our algorithm in terms of clustering cost, quality, and runtime complexity.},
  archive      = {J_TNNLS},
  author       = {Longkun Guo and Chaoqi Jia and Kewen Liao and Zhigang Lu and Minhui Xue},
  doi          = {10.1109/TNNLS.2025.3574268},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Near-optimal algorithms for instance-level constrained k-center clustering},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DashFusion: Dual-stream alignment with hierarchical bottleneck fusion for multimodal sentiment analysis. <em>TNNLS</em>, 1-12. (<a href='https://doi.org/10.1109/TNNLS.2025.3578618'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal sentiment analysis (MSA) integrates various modalities, such as text, image, and audio, to provide a more comprehensive understanding of sentiment. However, effective MSA is challenged by alignment and fusion issues. Alignment requires synchronizing both temporal and semantic information across modalities, while fusion involves integrating these aligned features into a unified representation. Existing methods often address alignment or fusion in isolation, leading to limitations in performance and efficiency. To tackle these issues, we propose a novel framework called dual-stream alignment with hierarchical bottleneck fusion (DashFusion). First, the dual-stream alignment module synchronizes multimodal features through temporal and semantic alignment. Temporal alignment employs cross-modal attention (CA) to establish frame-level correspondences among multimodal sequences. Semantic alignment ensures consistency across the feature space through contrastive learning. Second, supervised contrastive learning (SCL) leverages label information to refine the modality features. Finally, hierarchical bottleneck fusion (HBF) progressively integrates multimodal information through compressed bottleneck tokens, which achieves a balance between performance and computational efficiency. We evaluate DashFusion on three datasets: CMU-MOSI, CMU-MOSEI, and CH-SIMS. Experimental results demonstrate that DashFusion achieves state-of-the-art (SOTA) performance across various metrics, and ablation studies confirm the effectiveness of our alignment and fusion techniques. The codes for our experiments are available at https://github.com/ultramarineX/DashFusion},
  archive      = {J_TNNLS},
  author       = {Yuhua Wen and Qifei Li and Yingying Zhou and Yingming Gao and Zhengqi Wen and Jianhua Tao and Ya Li},
  doi          = {10.1109/TNNLS.2025.3578618},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {DashFusion: Dual-stream alignment with hierarchical bottleneck fusion for multimodal sentiment analysis},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ADP-based orbit tracking control for deep space probe flying around unknown asteroid. <em>TNNLS</em>, 1-12. (<a href='https://doi.org/10.1109/TNNLS.2025.3578863'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates the orbit tracking control problem for the deep space probe flying around an unknown asteroid under completely unknown dynamics. First, an orbit tracking control model for the relative motion of the probe to the asteroid is established. Then, a model-based controller is designed for the optimal tracking control problem and the asymptotic stability of the closed-loop system is proved. Next, an adaptive dynamic programming (ADP) algorithm based on policy iteration is adopted to obtain a model-free suboptimal controller that approximates the previous model-based controller, followed by the convergence analysis. Specifically, by collecting some data online, a system of high-order linear equations is constructed and then solved to obtain parameters utilized in controller construction. Finally, numerical simulations are provided to validate the effectiveness and the performance of the proposed control method.},
  archive      = {J_TNNLS},
  author       = {Zebin Chen and Yanwei Ding and Wenjian Tao and Jinxiu Zhang and Hui-Jie Sun},
  doi          = {10.1109/TNNLS.2025.3578863},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {ADP-based orbit tracking control for deep space probe flying around unknown asteroid},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comprehensively adaptive architectural optimization-ingrained quantum neural network model for cloud workloads prediction. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3577721'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate workload prediction and advanced resource reservation are indispensably crucial for managing dynamic cloud services. Traditional neural networks and deep learning models frequently encounter challenges with diverse, high-dimensional workloads, especially during sudden resource demand changes, leading to inefficiencies. This issue arises from their limited optimization during training, relying only on parametric (interconnection weights) adjustments using conventional algorithms. To address this issue, this work proposes a novel comprehensively adaptive architectural optimization-based variable quantum neural network (CA-QNN), which combines the efficiency of quantum computing with complete structural and qubit vector parametric learning. The model converts workload data into qubits, processed through qubit neurons with controlled not-gated activation functions for intuitive pattern recognition. In addition, a comprehensive architecture optimization algorithm for networks is introduced to facilitate the learning and propagation of the structure and parametric values in variable-sized quantum neural networks (VQNNs). This algorithm incorporates quantum adaptive modulation (QAM) and size-adaptive recombination during the training process. The performance of the CA-QNN model is thoroughly investigated against seven state-of-the-art methods across four benchmark datasets of heterogeneous cloud workloads. The proposed model demonstrates superior prediction accuracy, reducing prediction errors by up to 93.40% and 91.27% compared to existing deep learning and QNN-based approaches.},
  archive      = {J_TNNLS},
  author       = {Jitendra Kumar and Deepika Saxena and Kishu Gupta and Satyam Kumar and Ashutosh Kumar Singh},
  doi          = {10.1109/TNNLS.2025.3577721},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A comprehensively adaptive architectural optimization-ingrained quantum neural network model for cloud workloads prediction},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design of hopfield neural network based on DNA strand displacement circuits and its application in sudoku conjecture. <em>TNNLS</em>, 1-11. (<a href='https://doi.org/10.1109/TNNLS.2025.3576888'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, biological neural networks have developed rapidly due to their advantages of fast parallel computing processing speed and strong fault tolerance. This article is dedicated to explore innovation in this field and successfully constructing a Hopfield neural network model based on DNA strand displacement (DSD) circuits. First, this article constructs four core functional modules based on DSD, including an encoder module, weighted sum module, comparator module, and decoder module. These functional modules together form the design foundation of the DSD circuit, achieving effective circuit construction. Second, the construction of the Hopfield neural network is achieved through DSD circuits. The construction of this network achieves the integration of DSD technology and neural networks. Finally, the Sudoku conjecture problem is solved through the neural network. This article conducts a simulation in visual DSD, which verifies the feasibility of Sudoku conjecture. Our work integrates DSD technology with neural networks and uses them to solve practical problems. This fusion broadens the research field of neural networks and demonstrates the potential of biotechnology in practical applications.},
  archive      = {J_TNNLS},
  author       = {Junwei Sun and Haojie Wang and Yi Yue and Dan Ling and Yanfeng Wang},
  doi          = {10.1109/TNNLS.2025.3576888},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Design of hopfield neural network based on DNA strand displacement circuits and its application in sudoku conjecture},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SFAN: Selective filter and alignment network for cross-modal retrieval. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3577292'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bridging the gap between visual and textual modalities effectively has consistently been a key challenge in cross-modal retrieval. Fine-grained matching approaches improve performance by precisely aligning salient region features in visual modality with word embeddings in textual modality. However, how to effectively and efficiently filter out irrelevant features (e.g., irrelevant background regions and nonmeaningful prepositions) in multimodality remains a significant challenge. Furthermore, capturing key cross-modal relationships while minimizing misalignment interference is crucial for effective cross-modal retrieval. In this work, we propose a novel approach called the selective filter and alignment network (SFAN) to tackle these challenges. First, we propose modality-specific selective filter modules (SFMs) to selectively and implicitly filter out redundant information within each modality. We then propose the state-space models (SSMs)-based selective alignment module (SAM) to selectively capture key correspondences and reduce the disturbance of irrelevant associations. Finally, we utilize a fusion operation to combine these embeddings from both SFM and SAM to derive the final embeddings for similarity computation. Extensive experiments on the Flickr30k, MS-COCO, and MSR-VTT datasets reveal that our proposed SFAN can effectively learn robust patterns, significantly outperforming the state-of-the-art (SOTA) cross-modal retrieval methods by a wide margin.},
  archive      = {J_TNNLS},
  author       = {Yongle Huang and Zedong Liu and Shijie Sun and Ningning Cui and Jianxin Li},
  doi          = {10.1109/TNNLS.2025.3577292},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {SFAN: Selective filter and alignment network for cross-modal retrieval},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Granular-ball regeneration clustering with principle of justifiable granularity. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3579376'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classical clustering algorithms such as k-means face limitations in handling clusters with heterogeneous shapes, densities, and sizes, while exhibiting sensitivity to initial centroid selection. To overcome these challenges, this article proposes a novel clustering framework based on regenerated granular ball (RGGB) with the principle of justifiable granularity. Unlike existing granular-ball (GB) techniques that overemphasize purity criteria at the expense of uncontrolled ball sizes, RGGB dynamically adjusts granularity levels through iterative regeneration, achieving an optimal balance between detailed data representation and computational efficiency. This adaptability enhances stability in capturing data similarities while mitigating sensitivity to initialization. To validate the method, we integrate RGGB with a novel k-nearest neighbor (KNN) classifier using regenerated GBs to evaluate classification performance and demonstrate practical applications. Experiments on diverse public and realistic datasets demonstrate that the RGGB-based KNN algorithm consistently outperforms existing techniques, including traditional KNN and other methods, making a promising advancement in clustering and classification tasks.},
  archive      = {J_TNNLS},
  author       = {Wentao Li and Lingwei Wei and Witold Pedrycz and Weiping Ding and Chao Zhang and Tao Zhan and Shuyin Xia},
  doi          = {10.1109/TNNLS.2025.3579376},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Granular-ball regeneration clustering with principle of justifiable granularity},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Object detection with physical prior and AWConv in foggy weather for traffic scenes. <em>TNNLS</em>, 1-16. (<a href='https://doi.org/10.1109/TNNLS.2025.3577791'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite significant advances in object detection methods for traffic scenes, object detection under adverse weather conditions is still a challenging task. Especially in foggy weather, the presence of fog reduces visibility, thus weakening the feature information of traffic objects in images, and foggy weather occurs frequently. To cope with this problem, we propose an object detection method with physical prior and adaptive weight convolution (AWConv), and evaluate it on datasets such as Foggy Cityscapes and RTTS. We apply gamma correction in the improved defogging algorithm to enhance the key regions in the image, thus improving the separability of the features. Meanwhile, the feature extraction and representation ability of the model is enhanced by an adaptive weighting mechanism, which in turn improves the model detection performance. In addition, we explore the relationship between image quality and detection accuracy and observe that they are not linearly positively correlated. Due to the complexity of traffic objects in foggy weather, we conduct experiments on Foggy Cityscapes (synthetic fog), RTTS (real-world multiple adverse weather), Cityscapes (normal weather), and extended dataset (different fog concentrations) to validate the model’s effectiveness, generalization ability, and robustness. Experimental results show that the small model alone improves mean average precision (mAP) by 1.4% with only 24.6 giga floating point operations per second (GFLOPs) on the Foggy Cityscapes dataset, reduces GFLOPs by 3.8 and improves recall (R) by 1.1% on the RTTS dataset.},
  archive      = {J_TNNLS},
  author       = {Xue-Juan Han and Zhong Qu and Shi-Yan Wang and Shu-Fang Xia},
  doi          = {10.1109/TNNLS.2025.3577791},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Object detection with physical prior and AWConv in foggy weather for traffic scenes},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diverse representations embedding for lifelong person re-identification. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3571768'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lifelong person re-identification (LReID) aims to continuously learn from sequential data streams, enabling cross-camera matching of individuals over time. A critical challenge in LReID lies in balancing the preservation of previously acquired knowledge with the incremental acquisition of new information, due to task-level gaps and limited representation capacity. Conventional methods relying on CNN backbones struggle to fully capture the diverse perspectives of each instance, leading to suboptimal model performance. To tackle these limitations, we propose a diverse representation embedding (DRE) framework that balances preserving old knowledge with adapting to new information. Specifically, our DRE incorporates a robust Transformer-based backbone that utilizes maximum embedding (ME) and multiple class tokens to generate overlapping representations for each instance. To further enhance the model’s representation capacity, we design an adaptive constraint module (ACM), which performs integration and discrimination operations on overlapping representations to yield diverse yet diverse representations. Furthermore, we propose two strategies: knowledge update (KU) and knowledge preservation (KP), implemented within the adjustment and learner models, respectively. The KU strategy enhances the learner model’s ability to adapt to new information by leveraging prior knowledge from the adjustment model. The KP strategy ensures the retention of historical knowledge while maintaining the model’s adaptability. Extensive experiments validate that our DRE surpasses state-of-the-art approaches across large-scale, occluded, and holistic datasets, demonstrating significant performance gains. Our code is available at https://github.com/LiuShiBen/DRE},
  archive      = {J_TNNLS},
  author       = {Shiben Liu and Huijie Fan and Qiang Wang and Xiai Chen and Zhi Han and Yandong Tang},
  doi          = {10.1109/TNNLS.2025.3571768},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Diverse representations embedding for lifelong person re-identification},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). You never walk alone: A generalizable and nonparametric structure learning framework. <em>TNNLS</em>, 1-12. (<a href='https://doi.org/10.1109/TNNLS.2025.3580101'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The graph-structured learning (GSL) aims to assist graph neural networks (GNNs) to yield effective node embeddings for downstream tasks, especially in scenarios with the absence of structures or the existence of unreliable edges. Most GSL models are built on i.i.d. assumption across training and testing data. However, this assumption can be violated, where testing data contain out-of-distribution (OOD) samples. Consequently, those models are limited in generalization, which will lead to a poor structure. On the other hand, while they have made great progress, additional optimized parameters are required due to their implementation with parametric models. To tackle the above problems, we propose a novel generalizable and nonparametric structure learning framework named GNS, which can be easily and effectively applied to various tasks. GNS neither relies on i.i.d. assumption nor even involves any parameters being optimized, instead to find an appropriate similarity between nodes and an associated threshold to establish desirable structures. Specifically, we first incorporate the candidate neighbor distributions for nodes to refine the similarity. Then, we introduce an adaptive threshold discovery method inspired by Fisher’s criterion to determine final structures. Extensive experiments demonstrate that GNS excels not only in OOD scenarios but also in the general classification and regression prediction tasks.},
  archive      = {J_TNNLS},
  author       = {Jiaqiang Zhang and Xinrui Wang and Songcan Chen},
  doi          = {10.1109/TNNLS.2025.3580101},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {You never walk alone: A generalizable and nonparametric structure learning framework},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TC3Net: Transformer and convolution coupled contrastive network for single image super-resolution. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3577669'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The convolutional neural network (CNN) and transformer have gained significant attention in the field of single image super-resolution (SISR), owing to their powerful capacity in nonlinear feature extraction. Nonetheless, these two types of approaches hold their own limitations. For instance, the interaction between convolutional kernels and image content is agnostic in CNN, while the computational complexity increases quadratically along with the spatial resolution in the transformer. To address these concerns, in this article, we propose a novel unified framework named transformer and convolution coupled contrastive network (TC3Net) for SISR, which holds a triple-branch structure to integrate the merits of both CNN and transformer. The proposed TC3Net is mainly composed of several stacked CNN feature extraction (CFE) blocks, transformer feature extraction (TFE) blocks, and coupled contrastive blocks (CCBs) for diverse feature extraction. Particularly, the CCB that consists of the coupled attention block (CAB) and the local-global feature extraction (LGFE) block is designed to fuse feature maps and extract coupled information for better image reconstruction. Moreover, a contrastive loss between the transformer and CNN feature maps is further introduced to enhance their discriminative characteristics and complement the fused features. Experimental results demonstrate that TC3Net outperforms several state-of-the-art (SOTA) methods in the aspect of achieving a better balance between model size and performance.},
  archive      = {J_TNNLS},
  author       = {Licheng Liu and Qibin Zhang and Tingyun Liu and C. L. Philip Chen},
  doi          = {10.1109/TNNLS.2025.3577669},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {TC3Net: Transformer and convolution coupled contrastive network for single image super-resolution},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Double successive over-relaxation Q-learning with an extension to deep reinforcement learning. <em>TNNLS</em>, 1-7. (<a href='https://doi.org/10.1109/TNNLS.2025.3576581'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Q-learning (QL) is a widely used algorithm in reinforcement learning (RL), but its convergence can be slow, especially when the discount factor is close to one. Successive over-relaxation (SOR) QL, which introduces a relaxation factor to speed up convergence, addresses this issue but has two major limitations. In the tabular setting, the relaxation parameter depends on transition probability, making it not entirely model-free, and it suffers from overestimation bias. To overcome these limitations, we propose a sample-based, model-free double SORQL (MF-DSORQL) algorithm. Theoretically and empirically, this algorithm is shown to be less biased than SORQL. Furthermore, in the tabular setting, the convergence analysis under boundedness assumptions on iterates is discussed. The proposed algorithm is extended to large-scale problems using deep RL. Finally, both the tabular version of the proposed algorithm and its deep RL extension are tested on benchmark examples.},
  archive      = {J_TNNLS},
  author       = {S. R. Shreyas},
  doi          = {10.1109/TNNLS.2025.3576581},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-7},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Double successive over-relaxation Q-learning with an extension to deep reinforcement learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MetaIndux-TS: Frequency-aware AIGC foundation model for industrial time series. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3577203'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Implementing advanced AI techniques in industrial manufacturing requires large volumes of annotated sensor data. Unfortunately, collecting such data is often impractical due to extreme environments and the manual burden of expert annotation. Recent advancements in artificial intelligence generated content (AIGC) have inspired the exploration of industrial time-series generation to mitigate data shortages. However, existing AIGC models encounter difficulties in generating industrial time series due to their complex temporal dynamics, multichannel intercolumn correlations, and diverse frequency characteristics. To address these challenges, we propose MetaIndux-TS, a frequency-informed AIGC foundation model based on diffusion model frameworks. This model is designed to generate industrial time-series data under a variety of working conditions, across different types of equipment, and with variable lengths. Specifically, MetaIndux-TS integrates dual-frequency cross-attention networks, transforming time series into the frequency domain to model multivariate dependencies and capture intricate temporal details. In addition, the contrastive synthesis layer is constructed to generate high-fidelity time series by comparing periodic and long-term trends with initial noisy sequences. Comprehensive experiments show that MetaIndux-TS outperforms state-of-the-art models (SSSD, Dit, and TabDDPM), achieving a 57.5% improvement in fidelity and 20.4% in predictive score. MetaIndux-TS exhibits zero-shot generation capabilities for samples under unseen conditions, offering the potential to address data collection challenges in extreme environments. Codes are available at: https://github.com/Dolphin-wang/MetaIndux},
  archive      = {J_TNNLS},
  author       = {Haiteng Wang and Lei Ren and Yikang Li and Yuqing Wang},
  doi          = {10.1109/TNNLS.2025.3577203},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {MetaIndux-TS: Frequency-aware AIGC foundation model for industrial time series},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Topology-preserved information bottleneck for multiview anomaly detection. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3579412'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection (AD) techniques are widely used in various fields. Existing techniques primarily focus on learning a normal region from single-view data, which may be not suitable for multiview data that provides more comprehensive information from multiple perspectives. Therefore, AD techniques designed for multiview data are necessary. Straightforwardly, one can concatenate the features learned from multiple single-view data into a joint representation to conduct AD. However, this may overlook the inevitable overlaps between views, potentially masking view-specific information due to the repetitive calculations of these overlaps. Among the various possible methods, one way to address this is to compress redundant information while maintaining comprehensive information across views. Following this way, in this article, we leverage the principle of information bottleneck (IB) to extract concise and comprehensive representations for multiview data. But it is problematic to directly use these representations for AD, since the multiview fusion process may disturb the intrinsic structure of the original data. That is, samples distributed at the edges/center of the original normal data distribution are mapped closer to the center/edges. This might cause abnormal samples (close to the normal data at the edges) to be incorrectly mapped into the normal region during inference. In the AD scenario, the absence of abnormal training samples makes it unfeasible to preserve this structure using supervised information. In this article, we design a topology-preserved regularization that unsupervisedly constrains the latent representations to preserve the original data’s intrinsic structure, to improve the AD performance. Overall, we propose a topology-preserved multiview information bottleneck (TMVIB) feature extraction method to extract concise, comprehensive, and topology-preserved latent representations from multiview data. Interestingly, we find that the TMVIB feature extraction method itself can be viewed as a regularized anomaly detector, allowing it to output anomaly scores directly. Experiments on synthetic and real-world multiview datasets demonstrate the effectiveness of the proposed TMVIB.},
  archive      = {J_TNNLS},
  author       = {Tengfei Yan and Jiankai Tu and Chunguang Li and Fan Zhang},
  doi          = {10.1109/TNNLS.2025.3579412},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Topology-preserved information bottleneck for multiview anomaly detection},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GBPG-net: Global background prior-guided rain and snow image restoration. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3579050'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of image restoration in the presence of rain and snow effects is to eliminate these disturbances while retaining the underlying background structure. Most existing methods tend to directly learn the mapping from corrupted images to clean ones, often resulting in residual rain or snow artifacts and compromised background structures. In this work, both theoretical analysis and experimental findings confirm the robustness of the hue channel in HSV color space to rain and snow disturbances, even when extracted from corrupted images. Motivated by this insight, we propose to leverage the global clean background cues inherent in the hue channel to guide the network in preserving the image background structure and removing interference. To this end, we introduce the global background prior-guided network (GBPG-Net) for restoring rain and snow-affected images, which employs a triangular formation to facilitate continuous interaction and updating of the global background prior (GBP) with the image feature within the GBPG-unit, resulting in improved interference removal and background structure preservation. Specifically, the GBPG-Net incorporates the global clean background prior injector (GCBPI) to inject the GBP into the network. Subsequently, the prior-guided local detail excavation (PGLDE) module, built on GCBPI, further refines interference removal and structure preservation to process local details intricately. Finally, the prior-guided local-global aggregation (PGLGA) module aggregates global background features with local detailed features, enabling the network to better understand the overall content and subtle interference for more accurate reconstruction. Quantitative and qualitative evaluations on synthetic and real datasets demonstrate the effectiveness of the proposed GBPG-Net in deraining and desnowing tasks, highlighting its advantages over existing methods. The code and supplementary documentation are available at https://github.com/liux520/GBPG-Net},
  archive      = {J_TNNLS},
  author       = {Xiao Liu and Xiaofeng Wang and Shouyi Wang and Haosong Gou and Zhengyong Wang and Chao Ren},
  doi          = {10.1109/TNNLS.2025.3579050},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {GBPG-net: Global background prior-guided rain and snow image restoration},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). New WTOD protocol-based fault detection filter design for interval type-2 fuzzy systems via an adaptive differential evolution algorithm. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3579254'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article is concerned with the design problem of an $H_{\infty }$ optimal fault detection (FD) filter for networked interval type-2 (IT2) fuzzy systems that are subjected to stochastic cyberattacks. To effectively reduce the utilization of constrained network resources, a new dynamically adjusted event-triggered weighted try-once-discard (DAET-WTOD) protocol is developed, in which two adaptive rules are constructed based on the measured output and the probability of denial-of-service (DoS) attacks. Furthermore, a fuzzy switched-like FD filter is designed with the purpose of detecting system fault signals, while simultaneously considering the DAET-WTOD protocol and stochastic cyberattacks. Subsequently, by utilizing an imperfect premise matching (IPM) scheme, an opposition-based learning adaptive differential evolution algorithm is proposed to deal with the networked IT2 fuzzy systems. This algorithm is capable of iteratively searching the membership function values of the fuzzy filter in real time, thereby achieving improved $H_{\infty }$ performance. Finally, some simulation results are provided to verify the feasibility and advantages of the proposed $H_{\infty }$ optimal FD technique.},
  archive      = {J_TNNLS},
  author       = {Wei Qian and Yanmin Wu and Zidong Wang},
  doi          = {10.1109/TNNLS.2025.3579254},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {New WTOD protocol-based fault detection filter design for interval type-2 fuzzy systems via an adaptive differential evolution algorithm},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ArmBCIsys: Robot arm BCI system with Time–Frequency network for multiobject grasping. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3579332'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain–computer interface (BCI) offers a direct communication and control channel between the human brain and external devices, presenting new pathways for individuals with physical disabilities to operate robotic arms for complex tasks. However, achieving multiobject grasping tasks under low signal-to-noise ratio (SNR) consumer-grade EEG signals is a significant challenge due to the lack of robust decoding algorithms and precise visual tracking methods. This article proposes, ArmBCIsys, an integrated robotic arm system that combines a novel dual-branch frequency-enhanced network (DBFENet) to robustly decode EEG signals under noisy conditions with the high-precision vision-guided grasping module. The proposed DBFENet designs the scaling temporal convolution block (STCB) to extract multiscale spatiotemporal features from the time domain, while the designed DropScale projected Transformer (DSPT) utilizes discrete cosine transform (DCT) to capture key frequency-domain features, significantly improving decoding robustness. We fine-tune the masked-attention mask Transformer (Mask2Former) model on the Jacquard dataset and incorporate the multiframe centroid-intersection over union (IoU) tracking algorithm to build visual grasp segmenter (VisGraspSeg), enabling reliable segmentation and dynamic tracking for diverse daily objects. Experimental validations on both self-built code-modulated visual evoked potential (c-VEP) dataset (1344 samples) and two public c-VEP datasets demonstrate that DBFENet achieves the state-of-the-art recognition performance, and the system integrates the DBFENet and proposed vision-guided module and ensures stable multiobject selecting and automatic object grasping in dynamic environments, extending promising applications in healthcare robotics, assistive technology, and industrial automation. The self-built dataset has been made publicly accessible at https://github.com/wtu1020/ ArmBCIsys-Self-built-cVEP-Dataset},
  archive      = {J_TNNLS},
  author       = {Feng Yu and Zhongrui Rao and Neng Chen and Li Liu and Minghua Jiang},
  doi          = {10.1109/TNNLS.2025.3579332},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {ArmBCIsys: Robot arm BCI system with Time–Frequency network for multiobject grasping},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed projection neurodynamic approaches in continuous and discrete time for BP with block decomposition of measurement matrix. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3579161'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the situation where the measurement matrix B has a flexible block decomposition, this article designs two novel distributed continuous- and discrete-time projection neurodynamic approaches to solve the basis pursuit (BP) problem for sparse recovery. These approaches only require information from each flexible block of the measurement matrix B, rather than from each row, column, or the entire matrix. First, with the aid of the primal–dual dynamical approach, projection operator, and second-order multiagent consensus condition, a novel distributed projection neurodynamic approach in continuous time (DPNA-CT-B) is proposed, and its optimality and global asymptotic stability are rigorously proved. Moreover, based on the forward and backward Euler methods and variable substitution methods, a corresponding distributed projection neurodynamic approach in discrete time (DPNA-DT-B) is designed. Finally, through sparse signal and image reconstruction experiments, the effectiveness and superiority of the proposed neurodynamic approaches are verified.},
  archive      = {J_TNNLS},
  author       = {You Zhao and Xing He and Mingliang Zhou and Junzhi Yu and Tingwen Huang},
  doi          = {10.1109/TNNLS.2025.3579161},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Distributed projection neurodynamic approaches in continuous and discrete time for BP with block decomposition of measurement matrix},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IncTSVD: Incremental tensor singular value decomposition of multidimensional streaming data. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3578117'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we develop an online method called IncTSVD to incrementally compute the tensor singular value decomposition (TSVD) of a given sequence of third-order tensors based on the tensor-tensor concept. This can be considered an extension of incremental SVD based on updating matrices to tensors. IncTSVD is suitable for streamed tensor data and where memory resources are limited. Most existing methods to compute TSVD focus on approximating it using randomized or sketching techniques in a batch setting to decrease the storage and computational costs required. The IncTSVD extends the computation of TSVD to streaming by maintaining the basis tensors of previously arrived data and incrementally updating the approximation using the tensor of incoming data. The computational cost and approximation error of the proposed method were analyzed theoretically and through extensive numerical experiments, which included using synthetic and real-world datasets under streaming scenarios. The IncTSVD method was superior to existing deterministic and randomized tensor decompositions (TDs) based on the t-product for computational and storage costs, and had comparable accuracy to the standard TSVD method.},
  archive      = {J_TNNLS},
  author       = {Muhammad A. A. Abdelgawad and Ray C. C. Cheung and Hong Yan},
  doi          = {10.1109/TNNLS.2025.3578117},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {IncTSVD: Incremental tensor singular value decomposition of multidimensional streaming data},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generating simple cyclic memristive neural network circuit with controllable multiscroll attractors and multivariable amplitude control. <em>TNNLS</em>, 1-10. (<a href='https://doi.org/10.1109/TNNLS.2025.3581229'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to their synaptic-like characteristics and memory properties, memristors are often used in neuromorphic circuits, particularly neural network circuits. However, most of the existing neural network circuits that can generate complex dynamics have high dimensions and excessive connections, which is not conducive to implementation. This article introduces a memristor containing an arctangent function into a simple cyclic neural network (SCNN) circuit to design a simple cyclic memristive neural network (SCMNN) circuit capable of generating complex multiscroll chaotic attractors. The designed SCMNN contains an external stimulus current and generates multiscroll attractors, with the number of scrolls expanding as the switches in the memristor equivalent circuit are activated. By varying the parameters, the multiscroll attractors can be broken into different numbers of coexisting attractors, which also depends on the switch, and it can achieve multivariable amplitude control when there is only one scroll. The anti-interference ability of the circuit is tested. A low-cost circuit-based microcontroller suitable for engineering applications is designed for it, and multiscroll attractors are successfully captured in an oscilloscope. The National Institute of Standards and Technology (NIST) test is carried out to verify its application value.},
  archive      = {J_TNNLS},
  author       = {Qiang Lai and Yudi Xu and Luigi Fortuna},
  doi          = {10.1109/TNNLS.2025.3581229},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Generating simple cyclic memristive neural network circuit with controllable multiscroll attractors and multivariable amplitude control},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Counterfactual explanation through latent adjustment in disentangled space of diffusion model. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3580118'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rise of explainable artificial intelligence (XAI), counterfactual (CF) explanations have gained significant attention. Effective CFs must be valid (classified as the CF class), practical (minimally deviated from the input), and plausible (close to the CF data manifold). However, practicality and plausibility often conflict, making valid CF generation challenging. To address this, we propose a novel framework that generates CFs by adjusting only semantic information in the disentangled latent space of a diffusion model. This shifts the sample closer to the CF manifold and across the decision boundary. In our framework, the latent vector mapping step occasionally produces invalid CFs or CFs insufficiently close to the decision boundary, resulting in dissimilarity to the input. Our method overcomes this with a two-stage latent vector adjustment: 1) linear interpolation and 2) time-step-wise optimization during reverse diffusion within the space accommodating linear changes in class information from the input. Experiments demonstrate that our approach generates more valid, plausible, and practical CFs by effectively leveraging the properties of the disentangled latent space.},
  archive      = {J_TNNLS},
  author       = {Seung-Hyup Na and Seong-Whan Lee},
  doi          = {10.1109/TNNLS.2025.3580118},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Counterfactual explanation through latent adjustment in disentangled space of diffusion model},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Argus: Leveraging multiview images for improved 3-D scene understanding with large language models. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3581411'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advancements in foundation models have made it possible to conduct applications in various downstream tasks. Especially, the new era has witnessed a remarkable capability to extend large language models (LLMs) for tackling tasks of 3-D scene understanding. Current methods rely heavily on 3-D point clouds, but the 3-D point cloud reconstruction of an indoor scene often results in information loss. Some textureless planes or repetitive patterns are prone to omission and manifest as voids within the reconstructed 3-D point clouds. Besides, objects with complex structures tend to introduce distortion of details caused by misalignments between the captured images and the dense reconstructed point clouds. The 2-D multiview images present visual consistency with 3-D point clouds and provide more detailed representations of scene components, which can naturally compensate for these deficiencies. Based on these insights, we propose Argus, a novel 3-D multimodal framework that leverages multiview images for enhanced 3-D scene understanding with LLMs. In general, Argus can be treated as a 3-D large multimodal foundation model (3D-LMM) since it takes various modalities as input (text instructions, 2-D multiview images, and 3-D point clouds) and expands the capability of LLMs to tackle 3-D tasks. Argus involves fusing and integrating multiview images and camera poses into view-as-scene features, which interact with the 3-D features to create comprehensive and detailed 3-D-aware scene embeddings. Our approach compensates for the information loss while reconstructing 3-D point clouds and helps LLMs better understand the 3-D world. Extensive experiments demonstrate that our method outperforms existing 3D-LMMs in various downstream tasks.},
  archive      = {J_TNNLS},
  author       = {Yifan Xu and Chao Zhang and Hanqi Jiang and Xiaoyan Wang and Ruifei Ma and Yiwei Li and Zihao Wu and Zeju Li and Xiangde Liu},
  doi          = {10.1109/TNNLS.2025.3581411},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Argus: Leveraging multiview images for improved 3-D scene understanding with large language models},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Draw what you hear: High-fidelity image generation and manipulation via SoundAdapter. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3581455'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, the text-to-image (T2I) generation has established itself as a cornerstone within the realm of AI-generated content (AIGC), due its remarkable success to the availability of extensive datasets comprising paired text-vision samples. Nevertheless, the absence of audio-visual pairs hinders the growth of audio-to-image (A2I). Although prior approaches have pioneered the A2I task, the tight entanglement between initial audio and image encoders imposes the challenge of gathering audio-visual samples, resulting in degraded performance and limited sound flexibility. Therefore, this article proposes a novel SoundAdapter to draw what you hear. Specifically, the SoundAdapter’s structure is meticulously designed around transformer blocks, which are critical for capturing overarching patterns and dependencies within the data. In addition, it integrates a sophisticated multigranularity approach coupled with a hybrid supervisory signal, ensuring both fine-grained semantic alignment and seamless optimization across various levels of representation. Extensive tests demonstrate that the SoundAdapter excels in training, setting new benchmarks in zero-shot audio classification, as well as in creating and modifying images across a variety of datasets. The implementation code and several demos supporting this study are openly accessible at https://github.com/CV-MM-Lab/SoundAdapter, facilitating reproducibility and further research.},
  archive      = {J_TNNLS},
  author       = {Mingjie Wang and Song Yuan and Xian-Feng Han and Zili Yi},
  doi          = {10.1109/TNNLS.2025.3581455},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Draw what you hear: High-fidelity image generation and manipulation via SoundAdapter},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lifelong active inference of gait control. <em>TNNLS</em>, 1-12. (<a href='https://doi.org/10.1109/TNNLS.2025.3579814'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sustaining the robot’s longevity becomes challenging in dynamic deployments characterized by new unknown environments and embodiments outside of the prior knowledge. Hence, the knowledge of robot-environment interactions needs to be continually updated for system adaptation. It can be implemented through self-verification as a continual comparison of predictions with observations using the predictive coding (PC) principle. The principle has been further extended into the active inference control (AIC) in biomimetic robotics to drive the control, state estimation, and model update. However, continually updating one model leads to catastrophic forgetting in the long term. Therefore, we propose an autonomously expanding self-verifying world model (WM) of sensorimotor dynamics utilized in model-based gait control. The model combines PC with the incremental knowledge representation based on the internal model (IM) principle. The proposed method is experimentally validated in virtual and real scenarios, where the hexapod walking robot has to recognize and adapt to leg paralysis and then recognize the recovery. The method generates novel behaviors in real time, improving the performance and outperforming the examined state-of-the-art methods. Furthermore, the robot’s decisions and gained knowledge are interpretable and promise further functional scalability.},
  archive      = {J_TNNLS},
  author       = {Rudolf Szadkowski and Jan Faigl},
  doi          = {10.1109/TNNLS.2025.3579814},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Lifelong active inference of gait control},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neighboring state-aware policy for deep reinforcement learning. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3581217'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep reinforcement learning (DRL) methods, which train a policy to obtain the sequence of actions required to complete a task, have achieved remarkable success across diverse applications. It is a long-standing open issue in the DRL community to make the trained policy gradually approach the theoretically globally optimal policy, and existing research has also explored several challenges, such as exploration-exploitation, to improve the quality of the obtained policy. However, most DRL methods rely solely on the current state for decision-making, leading to short-sightedness and suboptimal learning. To overcome this, we propose a neighboring state-aware policy that enhances existing DRL methods by incorporating a neighboring state sequence in the decision-making process. Specifically, our approach saves multiple past and future states and concatenates them as the neighboring state sequence, along with the current state, and inputs them to the actor to generate an action during the training process. This global perspective, provided by neighboring states, is similar to human decision-making and helps the agent better understand state evolution, leading to improved policy learning. We present two specific implementations of our approach and demonstrate through extensive experiments that it effectively enhances ten representative DRL methods across nine tasks, based on three metrics, including return.},
  archive      = {J_TNNLS},
  author       = {Meng Xu and Xinhong Chen and Guanyi Zhao and Zihao Wen and Weiwei Fu and Jianping Wang},
  doi          = {10.1109/TNNLS.2025.3581217},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Neighboring state-aware policy for deep reinforcement learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatial–Spectral heterogeneity-aware network for hyperspectral and LiDAR joint classification. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3577231'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of hyperspectral (HS) imagery and light detection and ranging (LiDAR) data for land cover classification has emerged as a prominent research focus. Despite the satisfactory classification accuracies achieved by existing methodologies, several unaddressed issues that remain warrant consideration. First, current approaches overlook the pronounced spectral and spatial heterogeneities in remote sensing (RS) images designated for multiclassification tasks, limiting the performance of classification models. Moreover, most existing studies amalgamate elevation features with other characteristics through simple addition and interaction operations, and they do not delve deeply into exploiting elevation height information, leading to an imbalance in the representation of elevation height. In light of the aforementioned issues, this article introduces a spatial–spectral heterogeneity-aware network (S2HANet) for the joint classification of HS and LiDAR data. Specifically, a shared spectral correction module (SSCM) is designed in the spectral branch to preliminarily alleviate the problem of large intraclass variance, followed by the use of a contrastive learning framework to enhance the intraclass compactness and interclass separability of spectral features. A multichannel signed distance discrimination module (MCSDDM) is developed to learn the distance relationships between intra- and interclass pixels and boundaries, and using prior boundary information to improve spatial boundary information. In addition, an elevation boost module (EBM) and an elevation injection module (EIM) are meticulously designed to phase-in elevation height information, further enhancing the utilization of elevation data and better facilitating the fusion of the two modalities. The proposed S2HANet has demonstrated exceptional classification performance across three opening benchmark datasets.},
  archive      = {J_TNNLS},
  author       = {Shenfu Zhang and Qiang Liu and Zhenhua Zhang and Rui Zhao and Liang Chen and Feng Shao and Xiangchao Meng},
  doi          = {10.1109/TNNLS.2025.3577231},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Spatial–Spectral heterogeneity-aware network for hyperspectral and LiDAR joint classification},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inducing neural collapse via anticlasses and one-cold cross-entropy loss. <em>TNNLS</em>, 1-12. (<a href='https://doi.org/10.1109/TNNLS.2025.3580892'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While softmax cross-entropy (CE) loss is the standard objective for supervised classification, it primarily focuses on the ground-truth classes, ignoring the relationships between the nontarget, complementary classes. This leaves valuable information unexploited during optimization. In this work, we propose a novel loss function, one-cold CE (OCCE) loss, which addresses this limitation by structuring the activations of these complementary classes. Specifically, for each class, we define an anticlass, which consists of everything that is not part of the target class—this includes all complementary classes as well as out-of-distribution (OOD) samples, noise, or in general any instance that does not belong to the true class. By setting a uniform one-cold encoded distribution over the complementary classes as a target for each anticlass, we encourage the model to equally distribute activations across all nontarget classes. This approach promotes a symmetric geometric structure of classes in the final feature space, increases the degree of neural collapse (NC) during training, addresses the independence deficit problem of neural networks, and improves generalization. Our extensive evaluation shows that incorporating OCCE loss in the optimization objective consistently enhances performance across multiple settings, including classification, open-set recognition, and OOD detection.},
  archive      = {J_TNNLS},
  author       = {Dimitrios Katsikas and Nikolaos Passalis and Anastasios Tefas},
  doi          = {10.1109/TNNLS.2025.3580892},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Inducing neural collapse via anticlasses and one-cold cross-entropy loss},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated scientific machine learning for approximating functions and solving differential equations with data heterogeneity. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3580409'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By leveraging neural networks, the emerging field of scientific machine learning (SciML) offers novel approaches to address complex problems governed by partial differential equations (PDEs). In practical applications, challenges arise due to the distributed essence of data, concerns about data privacy, or the impracticality of transferring large volumes of data. Federated learning (FL), a decentralized framework that enables the collaborative training of a global model while preserving data privacy, offers a solution to the challenges posed by isolated data pools and sensitive data issues. Here, this article explores the integration of FL and SciML to approximate complex functions and solve differential equations. We propose two novel models: federated physics-informed neural networks (FedPINNs) and federated deep operator networks (FedDeepONets). We further introduce various data generation methods to control the degree of nonindependent and identically distributed (non-i.i.d.) data and utilize the 1-Wasserstein distance to quantify data heterogeneity in function approximation and PDE learning. We systematically investigate the relationship between data heterogeneity and federated model performance. In addition, we propose a measure of weight divergence and develop a theoretical framework to establish growth bounds for weight divergence in FL compared with centralized learning. To demonstrate the effectiveness of our methods, we conducted ten experiments, including two on function approximation, five PDE problems on FedPINN, and four PDE problems on FedDeepONet. These experiments demonstrate that proposed federated methods surpass the models trained only using local data and achieve competitive accuracy of centralized models trained using all data.},
  archive      = {J_TNNLS},
  author       = {Handi Zhang and Langchen Liu and Kangyu Weng and Lu Lu},
  doi          = {10.1109/TNNLS.2025.3580409},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Federated scientific machine learning for approximating functions and solving differential equations with data heterogeneity},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MonOri: Orientation-guided PnP for monocular 3-D object detection. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3577618'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monocular 3-D object detection is a challenging task in the field of autonomous driving and has made great progress. However, current monocular image methods tend to incorporate additional information such as pseudolabels to improve algorithm performance while overlooking the geometric relationship between the object’s keypoints, resulting in low performance for occluded object detection. To address this issue, we find that introducing the orientation information of objects in the 3-D detection pipeline can help improve the detection performance of occluded objects. An orientation-guided perspective-n-point (PnP) for monocular 3-D object detection method named MonOri is presented in this article, which uses object’s orientation to guide keypoints’ optimization. Considering the existence of different deformation objects in the scene, we design the feature aggregation detection module (FADM), which consists of the feature focus fusion module (FFFM) and CondConv detection module (CCDM). First, FFFM can highlight signals from irregularly occluded objects, effectively modeling features of elongated and small-sized objects. This module enhances the model’s ability to recognize elongated and small-sized objects in complex scenes. Then, the CCDM is designed to improve the network’s ability to estimate object keypoints’ location regression under occlusion conditions and minimize the network computational overhead. Finally, considering that the unoccluded portions of occluded objects are closely related to the orientation of the objects, an orientation-guided keypoints’ selection module (OGKSM) is proposed to enhance the accuracy of objected optimization for keypoint positions and spatial location inference of the object. Experimental results indicate that the MonOri method achieves competitive results; it is also demonstrated that the orientation information is introduced in the PnP algorithm to estimate the object’s spatial position that can mitigate the impact of occlusion on object detection, thus improving the recognition rate of occluded objects. Our code is available at https://github.com/DL-YHD/MonOri},
  archive      = {J_TNNLS},
  author       = {Hongdou Yao and Pengfei Han and Jun Chen and Zheng Wang and Yansheng Qiu and Xiao Wang and Yimin wang and Xiaoyu Chai and Chenglong Cao and Wei Jin},
  doi          = {10.1109/TNNLS.2025.3577618},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {MonOri: Orientation-guided PnP for monocular 3-D object detection},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical sparse representation clustering for high-dimensional data streams. <em>TNNLS</em>, 1-13. (<a href='https://doi.org/10.1109/TNNLS.2025.3582380'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data stream clustering reveals patterns within continuously arriving, potentially unbounded data sequences. Numerous data stream algorithms have been proposed to cluster data streams. The existing data stream clustering algorithms still face significant challenges when addressing high-dimensional data streams. First, it is intractable to measure the similarities among high-dimensional data objects via Euclidean distances when constructing and merging microclusters. Second, these algorithms are highly sensitive to the noise contained in high-dimensional data streams. In this article, we propose a hierarchical sparse representation clustering (HSRC) framework for clustering high-dimensional data streams. HSRC first employs a sparse representation-based technique to learn an affinity matrix for data objects in individual landmark windows with a fixed size, where the number of neighboring data objects is automatically selected. The sparse representation-based technique ensures that highly correlated data samples within clusters are grouped together. Then, HSRC applies a spectral clustering technique to the affinity matrix to generate microclusters. These microclusters are subsequently merged into macroclusters based on their sparse similarity degrees (SSDs). In addition, HSRC introduces sparsity residual values (SRVs) to adaptively select representative data objects from the current landmark window. These representatives serve as dictionary samples for the next landmark window. Finally, HSRC refines each macrocluster through fine-tuning. In particular, HSRC enables the detection of outliers in high-dimensional data streams via the associated SRVs. The experimental results obtained on several benchmark datasets demonstrate the effectiveness and robustness of the proposed HSRC framework.},
  archive      = {J_TNNLS},
  author       = {Jie Chen and Hua Mao and Yuanbiao Gou and Xi Peng},
  doi          = {10.1109/TNNLS.2025.3582380},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Hierarchical sparse representation clustering for high-dimensional data streams},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncertainty-aware graph neural networks: A multihop evidence fusion approach. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3581083'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) excel in graph representation learning by integrating graph structure and node features. Existing GNNs, unfortunately, fail to account for the uncertainty of class probabilities that vary with the depth of the model, leading to unreliable and risky predictions in real-world scenarios. To bridge the gap, in this article, we propose a novel evidence-fusing graph neural network (EFGNN) to achieve trustworthy prediction, enhance node classification accuracy, and make explicit the risk of wrong predictions. In particular, we integrate the evidence theory with multihop propagation-based GNN architecture to quantify the prediction uncertainty of each node with the consideration of multiple receptive fields. Moreover, a parameter-free cumulative belief fusion (CBF) mechanism is developed to leverage the changes in prediction uncertainty and fuse the evidence to improve the trustworthiness of the final prediction. To effectively optimize the EFGNN model, we carefully design a joint learning objective composed of evidence cross-entropy, dissonance coefficient, and false confident penalty. The experimental results on various datasets and theoretical analyses demonstrate the effectiveness of the proposed model in terms of accuracy and trustworthiness, as well as its robustness to potential attacks.},
  archive      = {J_TNNLS},
  author       = {Qingfeng Chen and Shiyuan Li and Yixin Liu and Shirui Pan and Geoffrey I. Webb and Shichao Zhang},
  doi          = {10.1109/TNNLS.2025.3581083},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {6},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Uncertainty-aware graph neural networks: A multihop evidence fusion approach},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GMM enhanced anchor-based spectral clustering for large-scale data. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3571473'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anchor-based methods are proposed to make use of anchors to produce an affinity matrix of objects to improve the scalability of traditional spectral clustering (SC). Nevertheless, the membership heterogeneity of objects inside a cluster, which would bring about low quality of anchors and hurt the clustering accuracy, is commonly neglected by existing anchor-based algorithms. To address this problem, this article proposes a novel approach to adopt the Gaussian mixture model (GMM) to enhance anchor-based SC for large-scale data in a two-stage divide-and-conquer manner. In the first stage, GMM with expectation maximization (EM) algorithm is employed to divide the objects into two categories as prior-consistent objects and prior-uncertain objects in considering the membership heterogeneity of objects. In the second stage, anchor-based SC is conducted on the prior-uncertain objects by sampling the anchors from the Gaussian components derived from the first stage. Then, the produced clusters in the second stage are aligned with those Gaussian components by maximizing the membership of objects with respect to clusters. The computation complexity of the proposed GMM-SC approach is much smaller than that of the anchor-based SC. The experiments on large-scale datasets also validate the superiority of the proposed GMM-SC approach over state-of-the-art techniques.},
  archive      = {J_TNNLS},
  author       = {Wen Zhang and Jiangpeng Zhao and Lean Yu and Song Wang},
  doi          = {10.1109/TNNLS.2025.3571473},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {5},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {GMM enhanced anchor-based spectral clustering for large-scale data},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RadCLIP: Enhancing radiologic image analysis through contrastive Language–Image pretraining. <em>TNNLS</em>, 1-10. (<a href='https://doi.org/10.1109/TNNLS.2025.3568036'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of artificial intelligence (AI) with radiology signifies a transformative era in medicine. Vision foundation models have been adopted to enhance radiologic imaging analysis. However, the inherent complexities of 2D and 3D radiologic data present unique challenges that existing models, which are typically pretrained on general nonmedical images, do not adequately address. To bridge this gap and harness the diagnostic precision required in radiologic imaging, we introduce radiologic contrastive language–image pretraining (RadCLIP): a cross-modal vision-language foundational model that utilizes a vision-language pretraining (VLP) framework to improve radiologic image analysis. Building on the contrastive language–image pretraining (CLIP) approach, RadCLIP incorporates a slice pooling mechanism designed for volumetric image analysis and is pretrained using a large, diverse dataset of radiologic image-text pairs. This pretraining effectively aligns radiologic images with their corresponding text annotations, resulting in a robust vision backbone for radiologic imaging. Extensive experiments demonstrate RadCLIP’s superior performance in both unimodal radiologic image classification and cross-modal image-text matching, underscoring its significant promise for enhancing diagnostic accuracy and efficiency in clinical settings. Our key contributions include curating a large dataset featuring diverse radiologic 2D/3D image-text pairs, pretraining RadCLIP as a vision-language foundation model on this dataset, developing a slice pooling adapter with an attention mechanism for integrating 2D images, and conducting comprehensive evaluations of RadCLIP on various radiologic downstream tasks.},
  archive      = {J_TNNLS},
  author       = {Zhixiu Lu and Hailong Li and Nehal A. Parikh and Jonathan R. Dillman and Lili He},
  doi          = {10.1109/TNNLS.2025.3568036},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {5},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {RadCLIP: Enhancing radiologic image analysis through contrastive Language–Image pretraining},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evidential deep learning for open-set active domain adaptation. <em>TNNLS</em>, 1-11. (<a href='https://doi.org/10.1109/TNNLS.2025.3571943'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Open-set domain adaptation (OSDA) seeks to transfer knowledge from a labeled source domain to an unlabeled target domain containing novel classes. Traditional OSDA methods rarely account for the uncertainty in predictions and typically require additional training overhead. Evidential deep learning (EDL) transforms the model’s predictions from point estimates to distributions over the probability simplex by replacing the standard softmax output of classification neural networks with Dirichlet distributions. Considering the presence of out-of-distribution novel classes in OSDA and the additional overhead of existing methods, we propose EDL for open-set active domain adaptation (EOSADA). Leveraging EDL, we construct an open-set classifier and employ a two-round selection strategy guided by the data uncertainty of target domain samples and semantic similarity scores with known classes. This strategy balances the selection of samples from known and novel classes while identifying informative samples, thereby maximizing the performance of the model in OSDA scenarios without modifying the model structure and utilizing a limited annotation budget. Extensive experiments demonstrate the superiority of our approach.},
  archive      = {J_TNNLS},
  author       = {Qing Tian and Jiangsen Yu and Yi Zhao and Wen Li and Zhen Lei},
  doi          = {10.1109/TNNLS.2025.3571943},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {5},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Evidential deep learning for open-set active domain adaptation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multilabel transfer learning method with dynamic multimetric for coupling fault diagnosis. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3573090'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In industrial practice, as systems become increasingly complex and integrated, the simultaneous failure of multicomponents, namely, coupling faults, has become more prevalent, which can be viewed as multilabel data. In addition, due to the changing industrial tasks, coupling fault diagnosis problems under varying operating conditions can be treated as cross-domain multilabel learning problems, which can be solved by multilabel transfer learning methods. However, existing multilabel transfer learning methods are all preliminary explorations lacking an in-depth exploring the multilevel similarity and complex features of coupling faults. To address this challenging problem, we propose a novel multilabel transfer learning method for coupling fault diagnosis, which achieves dual domain alignment at two levels. At the global feature level, the hypothesis space is reduced by minimizing the maximum mean discrepancy (MMD) at multistages of the network to align the global distribution. Furthermore, we decomposed the overall similarity into a combination of multiple local similarities and innovatively designed a dynamic multimetric structure to capture the diverse similarity characteristics of the data. By integrating the multimetric structure and dynamic mapping selection technique to form mathematical representations of this diverse similarity, this approach constrains the consistency of the local spatial structure of the two domains to achieve local space structure alignment. This method performs high superiority in multiple transfer tasks on the public and laboratory datasets, strongly demonstrating its effectiveness.},
  archive      = {J_TNNLS},
  author       = {Yaqi Xiao and Haiyin Zhou and Xuanying Zhou and Jiongqi Wang},
  doi          = {10.1109/TNNLS.2025.3573090},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {5},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Multilabel transfer learning method with dynamic multimetric for coupling fault diagnosis},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hypergraph foundation model for brain disease diagnosis. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3554755'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of the hypergraph foundation model (HGFM) is to learn an encoder based on the hypergraph computational paradigm through self-supervised pretraining on high-order correlation structures, enabling the encoder to rapidly adapt to various downstream tasks in scenarios, where no labeled data or only a small amount of labeled data are available. The initial exploratory work has been applied to brain disease diagnosis tasks. However, existing methods primarily rely on graph-based approaches to learn low-order correlation patterns between brain regions in brain networks, neglecting the modeling and learning of complex correlations between different brain diseases and patients. This article proposes an HGFM for brain disease diagnosis, which conducts multidimensional pretraining tasks to explore latent cross-dimensional high-order correlation patterns on various brain disease datasets. HGFM is a high-order correlation-driven foundation model for brain disease diagnosis and effectively improves prediction performance. Specifically, HGFM first performs brain functional network link prediction tasks on individual brain networks and group interaction network link prediction tasks on group brain networks, constructing an HGFM for brain disease diagnosis. In downstream tasks, it achieves predictions for different brain disease diagnosis tasks through few-shot learning fine-tuning methods. The proposed method is evaluated on functional magnetic resonance imaging (fMRI) data from 4409 patients across four brain diseases. Results show that it outperforms existing state-of-the-art methods in all brain disease diagnosis tasks, demonstrating its potential value in clinical applications.},
  archive      = {J_TNNLS},
  author       = {Xiangmin Han and Rundong Xue and Jingxi Feng and Yifan Feng and Shaoyi Du and Jun Shi and Yue Gao},
  doi          = {10.1109/TNNLS.2025.3554755},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {4},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Hypergraph foundation model for brain disease diagnosis},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond the hype: A dispassionate look at Vision–Language models in medical scenario. <em>TNNLS</em>, 1-12. (<a href='https://doi.org/10.1109/TNNLS.2025.3558857'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in large vision-language models (LVLMs) have demonstrated remarkable capabilities across diverse tasks, garnering significant attention in AI communities. However, their performance and reliability in specialized domains such as medicine remain insufficiently assessed. In particular, most assessments overconcentrate on evaluating VLMs based on simple visual question answering (VQA) on multimodality data while ignoring the in-depth characteristics of LVLMs. In this study, we introduce RadVUQA, a novel radiological visual understanding and question answering benchmark, to comprehensively evaluate existing LVLMs. RadVUQA mainly validates LVLMs across five dimensions: 1) anatomical understanding, assessing the models’ ability to visually identify biological structures; 2) multimodal comprehension, which involves the capability of interpreting linguistic and visual instructions to produce desired outcomes; 3) quantitative and spatial reasoning, evaluating the models’ spatial awareness and proficiency in combining quantitative analysis with visual and linguistic information; 4) physiological knowledge, measuring the models’ capability to comprehend functions and mechanisms of organs and systems; and 5) robustness, which assesses the models’ capabilities against unharmonized and synthetic data. The results indicate that both generalized LVLMs and medical-specific LVLMs have critical deficiencies with weak multimodal comprehension and quantitative reasoning capabilities. Our findings reveal the large gap between existing LVLMs and clinicians, highlighting the urgent need for more robust and intelligent LVLMs. The code is available at https://github.com/Nandayang/RadVUQA},
  archive      = {J_TNNLS},
  author       = {Yang Nan and Huichi Zhou and Xiaodan Xing and Guang Yang},
  doi          = {10.1109/TNNLS.2025.3558857},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {4},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Beyond the hype: A dispassionate look at Vision–Language models in medical scenario},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MSAFF: Multi-way soft attention fusion framework with the large foundation models for the diagnosis of alzheimer’s disease. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2025.3545101'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complementary information in multi-omics data are crucial for understanding the pathogenesis of Alzheimer’s Disease (AD). However, existing studies face challenges in addressing the high-level noise and heterogeneity in multi-omics data. This article presents a novel approach that combines large foundation models (LFMs) with soft attention mechanisms to enhance, select, and fuse multi-omics features, thereby improving the performance of disease classification. Specifically, we first propose a mathematical model based on soft attention mechanisms. This model employs multi-head attention (MHA) and self-attention (SA) for feature selection, and uses cross-attention (CA) for feature fusion. Then, a multi-way soft attention fusion framework (MSAFF) with LFMs is proposed. In this approach, biomedical LFMs are used to construct low-noise biomedical features. The multi-way soft attention algorithm implements effective feature selection and fusion described in the mathematical model. Experimental results on the public imaging genetics datasets demonstrate the advanced performances of MSAFF in both disease classification and AD-related pathogeny discrimination. This article provides intelligent support for the diagnosis and pathogenesis research of AD. Our code can be accessed at github.com/fmri123456/MSAFF.},
  archive      = {J_TNNLS},
  author       = {Xia-An Bi and Wenzhuo Shen and Yinglu Shan and Dayou Chen and Luyun Xu and Ke Chen and Zhonghua Liu},
  doi          = {10.1109/TNNLS.2025.3545101},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {3},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {MSAFF: Multi-way soft attention fusion framework with the large foundation models for the diagnosis of alzheimer’s disease},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CPST-GAN: Conditional probabilistic state transition generative adversarial network with the biomedical large foundation models. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2025.3539006'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The risk prediction of Alzheimer’s disease (AD) is crucial for its early prevention and treatment. However, current risk prediction methods face challenges in effectively extracting and fusing multiomics features, particularly overlooking the multilevel evolutionary mechanisms of AD. This article combines biomedical large foundation models with the conditional generative adversarial network (GAN) to mine the evolutionary patterns of AD by considering the regulatory effect of genes on brain lesions. Specifically, we first use biomedical large foundation models to effectively construct high-quality imaging genetic features. Next, a conditional probabilistic state transition mathematical model is constructed to describe AD progression as state transitions of brain regions under genetic regulations. Based on the mathematical model, a conditional probabilistic state transition GAN (CPST-GAN) is proposed. This algorithm can mine the dynamic evolutionary patterns of AD by fusing brain imaging and genetic features to achieve risk prediction of AD. Finally, experiments on the public imaging genetics datasets validate the effectiveness and superiority of CPST-GAN in evolutionary pattern mining and risk prediction of AD. This article not only provides a reliable intelligence algorithm for early intervention of AD but also offers new insights for future research on AD pathogenesis. The code has been published at github.com/fmri123456/CPST-GAN.},
  archive      = {J_TNNLS},
  author       = {Qiong Wang and Luyun Xu and Yinglu Shan and Wenzhuo Shen and Lou Li and Xia-An Bi and Zhonghua Liu},
  doi          = {10.1109/TNNLS.2025.3539006},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {CPST-GAN: Conditional probabilistic state transition generative adversarial network with the biomedical large foundation models},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Knowledge-guided semantic transfer network for few-shot image recognition. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2023.3240195'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning-based models have been shown to outperform human beings in many computer vision tasks with massive available labeled training data in learning. However, humans have an amazing ability to easily recognize images of novel categories by browsing only a few examples of these categories. In this case, few-shot learning comes into being to make machines learn from extremely limited labeled examples. One possible reason why human beings can well learn novel concepts quickly and efficiently is that they have sufficient visual and semantic prior knowledge. Toward this end, this work proposes a novel knowledge-guided semantic transfer network (KSTNet) for few-shot image recognition from a supplementary perspective by introducing auxiliary prior knowledge. The proposed network jointly incorporates vision inferring, knowledge transferring, and classifier learning into one unified framework for optimal compatibility. A category-guided visual learning module is developed in which a visual classifier is learned based on the feature extractor along with the cosine similarity and contrastive loss optimization. To fully explore prior knowledge of category correlations, a knowledge transfer network is then developed to propagate knowledge information among all categories to learn the semantic-visual mapping, thus inferring a knowledge-based classifier for novel categories from base categories. Finally, we design an adaptive fusion scheme to infer the desired classifiers by effectively integrating the above knowledge and visual information. Extensive experiments are conducted on two widely used Mini-ImageNet and Tiered-ImageNet benchmarks to validate the effectiveness of KSTNet. Compared with the state of the art, the results show that the proposed method achieves favorable performance with minimal bells and whistles, especially in the case of one-shot learning.},
  archive      = {J_TNNLS},
  author       = {Zechao Li and Hao Tang and Zhimao Peng and Guo-Jun Qi and Jinhui Tang},
  doi          = {10.1109/TNNLS.2023.3240195},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Knowledge-guided semantic transfer network for few-shot image recognition},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multiagent reinforcement learning with graphical mutual information maximization. <em>TNNLS</em>, 1-10. (<a href='https://doi.org/10.1109/TNNLS.2023.3243557'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Communication learning is an important research direction in the multiagent reinforcement learning (MARL) domain. Graph neural networks (GNNs) can aggregate the information of neighbor nodes for representation learning. In recent years, several MARL methods leverage GNN to model information interactions between agents to coordinate actions and complete cooperative tasks. However, simply aggregating the information of neighboring agents through GNNs may not extract enough useful information, and the topological relationship information is ignored. To tackle this difficulty, we investigate how to efficiently extract and utilize the rich information of neighbor agents as much as possible in the graph structure, so as to obtain high-quality expressive feature representation to complete the cooperation task. To this end, we present a novel GNN-based MARL method with graphical mutual information (MI) maximization to maximize the correlation between input feature information of neighbor agents and output high-level hidden feature representations. The proposed method extends the traditional idea of MI optimization from graph domain to multiagent system, in which the MI is measured from two aspects: agent features information and agent topological relationships. The proposed method is agnostic to specific MARL methods and can be flexibly integrated with various value function decomposition methods. Considerable experiments on various benchmarks demonstrate that the performance of our proposed method is superior to the existing MARL methods.},
  archive      = {J_TNNLS},
  author       = {Shifei Ding and Wei Du and Ling Ding and Jian Zhang and Lili Guo and Bo An},
  doi          = {10.1109/TNNLS.2023.3243557},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Multiagent reinforcement learning with graphical mutual information maximization},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust and rotation-equivariant contrastive learning. <em>TNNLS</em>, 1-14. (<a href='https://doi.org/10.1109/TNNLS.2023.3243258'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contrastive learning (CL) methods achieve great success by learning the invariant representation from various transformations. However, rotation transformations are considered harmful to CL and are rarely used, which results in failure when the objects show unseen orientations. This article proposes a representation focus shift network (RefosNet), which adds the rotation transformations to CL methods to improve the robustness of representation. First, the RefosNet constructs the rotation-equivariant mapping between the features of the original image and the rotated ones. Then, the RefosNet learns semantic-invariant representations (SIRs) based on explicitly decoupling the rotation-invariant features and the rotation-equivariant features. Moreover, an adaptive gradient passivation strategy is introduced to gradually shift the representation focus to invariant representations. This strategy can prevent catastrophic forgetting of the rotation equivariance, which is beneficial to the generalization of representations in both seen and unseen orientations. We adapt the baseline methods (i.e.“, SimCLR” and “momentum contrast (MoCo) v2”) to work with RefosNet to verify the performance. Extensive experimental results show that our method achieves significant improvements on the task of recognition. On ObjectNet-13 with unseen orientations, RefosNet gains 7.12% in terms of classification accuracy compared with SimCLR. On datasets in seen orientation, the performance improves by 5.5% on ImageNet-100, 7.29% on STL10, and 1.93% on CIFAR10. In addition, RefosNet has strong generalization on Place205, PASCAL VOC, and Caltech 101. Our method has also achieved satisfactory results in image retrieval tasks.},
  archive      = {J_TNNLS},
  author       = {Gairui Bai and Wei Xi and Xiaopeng Hong and Xinhui Liu and Yang Yue and Songwen Zhao},
  doi          = {10.1109/TNNLS.2023.3243258},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Robust and rotation-equivariant contrastive learning},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hierarchical dynamic graph convolutional network with interpretability for EEG-based emotion recognition. <em>TNNLS</em>, 1-12. (<a href='https://doi.org/10.1109/TNNLS.2022.3225855'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph convolutional networks (GCNs) have shown great prowess in learning topological relationships among electroencephalogram (EEG) channels for EEG-based emotion recognition. However, most existing GCN-only methods are designed with a single spatial pattern, lacking connectivity enhancement within local functional regions and ignoring the data dependencies of EEG original data. In this article, hierarchical dynamic GCN (HD-GCN) is proposed to explore dynamic multilevel spatial information among EEG channels, with discriminative features of EEG signals as auxiliary information. Specifically, representation learning in topological space consists of two branches: one for extracting global dynamic information and one for exploring augmentation information in local functional regions. In each branch, a layerwise adjacency matrix is utilized to enrich the expressive power of GCN. Furthermore, a data-dependent auxiliary information module (AIM) is developed to capture multidimensional fusion features. Extensive experiments on two public datasets, SJTU emotion EEG dataset (SEED) and DREAMER, demonstrate that the proposed method consistently exceeds state-of-the-art methods. Interpretability analysis of the proposed model is performed, discovering the active brain regions and important electrode pairs related to emotion.},
  archive      = {J_TNNLS},
  author       = {Mengqing Ye and C. L. Philip Chen and Tong Zhang},
  doi          = {10.1109/TNNLS.2022.3225855},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {12},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Hierarchical dynamic graph convolutional network with interpretability for EEG-based emotion recognition},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep adversarial inconsistent cognitive sampling for multiview progressive subspace clustering. <em>TNNLS</em>, 1-11. (<a href='https://doi.org/10.1109/TNNLS.2021.3093419'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep multiview clustering methods have achieved remarkable performance. However, all of them failed to consider the difficulty labels (uncertainty of ground truth for training samples) over multiview samples, which may result in a nonideal clustering network for getting stuck into poor local optima during the training process; worse still, the difficulty labels from the multiview samples are always inconsistent, and such a fact makes it even more challenging to handle. In this article, we propose a novel deep adversarial inconsistent cognitive sampling (DAICS) method for multiview progressive subspace clustering. A multiview binary classification (easy or difficult) loss and a feature similarity loss are proposed to jointly learn a binary classifier and a deep consistent feature embedding network, throughout an adversarial minimax game over difficulty labels of multiview consistent samples. We develop a multiview cognitive sampling strategy to select the input samples from easy to difficult for multiview clustering network training. However, the distributions of easy and difficult samples are mixed together, hence not trivial to achieve the goal. To resolve it, we define a sampling probability with a theoretical guarantee. Based on that, a golden section mechanism is further designed to generate a sample set boundary to progressively select the samples with varied difficulty labels via a gate unit, which is utilized to jointly learn a multiview common progressive subspace and clustering network for more efficient clustering. Experimental results on four real-world datasets demonstrate the superiority of DAICS over state-of-the-art methods.},
  archive      = {J_TNNLS},
  author       = {Renhao Sun and Yang Wang and Zhao Zhang and Richang Hong and Meng Wang},
  doi          = {10.1109/TNNLS.2021.3093419},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {7},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Deep adversarial inconsistent cognitive sampling for multiview progressive subspace clustering},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bioinspired gain-modulated recurrent neural network for controlling musculoskeletal robot. <em>TNNLS</em>, 1-15. (<a href='https://doi.org/10.1109/TNNLS.2021.3071196'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The motor cortex can arouse abundant transient responses to generate complex movements with the regulation of neuromodulators, while its architecture remains unchanged. This characteristic endows humans with flexible and robust abilities in adapting to dynamic environments, which is exactly the bottleneck in the control of complex robots. In this article, inspired by the mechanisms of the motor cortex in encoding information and modulating motor commands, a biologically plausible gain-modulated recurrent neural network is proposed to control a highly redundant, coupled, and nonlinear musculoskeletal robot. As the characteristics observed in the motor cortex, this network is able to learn gain patterns for arousing transient responses to complete the desired movements, while the connections of synapses keep unchanged, and the dynamic stability of the network is maintained. A novel learning rule that mimics the mechanism of neuromodulators in regulating the learning process of the brain is put forward to learn gain patterns effectively. Meanwhile, inspired by error-based movement correction mechanism in the cerebellum, gain patterns learned from demonstration samples are leveraged as prior knowledge to improve calculation efficiency of the network in controlling novel movements. Experiments were conducted on an upper extremity musculoskeletal model with 11 muscles and a general articulated robot to perform goal-directed tasks. The results indicate that the gain-modulated neural network can effectively control a complex robot to complete various movements with high accuracy, and the proposed algorithms make it possible to realize fast generalization and incremental learning ability.},
  archive      = {J_TNNLS},
  author       = {Shanlin Zhong and Junjie Zhou and Hong Qiao},
  doi          = {10.1109/TNNLS.2021.3071196},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {4},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Bioinspired gain-modulated recurrent neural network for controlling musculoskeletal robot},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
