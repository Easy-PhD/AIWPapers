<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TAI</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tai">TAI - 237</h2>
<ul>
<li><details>
<summary>
(2025). Ent-BAM: A generative framework for biomedical argument mining enriched with entity information. <em>TAI</em>, 1-10. (<a href='https://doi.org/10.1109/TAI.2025.3616076'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biomedical Argument Mining (BAM) aims to identify and extract argumentative structures, specifically, Argumentative Components (ACs) and Argumentative Relations (ARs), within biomedical texts. Primary challenges in BAM arise from the rich presence of specialized terms and a diverse range of entities. These entities often occur within ACs and co-occur in ARs, providing valuable cues for identifying ACs and ARs. Most of the existing approaches do not leverage these cues. This paper presents Ent-BAM, a BAM framework that incorporates entity (co-)occurrence information in a text-to-text generation paradigm. Plain text serves as the input, and the output is formatted in Augmented Natural Language (ANL). First, we employ a prompt-based strategy using a large language model (LLM) to extract (co-)occurred entities from the standard BAM dataset. Then, we construct the ANL output by embedding AC and AR labels, along with those extracted entities, within a single sequence. Ent-BAM significantly outperforms existing state-of-the-art (SoTA) methods by an average task margin of up to 4.86% Micro F1 Score, highlighting the strong potential of our approach.},
  archive      = {J_TAI},
  author       = {Nilmadhab Das and Yash Sunil Choudhary and V. Vijaya Saradhi and Ashish Anand},
  doi          = {10.1109/TAI.2025.3616076},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {10},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Ent-BAM: A generative framework for biomedical argument mining enriched with entity information},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Securing IoT: Unveiling attacks with multiview-multitask learning. <em>TAI</em>, 1-13. (<a href='https://doi.org/10.1109/TAI.2025.3615565'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid expansion and use of day-to-day IoT applications, cybercriminals are exploiting an increasingly wide attack surface and are capable of executing many successful attacks, leading to significant losses for individuals and organizations. The existing defense mechanisms often rely on single-view, single-task models that utilize a single feature set to perform one specific task. However, modern IoT systems are multifaceted, heterogeneous, and resource-constrained, posing considerable challenges for developing unified and scalable defense solutions. To address this, we propose a novel hybrid model called M2VT that integrates Multi-View Learning (MVL) and Multi-Task Learning (MTL) for effective cyber-attack defense. The model simultaneously processes three distinct subsets of relevant features (views) to perform three interrelated tasks: attack detection, attack category classification, and attack type classification. The model leverages AutoEncoder (AE) and Long Short-Term Memory (LSTM) networks to extract task-specific spatial and temporal features, enhancing both efficiency and cost-effectiveness. The M2VT model is evaluated using four publicly available IoT benchmark datasets and one testbed dataset. Across all tasks and datasets, the model achieves over 96% accuracy, consistently outperforming state-of-the-art approaches. The parallel execution of MVL and MTL, combined with taskspecific feature subsets, significantly boosts performance. The implementation of M2VT is publicly available in our code repository 1.},
  archive      = {J_TAI},
  author       = {Urkhimbam Boby Clinton and Nazrul Hoque and Shahid Raza and Monowar Bhuyan},
  doi          = {10.1109/TAI.2025.3615565},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {10},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Securing IoT: Unveiling attacks with multiview-multitask learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedImp: Enhancing federated learning convergence with impurity-based weighting. <em>TAI</em>, 1-13. (<a href='https://doi.org/10.1109/TAI.2025.3605307'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) is a collaborative paradigm that enables multiple devices to train a global model while preserving local data privacy. A major challenge in FL is the non-Independent and Identically Distributed (non-IID) nature of data across devices, which hinders training efficiency and slows convergence. To tackle this, we propose Federated Impurity Weighting (FedImp), a novel algorithm that quantifies each device’s contribution based on the informational content of its local data. These contributions are normalized to compute distinct aggregation weights for the global model update. Extensive experiments on EMNIST and CIFAR-10 datasets show that FedImp significantly improves convergence speed, reducing communication rounds by up to 64.4%, 27.8%, and 66.7% on EMNIST, and 44.2%, 44%, and 25.6% on CIFAR-10 compared to FedAvg, FedProx, and FedAdp, respectively. Under highly imbalanced data distributions, FedImp outperforms all baselines and achieves the highest accuracy. Overall, FedImp offers an effective solution to enhance FL efficiency in non-IID settings.},
  archive      = {J_TAI},
  author       = {Hai Anh Tran and Cuong Ta and Truong X. Tran},
  doi          = {10.1109/TAI.2025.3605307},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {FedImp: Enhancing federated learning convergence with impurity-based weighting},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Watermarking language models through language models. <em>TAI</em>, 1-10. (<a href='https://doi.org/10.1109/TAI.2025.3605117'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Watermarking the outputs of large language models (LLMs) is critical for provenance tracing, content regulation, and model accountability. Existing approaches often rely on access to model internals or are constrained by static rules and token-level perturbations. Moreover, the idea of steering generative behavior via prompt-based instruction control remains largely underexplored. We introduce a prompt-guided watermarking framework that operates entirely at the input level and requires no access to model parameters or decoding logits. The framework comprises three cooperating components: a Prompting LM that synthesizes watermarking instructions from user prompts, a Marking LM that generates watermarked outputs conditioned on these instructions, and a Detecting LM trained to classify whether a response carries an embedded watermark. This modular design enables dynamic watermarking that adapts to individual prompts while remaining compatible with diverse LLM architectures, including both proprietary and open-weight models. We evaluate the framework over 25 combinations of Prompting and Marking LMs, such as GPT-4o, Mistral, LLaMA3, and DeepSeek. Experimental results show that watermark signals generalize across architectures and remain robust under fine-tuning, model distillation, and prompt-based adversarial attacks, demonstrating the effectiveness and robustness of the proposed approach.},
  archive      = {J_TAI},
  author       = {Agnibh Dasgupta and Abdullah All Tanvir and Xin Zhong},
  doi          = {10.1109/TAI.2025.3605117},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Watermarking language models through language models},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond accurate distillation: Calibrated knowledge distillation for reliable predictionsn. <em>TAI</em>, 1-13. (<a href='https://doi.org/10.1109/TAI.2025.3605902'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation is a common technique for improving the performance of a shallow student network by transferring information from a teacher network, which in general, is comparatively large and deep. These teacher networks are pre-trained and often uncalibrated, as no calibration technique is applied to the teacher model while training. Calibration of a network measures the probability of correctness for any of its predictions, which is crucial for high-risk domains where reliable predictions are essential. In this paper, we study how to obtain a calibrated student from an uncalibrated teacher. Our approach relies on the fusion of the data-augmentation techniques, including but not limited to Mixup and CutMix, with knowledge distillation. We incorporate and analyze the impact of focal loss in the distillation framework to further improve the calibration of the student model. We perform extensive experiments to validate our approach on various datasets, including CIFAR-100, TinyImageNet, ImageNet and Diabetic Retinopathy datasets, and compare it with various techniques like CRD, RKD, DKD and MLLD to obtain calibrated student models. Furthermore, we conduct an ablation study to dissect the influence of augmentation techniques and the integration of focal loss. Additionally, we assess the robustness of our approach by evaluating its performance on corrupted CIFAR-100C data, demonstrating its consistent and reliable outcomes even under challenging conditions.},
  archive      = {J_TAI},
  author       = {Ishan Mishra and Vamsi Krishna Sethu and Deepak Mishra},
  doi          = {10.1109/TAI.2025.3605902},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Beyond accurate distillation: Calibrated knowledge distillation for reliable predictionsn},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A positive-unlabeled learning approach with self-correcting regularized risk. <em>TAI</em>, 1-13. (<a href='https://doi.org/10.1109/TAI.2025.3605890'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The primary objective of Positive Unlabeled learning (PU learning) is to train a binary classifier with positively labeled data and unlabeled data. An inherent aspect of this approach involves incorporating the positive class prior of unlabeled data directly into the classification process, which is typically challenging in real-world scenarios. Moreover, existing studies often lack evaluations of PU classifiers without involving the positive class prior (true or estimated) of the unlabeled data, representing a significant research gap. In this paper, we introduce a robust, two-step PU learning algorithm by incorporating a potential negative sampler in step 1 (warm start) and minimizing a self-correcting regularized risk function in step 2. The risk function possesses a self-correcting property that attempts to mitigate the weakness of the potential negative sampler in the warm start step. The risk function enables us to enhance robustness in the presence of mislabeled candidate negative samples. We demonstrate the effectiveness of our method on image as well as text benchmarks. Results show that the proposed method consistently outperforms the state-of-the-art PU learning algorithms.},
  archive      = {J_TAI},
  author       = {Sayantang Saha and Atif Hassan and Jiaul H. Paik},
  doi          = {10.1109/TAI.2025.3605890},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {A positive-unlabeled learning approach with self-correcting regularized risk},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ARD-LoRA: Dynamic rank allocation for parameter-efficient fine-tuning of foundation models with heterogeneous adaptation needs. <em>TAI</em>, 1-10. (<a href='https://doi.org/10.1109/TAI.2025.3605569'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional Low-Rank Adaptation (LoRA) methods employ a fixed rank, imposing uniform adaptation across transformer layers and attention heads despite their heterogeneous learning dynamics. This paper introduces Adaptive Rank Dynamic LoRA (ARD-LoRA), a novel framework that automates rank allocation through learnable scaling factors. These factors are optimized via a meta-objective balancing task performance and parameter efficiency, incorporating $\ell_1$ sparsity for minimal rank and Total Variation regularization for stable rank transitions. ARD-LoRA enables continuous, differentiable, per-head rank adaptation. Experiments on LLAMA-3.1-70B and PaliGemma-2 demonstrate ARD-LoRA’s efficacy, achieving up to 99.3% of full fine-tuning performance with only 0.32% trainable parameters, outperforming strong baselines like DoRA and AdaLoRA. Furthermore, it reduces multimodal adaptation memory by 41%. These results establish dynamic, fine-grained rank allocation as a critical paradigm for efficient foundation model adaptation.},
  archive      = {J_TAI},
  author       = {Haseeb Ullah Khan Shinwari and Muhammad Usama},
  doi          = {10.1109/TAI.2025.3605569},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {ARD-LoRA: Dynamic rank allocation for parameter-efficient fine-tuning of foundation models with heterogeneous adaptation needs},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Let invariant learning inspire neighbor-shift generalization on graphs. <em>TAI</em>, 1-12. (<a href='https://doi.org/10.1109/TAI.2025.3605894'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have achieved strong performance on various graph learning tasks under the assumption of independently and identically distributed (IID) data. However, recent studies reveal that GNNs suffer from performance drops under distribution shifts, prompting growing interest in out-of-distribution (OOD) generalization. In this work, we identify a previously underexplored challenge Neighbor Shift, which refers to structural inconsistencies in node neighborhoods across environments. We analyze its characteristics and demonstrate its negative impact on node-level classification. To tackle this issue, we propose the Neighbor-Shift Robust Graph Neural Network (NSRGNN), which disentangles invariant and variant subgraphs through conflict-based structure analysis, infers latent environments using the variant components, and regularizes semantic consistency of node representations across inferred environments. Extensive experiments on both real-world and synthetic benchmarks show that NSRGNN consistently outperforms strong OOD baselines and exhibits robust generalization under diverse structural shifts.},
  archive      = {J_TAI},
  author       = {Jiaxing Li and Jiayi Gao and Binhao Gu and Youyong Kong},
  doi          = {10.1109/TAI.2025.3605894},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Let invariant learning inspire neighbor-shift generalization on graphs},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Wasserstein distance based multi-source heterogeneous graph adaptation for cross-network node classification. <em>TAI</em>, 1-14. (<a href='https://doi.org/10.1109/TAI.2025.3606456'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-network node classification seeks to leverage labeled source networks to assist node classification in an unlabeled target network. However, existing heterogeneous graph adaptation methods often rely on restrictive assumptions, such as the presence of a single source network or strong correlations between source and target nodes, which rarely hold in practice. To address this, we propose a novel Wasserstein Distance Based Multi-Source Heterogeneous Graph Adaptation framework (WMHGA), which aims to learn transferable node representations across networks in order to improve the accuracy of node classification tasks. Specifically, we propose a Wasserstein Distance Based Heterogeneous Graph Adaptation (WHGA) approach to learn node representations that are invariant to domain variations. Then, we propose two Wasserstein distance-based knowledge distillation approaches to identify more valuable samples from the source graph and learn label-discriminative node representations of these samples for knowledge transfer. In addition, we devise a Wasserstein distance-based aggregated prediction to prioritize highly relevant source nodes while suppressing irrelevant ones, thereby ensuring more accurate node classification in the target network. Extensive experiments have been conducted on three real-world datasets, demonstrating that the proposed WMHGA model outperforms the state-of-the-art baselines.},
  archive      = {J_TAI},
  author       = {Hongwei Yang and Jiaoxuan Lin and Hui He and Weizhe Zhang and Letu Suya},
  doi          = {10.1109/TAI.2025.3606456},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Wasserstein distance based multi-source heterogeneous graph adaptation for cross-network node classification},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual thinking and logical processing in human vision and multi-modal large language models. <em>TAI</em>, 1-15. (<a href='https://doi.org/10.1109/TAI.2025.3606452'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dual thinking framework considers fast, intuitive, and slower logical processing. The perception of dual thinking in vision requires images where inferences from intuitive and logical processing differ, and the latter is under-explored in current studies. We introduce a novel adversarial dataset to provide evidence for the dual thinking framework in human vision, which also facilitates the study of the qualitative behavior of deep learning models. Our psychophysical studies show the presence of multiple inferences in rapid succession, and analysis of errors shows that the early stopping of visual processing can result in missing relevant information. MLLMs (Multi-modal Large Language Models) and VLMs (Vision Language Models) have made significant progress in correcting errors in intuitive processing in human vision and showed enhanced performance on images requiring logical processing. However, their improvements in logical processing have not kept pace with their advancements in intuitive processing. In contrast, segmentation models exhibit errors similar to those seen in intuitive human processing and lack understanding of sub-structures, as indicated by errors related to sub-components in identified instances. As AI (Artificial Intelligence)-based systems find increasing applications in safety-critical domains like autonomous driving, the integration of logical processing capabilities becomes essential. This not only enhances performance but also addresses the limitations of scaling-based approaches while ensuring robustness and reliability in real-world environments. The code for this paper is available at https://github.com/kailasdayanandan/dual thinking/},
  archive      = {J_TAI},
  author       = {Kailas Dayanandan and Nikhil Kumar and Anand Sinha and Brejesh Lall},
  doi          = {10.1109/TAI.2025.3606452},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Dual thinking and logical processing in human vision and multi-modal large language models},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Context guided multiscale attention for real-time semantic segmentation of road scene. <em>TAI</em>, 1-14. (<a href='https://doi.org/10.1109/TAI.2025.3606904'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lightweight deep neural networks have played a pivotal role in real-time semantic segmentation for autonomous driving in resource-constrained devices, which need to effectively learn the local semantics and global context at multiple scales due to varying object sizes. Recent methods design shallow and lightweight backbones with a small receptive field for faster inference, along with additional mechanisms such as attention to compensate for the accuracy loss due to the lightweight design. While some methods have exploited multi-scale feature learning by attaching pyramid modules at the encoder end, it is often neglected at the fundamental block level due to increased inference time. Furthermore, the attention weights are mostly generated at a single object scale by only using the high-level feature representations. To solve the first problem, a key module for the basic block, the Fast Hybrid Module (FHM), has been proposed. This module uses a hybrid approach to learn multi-scale features by combining dilated kernels and downsampling operations in a parallel three-branch structure. To solve the second problem, a novel attention module, the Multi-Scale Attention Module (MSAM), is proposed. MSAM uniquely generates context weights at varying scales from the low-level features rich in object boundary and edge information and multiplies them by the high-level semantic features obtained from the encoder. With these modules, a novel encoder-decoder network named Context Guided Multi-scale Attention Network (CGMA-Net) is proposed. With only 0.54 Million parameters, the network achieves 73.4% and 68.1% mean IoU accuracy at 128.24 and 85.5 FPS on the Cityscapes and CamVid datasets, respectively. In addition, the network can run in real-time on embedded GPUs with resource constraints. Through extensive ablation studies, the effectiveness of the proposed modules and network is shown. The qualitative results on unseen data demonstrate the robustness of the method. Code available at: https://github.com/saquibmazhar/SemanticSegmentation-CGMANet.},
  archive      = {J_TAI},
  author       = {Saquib Mazhar and Nadeem Atif and M.K. Bhuyan and Shaik Rafi Ahamed},
  doi          = {10.1109/TAI.2025.3606904},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Context guided multiscale attention for real-time semantic segmentation of road scene},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multirate distributed receding horizon reinforcement learning for optimal UAV-UGV formation control. <em>TAI</em>, 1-16. (<a href='https://doi.org/10.1109/TAI.2025.3607722'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The coordination of unmanned aerial vehicles (UAVs) and unmanned ground vehicles (UGVs) is valuable in many applications, such as emergency search and rescue, and has received increasing attention in recent years. Given their distinct tasks and dynamic characteristics, the UAV team is typically controlled with higher maneuverability for rapid searching, while the UGV team is operated on roads at lower speeds to ensure stability and performance. This discrepancy naturally results in a multirate control problem, which has not been adequately addressed in previous works. Therefore, we present a multirate distributed receding horizon reinforcement learning (RHRL) framework to solve the optimal UAV-UGV formation control problem on fast and slow time scales. The proposed approach includes a distributed RHRL algorithm operating at a slower time scale for the formation control of UGV teams, and another distributed RHRL algorithm functioning at a faster time scale for the formation control of UAV teams. The state information among homogeneous UAV/UGV agents and heterogeneous agents across different teams are exchanged at different frequencies to balance control performance and communication load. Notably, our approach integrates the receding horizon strategy to enhance learning efficiency and provides theoretical guarantees in multirate distributed RL. Theoretically, learning convergence at different time scales and closed-loop stability are guaranteed. Comparative numerical validations are conducted to demonstrate the effectiveness of our approach in heterogeneous UAV-UGV formation control under different time scales and tasks.},
  archive      = {J_TAI},
  author       = {Xinglong Zhang and Cong Li and Ronghua Zhang and Quan Xiong and Wei Jiang and Xin Xu},
  doi          = {10.1109/TAI.2025.3607722},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Multirate distributed receding horizon reinforcement learning for optimal UAV-UGV formation control},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed reinforcement learning optimal cluster consensus control for takagi-sugeno fuzzy multi-agent systems. <em>TAI</em>, 1-10. (<a href='https://doi.org/10.1109/TAI.2025.3607790'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the distributed optimal cluster consensus control problem with a data-driven value iteration (VI) algorithm for Takagi-Sugeno (T-S) fuzzy multi-agent systems (MASs) with unknown system dynamics. In distributed optimal cluster consensus control design, we view each agent’s control policy and its neighboring followers’ control policy as rival players, then a fuzzy distributed optimal cluster consensus control policy is proposed by applying differential graphical game theory and acyclic partition. Since the analytical optimal cluster consensus control solutions are reduced to solving the distributed game algebraic Riccati equations (GAREs), which is difficult to obtain their analytical solutions, a data-driven VI algorithm is presented. It is proved that the developed algorithm can converge to the approximation solutions of optimal controllers, and the proposed fuzzy distributed optimal cluster consensus control scheme not only guarantees the followers in each cluster to asymptotically track their corresponding leaders but also achieves the Nash equilibrium of differential graphical game. Finally, we apply the developed fuzzy distributed optimal cluster consensus control method with a data-driven VI algorithm to multiple nonlinear unmanned surface vehicle (USV) systems, the computer simulation results verify the effectiveness of the developed optimal control approach.},
  archive      = {J_TAI},
  author       = {Hui Li and Jun Ning and Shaocheng Tong},
  doi          = {10.1109/TAI.2025.3607790},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Distributed reinforcement learning optimal cluster consensus control for takagi-sugeno fuzzy multi-agent systems},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CIBLS-PLS: A class-incremental broad learning system with pseudo-label-guided stacked structure. <em>TAI</em>, 1-15. (<a href='https://doi.org/10.1109/TAI.2025.3606902'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class-incremental learning (CIL) with the Broad Learning System (BLS) has emerged as a computationally efficient alternative to deep incremental models. However, existing BLS-based CIL methods struggle with complex data distributions and are highly sensitive to hyperparameter tuning, leading to suboptimal knowledge retention. To address these challenges, we propose CIBLS-PLS (Class-Incremental Broad Learning System with Pseudo-Label-Guided Stacked Structure), which enhances knowledge retention and adaptability. Different from traditional stacked BLS, where blocks are strictly chained through input-output dependencies, CIBLS-PLS adopts a more flexible stacking structure, allowing each block to independently contribute to knowledge preservation. Each BLS layer integrates dual-storage modules that retain key features from previous data, while pseudo-labels are generated to facilitate seamless knowledge integration within the stacked residual learning framework. Model parameters are updated efficiently via closed-form ridge regression, significantly reducing computational overhead while maintaining high accuracy. Additionally, to further enhance model generalization, an adaptive scaling mechanism dynamically regulates the contribution of residual blocks, effectively preventing overfitting as the number of blocks increases. This property is rigorously validated through both theoretical analysis and extensive experiments. Results on seven large-scale image datasets demonstrate that CIBLS-PLS achieves state-of-the-art performance in accuracy and knowledge retention while maintaining competitive computational efficiency, paving the way for robust and scalable broad learning-based incremental models.},
  archive      = {J_TAI},
  author       = {Xin Liu and Zhaoyin Shi and Shuanghao Zhang and Long Chen and Weiping Ding and Xiaopin Zhong and Zongze Wu and C. L. Philip Chen},
  doi          = {10.1109/TAI.2025.3606902},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {CIBLS-PLS: A class-incremental broad learning system with pseudo-label-guided stacked structure},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FCA-HLP: Multi-layer feature cross-activation network with high- and low-level prototypes for few-shot segmentation. <em>TAI</em>, 1-12. (<a href='https://doi.org/10.1109/TAI.2025.3607850'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot segmentation (FSS) strives to segment novel categories using merely a limited number of labeled images. Current prototype learning and correlation learning approaches struggle to effectively harness both high- and low-level information from support and query images, leading to suboptimal segmentation results. In this work, we propose a multi-layer feature cross-activation (FCA) network with high- and low-level prototypes (HLP), which fully utilizes support and query information from both features and prototypes perspectives. Specifically, for the FCA module, we design a simple activation method that uses all the pixel-level support foreground features to activate query features, thereby obtaining activation maps without losing pixel-level detail information of support features. For the HLP module, we combine image-level prototypes with pixel-level prototypes to fully utilize high-level category information and low-level attribute information of support features. Besides, the prototype generation method integrates query information, which further enables the prototypes to better match target query features, especially when there are great differences between query and support images. Extensive experiments on PASCAL-5i and COCO-20i under 1-shot and 5-shot settings validate the effectiveness of our FCA-HLP. Our method establishes new state-of-the-art performance. Additionally, we analyze the performance of the multi-layer feature cross-activation network in the absence of the HLP module. The results indicate that even without prototypes, the FCA module can still deliver strong performance. Codes are available at https://github.com/Jiaguang-NEU/FCA-HLP.},
  archive      = {J_TAI},
  author       = {Jiaguang Li and Ying Wei and Zihan Gao and Yubo Wang},
  doi          = {10.1109/TAI.2025.3607850},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {FCA-HLP: Multi-layer feature cross-activation network with high- and low-level prototypes for few-shot segmentation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AdU-net: Glacial lake extraction and outburst risk assessment using satellite imagery. <em>TAI</em>, 1-14. (<a href='https://doi.org/10.1109/TAI.2025.3608120'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Glacial lake outburst floods (GLOFs) threaten downstream communities and infrastructure in high-mountain regions. Accurate extraction of glacial lakes and assessment of their susceptibility to outbursts are crucial for early warning systems and risk mitigation strategies. The proposed framework, named AdU-Net, combines a dilated U-Net with nested connections and an adaptable vision transformer encoder (AVi-TE) for glacial lake extraction. It also introduces a modified spiking neural network (SNN) to model the evolution of GLOF (Glacial Lake Outburst Flood) risk. This approach utilizes Landsat 8 satellite imagery for analysis of the Imja, Chandra, and Bhaga glacial regions. The AdU-Net efficiently captures spatial dependencies and hierarchies within satellite imagery, enabling precise delineation of glacial lakes. Subsequently, the extracted lake features are analyzed using the SNN, which excels at processing temporal information and detecting dynamic patterns indicative of outburst susceptibility. Combining spatial and temporal analyses, the proposed integrated approach provides comprehensive insight into glacial lake dynamics and improves understanding of factors influencing outburst susceptibility.},
  archive      = {J_TAI},
  author       = {Jagadeesh Thati and Allam Jaya Prakash and Samit Ari},
  doi          = {10.1109/TAI.2025.3608120},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {AdU-net: Glacial lake extraction and outburst risk assessment using satellite imagery},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CamoX: A diffusion-based method with few-shot learning for environment-guided camouflage pattern generation. <em>TAI</em>, 1-16. (<a href='https://doi.org/10.1109/TAI.2025.3608758'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective camouflage is needed for defense personnel and assets to blend seamlessly with the complex and dynamic environments. The camouflage technique must maintain the concealment capability across various environments and geographic regions. However, existing approaches, including manual design, computer-aided techniques, and deep learning methods, face significant challenges in achieving automation, scalability, and generalization across diverse and uncalibrated scenes. To address these limitations, we propose a novel diffusion-based method with few-shot learning to generate environment-guided camouflage patterns. Our method, called CamoX, consists of two major stages: meta learning and few-shot learning. In the meta learning stage, our method introduces a latent diffusion-based architecture that automatically generates camouflage patterns from noise, eliminating manual intervention and enabling scalable production. In the few-shot learning stage, our approach enforces similarity between the latent features of the camouflage patterns and target scenes by optimizing the guided mean absolute error loss. This innovation allows the generated camouflage patterns to adapt seamlessly to multiple environments with minimal retraining. Furthermore, this paper introduces a comprehensive camouflage dataset, called Camo-Meta, comprising 144,750 realistic camouflage patterns and associated metadata to support research in camouflage generation. Experimental results on multiple datasets demonstrate that CamoX outperforms existing state-of-the-art methods in key metrics.},
  archive      = {J_TAI},
  author       = {Tran Thanh Phong Nguyen and Tauseef Gulrez and Joanne B. Culpepper and Son Lam Phung and Hoang Thanh Le},
  doi          = {10.1109/TAI.2025.3608758},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {CamoX: A diffusion-based method with few-shot learning for environment-guided camouflage pattern generation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A conceptual framework of AI transparency from sociotechnical perspective. <em>TAI</em>, 1-14. (<a href='https://doi.org/10.1109/TAI.2025.3608735'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transparency serves as a cornerstone principle in artificial intelligence (AI) ethics and governance, playing a crucial role in upholding ethical standards and ensuring responsible AI deployment. Despite its critical importance, the concept of AI transparency remains fragmented in literature, highlighting the necessity for a unified and comprehensive understanding. This paper addresses this imperative by firstly conducting a systematic literature review about existing varied definitions of transparency to deepen our understanding of AI transparency. Then, the three key aspects of AI transparency, that is, transparent to whom, transparent of what, and how to be transparent, are examined. Building upon this groundwork, we propose a novel sociotechnical framework that uniquely integrates both intrinsic and extrinsic dimensions of AI transparency while accounting for the roles of internal and external stakeholders, resulting in a three-layered AI transparency framework encompassing intrinsic, internal, and external transparency. This comprehensive framework not only deepens our understanding of AI transparency but also provides a structured roadmap for navigating the complex sociotechnical landscape of AI systems. Our main contribution lies in developing this novel conceptual framework that enriches both the theory and practice of AI transparency and provides guidelines for designing and deploying transparent AI systems in the future.},
  archive      = {J_TAI},
  author       = {Changwu Huang and Ziming Wang and Xingnan Wen and Xiaozhen Wang and Xin Yao},
  doi          = {10.1109/TAI.2025.3608735},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {A conceptual framework of AI transparency from sociotechnical perspective},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Offline inverse constrained reinforcement learning for safe-critical decision making in healthcare. <em>TAI</em>, 1-10. (<a href='https://doi.org/10.1109/TAI.2025.3610390'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One important application of Reinforcement Learning (RL) is optimizing treatment decisions in healthcare. However, a na¨ıve RL policy can lead to unsafe medical decisions, such as excessive dosages or abrupt treatment changes, often because agents fail to account for common-sense constraints. To mitigate these problems, Constrained Reinforcement Learning (CRL) naturally emerges as a promising approach for safer decision-making by optimizing policies under predefined constraints. To extend CRL to healthcare applications, a fundamental challenge lies in accurately specifying the constraint function for different healthcare scenarios. Recent Inverse Constrained Reinforcement Learning (ICRL) is a promising approach that infers constraints from expert demonstrations. However, ICRL algorithms model Markovian decisions and rely on real-time interactive environments. These settings do not align with the practical requirement of a decision-making system in healthcare, where decisions rely on historical treatment recorded in an offline dataset. To tackle these issues, we propose the Constraint Transformer (CT). Specifically, 1) we utilize a causal attention mechanism to incorporate historical decisions and observations into the constraint modeling, while employing a Non-Markovian layer for weighted constraints to capture critical states. 2) A generative world model is used for exploratory data augmentation, enabling offline RL methods to simulate unsafe decision sequences. In multiple medical scenarios, empirical results demonstrate that CT can capture unsafe states and achieve strategies that approximate lower mortality rates, reducing the occurrence probability of unsafe behaviors.},
  archive      = {J_TAI},
  author       = {Nan Fang and Guiliang Liu and Wei Gong},
  doi          = {10.1109/TAI.2025.3610390},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Offline inverse constrained reinforcement learning for safe-critical decision making in healthcare},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attention-guided encoder-decoder design for efficient RIS phase configuration in time-varying IoT networks. <em>TAI</em>, 1-12. (<a href='https://doi.org/10.1109/TAI.2025.3610389'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of Artificial Intelligence (AI) into wireless communication has enabled adaptive, efficient, robust, and scalable system designs. Reconfigurable Intelligent Surfaces (RIS) offer a promising paradigm for AI-driven control by dynamically adjusting the wireless environment through Phase Configuration Sequence (PCS) bits sent from the Base Station (BS). By steering signals intelligently, RIS can improve coverage and direct transmissions to specific locations. However, the increasing size of RIS and rapidly changing IoT device positions in dynamic environments impose significant feedback bandwidth constraints due to frequent PCS bits updates. To address this, we propose a novel Attention-Guided Encoder-Decoder with Normalization Enhancement (AGENE) framework that compresses PCS bits at the BS using a lightweight encoder and reconstructs them at the RIS controller using a decoder. Our design incorporates a custom attention mechanism and Generalized Divisive Normalization (GDN)/Inverse GDN layers to enhance feature extraction and normalization. We also evaluate our method under different noise models, including Gaussian and Rician noise, to test robustness in practical scenarios. Finally, to evaluate the effectiveness of our proposed method (AGENE), we compared its performance with existing methods across different compression ratios and noise conditions, focusing on loss reduction and Normalized Mean Square Error (NMSE). In Additive White Gaussian Noise (AWGN) conditions, AGENE achieved a loss reduction of 28.12% compared to PSC-DN, 43.9% compared to DL-CsiNet, and 58.18% compared to CsiNet at a compression ratio of 2/9. Under Rician noise, AGENE showed a reduction of 19.39% compared to PSC-DN, 37.01% compared to DL-CsiNet, and 45.21% compared to CsiNet, again at the same compression ratio. These results consistently demonstrate that AGENE outperforms existing methods by a significant margin across both metrics and noise conditions.},
  archive      = {J_TAI},
  author       = {Vikash Kumar Bhardwaj and Abhisekh Singh and Omm Prakash Sahoo and Mahendra K. Shukla and Om Jee Pandey},
  doi          = {10.1109/TAI.2025.3610389},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Attention-guided encoder-decoder design for efficient RIS phase configuration in time-varying IoT networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Counterfactual causal inference of biomedical signals: Unveiling causal EEG patterns for ASD evaluation. <em>TAI</em>, 1-15. (<a href='https://doi.org/10.1109/TAI.2025.3610394'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The examination of complex diseases has greatly benefited from machine-learning techniques for interpreting biomedical signals. However, for diseases with multifactorial etiologies, such as Autism Spectrum Disorders (ASD), the inability of associative methods to distinguish between causal relationships and mere correlations often leads to unreliable outcomes. In contrast, causal models require well-defined causal structures, demanding a thorough understanding of their contributing factors. This study proposes a Generative Adversarial Network framework for Counterfactual Causal Inference (C2I-GAN) to uncover causal patterns from biomedical signals without a predefined causal structure. The framework leverages graph attention network to identify key features for directing counterfactual generation, applies generative adversarial learning to produce task-oriented counterfactuals, and supports inference by evaluating how modifications to specific features affect diagnostic outcomes. A case study of ASD evaluation is conducted on a resting-state EEG dataset (74 ASD and 143 TD children) using C2I-GAN against state-of-the-art methods (Associative: GAT; Counterfactual: CounteRGAN, Omnixai, and CXGAN). The findings show that C2I-GAN identified T3, T4, O1, and O2 channels as causal patterns while recognizing C3 and C4 as merely associative, aligning with the latest neuroscience evidence where counterpart methods failed. In terms of performance, the model improved actionability by 30E and accuracy by 10E compared to other counterfactual methods, and increased accuracy by 5E while reducing training loss by 20E against associative method, demonstrating enhanced precision and efficiency.},
  archive      = {J_TAI},
  author       = {Yaodong Wang and Yiping Zuo and Dan Chen and Albert Y. Zomaya and Rajiv Ranjan and Jingying Chen and Tengfei Gao},
  doi          = {10.1109/TAI.2025.3610394},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Counterfactual causal inference of biomedical signals: Unveiling causal EEG patterns for ASD evaluation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mitigating label noise in federated learning with regularized features and robust loss. <em>TAI</em>, 1-12. (<a href='https://doi.org/10.1109/TAI.2025.3609745'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning enables decentralized model training across distributed devices while preserving data privacy and reducing communication overhead. However, the presence of heterogeneous client data and noisy labels poses significant challenges, often leading to degraded model performance, especially in communication-constrained environments. In this work, we propose FedRFRL, a robust federated learning framework designed to mitigate the adverse effects of label noise by combining feature regularization and a robust loss function. Specifically, FedRFRL introduces a representation regularization strategy that leverages a high-dimensional projection layer to promote the learning of diverse and discriminative features across clients. Additionally, we incorporate adaptive sharpness-aware minimization (ASAM) to encourage flatter minima for improved generalization under non-IID and noisy settings. Extensive experiments on benchmark datasets, including CIFAR-10, CIFAR-100, SVHN, Fashion-MNIST, and the real-world noisy datasets CIFAR-N and Clothing1M, demonstrate that FedRFRL consistently outperforms existing methods, achieving strong robustness against both symmetric and asymmetric label noise. These results highlight the effectiveness and scalability of FedRFRL in real-world federated learning scenarios with imperfect supervision.},
  archive      = {J_TAI},
  author       = {Girum Fitihamlak Ejigu and Kitae Kim and Choong Seon Hong},
  doi          = {10.1109/TAI.2025.3609745},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Mitigating label noise in federated learning with regularized features and robust loss},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Air quality prediction with a meteorology-guided modality-decoupled spatio-temporal network. <em>TAI</em>, 1-14. (<a href='https://doi.org/10.1109/TAI.2025.3610393'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Air quality prediction plays a crucial role in public health and environmental protection. Accurate air quality prediction is a complex spatiotemporal problem, that involves pollutant spatiotemporal dependencies and meteorological influences that govern pollutant dispersion and transformation. However, existing predictive models often underestimate the critical influence of atmospheric conditions by treating air quality and meteorological data as a single, homogeneous modality or by using only limited surface-level features, which impairs performance. To overcome this, we propose MDSTNet, an encoder-decoder framework that takes historical air quality observations and multi-pressure-level meteorological data as input, explicitly modeling them as distinct modalities, while uniquely leveraging multi-step weather forecasts as dynamic prompts to guide prediction. Meantime, we construct ChinaAirNet, the first nationwide dataset combining air quality records with multi-pressure-level meteorological observations. Experimental results on ChinaAirNet and a public dataset KDDCUP-Beijing demonstrate MDSTNet’s superiority, substantially reducing 48-hour prediction errors by 17.54’ compared to the state-of-the-art model, showcasing the significant advantage of our meteorology-guided, modality-decoupled design. Code is available at this repository1, and dataset is available at here2.},
  archive      = {J_TAI},
  author       = {Hang Yin and Yan-Ming Zhang and Jian Xu and Jian-Long Chang and Yin Li and Cheng-Lin Liu},
  doi          = {10.1109/TAI.2025.3610393},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Air quality prediction with a meteorology-guided modality-decoupled spatio-temporal network},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fully adaptive multi-scale spatial-temporal recurrent networks for traffic flow prediction. <em>TAI</em>, 1-14. (<a href='https://doi.org/10.1109/TAI.2025.3610568'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic flow prediction is one of the most fundamental tasks of intelligent transportation systems. The complex and dynamic spatial-temporal dependencies make the traffic flow prediction quite challenging. Although existing spatial-temporal graph neural networks hold prominent, they often encounter challenges of using a static graph with the same set of edge weights across different time points, which greatly limits the representational power of spatial graph structures, as well as lacking capability of capturing spatial-temporal patterns at different time scales from a single time point to multiple time points. In this paper, we propose a fully adaptive Multi-Scale Spatial-Temporal Recurrent Network for traffic flow prediction, namely MSSTRN, which consists of two different recurrent neural networks: the single-step gate recurrent unit and the multi-step gate recurrent unit to fully capture the complex spatial-temporal information in the traffic data under different time steps. We integrate node embeddings with temporal position information at multiple scales to construct fully adaptive graphs and propose adaptive position graph convolution networks for capturing spatial dependencies in specific temporal contexts. Moreover, we propose a spatial-temporal position-aware attention mechanism that unifies adaptive graph convolutions and self-attention for joint spatial-temporal dependency learning. simultaneously capture spatialtemporal dependencies. Extensive experiments on four real-world traffic datasets show that our model outperforms 23 baselines with significant margins in prediction accuracy.},
  archive      = {J_TAI},
  author       = {Haiyang Liu and Chunjiang Zhu and Detian Zhang and Qing Li},
  doi          = {10.1109/TAI.2025.3610568},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Fully adaptive multi-scale spatial-temporal recurrent networks for traffic flow prediction},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards sample-efficiency and generalization of transfer and inverse reinforcement learning: A comprehensive literature review. <em>TAI</em>, 1-16. (<a href='https://doi.org/10.1109/TAI.2025.3610590'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning (RL) is a sub-domain of machine learning, mainly concerned with solving sequential decision-making problems by a learning agent that interacts with the decision environment to improve its behaviour through the reward it receives from the environment. This learning paradigm is, however, well-known for being time-consuming due to the necessity of collecting a large amount of data, making RL suffer from sample inefficiency and difficult generalization. Furthermore, the construction of an explicit reward function that accounts for the trade-off between multiple desiderata of a decision problem is often a laborious task. These challenges have been recently addressed utilizing transfer and inverse RL (T-IRL). In this regard, this paper is devoted to a comprehensive review of realizing the sample efficiency and generalization of RL algorithms through T-IRL. Following a brief introduction to RL, the fundamental T-IRL methods are presented and the most recent advancements in each research field have been extensively reviewed. Our findings denote that a majority of recent research works have dealt with the aforementioned challenges by utilizing human-in-the-loop and sim-to-real strategies for the efficient transfer of knowledge from source domains to the target domain under the transfer learning scheme. Under the IRL structure, training schemes that require a low number of experience transitions and extension of such frameworks to multi-agent and multi-intention problems have been the priority of researchers in recent years. This survey first reviews the theoretical foundations of RL and its challenges, then presents recent advances in T-IRL, and concludes with a discussion of open research directions and future trends.},
  archive      = {J_TAI},
  author       = {Hossein Hassani and Ehsan Hallaji and Roozbeh Razavi-Far and Mehrdad Saif and Liang Lin},
  doi          = {10.1109/TAI.2025.3610590},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Towards sample-efficiency and generalization of transfer and inverse reinforcement learning: A comprehensive literature review},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal control of unknown nonlinear systems via a multi-model-based multi-step reinforcement learning framework. <em>TAI</em>, 1-13. (<a href='https://doi.org/10.1109/TAI.2025.3608776'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal control of unknown nonlinear systems is challenging due to the absence of the underlying dynamics model. Reinforcement learning (RL) has become an effective framework for such control by optimizing policies with measurement data of the system. However, RL often suffers from (i) low sample efficiency due to the absence of domain knowledge (e.g., dynamics model) and (ii) low learning efficiency due to slow propagation of the reward signal. Model-based RL methods and multi-step RL methods were proposed to address these two challenges, respectively. It is natural to combine these two methods to take advantage of both benefits. However, this combination requires the learned single one-step dynamics model, commonly used in model-based settings, to perform multi-step prediction in a recursive manner, leading to the error accumulation (also known as compounding error) problem. This work presents a multi-model dynamics learning framework to address the error accumulation challenge for general model-based multi-step RL methods by circumventing the recursive prediction. We also present a specific multi-model-based multi-step RL algorithm and validate it on benchmark nonlinear systems. It is shown that the multi-model framework improves multi-step prediction of dynamics and that the presented multi-model-based multi-step RL mostly outperforms model-free, single-model, and one-step counterparts, respectively. We also discuss the limitations of this work and potential future work.},
  archive      = {J_TAI},
  author       = {Shanwu Li and Yongchao Yang},
  doi          = {10.1109/TAI.2025.3608776},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Optimal control of unknown nonlinear systems via a multi-model-based multi-step reinforcement learning framework},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Investigating primacy bias in multi-agent reinforcement learning: An empirical study. <em>TAI</em>, 1-10. (<a href='https://doi.org/10.1109/TAI.2025.3560617'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the past two years, the phenomenon of primacy bias in reinforcement learning has been extensively investigated, sparking discussions within the community regarding the plasticity of reinforcement learning. This study represents the first comprehensive exploration of primacy bias in multiagent reinforcement learning. Building on our previous works, we demonstrate that multi-agent reinforcement learning also encounters the challenge of primacy bias. We then provide a comparative analysis across various settings, including different evaluation methods, the sharing of policy parameters, and the adaptability of decentralized policies. We conducted extensive experiments on multiple multi-agent benchmarks. Our findings reveal specific characteristics of primacy bias in multi-agent learning, showing the difference between them with those in single-agent reinforcement learning. While, we discuss the limitations and challenges encountered when directly applying existing solutions from the reinforcement learning domain to multi-agent scenarios.},
  archive      = {J_TAI},
  author       = {Jingchen Li and Yusen Yang and Ziming He and Huarui Wu and Chunjiang Zhao and Kao-Shing Hwang},
  doi          = {10.1109/TAI.2025.3560617},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Investigating primacy bias in multi-agent reinforcement learning: An empirical study},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced defect detection network: Leveraging large kernel and dynamic task interaction for precise prediction. <em>TAI</em>, 1-12. (<a href='https://doi.org/10.1109/TAI.2025.3609718'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The surface quality of steel directly affects its performance and durability in industrial production. However, traditional deep learning technology struggles to balance performance and efficiency in detecting intricate steel surface flaws. This paper presents an enhanced defect detection network (EDDN) for real-time steel surface defect detection. First, we design a large kernel feature enrichment module (LFEM) to fuse the feature layers with rich detail information, while using continuous large kernel convolution to capture multi-scale features. Notably, a dynamic selection mechanism that adaptively captures significant spatial features on the basis of global information. This design addresses the problem of tiny and complicated target detection failures and significantly increases detection accuracy. In addition, we propose a dynamic task interaction detection head (DT-Head) that balances the detection by enabling the dynamic interaction between the localization and classification tasks. This interaction mechanism allows the two tasks to collaborate better for a more accurate prediction. Finally, extensive experiments on NEU-DET and GC10-DET show that EDDN improves mAP@50 accuracy by 2.9% and 4.6%, achieving detection speeds of 79 and 72 frames per second (FPS), respectively, outperforming current mainstream algorithms in terms of accuracy and efficiency},
  archive      = {J_TAI},
  author       = {Sixian Chan and Qiqi Miao and Yuan Yao and Hongkai Zhang and Zheng Wang and Xiaolong Zhou},
  doi          = {10.1109/TAI.2025.3609718},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Enhanced defect detection network: Leveraging large kernel and dynamic task interaction for precise prediction},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive successor features composition for transfer reinforcement learning. <em>TAI</em>, 1-12. (<a href='https://doi.org/10.1109/TAI.2025.3610392'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transfer reinforcement learning (TRL) aims to build a policy for a unseen target task by reusing previously found optimal policies from a fixed set of source tasks. Successor features (SFs) and Generalised Policy Improvement (GPI) have been adopted as a robust framework to achieve TRL expressing rewards as a linear combination of a shared feature function and a task-specific vector weights. SF-GPI are used for reusing, fast learning, and composing a fixed set of policies derived from SFs through two-level decision-making, which can be understood as a hierarchical method. However, SF-GPI performance on target tasks is related to the distance from the source tasks’ vector weights, limiting their ability to ensure optimal policies for more distant tasks. In this paper, we introduce a novel composition mechanism by defining a new Markov decision process involving high-level states and actions constructed of SFs, resulting in a high-level policy which adaptively selects high-level actions. This approach facilitates knowledge transfer across a varied-distance set of tasks without performance degradation. Finally, we empirically demonstrate that our approach learns and composes SF representations, outperforming SF-GPI by maintaining the performance across a varied-distance set of tasks in 3 widely-used problems in the SFs literature.},
  archive      = {J_TAI},
  author       = {Kiyoshige Garces and Junyu Xuan and Hua Zuo},
  doi          = {10.1109/TAI.2025.3610392},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Adaptive successor features composition for transfer reinforcement learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards vox populi in federated learning: A fair and inclusive client selection framework. <em>TAI</em>, 1-15. (<a href='https://doi.org/10.1109/TAI.2025.3609733'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) enables distributed model training without centralizing raw data, but existing client selection methods frequently marginalize resource-limited devices. To address this imbalance, we propose a novel Stackelberg-game-based framework that shifts decision-making from a server-centric model to a client-to-client paradigm. Resource-rich leaders form coalitions with resource-limited followers, allowing every client, regardless of capacity, to contribute to and benefit from the global model. We further introduce a comprehensive data scoring mechanism that evaluates the quality and diversity of each client’s dataset, ensuring that coalition formation is both fair and inclusive. Experiments on diverse benchmarks demonstrate that our approach outperforms the state-of-the-art, as well as different baselines on multiple metrics while promoting fairness. Our proposed strategy effectively tackles heterogeneous data distributions and uneven resource availability, offering a scalable, equitable solution for real-world FL scenarios.},
  archive      = {J_TAI},
  author       = {Sarhad Arisdakessian and Osama Wehbi and Omar Abdel Wahab and Azzam Mourad and Hadi Otrok},
  doi          = {10.1109/TAI.2025.3609733},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Towards vox populi in federated learning: A fair and inclusive client selection framework},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A simple and effective architecture selection method for differentiable architecture search. <em>TAI</em>, 1-11. (<a href='https://doi.org/10.1109/TAI.2025.3610384'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although differentiable architecture search (DARTS) improves the searching efficiency of neural architecture search (NAS), the widely applied magnitude-based selection method of DARTS can frequently lead to deteriorating architectures with degenerated performance. Most existing works propose to address this issue by improving the supernet’s optimization to guarantee the applicability of the magnitude-based method, while little attention has been paid to the selection criterion to obtain the final architecture. In this brief, we introduce a novel, simple, and effective architecture selection method, Manda (Magnitudes and activations), which estimates the contribution of an operation in an optimized supernet by both its architecture parameter’s magnitude and corresponding generated activation. Notably, Manda can effectively address the notorious degeneration issue in DARTS without any modification of the supernet’s optimization procedure, indicating the instability in DARTS can be attributed to the widely applied magnitude-based selection method. The experimental results on both NAS-Bench-201 and DARTS search spaces show the effectiveness of our method.},
  archive      = {J_TAI},
  author       = {Boxu Chen and Le Yang and Ziwei Zheng and Fan Li and Shiji Song and Gao Huang and Chao Shen},
  doi          = {10.1109/TAI.2025.3610384},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {A simple and effective architecture selection method for differentiable architecture search},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Empowering traditional ensemble learning through feature learning and wavelet transforms for environmental analysis. <em>TAI</em>, 1-15. (<a href='https://doi.org/10.1109/TAI.2025.3611909'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid expansion of urbanization and industrial activities has significantly increased atmospheric pollutants, posing critical risks to environmental sustainability and public health. To mitigate this issue, innovative and accurate air quality forecasting tools are essential to enable effective pollution monitoring and management. This study presents SR-ViT-FEL, an innovative deep-learning-based framework designed to enhance air quality forecasting by accurately predicting daily pollutant levels, such as carbon monoxide, by concurrently analyzing different environmental factors. The approach integrates time and frequency domain analyses via Continuous Wavelet Transform and employs a novel ensemble learning strategy that integrates multi-level features extracted from both convolutional and transformer-based architectures. SR-ViT-FEL achieves superior predictive accuracy and adaptability when compared to various traditional monitoring settings. The findings indicate that SR-ViT-FEL not only improves predictive performance but also offers scalability for broader air quality monitoring applications, potentially reducing costs by accurately estimating multiple air quality parameters with fewer physical sensors.},
  archive      = {J_TAI},
  author       = {Pietro Manganelli Conforti and Pietro Nardelli and Andrea Fanti and Paolo Russo},
  doi          = {10.1109/TAI.2025.3611909},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Empowering traditional ensemble learning through feature learning and wavelet transforms for environmental analysis},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inter-class and intra-class relationships incorporated knowledge distillation for continual learning. <em>TAI</em>, 1-10. (<a href='https://doi.org/10.1109/TAI.2025.3611366'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continual learning enables models to learn sequentially from a stream of tasks while retaining previously acquired knowledge. However, current methods lack the attention of tasks with different categories, as new task is introduced, models often adjust their internal representations to accommodate the new knowledge, which leads to decision boundary shifts and catastrophic forgetting, limiting the performance of continual learning methods. To address these limitations, this paper proposes continual learning with inter-class and intraclass relationships incorporated knowledge distillation (2ICL). The inter-class ensures stable decision boundaries by capturing the relative positioning between task categories. Intra-class relationships preserve internal coherence within each class to enhance generalization. Furthermore, 2ICL incorporates a dynamically expandable representation, enabling it to expand its feature space as new tasks are added while retaining old and new knowledge. Experiments conducted on CIFAR-10, CIFAR-100, and Pathmnist datasets demonstrate that 2ICL not only significantly alleviates catastrophic forgetting but also maintains high accuracy across tasks.},
  archive      = {J_TAI},
  author       = {Qingya Sui and Lin Zhong and Lianbo Ma and Ziqian Wang and Zhenyu Lei and Shangce Gao},
  doi          = {10.1109/TAI.2025.3611366},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Inter-class and intra-class relationships incorporated knowledge distillation for continual learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic belief rule learning for classification with expert in the loop. <em>TAI</em>, 1-15. (<a href='https://doi.org/10.1109/TAI.2025.3612317'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The belief rule-based classification system (BRBCS) has been explored as an effective and promising framework for designing classifiers, owing to its ability to create user-friendly linguistic models and handle different types of uncertainty. Nevertheless, current BRBCSs operate in a static manner, which restricts their use in dynamic classification environments. To this end, the paper develops a dynamic belief rule-based classification system (DBRBCS) by dynamically learning belief rules with an expert in the loop. First, a compact and interpretable model of the initial belief rule is constructed using the existing labeled data. Then, an algorithm for updating the belief rule base is developed to modify the rule parameters or add/delete rules from the rule base based on the sequential data and the labels fed by the expert. The proposed method can well address the dynamic classification tasks such as changes of feature distributions, emergence of new categories, and extinction of old categories. A case study of target classification and the comparative experiments with representative classification methods demonstrate the superiority of the proposed DBRBCS for various dynamic classification tasks.},
  archive      = {J_TAI},
  author       = {Lianmeng Jiao and Xianggang Ma and Han Zhang and Jiawei Wu and Haonan Ma},
  doi          = {10.1109/TAI.2025.3612317},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Dynamic belief rule learning for classification with expert in the loop},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online multi-label streaming feature selection based on agglomeration degree and local-global correlation. <em>TAI</em>, 1-15. (<a href='https://doi.org/10.1109/TAI.2025.3612314'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, multi-label streaming feature selection is receiving increasing attention in various applications. Considering label correlation is a common approach in the field of multi-label streaming feature selection to improve algorithm performance. Researchers commonly explore label relationship through label clustering, a method widely adopted in theoretical and practical domains. However, existing studies only focus on the global semantic structure of the entire label set, overlooking the local semantic structure within label cluster. To address this issue, this paper proposes a novel feature evaluation function that simultaneously considers agglomeration degree and local-global correlation. Firstly, we introduce agglomeration degree to explore the local semantic structure of intra-luster labels and accordingly weight different clusters. Furthermore, we design an intra-cluster label weight calculation method that leverages the high correlation characteristics of intra-cluster labels. Additionally, this algorithm also takes into account the local relevance among labels and the global relevance among features. Finally, we integrate this feature evaluation function into the multi-label streaming feature selection framework. Through online significance analysis, online correlation analysis, and online redundancy analysis, we effectively filter irrelevant and redundant features, retaining those critical for label identification. Experimental results indicate that the proposed method outperforms other compared representative online and offline multi-label feature selection methods.},
  archive      = {J_TAI},
  author       = {Qiang Li and Wenhai Yang and Jianhua Dai},
  doi          = {10.1109/TAI.2025.3612314},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Online multi-label streaming feature selection based on agglomeration degree and local-global correlation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TransWaveNet: Transformer for underwater image restoration with wavelets. <em>TAI</em>, 1-11. (<a href='https://doi.org/10.1109/TAI.2025.3613670'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater image restoration aims to improve the quality and visibility of images taken in underwater environments. These images find application in diverse fields like marine biology research, underwater archaeology, environmental monitoring, surveillance tasks, and offshore infrastructure inspection. However, the complexities of the underwater environment make these applications challenging, as light scattering and absorption cause blur, color cast, and reduced contrast in images. With the promising results on restoring underwater degraded images, existing approaches limit their performance in case of the above-mentioned complex and nonlinear degradation. In this research work, we propose a multi-directional wavelet coefficient space transformer model for underwater image deblurring and color restoration. Incorporating an attention mechanism within transformed spaces, our model dynamically adapts to underwater degradation. Additionally, we introduce a wavelet attention fusion transformer block for attention computation in the wavelet coefficient space, along with an edge-preserving wavelet down-sampling block to retain fine details and textures during downsampling. A thorough assessment of our method on real-world (UCCS, U45, SQUID) and synthetic (UIEB, UCDD) datasets, along with profound ablation studies, validates its edge over existing techniques. Further, we have evaluated our method for tasks such as depth estimation, and low-light enhancement and deblurring, demonstrating its versatility and broad applicability across various image processing tasks. The code is made available at: https://github.com/Priyanka01mishra/TransWaveNet.},
  archive      = {J_TAI},
  author       = {Priyanka Mishra and MD Raqib Khan and Shruti S. Phutke and Santosh Kumar Vipparthi and Subrahmanyam Murala},
  doi          = {10.1109/TAI.2025.3613670},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {TransWaveNet: Transformer for underwater image restoration with wavelets},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable and position-aware learning in digital pathology. <em>TAI</em>, 1-10. (<a href='https://doi.org/10.1109/TAI.2025.3613475'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to their gigapixel resolutions, whole slide images (WSIs) pose significant computational challenges when using traditional machine learning approaches. Representing WSIs as graphs is a promising solution, allowing the entire image to be processed effectively using graph-based learning. In this approach, WSIs are divided into smaller patches, each serving as a node in the graph, with edges representing relationships between different patches. However, existing graph learning methods primarily rely on message passing between neighboring nodes and often neglect the position of patches in WSIs. As a result, patches located in topologically similar neighborhoods may produce nearly indistinguishable embeddings, reducing model discriminability. To address this limitation, a graphbased framework is introduced for cancer classification in WSIs, incorporating positional embeddings through spline-based convolutional neural networks and graph attention mechanisms. This approach captures both structural and spatial context, enhancing classification accuracy. Evaluation on WSI datasets for prostate and kidney cancer grading demonstrates improved performance compared to other approaches. In addition to classification, model interpretability is emphasized. A gradient-based saliency mapping technique is employed to identify and visualize the regions within WSIs that contribute most to the diagnostic predictions, thereby enhancing the explainability of the proposed method and supporting clinical decision-making.},
  archive      = {J_TAI},
  author       = {Milan Aryal and Nasim Yahya Soltani and Masoud Ganji},
  doi          = {10.1109/TAI.2025.3613475},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Explainable and position-aware learning in digital pathology},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Point cloud simplification method based on frequency domain coding. <em>TAI</em>, 1-16. (<a href='https://doi.org/10.1109/TAI.2025.3613685'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of intelligent construction, three-dimensional (3D) point cloud data (PCD) simplification has played an important role in back-end scenario analysis, reducing the computational and storage burden. However, the existing simplification methods are not applicable to the modeling analysis tasks in the architecture, engineering and construction industry. To address this issue, this study proposes a new simplification method, named as the frequency domain coding-based maximum difference simplification (FDCMDS). The FDCMDS is able to convert PCD into frequency domain multidimensional features to capture fine-grained structural variations of PCD. To improve the simplification efficiency, a 3D Canny key point detection combined with PCD gradient is proposed as a key point extraction module. Finally, a method for evaluating PCD density is designed by combining existing metrics. The validation experiments on PCD with different density distributions and volumes prove the effectiveness and feasibility of the proposed method.},
  archive      = {J_TAI},
  author       = {Zhou Wu and Tianze Chen and Dongsheng Li and Jiepeng Liu and Hongxu Wang and Pengkun Liu and Yuancheng Qi},
  doi          = {10.1109/TAI.2025.3613685},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Point cloud simplification method based on frequency domain coding},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modality-specific knowledge distillation with wasserstein distance minimization for vision-language pretrained models. <em>TAI</em>, 1-13. (<a href='https://doi.org/10.1109/TAI.2025.3613686'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The vast costs of storage and computational resources raise obstacles to deploying vision-language pretrained models (VL-PTMs) on resource-constrained devices for services computing. To compress these models, recent studies have suggested using knowledge distillation (KD) to train a compact student model under the supervision of a complicated teacher model. A critical issue of the KD methods is one-to-one layer mapping, where each student layer can be distilled only by one specific teacher layer. In addition, different modality features contain different amounts of knowledge, which may lead to an imbalanced distribution of different modalities such that the dominant modality will overwhelm the minor modalities. This study proposes a modality-specific knowledge distillation (MKD) by minimizing the Wasserstein distance for a vision-language pretrained model. Instead of empirically finding the one-to-one layer mapping, the proposed MKD performs a many-to-many layer mapping strategy, where each layer of the student model has a chance to learn from different intermediate layers of the teacher model. To balance the distribution between modalities, we used two extra inputs (text-only and image-only), and two auxiliary loss objectives to encourage more effective distillation. Experiments conducted on four multimodal tasks demonstrate the effectiveness of the proposed MKD with Wasserstein distance minimization for compressing vision-language pretrained models.},
  archive      = {J_TAI},
  author       = {Lung-Hao Lee and Hsiu-Min Shih and Jin Wang},
  doi          = {10.1109/TAI.2025.3613686},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Modality-specific knowledge distillation with wasserstein distance minimization for vision-language pretrained models},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EEGcMamba: EEG clustering via state space model. <em>TAI</em>, 1-15. (<a href='https://doi.org/10.1109/TAI.2025.3614230'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalography (EEG) is extensively employed for supervised analysis across various scenarios, including disease diagnosis, neurocognition, and brain-computer interfaces. It has heightened the demand for effective EEG labeling. However, the manual labeling process is labor-intensive and time-consuming. Furthermore, there are few studies that attempt to decode information from EEG in an unsupervised manner using deep learning. In this paper, we present a novel end-to-end EEG clustering approach via a state space model (SSM), termed EEGcMamba. EEGcMamba introduces a universal backbone, BrainMamba, for EEG feature learning, and incorporates both a weighted instance-level contrast head and a dual-branch cluster-level contrast head for contrastive learning. Specifically, BrainMamba utilizes a slice-aware scanning mechanism to input segmented EEG slices through multiple sequences, capturing fine-grained contextual connections between slices. To mitigate risks of pushing similar EEG samples apart further in the embedding space, we introduce weight terms from the data space during calculating the instance-level contrastive losses. Furthermore, in the cluster-level contrast head, the assignment-discrimination branch accounts for the clustering distribution consistency, while the semantic-aware branch employs pseudo-labeling semantics to establish group-instance discrimination. Extensive experiments on 11 EEG benchmark datasets demonstrate the superiority of EEGcMamba over existing advanced methods. The code will be available at Github.},
  archive      = {J_TAI},
  author       = {Junfu Chen and Dechang Pi and Xiaoyi Jiang and Feng Gao and Qiao Yang and Yang Chen},
  doi          = {10.1109/TAI.2025.3614230},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {EEGcMamba: EEG clustering via state space model},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards generalizable meta-deep reinforcement learning algorithm for multi-objective traveling salesman problems. <em>TAI</em>, 1-15. (<a href='https://doi.org/10.1109/TAI.2025.3614210'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multi-objective traveling salesman problem (MOTSP) is a representative class of multi-objective combinatorial optimization problems, with significant implications for both theoretical research and practical applications. Although deep reinforcement learning (DRL) has shown promise in solving MOTSPs, existing approaches often struggle with generalization to large-scale problem instances. To address this challenge, we propose a novel meta-deep reinforcement learning framework with preference-fused attention networks (MDRL-PFAN). This framework integrates a preference-fused mechanism to jointly encode problem instances and weight preferences into a unified feature space. Moreover, an ensemble meta-learning strategy is adopted to train the meta-model across tasks with varying scales, equipping MDRL-PFAN with robust solving and strong crossscale generalization capabilities. During inference, a lightweight fine-tuning process on small-batch adaptation tasks is employed to further enhance optimization performance. Extensive experiments on diverse MOTSP instances demonstrate that MDRL-PFAN achieves superior performance compared to classic evolutionary algorithms and state-of-the-art DRL algorithms in terms of training efficiency, solution quality, and cross-scale generalization capability.},
  archive      = {J_TAI},
  author       = {Xiaoyu Fu and Shenshen Gu and Chee-Meng Chew and Tengfei Li},
  doi          = {10.1109/TAI.2025.3614210},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Towards generalizable meta-deep reinforcement learning algorithm for multi-objective traveling salesman problems},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Instance-wise joint feature and expert decision acquisition for classification. <em>TAI</em>, 1-15. (<a href='https://doi.org/10.1109/TAI.2025.3614214'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many real–world applications, such as medical diagnosis, financial decision–making, and AI–driven content moderation, obtaining features and expert inputs is both time– consuming and expensive. To address these challenges, we present a supervised learning framework for sequential feature and expert decision acquisition. The objective of this framework, which operates in two phases, is to assign labels to each instance while reducing the cost of acquiring features and requesting experts’ decisions. The process begins with an initial belief about the label of a data instance, and at each step, there is a choice to either stop or continue acquiring features. Once feature acquisition terminates, the framework either assigns a label, or switches to expert decision acquisition, both based on the acquired features. The framework’s performance is evaluated using thirteen publicly available datasets, showing improvements in accuracy while acquiring fewer features and expert decisions on average than baselines. Its generalizability across expert types is demonstrated through experiments using standard supervised learning models, widely–used ensemble methods, and neural networks as experts, highlighting its broad applicability across domains.},
  archive      = {J_TAI},
  author       = {Sachini Piyoni Ekanayake and Daphney-Stavroula Zois and Nipun Dulantha Wickramasinghe},
  doi          = {10.1109/TAI.2025.3614214},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Instance-wise joint feature and expert decision acquisition for classification},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CIGformer: Leveraging continuous information guidance in transformer-based pansharpening. <em>TAI</em>, 1-15. (<a href='https://doi.org/10.1109/TAI.2025.3614584'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pansharpening has been a critical area of interest. However, current methods often fail to fully leverage the correlation between Panchromatic (PAN) and Multispectral (MS) images, resulting in spatial and spectral information loss. Additionally, uniform processing across different scales can cause information interference. We introduce CIGformer, a multi-scale fusion network utilizing a continuous information guidance mechanism to tackle these issues. Our approach introduces an Intensity Substitute Block (ISB) to separate shared and unique features of PAN and MS, setting the stage for subsequent guidance. The core component, an Information Guidance Block (IGB) based on Transformer architecture, ensures adaptive retention of unique information while utilizing shared information. Furthermore, our multi-level Encoder-Decoder bidirectional pyramid structure minimizes multi-scale information mixing, with IGB applied at each encoder level for optimal information use. A consistency loss function is also introduced to enhance training by assessing unique information retention. Our method significantly enhances the efficiency of using PAN and MS images through distinctive information guidance, as demonstrated by experiments on the GaoFen-1, GaoFen-2, and WorldView-3 datasets.},
  archive      = {J_TAI},
  author       = {Hao Zhu and Yuan Wang and Xiaotong Li and Biao Hou and Bo Ren and Yifan Meng and Kefan Chen and Licheng Jiao},
  doi          = {10.1109/TAI.2025.3614584},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {CIGformer: Leveraging continuous information guidance in transformer-based pansharpening},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generative models for time series anomaly detection: A survey. <em>TAI</em>, 1-21. (<a href='https://doi.org/10.1109/TAI.2025.3614213'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series anomaly detection (TSAD) is a fundamental practice in information management, aimed at identifying unusual patterns in temporal datasets. This process is critical to maintaining the integrity and reliability of systems. Recently, generative models have significantly advanced the capabilities of artificial general intelligence, presenting novel methodologies to understand and interpret complex data structures. In this review, we examine the latest advancements in applying generative models to TSAD and highlight how these models present a paradigm shift in detecting and analyzing anomalies within sequential data. In particular, we first present the background information, including definitions of key concepts, a taxonomy of anomaly types, and the distinction between generative and discriminative models in time series data. Then, we investigate a range of generative models, offering mathematical summaries of the predominant techniques in TSAD. Furthermore, we provide a summary of the datasets and propose recommendations for appropriate generative methods tailored to various application domains. Finally, we address the significant challenges in current research and propose potential directions for future study.},
  archive      = {J_TAI},
  author       = {Jie Cao and Jiawei Miao and Haicheng Tao and Youquan Wang and Jia Wu and Zidong Wang and Xindong Wu},
  doi          = {10.1109/TAI.2025.3614213},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  pages        = {1-21},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Generative models for time series anomaly detection: A survey},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards quantum image generation on single qubit using quantum information bottleneck. <em>TAI</em>, 1-12. (<a href='https://doi.org/10.1109/TAI.2025.3615187'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Amidst the rapidly evolving landscape of information technology, the convergence of quantum computing and machine learning—referred to as quantum machine learning—offers promising potential to enhance classical algorithms. However, significant challenges remain in both hardware and software implementation during the Noisy Intermediate-Scale Quantum (NISQ) era, including imperfect qubits, architectural constraints, and high noise levels. In response to these obstacles, this research introduces a novel solution: Quantum Convolutional Variational Autoencoders (QCVAE), designed to operate with only a single qubit. This innovative approach efficiently utilizes a single qubit to manage large-scale data, making it particularly well-suited for quantum computers with limited resources. Simulation results demonstrate the robustness of QCVAE in handling image data, and its deployment on a real quantum computer showcases the model’s practical viability. Additionally, the proposed approach leverages the information bottleneck principle to optimize quantum embeddings, effectively mitigating the impact of prevalent quantum noise. By addressing these core challenges, QCVAE presents a compelling solution for advancing quantum computing applications within the constraints of current NISQ technology.},
  archive      = {J_TAI},
  author       = {Yijie Zhu and Vaneet Aggarwal and Debanjan Konar and Yuri Pashkin and Plamen Angelov and Richard Jiang},
  doi          = {10.1109/TAI.2025.3615187},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Towards quantum image generation on single qubit using quantum information bottleneck},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ILVMamba: Illumination-aware lightweight visual mamba framework for efficient high-resolution image enhancement. <em>TAI</em>, 1-13. (<a href='https://doi.org/10.1109/TAI.2025.3595115'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world image quality is often degraded by suboptimal lighting conditions, such as low light and vignetting. With advancements in sensor technology, there is an increasing demand for efficient algorithms capable of processing high-resolution images. However, existing approaches primarily focus on low-resolution data or require significant computational resources for high-resolution processing. To address these challenges, we propose a lightweight framework, ILVMamba, specifically designed for high-resolution image restoration under adverse lighting conditions. We introduce Illumination-aware Visual Mamba Blocks (IVMBs), which are developed based on the Retinex theory. These IVMBs efficiently utilize illumination information to enhance image feature representation. Additionally, IVMBs integrate Mamba2 to reduce model complexity while preserving reliable performance on large-scale images. We conduct extensive experiments on various high-resolution datasets, including UHD-LOL4K for low-light enhancement and VigSet for vignetting removal. The results indicate that ILVMamba demonstrates competitive performance on public high-resolution benchmarks while maintaining low model complexity. Additionally, our method also shows superior performance on public low-resolution datasets. https://github.com/MingyuLiu1/ILVMamba.git},
  archive      = {J_TAI},
  author       = {Mingyu Liu and Jiong Xu and Yuning Cui and Xiaobin Hu and Leah Strand and Huilin Yin and Alois C. Knoll},
  doi          = {10.1109/TAI.2025.3595115},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {8},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {ILVMamba: Illumination-aware lightweight visual mamba framework for efficient high-resolution image enhancement},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Educational knowledge graph question answering: Insights from benchmarks and LLM-based solutions. <em>TAI</em>, 1-10. (<a href='https://doi.org/10.1109/TAI.2025.3595531'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Educational question answering plays an extremely important role in online education all over the world. Among these, Educational Knowledge Graph Question Answering (EKGQA) focuses on extracting knowledge from the educational knowledge base to answer educational questions. Although some work has been done, the scarcity of the real Chinese annotated dataset has restricted the development of EKGQA. Unlike current datasets where the questions are direct, educational questions asked by learners may involve diverse, mixed cognitive expressions and language styles due to differences in personal experiences, cultural backgrounds, and cognitive levels. To address these issues, in this paper, we proposed to benchmark such challenges for EKGQA by establishing a more realistic dataset EDUCEQ. It contains 236.3k questions in 12 categories. Compared with existing datasets, EDUCEQ features two more authentic features - diverse cognitive expressions and various language styles. Additionally, we have conducted an in-depth evaluation of the EDUCEQ dataset and developed a robust LLM-based EKGQA method that established competitive benchmarks for future research. EDUCEQ is the first dataset to portray a more realistic view of educational phenomena from a cognitive and computational linguistics perspective, which is beneficial to educational knowledge graph question answering, AI4Education and also the online education field in general.},
  archive      = {J_TAI},
  author       = {Runhao Zhao and Weixin Zeng and Jiuyang Tang and Feng Tian and Xiang Zhao},
  doi          = {10.1109/TAI.2025.3595531},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {8},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Educational knowledge graph question answering: Insights from benchmarks and LLM-based solutions},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A local 2-order mutual information metric approach for service community detection in complex service networks. <em>TAI</em>, 1-14. (<a href='https://doi.org/10.1109/TAI.2025.3595107'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel local 2-order mutual information metric (L2oMI) approach for service community detection, addressing the limitations of traditional methods in dealing with large scale and complex service networks. Firstly, a local 2-order mutual information metric module is proposed to measure the inner-distance between each pair of service stations from different-sized receptive fields in complex service networks, based on which useful semantic node embeddings are obtained for service community detection. Next, a multi-order subgraph information bottleneck for topology module is introduced for the L2oMI approach as a topology constraint to improve the effectiveness of node embedding. Furthermore, a hierarchical interaction learning module is proposed to learn the complicated interactions between pairs of service station and to encode their node features in complex service networks. Numerical experiments using several service network datasets demonstrate the efficacy of the proposed approach.},
  archive      = {J_TAI},
  author       = {Kexin Zhang and Qing Gao and Jinhu Lü and Maciej Ogorzaek and Yue Deng},
  doi          = {10.1109/TAI.2025.3595107},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {8},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {A local 2-order mutual information metric approach for service community detection in complex service networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid ResNet-ViT transfer learning approach for brain stroke classification on computed tomography images. <em>TAI</em>, 1-15. (<a href='https://doi.org/10.1109/TAI.2025.3596534'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the utilization of a hybrid Convolutional Neural Network (CNN) and Vision Transformer (ViT) model, employing transfer learning methods, to enhance brain stroke detection and classification of CT images. The objective is to integrate ResNet-101’s local feature extraction capabilities with ViT’s global context comprehension to develop a resilient model for precise detection and categorization of brain strokes using non-contrast-enhanced brain computed tomography (NCCT) data. Data from two hospitals in Sri Lanka comprising 11,300 images were retrospectively collected. ViT and ResNet-101 architectures were modified for multi-class classification of brain normal, ischemic, and hemorrhagic conditions, and further differentiated ischemic acute, subacute, and chronic conditions in two-step ways including two models of the proposed architecture. We developed two models, incorporating the ResNet-101 component with MC dropout layer and a fully connected layer by removing the final two layers and the ViT component modifying multi-layer perceptron, incorporating three classes by adding a fully connected layer. The proposed model 01 training, and testing accuracy were 99.69%, 99.16% whereas model 02 achieved 97.31%, and 95.33% respectively. The hybrid models offer a robust method for impartial stroke diagnosis, potentially enabling tailored treatment approaches based on stroke type and severity. Further validation of the proposed approach on larger and more diverse datasets in clinical settings is required.},
  archive      = {J_TAI},
  author       = {Chathura D. Kulathilake and Jeevani Udupihille and Atsushi Senoo},
  doi          = {10.1109/TAI.2025.3596534},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {8},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Hybrid ResNet-ViT transfer learning approach for brain stroke classification on computed tomography images},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Topic-aware multi-heterogeneous graph neural network for predicting the next participant in information cascades. <em>TAI</em>, 1-14. (<a href='https://doi.org/10.1109/TAI.2025.3596930'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting the next participant in an information cascade on social networks has always been an open problem. Recently, graph neural networks (GNN) have been demonstrated to be one of the most effective schemes to handle this task. The GNN improves users’ representations by aggregating the representations of the users followed directly or indirectly by them in the social network. In contrast, these links are only one type of pathway for users to receive information. There are yet information propagation channels between disconnected users. Previous studies on the information propagation channels are limited, let alone a deep learning framework utilizing them for participant prediction. Inspired by these facts, we first mine the hidden information propagation channels from users’ tweets in cascades and construct a multi-heterogeneous graph by combining these channels with the following links. Subsequently, we propose a Topic-aware Multi-heterogeneous Graph Neural Network (TMGNN) model to exploit the extended channels for learning user representations. We learn the attention among users’ extended neighbors on a particular topic and integrate topic-aware attention to tackle the task in cascades involving unknown topics. Extensive experimental results on two publicly available datasets show that the TMGNN achieves a relative improvement of over 15% against the best performance of the tested state-of-the-art models in terms of MAP@10, demonstrating its generalizability and robustness. Code for this study is publicly available at https://github.com/william-wang-stu/TMGNN.},
  archive      = {J_TAI},
  author       = {Yichao Zhang and Zejian Wang and Guanghui Wen and Jihong Guan and Shuigeng Zhou and Wengen Li and Zhiwei Cao},
  doi          = {10.1109/TAI.2025.3596930},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {8},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Topic-aware multi-heterogeneous graph neural network for predicting the next participant in information cascades},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prompt-aware adapter: Learning adaptive visual tokens for multimodal large language models. <em>TAI</em>, 1-10. (<a href='https://doi.org/10.1109/TAI.2025.3596925'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To bridge the gap between vision and language modalities, Multimodal Large Language Models (MLLMs) usually learn an adapter that converts visual inputs to understandable tokens for Large Language Models (LLMs). However, most adapters generate consistent visual tokens, regardless of the specific objects of interest mentioned in the prompt. Since these adapters distribute equal attention to every detail in the image and focus on the entire scene, they may increase the cognitive load for LLMs, particularly when processing complex scenes. To alleviate this problem, we propose prompt-aware adapters. These adapters are designed with the capability to dynamically embed visual inputs based on the specific focus of the prompt. Specifically, prompt-aware adapters utilize both global and local textual features to capture the most relevant visual clues from the prompt at both coarse and fine granularity levels. This approach significantly enhances the ability of LLMs to understand and interpret visual content. Experiments on various visual question answering tasks, such as counting and position reasoning, demonstrate the effectiveness of prompt-aware adapters. Code is at: https://github.com/YueCheong/prompt-aware-adapter.},
  archive      = {J_TAI},
  author       = {Yue Zhang and Hehe Fan and Wei Ji and Yongkang Wong and Roger Zimmermann and Yi Yang},
  doi          = {10.1109/TAI.2025.3596925},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {8},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Prompt-aware adapter: Learning adaptive visual tokens for multimodal large language models},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Direct learning of neuronal firing representations for long-term motor intent predictions. <em>TAI</em>, 1-12. (<a href='https://doi.org/10.1109/TAI.2025.3597271'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate hand movement prediction plays a pivotal role in advancing robotic control technologies. Neuronal firing signals, as the driving representation of motor intentions, offer a physiologically meaningful approach to decode motor commands. These representations are typically extracted using blind source separation techniques. However, the high computational intensity of these methods limits practical applications. Therefore, we directly learned neuronal firing representations from surface electromyogram (sEMG) signals via an efficient deep forest (DF) framework. Specifically, we first obtained populational neuronal firing rate signals as the ground truth. The DF model was trained to map sEMG signals directly to populational neuronal firing rate. To enable robust and continuous finger force predictions, we evaluated the DF framework on data obtained across multiple sessions, with an average session interval of 6.58 days. Our results revealed that the DF framework accurately maps sEMG amplitudes to neuronal firing representations, achieving comparable accuracy to source-separation-based method with significantly reduced computational time. The developed DF model also outperformed neural network models and other decision-tree-based ensemble methods. Furthermore, despite utilizing the same input features, the DF framework significantly outperformed the sEMG-amplitude approach, showcasing its capacity to capture complex neural drive information for more accurate finger force predictions. Moreover, the robustness test against noise interference revealed that the DF framework maintained stable performance under different noise levels. These findings highlight the potential of DF framework as an efficient solution for real-time robotic control applications.},
  archive      = {J_TAI},
  author       = {Long Meng and Xiaogang Hu},
  doi          = {10.1109/TAI.2025.3597271},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {8},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Direct learning of neuronal firing representations for long-term motor intent predictions},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing successive over-relaxation Q-learning with deterministic perturbation gradient search. <em>TAI</em>, 1-14. (<a href='https://doi.org/10.1109/TAI.2025.3597581'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Successive Over-Relaxation Q-learning (SOR-QL) has been proposed recently as an alternative to the widely popular Q-learning algorithm as it is seen to provide better performance where applicable. However, several limitations exist in SOR-QL that make the algorithm less useful in real-world applications. In particular, SOR-QL requires knowledge of transition probabilities and a constraining requirement of having a positive probability of self-transition to each state. Further, the actual parameter utilized in SOR-QL is kept below an unknown optimal threshold. In order to overcome these limitations, we propose an optimized variant of SOR-QL that optimizes its associated relaxation parameter directly. Our algorithm does not make use of transition probabilities at all and directly optimizes the relaxation parameter. Further, we do not impose the aforementioned special structure on the transition probabilities. Our resulting proposed algorithm is a purely data-driven, two-timescale stochastic approximation scheme, where on the slower timescale, the relaxation parameter in SOR-QL is updated, and on the faster timescale, the SOR-QL update is performed. We prove the asymptotic convergence of our algorithm. Further, experimental results demonstrate the superiority of our algorithm over various existing state-of-the-art algorithms as it achieves better computational time in the majority of the cases and the least cost (as an error) performance. Our algorithm outperforms the next best-performing algorithm in terms of average error and standard error metrics by two to six times and three to ten times, respectively, across different RL environments.},
  archive      = {J_TAI},
  author       = {Lakshmi Mandal and Shalabh Bhatnagar},
  doi          = {10.1109/TAI.2025.3597581},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {8},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Optimizing successive over-relaxation Q-learning with deterministic perturbation gradient search},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature transformation for fast and efficient learning in near-field source localization. <em>TAI</em>, 1-12. (<a href='https://doi.org/10.1109/TAI.2025.3597585'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work develops an efficient and fast learning method for near-field acoustic source localization using the spherical harmonics (SH) feature transformation. The SH features are derived through the SH decomposition of the microphone array recordings. However, these SH features are often impaired by noise, interference, and reverberation, hindering localization accuracy. In this context, we proposed a feature transformation that leverages the signal subspace of the SH decomposed signals. The feature transformation reduces the irregularities in decomposed SH parameter in the noisy and reverberate condition. Therefore, the proposed subspace based feature captures significant directional and range-dependent cues for localization and enhances the training performance and accuracy with fewer epochs. The efficacy of this fast learning approach is demonstrated using convolutional neural network (CNN) training to map the input features to localization classes. The performance of the proposed approach is evaluated through exhaustive simulation and experiments and compared with the previous methods.},
  archive      = {J_TAI},
  author       = {Priyadarshini Dwivedi and Gyanajyoti Routray and Rajesh M Hegde},
  doi          = {10.1109/TAI.2025.3597585},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {8},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Feature transformation for fast and efficient learning in near-field source localization},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PipeMamba: State space model for efficient video-based sewer defect classification. <em>TAI</em>, 1-15. (<a href='https://doi.org/10.1109/TAI.2025.3597580'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the community of sewer pipe defect analysis, CNN-based methods have suffered from modeling the long-range dependencies in the long-sequence videos, such as closed-circuit television (CCTV-) and quick-view (QV)-based videos, resulting in the suboptimal performance. Besides, Transformer-based methods are limited in the real-time applications due to their high computational complexity during the inference. Recently, Mamba-based methods have performed the significant capability with a trade-off between accuracy and efficiency, which present a promising direction for modeling an efficient defect inspection method. Nevertheless, directly adapting Mamba to sewer pipe defect inspection achieves a poor performance, since the multi-focus complementarity of representing the sewer defects is ignored, and the bidirectional scan method disrupts the spatial and semantic continuity of the sewer pipes. To address these challenges, we propose a method for the video-based sewer pipe defect classification using a state space model, namely PipeMamba. Specifically, a flow-based selection module (FSM) is designed to split the sewer video into the long-focus and shortfocus segments, where the multi-focus segments can be modeled to represent the multi-scale information of sewer defects. Then, a novel circle scan strategy (CSS) is proposed to specify the appearances of the sewer pipes, which aims to capture the sewer defects efficiently without disrupting the semantic consistency and spatial continuity of the sewer pipes. Extensive experiments conducted on the public benchmark demonstrate the superiority of PipeMamba, which achieves the inference speed nearly 3 to 7 times faster than the Transformer-based methods, while maintaining high classification performance. Code is available at: https://anonymous.4open.science/r/PipeMamba-3637.},
  archive      = {J_TAI},
  author       = {Chenyang Zhao and Chuanfei Hu and Hang Shao and Jingtai Liu},
  doi          = {10.1109/TAI.2025.3597580},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {8},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {PipeMamba: State space model for efficient video-based sewer defect classification},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diffusion-assisted distillation for self-supervised graph representation learning with MLPs. <em>TAI</em>, 1-12. (<a href='https://doi.org/10.1109/TAI.2025.3598791'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For large-scale applications, there is growing interest in replacing Graph Neural Networks (GNNs) with lightweight Multi-Layer Perceptrons (MLPs) via knowledge distillation. However, distilling GNNs for self-supervised graph representation learning into MLPs is more challenging. This is because the performance of self-supervised learning is more related to the model’s inductive bias than supervised learning. This motivates us to design a new distillation method to bridge a huge capacity gap between GNNs and MLPs in self-supervised graph representation learning. In this paper, we propose Diffusion-Assisted Distillation for Self-supervised Graph representation learning with MLPs (DAD-SGM). The proposed method employs a denoising diffusion model as a teacher assistant to better distill the knowledge from the teacher GNN into the student MLP. This approach enhances the generalizability and robustness of MLPs in self-supervised graph representation learning. Extensive experiments demonstrate that DAD-SGM effectively distills the knowledge of self-supervised GNNs compared to state-of-the-art GNN-to-MLP distillation methods. Our implementation is available at https://github.com/SeongJinAhn/DAD-SGM.},
  archive      = {J_TAI},
  author       = {Seong Jin Ahn and Myoung-Ho Kim},
  doi          = {10.1109/TAI.2025.3598791},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {8},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Diffusion-assisted distillation for self-supervised graph representation learning with MLPs},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stop rumors fast: A multi-objective blocking approach with deep reinforcement learning in social networks. <em>TAI</em>, 1-13. (<a href='https://doi.org/10.1109/TAI.2025.3597883'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rumor blocking approaches in social networks aim to identify a small set of counter-rumor seed nodes to quickly stop the propagation of rumors. Existing solutions predominantly focus on minimizing the influence of rumor propagation (i.e., the number of affected nodes), while treating transmission time as a constraint rather than an optimization objective, despite its critical importance in real-world scenarios. In this view, we firstly elaborate on a multi-objective rumor blocking optimization problem, which strives to simultaneously minimize the influence of rumor propagation and the transmission time, that is, to stop the rumor propagation in the shortest possible time. Then, we further propose a Continuous-Time Competitive Cascading (CTCC) model, which, adapted from the independent cascading model, introduces the concept of transmission time and the competitions between nodes, and characterizes the influence process of different nodes as a continuous process. Besides, to tackle the multi-objective rumor blocking problem, we design a Reinforcement Learning approach with Graph Convolution network (denoted as RLGC) to effectively select counter-rumor seed nodes. Extensive experimental results on three real datasets validate that RLGC can consistently perform better than representative, state-of-the-art baselines regarding both the two objectives (i.e., rumor influence strength and transmission time).},
  archive      = {J_TAI},
  author       = {Zhen Tang and Qiang He and Runze Jiang and Zelin Zhang and Hui Fang and Xingwei Wang and Lianbo Ma},
  doi          = {10.1109/TAI.2025.3597883},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {8},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Stop rumors fast: A multi-objective blocking approach with deep reinforcement learning in social networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ICC: Intra-cluster contraction for pedestrian anomaly detection under one-class classification setting. <em>TAI</em>, 1-12. (<a href='https://doi.org/10.1109/TAI.2025.3601079'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video anomaly detection (VAD) focuses on identifying unusual or unexpected events within video sequences. However, fully supervised learning approaches are ill-suited for this task because of the scarcity of anomaly examples. To tackle this challenge, one-class classification (OCC) has emerged as an effective solution for VAD. Under the OCC framework, the training phase requires only normal samples to build a detection model. Therefore, the core of VAD in the OCC setting lies in effectively modeling the normality of pedestrian behaviors during training. Recent studies often rely on appearance features for accurate feature modeling. Nevertheless, an over reliance on appearance-only features makes the detection system insensitive to pedestrian movement anomalies. In this study, we combine general scene-appearance features with a simple velocity representation derived from optical flow to achieve high-performance VAD. We posit that velocity information, when combined with a well-designed distribution modeling, can effectively describe pedestrian activities. Given the diversity of normal pedestrian motion, we employ a multi-modal probabilistic model to learn the distribution of velocity normality during training. Directly fitting on the original velocity features, however, leads to mixed clusters and dispersed cluster boundaries. This impedes the separation between normal and abnormal samples. To address this, we propose an Intra-Cluster Contraction (ICC) module. The ICC maps the extracted features to the neighborhoods of their local high-density centers, forcing more compact local clusters. This significantly enhances the distinction between normal and abnormal samples. For deep scene-appearance features, we also apply the ICC to adjust the feature distribution and design a distance-based density estimator to detect appearance anomalies. Supported by both appearance and motion information, our method demonstrates high adaptability to complex and variable scenarios. It achieves competitive results on three benchmark datasets.},
  archive      = {J_TAI},
  author       = {Xiaolei Wang and Xiaoyang Wang and Huihui Bai and Eng Gee Lim and Jimin Xiao},
  doi          = {10.1109/TAI.2025.3601079},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {8},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {ICC: Intra-cluster contraction for pedestrian anomaly detection under one-class classification setting},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing deep boosting algorithm performance for panic disorder detection through biometric and spatiotemporal data integration. <em>TAI</em>, 1-10. (<a href='https://doi.org/10.1109/TAI.2025.3601081'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing proliferation of mobile devices, sensors, and Internet of Things (IoT) technologies, intensive research continues in the scientific community, driven by a commitment to promoting the well-being of the general population. It is the need of the hour to pay more attention to mental health as it directly impacts people’s lives. This paper aims to predict panic disorder ‘PD’ state by analyzing numerous health parameters in real time. To achieve this, the machine learning technique Bayesian-Light Gradient Boosting Machine hereafter referred to as ‘B-LGBM’ deep boosting is used to diagnose the health status of a person with PD. Hyperparameter optimization using the Bayesian technique is applied to identify the optimal set of parameters for the base learners, resulting in refined regularization values and reduced errors (overfitting) within the proposed model. Experiments on the open-source dataset reveal that the proposed B-LGBM model performed competitively with a mean square error ‘MSE’ score of 0.0364 and an accuracy of 96.36%. By combining artificial intelligence models with blockchain technology, future studies can enhance prediction accuracy and ensure secure, privacy-preserving assessment of complex physiological patterns in panic disorder. Our findings offer benefits in the areas of public mental health systems and clinical psychiatry in terms of tailored assessment and intervention.},
  archive      = {J_TAI},
  author       = {Cephas Iko-Ojo Gabriel and Randhir Kumar and Krishna Prasad},
  doi          = {10.1109/TAI.2025.3601081},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {8},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Enhancing deep boosting algorithm performance for panic disorder detection through biometric and spatiotemporal data integration},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). P-mix: A data augmentation method for contrastive learning based human activity recognition. <em>TAI</em>, 1-13. (<a href='https://doi.org/10.1109/TAI.2025.3601599'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supervised human activity recognition (HAR) with sensor data typically demands substantial labeled datasets to train robust models. Contrastive learning offers a self-supervised alternative by leveraging data augmentation to improve representation learning. However, most existing augmentation methods operate independently on either the time or channel dimension and often introduce unstructured noise, which can distort meaningful temporal and spectral patterns. To address these limitations, we present a novel P-Mix data augmentation method for contrastive learning in HAR tasks, specifically designed to be compatible with the SimCLR framework. P-Mix is a customized data augmentation method tailored to sensor data for human activity recognition, which slices and recombines both the time and channel dimensions, merging multiple temporal segments to encourage the model to explore the underlying relationships and variations in the data in an unsupervised setting. To capture motion cycles and long-term dependencies, we employ shorter temporal segments as fundamental processing units along the time dimension. By incorporating structured noise patterns based on motion cycle characteristics within these segments, we effectively enhance the model’s robustness and generalization capabilities. Extensive evaluations across five HAR benchmarks demonstrate that P-Mix achieves consistent improvements over the strongest baseline (Resample), delivering relative F1-score gains ranging from 1.87% (USC-HAD: 85.63% vs 83.93%) to 6.53% (DSADS: 97.24% vs 91.28%) through controlled multidimensional fusion. These results demonstrate the effectiveness of our approach in optimizing data generation and augmentation strategies for HAR tasks.},
  archive      = {J_TAI},
  author       = {Yingjie Chen and Qi Xie and Wenxuan Cui and Liming Chen and Houbing Herbert Song and Tao Zhu},
  doi          = {10.1109/TAI.2025.3601599},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {8},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {P-mix: A data augmentation method for contrastive learning based human activity recognition},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive fuzzy distributed optimal fault tolerant control of nonlinear multi-agent systems under weight-unbalanced directed graphs. <em>TAI</em>, 1-10. (<a href='https://doi.org/10.1109/TAI.2025.3602015'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The adaptive fuzzy distributed optimal fault tolerant control (FTC) problem is investigated for high-order nonlinear multi-agent (NMA) systems under weight-unbalanced directed graph. Since the optimization point of the high-order NMA systems considered in this study is unknown, the optimal signal generator is formulated to obtain the optimization point. Then, a fuzzy state observer is established to estimate unmeasurable states. Based on the designed optimal signal generator and fuzzy state observer, an adaptive fuzzy distributed optimal output-feedback FTC scheme is proposed by using backstepping control technology. It is proved that the NMA system is asymptotically stable, and the global cost function is minimized. Finally, we apply the proposed adaptive fuzzy distributed optimal output-feedback FTC approach to nonholonomic mobile robots with two actuated wheels, the simulation results and comparison results verify its effectiveness.},
  archive      = {J_TAI},
  author       = {Mengyuan Cui and Yi Zuo and Shaocheng Tong},
  doi          = {10.1109/TAI.2025.3602015},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {8},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Adaptive fuzzy distributed optimal fault tolerant control of nonlinear multi-agent systems under weight-unbalanced directed graphs},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MFENet: Multi-information feature enhancement network for vehicle re-identification. <em>TAI</em>, 1-13. (<a href='https://doi.org/10.1109/TAI.2025.3601594'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle re-identification (Re-ID) targets cross-camera image retrieval and is a widely used technology in intelligent transportation systems. Current Re-ID methods primarily enhance feature extraction by focusing on either global or local features, but they often fail to effectively leverage diverse information. To address these limitations, we propose a multi-information feature enhancement network (MFENet) that integrates diverse information types to enhance feature representation and boost model accuracy. Specifically, (1) a coarse-grained feature enhancement (CFE) module is employed to remove background influence on image features. This module filters the background, enabling the network model to extract more accurate vehicle features, such as color and model. (2) A fine-grained feature enhancement (FFE) module collects detailed information about vehicles by extracting features from subtle areas (e.g., vehicle lights and rearview mirrors) of an image, providing more unique clues about the vehicle. (3) A latent feature enhancement (LFE) module is designed to mine latent features and enrich vehicle features using non-visual cues, such as the vehicle’s camera and orientation, without relying on image information. Extensive experiments on vehicle Re-ID datasets demonstrate that MFENet outperforms most existing methods.},
  archive      = {J_TAI},
  author       = {Zhangwei Li and Yuhui Deng and Ke Wang and Junhao Huang and Zhimin Tang and Weiping Ding},
  doi          = {10.1109/TAI.2025.3601594},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {8},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {MFENet: Multi-information feature enhancement network for vehicle re-identification},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel ensemble method based on support vector dynamic learning neural network for breast cancer diagnosis. <em>TAI</em>, 1-11. (<a href='https://doi.org/10.1109/TAI.2025.3602017'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To improve the accuracy of breast cancer diagnosis and reduce examination costs, a novel ensemble learning method called support vector dynamic learning neural network (SVDL) is proposed in this paper. The method first constructs the breast cancer classification problem as a standard quadratic programming (QP) problem based on support vector machine (SVM). Then, a novel dynamic learning neural network (DLNN) solver is designed to solve this problem to obtain the optimal diagnosis model. The experimental results on the Wisconsin Diagnostic Breast Cancer dataset show that the proposed method is superior to traditional and state-of-the-art machine learning methods, achieving the best accuracy (98:59%) and area under curve value (0.9956), as well as high specificity (98:85%) and sensitivity (98:18%). It demonstrates that the proposed method has good classification performance. Furthermore, the proposed method may further enhance the model performance by introducing swarm intelligence algorithm to search for the optimal value of model parameters, which will contribute to the diagnosis of breast cancer and other diseases as well.},
  archive      = {J_TAI},
  author       = {Zhijun Zhang and Yong Ding and Jian Zhang},
  doi          = {10.1109/TAI.2025.3602017},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {8},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {A novel ensemble method based on support vector dynamic learning neural network for breast cancer diagnosis},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MSAF: Multi-modal sentiment detection via multi-scale adaptive fusion. <em>TAI</em>, 1-13. (<a href='https://doi.org/10.1109/TAI.2025.3602409'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid increase of multimodal comments on social media, multimodal sentiment detection has become increasingly important. However, most existing methods overlook the difference in information density between text and images, and fall short in fully utilizing multi-scale information in images. To address this issue, we propose a multi-scale adaptive fusion model termed MSAF for multimodal sentiment detection. MSAF first extracts fine-scale and coarse-scale features of images through a multi-scale visual encoder, and uses a multi-scale adaptive pooling module to adaptively adjust the weights of different regional features. Then, MSAF incorporates multi-scale contrastive learning and multi-scale rivalry tasks to ensure that the model retains associations between features at different scales while maintaining their diversity. These features are sequentially fused with text through a hierarchical fusion encoder guided by textual information, enabling MSAF to focus on sentiment-salient regions in the image. Finally, the multimodal fusion embeddings are fed into a classifier to predict the sentiment. Extensive experiments on multiple public datasets demonstrate the effectiveness and superiority of MSAF. The codes of MSAF are available at https://github.com/ADMIS-TONGJI/MSAF.},
  archive      = {J_TAI},
  author       = {Jihong Guan and Yulou Shu and Wuchao Liu and Wengen Li and Shuigeng Zhou and Yichao Zhang},
  doi          = {10.1109/TAI.2025.3602409},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {8},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {MSAF: Multi-modal sentiment detection via multi-scale adaptive fusion},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Steganography in large language models. <em>TAI</em>, 1-12. (<a href='https://doi.org/10.1109/TAI.2025.3602763'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of deep learning has provided new momentum for steganography. However, existing model steganography methods are generally applicable to CNNs models, which suffer from low embedding capacity and poor robustness. To this end, we propose a stego scheme designed for large language models based on the Transformer architecture. Using the powerful feature representation ability and multilayer self-attention mechanism of Transformer, a large amount of secret data can be embedded without significantly affecting the performance of the model. In our scheme, the sender uses matrix multiplication to encode the coverage parameters of a specific Transformer block to embed secret data during the training process of the large language models. Ordinary users can use the stego model for text classification, text generation, and other routine tasks, while receivers can use a secret key to extract the secret data from the stego model, allowing for covert communication of secret data. Experimental results affirm the efficacy of our scheme in terms of embedding capacity, undetectability, and robustness.},
  archive      = {J_TAI},
  author       = {Xinxin Li and Zichi Wang and Xinpeng Zhang},
  doi          = {10.1109/TAI.2025.3602763},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {8},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Steganography in large language models},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Annealing genetic slicing adversarial networks based feedback for imbalanced visual classification. <em>TAI</em>, 1-15. (<a href='https://doi.org/10.1109/TAI.2025.3602750'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data imbalance is a common challenge in real-world applications, often addressed by augmenting minority classes data for a balanced dataset. Generative adversarial networks (GANs) can generate realistic minority class samples in the dynamical adversarial learning way but face limitations due to the optimization falling into local minima. To address this, incorporating simulated annealing into GANs offers a potential method by accepting worse solutions to expand solution exploration. However, it remains underexplored whether every accepting worse solution in the learning dynamics of GAN benefits the learning of minority or majority classes. Therefore, we propose an annealing genetic slicing adversarial network (AGSAN) learning method for visual imbalance classification. It treats adversarial learning as an evolutionary process with the generator undergoing multiple offspring generation, best offspring selection, and individual updating. AGSAN builds a gradient-informed selection mechanism to facilitate individual updating and the best offspring selection, leveraging gradient consistency—measuring similarity between minority classes gradients and overall gradients—to guide optimization. Furthermore, AGSAN expands optimization ranges to facilitate multiple offspring generation by a mixture of multiple adversarial objectives. Additionally, AGSAN ensures the minimization objective function of GAN equals the distance between the generated and target distributions with relaxing the assumption of the optimal discriminator. Compared with 21 existing methods, our AGSAN can achieve state-of-the-art performance on imbalanced classification.},
  archive      = {J_TAI},
  author       = {Yongting Zhao and Zhifan Gao and Jingyu Hao and Yiwen Wang and Heye Zhang},
  doi          = {10.1109/TAI.2025.3602750},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {8},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Annealing genetic slicing adversarial networks based feedback for imbalanced visual classification},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust unknown object detection in dynamic environments through dual-granularity reconstruction error modeling. <em>TAI</em>, 1-14. (<a href='https://doi.org/10.1109/TAI.2025.3602943'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Open World Object Detection (OWOD) aims to detect both known and unknown objects in dynamic environments, where unknown instances lack ground-truth supervision during training. Existing methods typically rely on supervision from known categories, leading models to overconfidently classify visually similar unknowns as known classes, and dissimilar ones as background. This known-class prior bias severely hinders the detection of truly novel objects. To address this challenge, we propose a robust unknown object detection method based on dual-granularity reconstruction error modeling. At the fine-grained level, we propose Fine-grained Masked Reconstruction (FMR), which randomly masks feature regions to guide reconstruction toward semantic structures, thereby improving foreground–background discrimination. At the coarse-grained level, we propose Adaptive Region-based Error Aggregation (AREA), which aggregates reconstruction errors over object proposals to enhance the model’s sensitivity to ambiguous semantic boundaries while suppressing local outliers. Furthermore, we perform decoupled probabilistic modeling of foreground and background reconstruction errors, enabling soft estimation of unknown object likelihoods without supervision. Extensive experiments on standard OWOD benchmarks demonstrate that our method consistently outperforms state-of-the-art approaches, achieving a +20.6 improvement in unknown object recall (U-Recall) while maintaining strong performance on known classes.},
  archive      = {J_TAI},
  author       = {Linhua Ye and Yangyang Huang and Ronghua Luo},
  doi          = {10.1109/TAI.2025.3602943},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {8},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Robust unknown object detection in dynamic environments through dual-granularity reconstruction error modeling},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Certified local transferability for evaluating adversarial attacks. <em>TAI</em>, 1-10. (<a href='https://doi.org/10.1109/TAI.2025.3602931'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks are known to be vulnerable to adversarial examples. Though adversarial attacks show effectiveness in misleading models, most attack methods are designed to poison a specific image. To investigate the actual effect on the feature space, we introduce the concept of the certified local transferable region. This is a connected area of inputs where we can mathematically guarantee that a single adversarial perturbation will successfully fool the model. The size of this region is a metric to evaluate the local transferability of perturbations. We present a novel method, RAOS, to estimate the maximum size of this region. Our approach efficiently searches for the largest possible vulnerable area around an original input by iteratively refining its boundaries. Each step is guided with a minimal distance attack algorithm and proven with state-of-the-art verifiers. We conduct empirical experiments to evaluate various attacks on different model structures and adversarial training scenarios.We show the advantage of our proposed metric over existing ones and demonstrate its utility in exploring the robustness of neural networks.},
  archive      = {J_TAI},
  author       = {Minyu Chen and Jingyang Li and Ling-I Wu and Guoqiang Li},
  doi          = {10.1109/TAI.2025.3602931},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {8},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Certified local transferability for evaluating adversarial attacks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correlation-guided information deep fusion for multimodal recommendation. <em>TAI</em>, 1-12. (<a href='https://doi.org/10.1109/TAI.2025.3602935'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal recommendation plays a crucial role on online platforms by integrating modalities information such as visual, textual, and audio, which significantly mitigates the sparsity of user-item interaction networks. However, current multimodal recommendation methods primarily enrich item-side representations while neglecting user-side learning. And the fusion of structure and information is insufficient. To address these issues, we propose Correlation-guided Information Deep Fusion for Multimodal Recommendation(CIDF). First, we employ graph neural networks to capture collaborative signals based on ID embeddings and multimodal features separately, thereby capturing the independent information of each node’s different representations. Next, we construct the user-user similarity ID graph and the item-item correlation modality graph to capture connection information on user and item sides, respectively. Finally, we propose an information deep fusion method. This method integrates the aforementioned two graphs and the user-item interaction graph, thereby obtaining fused representations for both users and items through the process of information propagation and aggregation on graphs. The fused representations are further updated in user-item interaction graph to obtain node representations that better align with user interaction behaviors. We conducted experiments on real-world datasets, and the results demonstrate that CIDF outperforms state-of-the-art methods in multimodal recommendation. Our code is available at: https://github.com/Andrewsama/CIDF-master.},
  archive      = {J_TAI},
  author       = {Gang-Feng Ma and Xu-Hua Yang and Peng Jiang},
  doi          = {10.1109/TAI.2025.3602935},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {8},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Correlation-guided information deep fusion for multimodal recommendation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online safety analysis for LLMs: A benchmark, an assessment, and a path forward. <em>TAI</em>, 1-16. (<a href='https://doi.org/10.1109/TAI.2025.3603547'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While Large Language Models (LLMs) have seen widespread applications across numerous fields, their limited interpretability poses concerns regarding their safe operations from multiple aspects, e.g., truthfulness and toxicity. Recent research has started developing quality assurance methods for LLMs, introducing techniques such as offline detectors or uncertainty estimation methods. However, these approaches mainly focus on post-generation analysis, leaving the online safety analysis for LLMs during the generation phase an unexplored area. To bridge this gap, we conduct in this work a comprehensive evaluation of the effectiveness of existing online safety analysis methods on LLMs. We begin with a pilot study that validates the feasibility of detecting unsafe outputs in the early generation process. Following this, we establish the first publicly available benchmark of online safety analysis for LLMs, including a broad spectrum of methods, models, tasks, datasets, and evaluation metrics. Utilizing this benchmark, we extensively analyze the performance of state-of-the-art online safety analysis methods on both open-source and closed-source LLMs. This analysis reveals the strengths and weaknesses of individual methods and offers valuable insights into selecting the most appropriate method based on specific application scenarios and task requirements. Furthermore, we also explore the potential of using hybridization methods, i.e., combining multiple methods to derive a collective safety conclusion, to enhance the efficacy of online safety analysis. Our findings indicate a promising direction for the development of trustworthy assurance methodologies for LLMs, facilitating their reliable deployments across diverse domains.},
  archive      = {J_TAI},
  author       = {Xuan Xie and Jiayang Song and Zhehua Zhou and Yuheng Huang and Da Song and Lei Ma},
  doi          = {10.1109/TAI.2025.3603547},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {8},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Online safety analysis for LLMs: A benchmark, an assessment, and a path forward},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NeuroAMP: A novel end-to-end general purpose deep neural amplifier for personalized hearing aids. <em>TAI</em>, 1-16. (<a href='https://doi.org/10.1109/TAI.2025.3603538'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prevalence of hearing aids is increasing. However, optimizing their amplification remains challenging due to the complexity of integrating multiple components in traditional methods. To address this, we present NeuroAMP, a novel deep neural network for end-to-end, personalized amplification in hearing aids. NeuroAMP leverages spectral features and the listener’s audiogram as inputs, and we explore four architectures: Convolutional Neural Network (CNN), Long Short-Term Memory (LSTM), Convolutional Recurrent Neural Network (CRNN), and Transformer. We also introduce Denoising NeuroAMP, an extension that integrates noise reduction with amplification for improved real-world performance. To enhance generalization, we employed a comprehensive data augmentation strategy during training on diverse speech (TIMIT, TMHINT) and music (Cadenza Challenge MUSIC) datasets. Evaluation using the Hearing Aid Speech Perception Index (HASPI), Hearing Aid Speech Quality Index (HASQI), and Hearing Aid Audio Quality Index (HAAQI) shows that the Transformer-based NeuroAMP achieves the best performance, with SRCC scores of 0.9927 (HASQI) and 0.9905 (HASPI) on TIMIT, and 0.9738 (HAAQI) on Cadenza dataset. Notably, the augmentation strategy maintains robust performance on unseen datasets (e.g., VoiceBank-DEMAND, MUSDB18-HQ). Furthermore, Denoising NeuroAMP outperforms both the conventional NAL-R+WDRC method and a two-stage baseline on the VoiceBank-DEMAND dataset, achieving HASPI of 0.90 and HASQI of 0.59. These results highlight the strong potential of NeuroAMP and Denoising NeuroAMP to provide a novel and effective framework for personalized hearing aid amplification.},
  archive      = {J_TAI},
  author       = {Shafique Ahmed and Ryandhimas E. Zezario and Hui-Guan Yuan and Amir Hussain and Hsin-Min Wang and Wei-Ho Chung and Yu Tsao},
  doi          = {10.1109/TAI.2025.3603538},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {8},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {NeuroAMP: A novel end-to-end general purpose deep neural amplifier for personalized hearing aids},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Community-structure enhanced brain graph mining. <em>TAI</em>, 1-10. (<a href='https://doi.org/10.1109/TAI.2025.3598793'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain neuroimaging technology has become increasingly valuable in diagnosing brain disorders, with brain graphs constructed from neuroimaging data providing critical insights into the properties of the human brain. Although functional connectivity-based brain graph construction methods have proven effective in diagnostic tasks, they often fail to incorporate prior knowledge from neuroscience, such as the existence of distinct functional modules that govern various aspects of brain function. In this work, we define these functional modules as different communities of brain graphs and propose a community-structure enhanced brain graph mining framework. Specifically, we design community-constrained node identity vectors as part of node features to adaptively capture the community structure in the process of model optimization toward downstream tasks. Importantly, since common community variations are identified across subjects with the same disorder, these identity vectors are shared among all subjects within a specific brain disorder diagnostic task. Additionally, to improve the interpretability of our model, we generate attention scores solely from the identity vectors, enabling the model to constantly focus on specific brain regions and communities associated with a particular disorder. Finally, we conduct extensive experiments on three real-world datasets. The analysis results demonstrate the effectiveness of our approach and provide valuable insights for identifying biomarkers associated with corresponding brain disorders.},
  archive      = {J_TAI},
  author       = {Shichen Luo and Xuexiong Luo and Jing Du and Jia Wu and Jian Yang},
  doi          = {10.1109/TAI.2025.3598793},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {8},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Community-structure enhanced brain graph mining},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Refined two-sided learning rate tuning for robust evaluation in federated learning. <em>TAI</em>, 1-12. (<a href='https://doi.org/10.1109/TAI.2025.3585090'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the impact of client and server learning rates on training deep neural networks in Federated Learning (FL). While previous research has primarily focused on optimizing the initial values of these learning rates, we demonstrate that this approach alone is insufficient for maximizing model performance and training efficiency. To address this weakness, we propose a revised two-sided learning rate optimization strategy that integrates learning rate decay schedules as tunable variables and adjusts the learning rate configurations based on the target training budget, allowing for more effective optimization. We conduct an extensive experimental evaluation to quantify the improvements offered by our approach. The results reveal that (i) integrating decay schedules into the tuning process leads to significant performance enhancements, and (ii) the optimal configuration of client-server decay schedules is strongly influenced by the training round budget. Based on these findings, we claim that performance evaluations of new FL algorithms should extend beyond the fine-tuning of the initial learning rate values, as done in the state-of-the-art approach, and include the optimization of decay schedules according to the available training budget.},
  archive      = {J_TAI},
  author       = {Erich Malan and Valentino Peluso and Andrea Calimera and Enrico Macii},
  doi          = {10.1109/TAI.2025.3585090},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {7},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Refined two-sided learning rate tuning for robust evaluation in federated learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PGR: Pseudo graph regularization for semi-supervised classification. <em>TAI</em>, 1-14. (<a href='https://doi.org/10.1109/TAI.2025.3585095'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised learning (SSL) is gaining attention for its intrinsic ability to extract valuable information from labeled and unlabeled data with improved performance. Recently, consistency regularization methods have gained interest due to their efficient learning procedures. However, they are confined to pseudo-label or feature representation-level perturbations, negating the benefit of having both forms in a single framework. This leads to the model remaining robust to either the pseudo-label or the feature representation. To this end, we propose Pseudo Graph Regularization (PGR) for Semi-Supervised Classification, which leverages graph-based contrastive learning to unify pseudo-labels and feature embeddings in a single semi-supervised framework. The model imposes graph regularization on both pseudo-labels and feature embeddings of unlabeled data to retain the intrinsic geometric structure. Feature embeddings into the model impose constraints on the class probability, forcing the class probability distributions of unlabeled data subject to different perturbations to be consistent. The pseudo-labels regularly optimize the embedding space’s structure through graph-based contrastive learning, which allows data with similar pseudo-labels to have similar feature embeddings in latent space. PGR unifies pseudo-label and feature representation of unlabeled data to improve the ability of model to resist noise interference and generalization ability. Extensive experiments on four benchmark datasets demonstrate that PGR can generate higher quality pseudo-labels for unlabeled data, and is superior to the state-of-the-art (SOTA) methods. The code is available at https://github.com/song-leap/PGR.},
  archive      = {J_TAI},
  author       = {Cong Hu and Jiangtao Song and Xiao-Jun Wu},
  doi          = {10.1109/TAI.2025.3585095},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {7},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {PGR: Pseudo graph regularization for semi-supervised classification},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Practical group consensus of T-S fuzzy positive multi-agent systems using compensative control. <em>TAI</em>, 1-12. (<a href='https://doi.org/10.1109/TAI.2025.3584905'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the practical group consensus of type-1 and type-2 T-S fuzzy positive multi-agent systems. First, a positive disturbance observer and a distributed positive compensator are proposed. A group consensus protocol is designed by integrating event-triggered mechanism, which utilizes the state information of the compensator. Some feasible conditions are addressed for practical group positive consensus in the form of linear programming. The key novelties are threefold: (i) A novel positive disturbance observer and compensator framework is constructed, (ii) A fuzzy positive group consensus protocol is established, and (iii) Linear programming is employed for describing the corresponding conditions. Finally, two examples are provided to verify the effectiveness of the theory findings.},
  archive      = {J_TAI},
  author       = {Junfeng Zhang and Hao Ji and Tarek Raïssi and Haoyue Yang},
  doi          = {10.1109/TAI.2025.3584905},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {7},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Practical group consensus of T-S fuzzy positive multi-agent systems using compensative control},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fourier-driven lightweight token mixing model for efficient time series forecasting. <em>TAI</em>, 1-14. (<a href='https://doi.org/10.1109/TAI.2025.3584693'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time-series forecasting is crucial in a wide range of real-world applications, such as weather prediction, energy planning, and financial risk management. Although previous Transformer-based models have performed well in forecasting over long time horizons using self-attention mechanisms and stacked architectures, challenges remain in effectively learning complex temporal patterns while minimizing trainable parameters and computational costs. This paper introduces Fourier-driven Network (F-Net), a novel architecture for multivariate time series forecasting that replaces the traditional attention mechanism with Fourier-driven Representation Learning (FdRL). F-Net is extended to Efficient F-Net (EF-Net) to further enhance computational efficiency by incorporating a Latent Mapping Model (LMM). Experimental results demonstrate that F-Net outperforms state-of-the-art (SoTA) methods by an average margin of 28.18%, surpassing the conventional attention-based vanilla transformer by 27%. F-Net is exceptionally lightweight, with ~103 parameters, achieving a reduction of more than a thousand times compared to existing SoTA approaches. Adding the LMM with F-Net further enhances its efficiency, cutting inference time by an average of 72% across benchmark datasets while maintaining a similar parameter count, making it ideal for real-time applications. EF-Net also gives comparative accuracy and outperforms various SoTAs.},
  archive      = {J_TAI},
  author       = {Jyoti Kumari and Arijit Mondal and Jimson Mathew},
  doi          = {10.1109/TAI.2025.3584693},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {7},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Fourier-driven lightweight token mixing model for efficient time series forecasting},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Temporal domain guided prediction network. <em>TAI</em>, 1-10. (<a href='https://doi.org/10.1109/TAI.2025.3584867'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infertility affects approximately one in six reproductive-age couples globally, potentially leading to in vitro fertilization (IVF) treatment. In IVF treatment, the decision to transfer embryos on day 3 or to extend culture to day 5 remains a critical challenge for reproductive specialists. Through a guided learning approach, we propose a novel architecture named Temporal Domain Guided Prediction Network (TDGP-Net), which predicts whether the blastocyst stage quality is recommended for transfer (BRT) or not recommended for transfer (BNT) on day 3. Our experimental results demonstrate that TDGP-Net outperforms existing machine learning methods across various metrics. This advanced predictive tool can optimize embryo selection, representing a significant advancement in personalized embryo assessment.},
  archive      = {J_TAI},
  author       = {Song-Po Pan and Jui-Chien Hung and Shih-Chia Huang and Jun-Yun Wu and Da-Wei Jaw},
  doi          = {10.1109/TAI.2025.3584867},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {7},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Temporal domain guided prediction network},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Constrained gaussian splatting via implicit TSDF hash grid for dense RGB-D SLAM. <em>TAI</em>, 1-14. (<a href='https://doi.org/10.1109/TAI.2025.3584900'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D Gaussian Splatting (3DGS) has emerged as a promising technique in SLAM due to its rapid and high-quality rendering capabilities. However, its reliance on discrete Gaussian primitives limits its effectiveness in capturing essential geometric features crucial for accurate pose estimation. To overcome this limitation, we propose a novel dense RGB-D SLAM system that integrates an implicit Truncated Signed Distance Function (TSDF) hash grid to constrain the distribution of Gaussian primitives. This innovative approach enables precise estimation of the scene’s geometric structure by smoothing the discrete Gaussian primitives and anchoring them to the scene’s surface. Acting as a low-pass filter, the implicit TSDF hash grid mitigates the inductive biases inherent in traditional 3DGS methods while preserving rendering quality. Our geometrically constrained map also significantly enhances generalization capabilities for depth estimation in novel views. Extensive experiments on the Replica, ScanNet, and TUM datasets demonstrate that our system achieves state-of-the-art tracking and mapping accuracy at speeds up to 30 times faster than existing 3DGS-based systems.},
  archive      = {J_TAI},
  author       = {Guanghao Li and Qi Chen and Sijia Hu and Yuxiang Yan and Jian Pu},
  doi          = {10.1109/TAI.2025.3584900},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {7},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Constrained gaussian splatting via implicit TSDF hash grid for dense RGB-D SLAM},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic obstacle avoidance using path reshaping on probabilistic roadmaps for high-degree-of-freedom robots. <em>TAI</em>, 1-10. (<a href='https://doi.org/10.1109/TAI.2025.3584023'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic manipulators operating in dynamic environments frequently encounter unpredictable obstacles. Existing state-of-the-art motion planning and replanning algorithms struggle to achieve real-time replanning for high-degree-of-freedom robots in these complex, dynamic settings. To address this limitation, we propose a novel local path-reshaping technique to avoid collision from dynamic obstacles in real-time. The developed technique, Probabilistic Roadmap with Deep Neural Network-based Collision-Checking (PRM-DNNCC), leverages a deep neural network (DNN) architecture to accelerate collision checking, which is a critical computational bottleneck during replanning. Upon detecting dynamic obstacles within the workspace, the system locally replans the path by generating a mini-batch PRM around the obstacle. The DNN model is employed to perform both discrete and continuous collision checks on these mini-batch PRMs. A locally optimal path is then executed to ensure safe navigation. The application of the developed algorithm on manipulators with up to six-DOF demonstrates an average success rate of 94.6%, significantly surpassing traditional approaches and proving highly competitive to various other state-of-the-art approaches. Additionally, the DNN-based collision-checking architecture has an accuracy of 98.15% with an average inference time of 6 milliseconds for collision checking, which is faster than all other geometric collision-checking algorithms reported in the literature. We envisage that the developed technique holds promise in motion planning for human-robot collaboration in sectors like healthcare, logistics, manufacturing, and agriculture.},
  archive      = {J_TAI},
  author       = {Pritam Ojha and Atul Thakur},
  doi          = {10.1109/TAI.2025.3584023},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {7},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Dynamic obstacle avoidance using path reshaping on probabilistic roadmaps for high-degree-of-freedom robots},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SpikeNAS: A fast memory-aware neural architecture search framework for spiking neural network-based embedded AI systems. <em>TAI</em>, 1-12. (<a href='https://doi.org/10.1109/TAI.2025.3586238'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Embedded AI systems are expected to incur low power/energy consumption for solving machine learning tasks, as these systems are usually power constrained (e.g., object recognition task in autonomous mobile agents with portable batteries). These requirements can be fulfilled by Spiking Neural Networks (SNNs), since their bio-inspired spike-based operations offer high accuracy and ultra low-power/energy computation. Currently, most of SNN architectures are derived from Artificial Neural Networks whose neurons’ architectures and operations are different from SNNs, and/or developed without considering memory budgets from the underlying processing hardware of embedded platforms. These limitations hinder SNNs from reaching their full potential in accuracy and efficiency. Toward this, we propose SpikeNAS, a novel fast memory-aware neural architecture search (NAS) framework for SNNs that quickly finds an appropriate SNN architecture with high accuracy under the given memory budgets from targeted embedded systems. To do this, our SpikeNAS employs several key steps: analyzing the impacts of network operations on the accuracy, enhancing the network architecture to improve the learning quality, developing a fast memory-aware search algorithm, and performing quantization. The experimental results show that our SpikeNAS improves the searching time and maintains high accuracy compared to state-of-the-art while meeting the given memory budgets (e.g., 29x, 117x, and 3.7x faster search for CIFAR10, CIFAR100, and TinyImageNet200 respectively, using an Nvidia RTX A6000 GPU machine), thereby quickly providing the appropriate SNN architecture for the memory-constrained embedded AI systems.},
  archive      = {J_TAI},
  author       = {Rachmad Vidya Wicaksana Putra and Muhammad Shafique},
  doi          = {10.1109/TAI.2025.3586238},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {7},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {SpikeNAS: A fast memory-aware neural architecture search framework for spiking neural network-based embedded AI systems},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Application of gaussian distribution crayfish optimization in adaptive FIR filter bank: Four-channel uniform and non-uniform designs. <em>TAI</em>, 1-16. (<a href='https://doi.org/10.1109/TAI.2025.3585868'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Filter bank design remains a critical challenge in signal processing, particularly in achieving high-performance metrics while maintaining computational efficiency. Current methods, including various optimization algorithms, have made strides in addressing these challenges but often need to improve in balancing Perfect Reconstruction (PR) and magnitude response accuracy. This research addresses these gaps by introducing the Gaussian Distribution Crayfish Optimization Algorithm (GD-COA), an enhanced version of the Crayfish Optimization Algorithm (COA), for designing a four-channel Finite Impulse Response (FIR) filter bank. The GD-COA formulates the design problem as a meta-heuristic optimization task, integrating PR and magnitude criteria to guide the filter design. It applies to uniform (critically sampled and oversampled) and non-uniform filter banks, accommodating various sampling rates. Our results show that GD-COA achieves significant improvements in filter bank performance. Specifically, for a critically sampled uniform filter bank, it attained a PR Error of 7.2219 × 10−16 and a Magnitude Response Approximation Error (MRAE) of 3.8018 × 10−16. In an oversampled uniform filter bank, the PR Error was 1.7321 × 10−5 with an MRAE of 7.2444 × 10−6. The algorithm yielded a PR Error of 3.2831 × 10−4 and an MRAE of 8.5113 × 10−5 for a non-uniform filter bank with a consistent sampling set. When applied to a variable filter bank with an inconsistent sampling set, the PR Error was 1.1403 × 10−4, and the MRAE was 2.34423 × 10−5. These results demonstrate the GD-COA’s effectiveness in optimizing filter coefficients, ensuring minimal reconstruction errors and satisfactory magnitude response across various design scenarios.},
  archive      = {J_TAI},
  author       = {Himani Daulat and Krishna Chauhan and Tarun Varma},
  doi          = {10.1109/TAI.2025.3585868},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {7},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Application of gaussian distribution crayfish optimization in adaptive FIR filter bank: Four-channel uniform and non-uniform designs},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Zero-parameter attention sharing transformer for joint human activity and identity recognition. <em>TAI</em>, 1-13. (<a href='https://doi.org/10.1109/TAI.2025.3586571'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {WiFi-based human sensing is gaining popularity thanks to it not requiring additional devices and it not being as intrusive as cameras. Specifically, human features can be extracted from WiFi Channel State Information (CSI) to recognize human activities, identities, etc. However, most previous works rely on single-task learning models for recognition (e.g., to either recognize activities OR identities solely). The lack of cross-task knowledge sharing restricts these models to task-specific features and poor generalization. Recent studies have applied multi-task learning (MTL) to tackle this, but their cross-task sharing modules add vast amounts of extra parameters. Such massive parameters increase model complexity and reduce time efficiency. In this paper, we propose a novel Zero-parameter Attention Sharing Transformer (ZAST) to efficiently recognize both activities and identities. In ZAST, a Cross-task Attention on Attention (CAoA) mechanism computes the relevance of attention scores for cross-task knowledge sharing, as a new paradigm for lightweight MTL. To mitigate the perturbation caused by attention sharing, we formulate a Multi-head Similarity Loss (L-MS) for stable model training. We further equip ZAST with Channel-wise Squeeze and Excitation (CSE) that efficiently learns the channel correlations of CSI. Extensive experiments on four public datasets indicate that ZAST achieves state-of-the-art recognition performance with the lowest complexity and the highest efficiency.},
  archive      = {J_TAI},
  author       = {Shuokang Huang and Po-Yu Chen and Peilin Zhou and Kaihan Li and Julie A. McCann},
  doi          = {10.1109/TAI.2025.3586571},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {7},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Zero-parameter attention sharing transformer for joint human activity and identity recognition},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimization for community detection in multilayer networks: A comprehensive review and novel taxonomy. <em>TAI</em>, 1-16. (<a href='https://doi.org/10.1109/TAI.2025.3586828'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection is a rapidly growing field, especially for multilayer networks—systems with multiple interaction types. While these networks offer great potential, analyzing them remains complex and underexplored. Recently, researchers have turned to optimization techniques to address these challenges. However, despite diverse approaches, there’s no comprehensive study consolidating these advancements. To bridge this gap, this paper provides a structured review of optimization techniques for community detection in multilayer networks, classifying methods by three criteria: resolution types, optimization types, and resolution methods. This aims to clarify the field and guide future research. This effort seeks to bring clarity to the field, offering a unified perspective on existing methods, while also providing a foundation to inspire and guide future research directions.},
  archive      = {J_TAI},
  author       = {Randa Boukabene and Fatima Benbouzid-Si Tayeb},
  doi          = {10.1109/TAI.2025.3586828},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {7},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Optimization for community detection in multilayer networks: A comprehensive review and novel taxonomy},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Normalizing flow-based fine-grained modeling for unknown gesture rejection in myoelectric pattern recognition. <em>TAI</em>, 1-13. (<a href='https://doi.org/10.1109/TAI.2025.3590706'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gesture recognition systems based on surface electromyography (sEMG) exhibit high accuracy in laboratory settings. However, they often underperform in real-world applications due to the occurrence of unknown gestures not encountered during training. Prototype learning methods, which learn gesture prototypes and classify unknown gestures based on distances to these prototypes, effectively reject unknown gestures. However, relying solely on global feature distances may overlook subtle variations, weakening discrimination between similar features and reducing the model’s ability to identify unknown gestures resembling known ones. To address these limitations, we propose a fine-grained method that models the probability distribution of each feature point, enabling the detection of subtle differences in partial features. Specifically, we employ normalizing flows to capture detailed information at the feature-point level. This approach enhances the model’s capacity to recognize challenging unknown gestures that partially differ from known gesture patterns. In addition, we introduce synthetic unknown gestures generated by applying slight perturbations to known samples, simulating challenging unknown scenarios. We then design a novel loss function that pulls known gestures closer together while pushing synthetic unknown gestures further apart, creating a more robust rejection model. Extensive experiments on both custom and public datasets demonstrate that our method achieves an area under the curve (AUC) of 0.988 on the custom dataset and an average AUC of 0.984 and 0.782 on the two public datasets, Capgmyo-dbc and NinaproDB5, respectively. These results indicate that the proposed method provides a robust and practical solution for reliable myoelectric control in real-world applications.},
  archive      = {J_TAI},
  author       = {Jingyang Jia and Le Wu and Shengcai Duan and Xun Chen},
  doi          = {10.1109/TAI.2025.3590706},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {7},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Normalizing flow-based fine-grained modeling for unknown gesture rejection in myoelectric pattern recognition},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning-driven optimization of a sensor network for accurate pollutant source identification. <em>TAI</em>, 1-15. (<a href='https://doi.org/10.1109/TAI.2025.3590691'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimizing sensor networks for localizing atmospheric pollution sources and enhancing estimation accuracy remains a significant challenge in air pollution studies. To address this, various techniques have been recently developed. Among them, machine learning has demonstrated its ability to model and optimize complex problems, including sensor network optimization. To improve the localization of atmospheric pollution sources in air quality research activities, we propose in this paper, a Machine Learning-driven Optimization of Sensor Networks method (ML-OSN). The method introduces a new combination of Hierarchical Agglomerative Clustering and Siamese Neural Networks, thereby improving the prediction of similarities in pollutant concentrations across different wind directions and leading to an optimized sensor network. The proposed ML-OSN method was evaluated and compared to a standard clustering approach based on the Pearson correlation coefficient, using the augmented Indianapolis dataset. The resulting optimal sensor network configuration achieved broader spatial coverage and improved source estimation accuracy, reducing the error score to 1.34 compared to 1.44 obtained with the Pearson-based approach.},
  archive      = {J_TAI},
  author       = {Sidi Mohammed Alaoui and Khalifa Djemal and Ehsan Sedgh Gooya and Amir Ali Feiz and Ayman Al Falou},
  doi          = {10.1109/TAI.2025.3590691},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Machine learning-driven optimization of a sensor network for accurate pollutant source identification},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stragglers reimagined: Explainability-driven adaptive federated learning for resource constrained IoMT system. <em>TAI</em>, 1-10. (<a href='https://doi.org/10.1109/TAI.2025.3590703'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present FlexiFed, a framework designed to enhance Federated Learning (FL) by addressing the challenges of device inclusivity and data prioritization. FL systems typically exclude low-resource devices, known as stragglers, due to their limited computational power, leading to the loss of valuable and often unique data. Additionally, current FL systems lack transparency, making it difficult to prioritize the contributions of individual devices. FlexiFed overcomes these issues by enabling stragglers to share simplified outputs, such as predictions and key feature importance scores, instead of full model updates. This reduces their computational and communication burden. The framework integrates explainability techniques to identify and emphasize critical data, ensuring rare and significant contributions are prioritized during training. FlexiFed distinguishes itself from similar frameworks by combining hierarchical aggregation with explainability-driven prioritization, directly addressing the need for fairness and transparency in diverse and resource-constrained environments.},
  archive      = {J_TAI},
  author       = {Riya Tapwal},
  doi          = {10.1109/TAI.2025.3590703},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {7},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Stragglers reimagined: Explainability-driven adaptive federated learning for resource constrained IoMT system},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contrastive learning feature enhancement and high-low frequency texture interaction networks for DIBR-synthesized view quality assessment. <em>TAI</em>, 1-15. (<a href='https://doi.org/10.1109/TAI.2025.3590692'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depth image-based rendering (DIBR) is a common method for synthesizing virtual views to achieve smooth transitions in immersive media, but its immature technology often introduces distortions, adversely affecting visual quality. Obviously, accurately assessing the quality of synthesized views is crucial for monitoring and guiding rendering process. To this end, this paper proposes a no-reference deep learning-based quality assessment method for DIBR-synthesized views, which is primarily achieved by combining a contrastive learning feature enhancement network and a high-low frequency texture interaction network, abbreviated as CONTIN. Different from the traditional methods based on handcrafted feature extraction, the proposed method employs an end-to-end deep learning approach, fully exploiting the data characteristics and feature correlations. Specifically, to address the issue of sample expansion in existing deep learning methods, a contrastive sample database is first constructed by simulating various traditional and rendering distortions based on natural images, and training is performed on this database to obtain a contrastive learning feature enhancement network, which is used to extract contrastive features. Additionally, since contrastive learning tends to focus on learning abstract semantic-level features rather than pixel-level texture details, a wavelet transform decoupling is further applied to the synthetic distortion samples to construct a high-low frequency texture interaction network for extracting texture features. Finally, the two types of features are fused and regressed to generate the final quality score. Experimental results show that the proposed method achieves superior performance across three benchmark databases (namely IRCCyN/IVC, IETR and MCL-3D), with PLCC reaching 0.9404, 0.8380, and 0.9666 respectively, representing improvements of 0.0179, 0.0350, and 0.0175 higher than the existing best methods.},
  archive      = {J_TAI},
  author       = {Chongchong Jin and Yuanhao Cai and Yeyao Chen and Ting Luo and Zhouyan He and Yang Song},
  doi          = {10.1109/TAI.2025.3590692},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Contrastive learning feature enhancement and high-low frequency texture interaction networks for DIBR-synthesized view quality assessment},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Demystifying MuZero planning: Interpreting the learned model. <em>TAI</em>, 1-11. (<a href='https://doi.org/10.1109/TAI.2025.3591082'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {MuZero has achieved superhuman performance in various games by using a dynamics network to predict the environment dynamics for planning, without relying on simulators. However, the latent states learned by the dynamics network make its planning process opaque. This paper aims to demystify MuZero’s model by interpreting the learned latent states. We incorporate observation reconstruction and state consistency into MuZero training and conduct an in-depth analysis to evaluate latent states across two board games: 9x9 Go and Gomoku, and three Atari games: Breakout, Ms. Pacman, and Pong. Our findings reveal that while the dynamics network becomes less accurate over longer simulations, MuZero still performs effectively by using planning to correct errors. Our experiments also show that the dynamics network learns better latent states in board games than in Atari games. These insights contribute to a better understanding of MuZero and offer directions for future research to improve the performance, robustness, and interpretability of the MuZero algorithm. The code and data are available at https://rlg.iis.sinica.edu.tw/papers/demystifying-muzero-planning.},
  archive      = {J_TAI},
  author       = {Hung Guei and Yan-Ru Ju and Wei-Yu Chen and Ti-Rong Wu},
  doi          = {10.1109/TAI.2025.3591082},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {7},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Demystifying MuZero planning: Interpreting the learned model},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge distillation for an ensemble of students from a pyramid of teachers with diverse perspective. <em>TAI</em>, 1-10. (<a href='https://doi.org/10.1109/TAI.2025.3591588'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation (KD) can be used for enhancing the performance of a lightweight student models with the help of knowledge from heavier teacher models. Most KD methods for classification use a one-teacher one-student architecture where only one teacher is responsible for transferring knowledge to a student for all the classes. However, when the number of classes increases, it may become difficult for a single teacher to learn the salient characteristics of all the classes. This may also adversely affect the performance of a student in a KD approach. In this paper, we present a novel KD method where an ensemble of lightweight students is trained by a pyramid of teachers. At the top level of the pyramid, we have one teacher that learns all the class labels under consideration. As we go down the pyramid, the number of teachers increases at each level. However, except for the top level, each teacher learns a smaller subset of classes compared to its upper levels. Hence, different teachers learn different perspectives of the classification problem. Also, as we move down the pyramid, the teachers become more and more specialized. On the contrary, as we move upward, the teachers learn a broader and broader perspective about the classification problem. We design a novel distillation loss to distill the knowledge between the student and the pyramid of teachers. Experimental results on publicly available datasets show the effectiveness of the proposed method. The code can be found at https://github.com/Shilajit77/Pyramid-Distill/tree/main.},
  archive      = {J_TAI},
  author       = {Shilajit Banerjee and Angshuman Paul},
  doi          = {10.1109/TAI.2025.3591588},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {7},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Knowledge distillation for an ensemble of students from a pyramid of teachers with diverse perspective},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid clinical knowledge-driven transformer for breast ultrasound video classification. <em>TAI</em>, 1-11. (<a href='https://doi.org/10.1109/TAI.2025.3591580'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early diagnosis of breast cancer is critical for reducing mortality rates. Dynamic ultrasound videos contain rich tumor-specific features, offering valuable information for clinical diagnosis. In standard clinical practice, sonographers typically first identify keyframes before scanning the surrounding area of it to gather more information. Previous research based on ultrasound videos has been devoted to temporal modeling while neglecting the contribution of keyframes to tumor diagnosis. In this paper, we propose a two-stage hybrid network, Hybrid Keyframe-Guided Video Transformer (HKVT), to model both static keyframe and dynamic video information in breast ultrasound videos. In the first stage, the model uses a multi-instance learning paradigm to construct an efficient video classification model that automatically identifies keyframes using self-attention scores. In the second stage, the embedding tokens of the keyframe are extracted, and a keyframe-guided transfromer block is constructed for ultrasound video classification. Specifically, we designed a Keyframe-Guided Temporal Attention Module and a Keyframe-Guided Spatial Co-Attention Module to incorporate static keyframe features alongside dynamic video features. We evaluated the proposed model on an internal dataset of 342 patients and an external test dataset of 119 patients. The HKVT model achieved an AUC of 0.921 on the internal dataset and 0.901 on the external test dataset, outperforming other state-of-the-art models. Furthermore, our model demonstrated robust performance on 242 multi-center test cases, outperforming other models by at least 2.1% in AUC. These results demonstrate the superiority of our approach for breast ultrasound video classification.},
  archive      = {J_TAI},
  author       = {Mutian Li and Chenqian Zhao and Jiale Xu and Min Liu and Jinhua Yu and Zhao Yao},
  doi          = {10.1109/TAI.2025.3591580},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {7},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {A hybrid clinical knowledge-driven transformer for breast ultrasound video classification},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-label chest X-ray image classification via category disentangled causal learning. <em>TAI</em>, 1-14. (<a href='https://doi.org/10.1109/TAI.2025.3591094'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chest X-rays (CXR) are widely used to diagnose chest diseases. Since patients often suffer from multiple diseases simultaneously, it is crucial to identify multiple abnormalities in a single CXR image, which is defined as a multi-label classification task. Recent methods aim to improve performance by leveraging label co-occurrences as prior knowledge. However, these statistical co-occurrences often introduce spurious correlations, which reduce the reliability of the model, and data imbalance further amplifies the harm of such spurious correlations for rare disease diagnosis. In this study, we proposed a Category Disentangled Causal Learning (CDCL) framework that considers both category-level and causal-level representations to provide robust and reliable CXR image diagnosis results. Specifically, we introduce the Category Attention (CA) mechanism to disentangle disease-specific features, enabling the model to effectively capture the discriminative features of each disease in the image. Additionally, we employ the label embeddings to learn a set of discriminative features at the global category level, complementing CA to enhance the effectiveness of category disentanglement. Causal intervention is then applied to the disentangled features to guide the model in learning true causal relationships, mitigating the impact of spurious correlations. The proposed CDCL framework was evaluated on the ChestX-Ray14 and CheXpert datasets, achieving mean AUC of 0.849 and 0.896, respectively. Ablation studies and visualization experiments demonstrated its competitiveness, particularly with significant improvements in rare disease identification.},
  archive      = {J_TAI},
  author       = {Qiang Li and Mengdi Liu and Rihao Chang and Weizhi Nie and Shaojin Bai and Anan Liu},
  doi          = {10.1109/TAI.2025.3591094},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {7},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Multi-label chest X-ray image classification via category disentangled causal learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Frequency-domain feature reconstruction network with memory units for anomaly detection of fused magnesium furnaces. <em>TAI</em>, 1-11. (<a href='https://doi.org/10.1109/TAI.2025.3591089'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection of smelting process benefits the operation safety of fused magnesium furnaces (FMFs). While generative models that fit well complex data distributions in the latent space offer an effective way to anomaly detection, conventional generative models have difficulties in adapting to visual interferences such as dynamic water mist, dust, and on-site lighting changes. To this end, this paper establishes a new frequency-domain feature reconstruction network with memory units for anomaly detection of fused magnesium furnaces. This network utilizes high-frequency filtering to extract features in the frequency domain to suppress the adverse effects of brightness variations caused by fluctuations in the furnace flame. Using the extracted frequency domain features, wavelet sampling is integrated with memory units for reconstruction to eliminate interferences in the frequency domain while preserving anomalous features, thereby alleviating overgeneralization. Moreover, a new adaptive threshold calculation method is proposed for the anomaly detection of FMFs. Finally, the effectiveness of the proposed method is demonstrated by using the image collected from a real FMF.},
  archive      = {J_TAI},
  author       = {Qiang Liu and Yuxin Wang and Chao Yang and Jialin An and Yiu-ming Cheung},
  doi          = {10.1109/TAI.2025.3591089},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {7},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Frequency-domain feature reconstruction network with memory units for anomaly detection of fused magnesium furnaces},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CLARITY: A lightweight multimodal transformer for harmful content detection. <em>TAI</em>, 1-11. (<a href='https://doi.org/10.1109/TAI.2025.3591585'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social media platforms are vital to modern communication, but they also enable the spread of harmful content, such as hate speech and misinformation. Current detection models, while accurate, are often resource-intensive and unsuitable for real-time or resource-constrained environments. Moreover, even models that incorporate multilingual capabilities often fail to generalize effectively across different languages. To address this challenge, we propose CLARITY, a novel lightweight cross-modal transformer architecture designed for efficient and scalable harmful content detection. Unlike traditional models, CLARITY achieves faster processing while maintaining accuracy, making it accessible to a wider range of platforms and devices. CLARITY integrates text, image, and audio modalities to capture complex, multimodal interactions that enhance detection across diverse content types. By employing contrastive learning, CLARITY accurately distinguishes between reclaimed language and genuinely harmful content, significantly reducing false positives and promoting inclusivity, particularly for marginalized communities. Additionally, CLARITY incorporates a domain adaptation module with cross-lingual and multi-lingual, enabling it to generalize effectively across various platforms and ensuring robust performance even in dynamic online environments. We evaluate CLARITY across multiple benchmark datasets and GPUs, including Kaggle’s Tesla P100, Colab Pro’s NVIDIA T4, and NVIDIA A100. The results demonstrate a significant reduction in inference time, with the A100 achieving an average inference time of 0.85 seconds per instance–over 30% faster than traditional models–while maintaining competitive accuracy.},
  archive      = {J_TAI},
  author       = {Gautam Siddharth Kashyap and Niharika Jain and Ebad Shabbir and Harsh Joshi and Usman Naseem and Jiechao Gao},
  doi          = {10.1109/TAI.2025.3591585},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {7},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {CLARITY: A lightweight multimodal transformer for harmful content detection},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated stochastic configuration networks with universal approximation property. <em>TAI</em>, 1-15. (<a href='https://doi.org/10.1109/TAI.2025.3592179'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic Configuration Networks (SCNs), a class of randomized learner models, are incrementally constructed under a supervisory mechanism, ensuring the universal approximation property. As powerful tools for data modeling, SCNs have received considerable attention due to their guaranteed reliable learning performance, easy implementation, and robustness with respect to learning parameters. In this work, we aim to touch the base of Federated Learning (FL) with neural networks, and propose a novel FL framework with SCN models, termed Federated Stochastic Configuration Networks (FSCNs). Our key contribution lies in the first time establishing some fundamental results on the universal approximation property, which can be regarded as a milestone in the working field. The proposed method incorporates a collaborative Particle Swarm Optimization (PSO) mechanism, enabling clients to collectively optimize hidden nodes without sharing local data. Unlike the traditional Federated Averaging (FedAvg) methods, which rely on weighted average aggregation, our approach leverages the global search capability of PSO to configure new hidden nodes, thereby enhancing the learning performance and model stability. Experiments on both benchmark and real-world datasets show that the proposed Federated Stochastic Configuration Networks (FSCNs) outperform the existing solutions in terms of learning capability, convergence speed and model compactness.},
  archive      = {J_TAI},
  author       = {Dianhui Wang and Ningning Xie and Xiufeng Yan},
  doi          = {10.1109/TAI.2025.3592179},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Federated stochastic configuration networks with universal approximation property},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On expressivity of height in neural networks. <em>TAI</em>, 1-13. (<a href='https://doi.org/10.1109/TAI.2025.3592162'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, beyond width and depth in a traditional neural network, we augment a neural network with a new dimension called height by inserting links to neurons in the same layer, which gives rise to the notion of height. These links, referred to as intra-layer links, form hierarchical structures that enhance the network’s approximation ability (expressivity) without increasing its parameter count. We show that this 3D architecture (width × depth × height) is more powerful than conventional 2D networks (width × depth) theoretically and empirically. First, given the same number of neurons, a 3D ReLU network (W × K × H) can generate exponentially more pieces in a piecewise linear function than a 2D one (HW × K), i.e., $\mathcal{O}((2^{H} - 1)W)^{K})$ vs $\mathcal{O}((HW)^{K})$. Next, from the perspective of approximation, a 3D network (W × K × W) can achieve higher accuracy in approximating polynomials and reduce errors exponentially compared to a traditional 2D network (W2 × K), i.e., $\mathcal{O}(2^{-2W\,K})$ vs $\mathcal{O}(W^{-K})$. Lastly, numerical experiments on 5 synthetic datasets, 15 tabular datasets, and 3 image benchmarks verify that 3D networks can deliver competitive regression and classification performance. Our code has been released for readers’ free download and evaluation.},
  archive      = {J_TAI},
  author       = {Feng-Lei Fan and Ze-Yu Li and Huan Xiong and Tieyong Zeng},
  doi          = {10.1109/TAI.2025.3592162},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {7},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {On expressivity of height in neural networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Balanced sampling and reusing imaginary data for world models in reinforcement learning. <em>TAI</em>, 1-13. (<a href='https://doi.org/10.1109/TAI.2025.3592174'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep reinforcement learning (DRL) has shown significant success in domains such as computer vision and robot control. However, DRL agents often suffer from low sample efficiency, limiting their practical applicability in industrial settings. Recent advances in model-based DRL, particularly model-based approaches, have sought to address this issue by leveraging imaginary data to improve decision-making and sampling efficiency. Despite their promise, these methods face challenges such as overreliance on early experiences in the replay buffer and under-utilization of imaginary data, which can lead to overfitting and suboptimal policy optimization. To overcome these limitations, we propose a novel reinforcement learning framework, balanced sampling and reusing imaginary data (BSRID), which introduces two key innovations: (1) a balanced sampling (BS) mechanism that ensures uniform sampling rates to mitigate bias toward early experiences and (2) a reusing imaginary data (RID) strategy that enhances policy optimization by increasing update frequency and maximizing the utility of imaginary data. The experimental results on the Atari 100k benchmark demonstrate that BSRID significantly improves sample efficiency and achieves state-of-the-art performance. This work provides a robust and efficient solution for DRL applications in scenarios requiring high sample efficiency and reliable decision making. The code is available at https://github.com/wwwqqyy/BSRID.},
  archive      = {J_TAI},
  author       = {Qianyu Wang and Xuekai Wei and Jielu Yan and Leong Hou U and Huayan Pu and Jun Luo and Weijia Jia and Mingliang Zhou},
  doi          = {10.1109/TAI.2025.3592174},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {7},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Balanced sampling and reusing imaginary data for world models in reinforcement learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimising ADHD detection: An autoencoder approach for multimodal classification. <em>TAI</em>, 1-11. (<a href='https://doi.org/10.1109/TAI.2025.3592157'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attention Deficit Hyperactivity Disorder (ADHD) is commonly found in children, with the prevalence in adults said to be under-reported. In this paper, we aim to detect adult ADHD symptoms using two autoencoder architectures. We train and test on the novel multimodal ADHD dataset recorded under the Intelligent Sensing ADHD Trial in collaboration with the Cumbria, Northumberland, Tyne and Wear NHS Foundation Trust, UK. The autoencoder architectures perform an image reconstruction task to optimise the latent bottleneck feature space to perform downstream classification tasks to detect ADHD subjects or control participants. The RGB video data is specifically exploited to inform the autoencoders about the hyperactivity symptoms. The Audio data is used to further support hyperactivity symptoms while also hoping to gain scope on inattentive symptoms. The self report questionnaire is a subjective measure, where the individual can provide details of ADHD symptoms that they experience. It is a vital data source to include in the proposed work for providing the autoencoders previously unidentifiable symptoms. An ablation study is undertaken to demonstrate the effectiveness of the individual data modality, attempting to distinguish the associated discriminatory power. Using rigorous validation techniques, we achieve a state-of-the-art classification accuracy, sensitivity and specificity of 98.9%, 99.2% and 98.5% respectively. With ADHD classification being a preliminary subjective decision, the proposed work demonstrates that an objective system can provide robust support to ADHD clinicians in the future.},
  archive      = {J_TAI},
  author       = {Christian Nash and Rajesh Nair and Syed Mohsen Naqvi},
  doi          = {10.1109/TAI.2025.3592157},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {7},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Optimising ADHD detection: An autoencoder approach for multimodal classification},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SleepLog: Local-global deep fusion learning for sleep staging transformer. <em>TAI</em>, 1-13. (<a href='https://doi.org/10.1109/TAI.2025.3591587'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sleep disorders affect a significant portion of the global population and contribute to increased overall mortality. Automatic sleep staging through analyzing physiological signals is pivotal in expanding sleep assessment and diagnostic capabilities. However, due to the complex non-stationary characteristics of physiological signals and the individual differences between subjects, obtaining the effective features of the physiological signals is still challenging. To this end, we propose a novel Transformer-based sleep staging method, SleepLog, to combine local and global information for feature extraction. First, a CNN-based (convolutional neural network, CNN) module was used to extract the local information to capture the features of sleep characteristic wave events. Then, we extract the global information that reflects the transformation between different characteristic waves using a self-attention-based patch encoder module. Furthermore, the local and global information was fed to the Transformer encoder module to enable the class (CLS) token of each branch to extract supplementary information from the associated features. Finally, we propose a simple yet effective cross-attention-based feature fusion module, which uses a single class token for each branch as a query to exchange information with other branches. The proposed cross-attention only requires linear time for both computational and memory complexity. To validate the performance of the proposed method, we evaluate SleepLog on a publicly available dataset Sleep-EDF. The experimental results show that the proposed model can maintain superior performance, indicating that it has the potential to develop and apply a home-environment automatic sleep staging system.},
  archive      = {J_TAI},
  author       = {Jingpeng Sun and Chen Chen and Weiping Ding and Xiyuan Hu},
  doi          = {10.1109/TAI.2025.3591587},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {7},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {SleepLog: Local-global deep fusion learning for sleep staging transformer},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Collective performance induced by social and individual learning in any population structure: An evolutionary game approach. <em>TAI</em>, 1-15. (<a href='https://doi.org/10.1109/TAI.2025.3592636'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collective decision-making is vital and widespread in human and artificial societies. Individuals often choose the option by assessing the intrinsic values of options in decision-making through individual learning. But they are also influenced by peer pressure and select the option by conformity-based social learning. A central question is whether the population can settle on the most beneficial option when social learning is involved. Previous studies concerning social learning focused on well-mixed populations where individuals are equally likely to interact with each other. But real social interactions are often more subtle that are modeled by a graph. Therefore it is challenging to theoretically analyze the effect of social learning on collective decision-making in structured populations. To address this issue, using evolutionary game theory we propose an evolutionary model of binary options jointly integrating individual and social learning in any population structure. We first derive the average fraction of the option with higher merit by means of coalescing random walks and find that the introduction of conformity-based social learning is detrimental to collective performance of decision-making. Interestingly, however, our theoretical analysis reveals that the majority of the population always favors the option with higher merit regardless of the preference of social learning. Importantly, these theoretical predictions are valid for any population structure and they are verified by intensive numerical simulations made in three representative static interaction structures. We further show that they hold in dynamic networks via computer simulations. We also demonstrate the robustness of our findings to different conformity-based social learning procedures.},
  archive      = {J_TAI},
  author       = {Zhifang Li and Jingwei Zhang and Xiaojie Chen and Attila Szolnoki},
  doi          = {10.1109/TAI.2025.3592636},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Collective performance induced by social and individual learning in any population structure: An evolutionary game approach},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards general protein structure representation learning with a protein size prompt. <em>TAI</em>, 1-10. (<a href='https://doi.org/10.1109/TAI.2025.3592637'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning-based protein function analysis is rapidly advancing, but most methods rely heavily on labeled data, which is typically scarce due to the need for expensive wet lab experiments. Self-supervised learning (SSL) is a viable solution because it can improve the model performance on downstream tasks by pre-training on large-scale unlabeled data. However, existing SSL methods overlook the disparities in data distributions between pre-training and downstream tasks, which we show has a large influence on the effectiveness of SSL. To tackle this problem, we propose a new protein representation learning framework with a protein size prompt (ProSP). ProSP allows the pre-trained model to learn size-related information during pre-training and adapt to downstream tasks with different protein size distributions. Results of 48 experiments across eight downstream tasks, three data splits, and two data representations show that ProSP successfully improves the performance in all experiments with minimal modifications to the original model.},
  archive      = {J_TAI},
  author       = {Ao Shen and Mingzhi Yuan and Yingfan Ma and Qiao Huang and Jie Du and Zhijuan Cao and Manning Wang},
  doi          = {10.1109/TAI.2025.3592637},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {7},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Towards general protein structure representation learning with a protein size prompt},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learn once plan arbitrarily (LOPA): Dynamic observation-based deep reinforcement learning method for global path planning in mountainous terrain environment. <em>TAI</em>, 1-15. (<a href='https://doi.org/10.1109/TAI.2025.3592648'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep reinforcement learning (DRL) methods have recently shown promise in path planning tasks. However, when dealing with global planning tasks in mountainous terrain (2.5D) environment, these methods face serious challenges such as poor convergence and generalization. To this end, we propose LOPA (Learn Once Plan Arbitrarily), an enhanced DRL method that learns on a single map yet generalizes to topographically similar terrains. Consequently, it enables path planning across multiple mountainous terrain maps while balancing path distance and energy consumption. Firstly, we analyze the reasons of convergence and generalization problems from the perspective of DRL’s observation, revealing that the conventional design causes DRL to be interfered by irrelevant map information. Secondly, we develop the LOPA which utilizes a novel dynamic observation mechanism to attain an improved capability in focusing on key information of the observation. Such a mechanism is realized by two steps: (1) a dynamic observation model is built to transform the DRL’s observation into two dynamic views: local and global, significantly guiding the LOPA to focus on the key information of the given maps; (2) a dual-channel network is constructed to process these two views and integrate them to attain an improved reasoning capability. Meanwhile, through Rademacher Complexity analysis, we provide theoretical justification for LOPA’s improved generalization capability, demonstrating a lower upper bound on the generalization error. The LOPA is validated through multi-objective global path planning experiments conducted on both simulated and real maps. The results suggest that LOPA has improved convergence and generalization performance, as well as great planning efficiency.},
  archive      = {J_TAI},
  author       = {Shuqiao Huang and Mingxin Hou and Xiaofang Yuan and Xiru Wu and Yaonan Wang and Guoming Huang},
  doi          = {10.1109/TAI.2025.3592648},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Learn once plan arbitrarily (LOPA): Dynamic observation-based deep reinforcement learning method for global path planning in mountainous terrain environment},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AR2FL: Anomaly-resistant robust framework for federated learning. <em>TAI</em>, 1-11. (<a href='https://doi.org/10.1109/TAI.2025.3592635'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) enables collaborative model training across decentralized data sources while preserving privacy. However, FL systems are vulnerable to attacks from malicious clients that can degrade model performance and compromise integrity. In this work, we propose AR2FL, an anomaly-resistant and robust framework that enhances FL aggregation by leveraging mean latent representations of client updates. This data-driven approach enables the server to estimate inter-client similarity and dynamically scale clients contributions, reducing the influence of anomalous or adversarial updates. Unlike methods based on fixed distance metrics such as cosine similarity or Euclidean distance, AR2FL captures deeper statistical patterns in the latent space, enabling more accurate and secure model updates. Experiments on several datasets show AR2FL maintains strong accuracy, fast convergence, and high robustness, making it suitable for secure large-scale FL.},
  archive      = {J_TAI},
  author       = {Mayank Kumar Kundalwal and Deepak Mishra},
  doi          = {10.1109/TAI.2025.3592635},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {7},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {AR2FL: Anomaly-resistant robust framework for federated learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Event-driven implementation of a physical reservoir computing framework for superficial EMG-based gesture recognition. <em>TAI</em>, 1-13. (<a href='https://doi.org/10.1109/TAI.2025.3592899'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wearable health devices have a strong demand in real-time biomedical signal processing. However traditional methods often require data transmission to centralized processing unit with substantial computational resources after collecting it from edge devices. Neuromorphic computing is an emerging field that seeks to design specialized hardware for computing systems inspired by the structure, function, and dynamics of the human brain, offering significant advantages in latency and power consumption. This paper explores a novel neuromorphic implementation approach for gesture recognition by extracting spatiotemporal spiking information from surface electromyography (sEMG) data in an event-driven manner. At the same time, the network was designed by implementing a simple-structured and hardware-friendly Physical Reservoir Computing (PRC) framework called Rotating Neuron Reservoir (RNR) within the domain of Spiking neural network (SNN). The spiking RNR (sRNR) is promising to pipeline an innovative solution to compact embedded wearable systems, enabling low-latency, real-time processing directly at the sensor level. The proposed system was validated by an open-access large-scale sEMG database and achieved an average classification accuracy of 74.6% and 80.3% using a classical machine learning classifier and a delta learning rule algorithm respectively. While the delta learning rule could be fully spiking and implementable on neuromorphic chips, the proposed gesture recognition system demonstrates the potential for near-sensor low-latency processing.},
  archive      = {J_TAI},
  author       = {Yuqi Ding and Elisa Donati and Haobo Li and Hadi Heidari},
  doi          = {10.1109/TAI.2025.3592899},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {7},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Event-driven implementation of a physical reservoir computing framework for superficial EMG-based gesture recognition},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enable quantum graph neural networks on a single qubit with quantum walk. <em>TAI</em>, 1-10. (<a href='https://doi.org/10.1109/TAI.2025.3592896'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum computing holds significant potential for advancing machine learning, particularly in handling complex graph-structured data. This paper introduces Single-Qubit Quantum Graph Neural Networks (sQGNNs), a novel model that integrates quantum networks with quantum walk operations to improve generalization in graph learning tasks. By leveraging quantum walks, we demonstrated sQGNNs capture complex relational patterns and enhance network expressiveness beyond classical methods. Our results proved that quantum encoding efficiently represents high-dimensional graph data, preserving dependencies and optimizing memory use. Across benchmark datasets, sQGNNs demonstrate superior generalization and robustness against overfitting, achieving higher accuracy with reduced computational cost. Our results underscore sQGNNs’ promise for scalable, quantum-enhanced graph learning, establishing a foundation for future quantum-assisted machine learning applications.},
  archive      = {J_TAI},
  author       = {Yijie Zhu and Richard Jiang and Qiang Ni and Ahmed Bouridane},
  doi          = {10.1109/TAI.2025.3592896},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {7},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Enable quantum graph neural networks on a single qubit with quantum walk},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Histogram layers for neural “Engineered” features. <em>TAI</em>, 1-13. (<a href='https://doi.org/10.1109/TAI.2025.3593445'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the computer vision literature, many effective histogram-based features have been developed. These “engineered” features include local binary patterns and edge histogram descriptors among others and they have been shown to be informative features for a variety of computer vision tasks. In this paper, we explore whether these features can be learned through histogram layers embedded in a neural network and, therefore, be leveraged within deep learning frameworks. By using histogram features, local statistics of the feature maps from the convolution neural networks can be used to better represent the data. We present neural versions of local binary pattern and edge histogram descriptors that jointly improve feature representation for image classification. Experiments are presented on benchmark and real-world datasets. Our code is publicly available 11https://github.com/Advanced-Vision-and-Learning-Lab/NEHD NLBP.},
  archive      = {J_TAI},
  author       = {Joshua Peeples and Salim Al Kharsa and Luke Saleh and Alina Zare},
  doi          = {10.1109/TAI.2025.3593445},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {7},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Histogram layers for neural “Engineered” features},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Teleportation: Defense against stealing attacks of data-driven healthcare APIs. <em>TAI</em>, 1-15. (<a href='https://doi.org/10.1109/TAI.2025.3593470'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increased popularity of digital healthcare services has prompted the development of different types of datadriven healthcare APIs on top of electronic health records, offering the convenience of aided diagnostic services without compromising privacy. Defense against the unauthorized extraction of healthcare APIs is important due to: 1) the unauthorized cloned model could serve online as fake healthcare service providers and pose harm to the general public; 2) protected training data containing private electronic health records could be further extracted from the stolen model. It is therefore important to protect the data-driven healthcare APIs from unauthorized clone and extraction. In this work, we propose a principled defense strategy with adaptive teleportation of incoming queries to effectively guard against extraction attacks of healthcare APIs. The proposed mechanism prevents unauthorized copy of model functionality while maintaining the utility of APIs to serve benign queries. The adaptive teleportation operations are generated based on the formulated bi-level optimization target and follows the evolution trajectory depicted by the Wasserstein gradient flows, which effectively push attacking queries to cross decision boundary while constraining the deviation level of benign queries, utilizing the fact that attacker generated pseudo-queries are mostly closer to decision boundaries than normal queries. This provides misleading information on malicious queries while preserving model utility. We performed detailed analysis of the proposed mechanism on three healthcare related prediction tasks including in-hospital mortality, bleed risk and ischemic risk prediction for validation of its effectiveness under different types of attacking scenarios. The proposed mechanism is significantly more effective to suppress the performance of cloned model while maintaining comparable serving utility compared to existing defense approaches.},
  archive      = {J_TAI},
  author       = {Tiehang Duan and Zhenyi Wang and Li Shen and Siyu Luan and Fang Li and Gianfranco Doretto and Donald A. Adjeroh and Shuteng Niu and Jianfu Li and Cui Tao},
  doi          = {10.1109/TAI.2025.3593470},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Teleportation: Defense against stealing attacks of data-driven healthcare APIs},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attention based traffic flow forecasting model as a service of intelligent transportation system. <em>TAI</em>, 1-10. (<a href='https://doi.org/10.1109/TAI.2025.3593471'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate traffic forecasting has become necessary due to the increase in vehicles on the road and it’s potential use in autonomous vehicles. Although many traffic forecasting algorithms have been suggested but the majority of these systems only anticipate short-term traffic prediction. Future vehicular systems, however, will need a hybrid traffic forecasting model that foresees vehicular traffic at different time values. In this paper, a time-varying Attention based Traffic Flow Forecasting Model (ATFFM) is proposed that forecasts vehicular traffic at a particular location for different time spans. ATFFM is based on network-wide, large-scale traffic with spatial and temporal characteristics. The traffic data is obtained using object detection method on traffic images/videos and is further applied with ATFFM. The final forecast is computed by fusing the external factors with temporal and spatial information. Using vehicular communication, the predicted information can be disseminated to all other nearby vehicles for decision making. The proposed model exhibits scalability, adaptability and lower computational overhead in predicting the traffic. Obtained values of traffic prediction errors falls in an average range of 2% to 10% for traffic intersection points of varying vehicular density.},
  archive      = {J_TAI},
  author       = {Nishu Bansal and Rasmeet Singh Bali},
  doi          = {10.1109/TAI.2025.3593471},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {7},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Attention based traffic flow forecasting model as a service of intelligent transportation system},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DDConv: Dynamic dilated convolution. <em>TAI</em>, 1-10. (<a href='https://doi.org/10.1109/TAI.2025.3593177'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dilated convolution is a powerful technique for expanding the receptive field without increasing the convolution kernel size, making it highly valuable in image segmentation tasks. However, some challenges still exist, such as sparse feature extraction at high dilation rates and limited neighboring information interaction. To address these issues, a novel approach, termed Dynamic Dilated Convolution (DDConv), is proposed for adaptive feature extraction by dynamically adjusting dilation rates in this paper. In DDConv, dilated convolutions are divided into four groups along the channel, each assigned distinct dilation rates. Attention weights are then used to aggregate information across these groups, enabling the convolution kernel to dynamically select the dilation rate during feature map convolution. Experimental results demonstrate the effectiveness of the proposed methods, with DDConv delivering outstanding performance. These findings suggest promising implications for DDNeXt as a novel backbone construction approach for future developments in the field.},
  archive      = {J_TAI},
  author       = {Haigen Hu and Chenghan Yu and Qianwei Zhou and Qiu Guan and Tongxue Zhou},
  doi          = {10.1109/TAI.2025.3593177},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {7},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {DDConv: Dynamic dilated convolution},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ConvRoBERTa: Detecting fake reviews by fusing sequential and weighted non-sequential features. <em>TAI</em>, 1-14. (<a href='https://doi.org/10.1109/TAI.2025.3594314'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {E-commerce platforms increasingly rely on product reviews to support consumer decision-making. However, some merchants manipulate these reviews by hiring individuals to post fake feedback, complicating the evaluation process for potential buyers. Consequently, detecting fraudulent reviews has emerged as a critical research challenge. Existing studies primarily focus on linguistic and behavioural features, employing traditional machine learning (ML) methods that treat all features with equal importance. This approach is suboptimal because not all features contribute equally to model performance. To address these limitations, we propose ConvRoBERTa, a hybrid deep learning model that effectively integrates non-sequential (NS) and sequential (S) features for fake review detection. Initially, feature importance is determined using the Classification and Regression Trees (CART) method on NS data, followed by a Convolutional Neural Network (CNN) to extract enhanced patterns from the weighted features. Simultaneously, sequential features are processed using the RoBERTa model to obtain contextual representations. A dot-product attention mechanism is then employed to fuse both feature types, forming a comprehensive joint representation for classification. Experimental results on the Yelp dataset show that ConvRoBERTa outperforms traditional baselines with a 2.94% increase in accuracy. Moreover, the ConvRoBERTa-SVM variant further improves accuracy to 91.93%, demonstrating the model’s effectiveness and offering valuable insights for future research in fake review detection.},
  archive      = {J_TAI},
  author       = {Arvind Mewada and Rupesh Kumar Dewang},
  doi          = {10.1109/TAI.2025.3594314},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {7},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {ConvRoBERTa: Detecting fake reviews by fusing sequential and weighted non-sequential features},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Universal domain alignment framework for classification and regression tasks. <em>TAI</em>, 1-14. (<a href='https://doi.org/10.1109/TAI.2025.3594315'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised Domain Adaptation (UDA), a critical technique for transferring knowledge from labeled source domains to unlabeled target domains, holds significant value in both classification and regression tasks. However, existing methods are often designed for a single task, lacking a unified framework that can handle both types of tasks simultaneously. Moreover, while global distribution alignment can reduce the overall discrepancy between the source and target domains, inconsistencies in local feature spaces persist. These local inconsistencies may introduce biases in high-level semantic structures, increasing the variability of feature distributions and significantly weakening the model’s generalization ability in the target domain. To address these challenges, we propose a Universal Domain Alignment Framework (UDAF), which achieves unified modeling for classification and regression tasks while reducing local distribution discrepancies through the Target Space Coupling Module (TSCM) and the Domain Embedding Consistency Loss (DECL). In UDAF, TSCM optimizes the structure of the output space to meet the requirements of both classification and regression tasks. Specifically, for labeled source domain data, we minimize the distance between features and their corresponding class centers to cluster similar samples in the output space. For unlabeled target domain data, pseudo labels are generated using prediction probabilities to estimate target class centers, and the class centers are dynamically updated to optimize the output space structure. Meanwhile, DECL models local feature alignment from a sample-to-domain perspective. By measuring the distance between target domain samples and the orthogonal basis of source domain subspaces, DECL explicitly captures local distribution biases and incorporates them as optimization objectives, further enhancing the fine-grained alignment of cross-domain features. The proposed UDAF is highly extensible and can be seamlessly integrated into existing methods. Comprehensive experiments conducted on seven datasets demonstrate that this approach achieves a performance improvement, especially with an 2.1% improvement on DomainNet dataset.},
  archive      = {J_TAI},
  author       = {Xin Wang and Jielong Yang and Yixing Gao},
  doi          = {10.1109/TAI.2025.3594315},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {7},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Universal domain alignment framework for classification and regression tasks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed generative model: A data synthesizing framework for multi-source heterogeneous data. <em>TAI</em>, 1-13. (<a href='https://doi.org/10.1109/TAI.2025.3575548'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancement in generative AI influenced a broad area with successful applications across multiple domains, including computer vision, natural language processing, and the Internet of Things (IoT). However, many existing implementations rely on centralized architectures, which introduce security and privacy concerns while also increasing communication overhead. Limited research has explored the development of distributed generative models, particularly in scenarios where training data originates from various heterogeneous sources. To fill the gap, this paper introduces a distributed generative model framework aimed at enhancing data generation in hierarchical IoT systems. The proposed framework supports distributed data generation across three distinct scenarios: feature-related data, label-related data, and feature-label non-related data. Furthermore, both synchronous and asynchronous update mechanisms are incorporated to accommodate diverse application requirements within IoT environments. Comprehensive experiments using simulated, image, and tabular datasets are conducted to assess the performance of the proposed framework in comparison with state-of-the-art methods. The results indicate that the framework effectively produces high-quality synthetic data while preserving the integrity of downstream tasks. Beyond large language models (LLMs), these findings suggest that generative AI have the potential to transform data generation in distributed IoT systems and be extended to a broader range of applications.},
  archive      = {J_TAI},
  author       = {Zuobin Xiong and Wei Li and Yingshu Li and Zhipeng Cai},
  doi          = {10.1109/TAI.2025.3575548},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {6},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Distributed generative model: A data synthesizing framework for multi-source heterogeneous data},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large linguistic models: Investigating LLMs’ metalinguistic abilities. <em>TAI</em>, 1-15. (<a href='https://doi.org/10.1109/TAI.2025.3575745'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of large language models (LLMs) has recently improved to the point where models can perform well on many language tasks. We show here that—for the first time—the models can also generate valid metalinguistic analyses of language data. We outline a research program where the behavioral interpretability of LLMs on these tasks is tested via prompting. LLMs are trained primarily on text—as such, evaluating their metalinguistic abilities improves our understanding of their general capabilities and sheds new light on theoretical models in linguistics. We show that OpenAI’s (2024) o1 vastly outperforms other models on tasks involving drawing syntactic trees and phonological generalization. We speculate that OpenAI o1’s unique advantage over other models may result from the model’s chain-of-thought mechanism, which mimics the structure of human reasoning used in complex cognitive tasks, such as linguistic analysis.},
  archive      = {J_TAI},
  author       = {Gasper Begus and Maksymilian Dabkowski and Ryan Rhodes},
  doi          = {10.1109/TAI.2025.3575745},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {6},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Large linguistic models: Investigating LLMs’ metalinguistic abilities},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ICQ-TransE: LLM-enhanced image-caption-question translating embeddings for knowledge-based visual question answering. <em>TAI</em>, 1-14. (<a href='https://doi.org/10.1109/TAI.2025.3575553'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In knowledge-based visual question answering (KB-VQA), the answer can be naturally represented by translating visual object embedding referred by the question according to the cross-modality relation embedding related to both the question and the image. Though the triplet representation of cross-modality knowledge is plausible and proven effective, these methods often encounter two challenges: 1) The semantic gap between the image and the question makes it difficult to accurately embed the cross-modality relation; 2) The visual objects in the question often have ambiguous references in the input image. To solve the above challenges, we propose the Image-Caption-Question Translating Embeddings (ICQ-TransE), which more effectively models both the cross-modality relation and the head entity of visual objects. Specifically, for cross-modality relation embedding, the designed image-caption-question information transmission mechanism transmits the information flow from image to question through the caption bridge, where the caption simultaneously has the visual content and the textual form. With this powerful bridge, cross-modality information can be more effectively fused, resulting in more precisely encoded relation embeddings. For the visual object embedding, instead of using a fixed number of visual regions as the previous methods, the most relevant visual regions to the question are dynamically selected. Experimental results on OK-VQA and KRVQA challenging datasets verify the effectiveness of ICQ-TransE compared to multiple state-of-the-art methods for visual question answering with knowledge. Our code will be available at https://github.com/cmcv2022/ICQ-TransE.},
  archive      = {J_TAI},
  author       = {Heng Liu and Boyue Wang and Xiaoyan Li and Yanfeng Sun and Yongli Hu and Baocai Yin},
  doi          = {10.1109/TAI.2025.3575553},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {6},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {ICQ-TransE: LLM-enhanced image-caption-question translating embeddings for knowledge-based visual question answering},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Causal disentanglement for tackling popularity bias in sequential recommendation. <em>TAI</em>, 1-13. (<a href='https://doi.org/10.1109/TAI.2025.3575554'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems typically exhibit severe popularity bias, with a few highly popular items receiving excessive exposure. Most existing studies tackle this bias in static settings. However, they neglect the dynamic nature of real-world recommendation scenarios and lack a thorough analysis into the root causes of bias, which makes it challenging to accurately model and mitigate the dynamically changing popularity bias and capture genuine user preferences. To this end, we propose a Causal Disentanglement Sequential Recommendation Model (CDSRec) based on time series analysis and hidden variable separation. Our model leverages Markov chains to analyze historical interaction data within sequential recommendations, capturing the dynamic variations of item popularity and user preferences. Employing causal inference, we disentangle the potential factors implicated in popularity bias. Specifically, user-item interactions are primarily driven by personalized demands and item popularity. Through empirical analysis from a temporal perspective, we reveal that popularity has both positive and negative impacts, and attribute them to stable intrinsic quality factors and dynamic external interference factors. We construct a causal Directed Acyclic Graph to elucidate the temporal correlations among different factors. Subsequently, we utilize historical interaction sequences and item-related attributes as auxiliary information to explicitly disentangle these factors as hidden variables. By reformulating the objective function to optimize the sequential VAE framework, our model effectively mitigates the negative impact of external interference factors. Extensive experimental results on three real-world datasets demonstrate the superiority of our proposed model.},
  archive      = {J_TAI},
  author       = {An-An Liu and Yadong Zhao and Xin Wen and Rihao Chang and Weizhi Nie},
  doi          = {10.1109/TAI.2025.3575554},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {6},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Causal disentanglement for tackling popularity bias in sequential recommendation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FG-KD: A novel forward gradient-based framework for teacher knowledge augmentation. <em>TAI</em>, 1-16. (<a href='https://doi.org/10.1109/TAI.2025.3576087'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation has become increasingly popular for training compact neural network models that can achieve comparable performance to larger models. In order to improve the effectiveness of knowledge distillation, enhancing the quality of the teacher knowledge is a crucial aspect to consider. While existing efforts have predominantly focused on optimizing the structure of teacher models and refining training procedures, we argue that there is untapped potential in further enhancing knowledge distillation through the augmentation of the teacher knowledge itself. In this paper, we introduce FG-KD, a novel forward gradient-based framework specifically designed for augmenting teacher knowledge in knowledge distillation. FG-KD comprises two fundamental components: a feature reconstructor and a relation-aware enhancer. Both components employ a forward gradient-based approach to unlock the latent potential for enhancing teachers’ knowledge, thereby providing an enriched foundation for knowledge distillation. The feature reconstructor operates at the feature level, enabling the optimization of the teacher knowledge by enhancing the encoding of high-dimensional spaces. On the other hand, the relation-aware enhancer operates at the logit level, with a focus on identifying and reinforcing the inter-class and intra-class relationships within the teacher knowledge. Through extensive experiments conducted on image recognition tasks, we demonstrate the effectiveness of FG-KD in improving the performance of various knowledge distillation techniques, regardless of the specific teacher-student model combinations},
  archive      = {J_TAI},
  author       = {Yang Yang and Chao Wang and Lei Gong and Min Wu and Zhenghua Chen and Xuehai Zhou},
  doi          = {10.1109/TAI.2025.3576087},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {6},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {FG-KD: A novel forward gradient-based framework for teacher knowledge augmentation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Soft parameter sharing model for cross-problem generalization in vehicle routing problems. <em>TAI</em>, 1-15. (<a href='https://doi.org/10.1109/TAI.2025.3576336'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural Combinatorial Optimization (NCO) has achieved remarkable performance in solving individual Vehicle Routing Problems (VRPs) by leveraging attention mechanisms. However, when generalizing across different problems, these methods perform poorly because the hard parameter sharing models they adopted are unable to capture the commonalities and peculiarities of different problems. To address this limitation, we propose a novel multi-task NCO method called the Soft Parameter Sharing Model (SPSM) that incorporates multiple independent attention modules and a gating network. SPSM allows the model to learn both universal patterns and individualized requirements without explicitly designating any module as shared or task-specific. When solving a specific VRP, the gating network may decide the importance of the characteristics learned by each attention module. Additionally, we adopt the maximum entropy reinforcement learning to maintain the diversity of the model in the training process, which can prevent the model from being greedy for some dominant tasks or only for the training tasks. Experimental results demonstrate that SPSM significantly enhances zero-shot generalization performance across ten unseen VRP variants and real-world benchmark instances. Our code is available at https://github.com/ftwangyang/SPSM.},
  archive      = {J_TAI},
  author       = {Yang Wang and Ya-Hui Jia and Wei-Neng Chen and Yi Mei},
  doi          = {10.1109/TAI.2025.3576336},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {6},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Soft parameter sharing model for cross-problem generalization in vehicle routing problems},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PFedBL: Federated bayesian learning with personalized prior. <em>TAI</em>, 1-15. (<a href='https://doi.org/10.1109/TAI.2025.3576201'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing federated learning (FL) frameworks use deterministic models as the task model, which may suffer from overfitting due to small-scale data at client sides. Since Bayesian learning (BL) can quantify the uncertainty associated with both model parameters and prediction outcomes, there have been efforts to integrate BL with FL and the global objective is transformed into posterior approximation using Bayesian optimization. Variational inference is commonly used in such efforts which utilize the global distribution as the prior for the optimization of local Bayesian neural networks (BNNs) and thus eliminates the need for assigning specific prior distributions for clients. However, due to statistical heterogeneity across clients, the global distribution, representing the collective knowledge of all clients, may not be precise as client prior. To address this concern, we propose a federated Bayesian learning framework with personalized priors (pFedBL) where each client is assigned with a local BNN. Specifically, we first introduce a KL-divergence-based distribution aggregation scheme to ensure the effectiveness of the global distribution. Meanwhile, under the mild assumption that the server has access to a general unlabeled dataset, the server uses predictions as well as predictive uncertainty of these data, derived from local BNNs, to construct feature distributions. These distributions are then provided to clients for fine-tuning the global distribution, resulting in personalized priors. In addition, to ensure optimal integration of local and global data insights, we design an adaptive ζ strategy in the local objective function to balance the log-likelihood estimation term and the KL divergence term. We provide theoretical analysis regarding the upper bound of the averaged generalization error for the proposed pFedBL and experimental results demonstrate its effectiveness on three datasets under different problem settings},
  archive      = {J_TAI},
  author       = {Xinhui Yu and Arvin Tashakori and Liang Zou and Z. Jane Wang},
  doi          = {10.1109/TAI.2025.3576201},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {6},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {PFedBL: Federated bayesian learning with personalized prior},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contrastive learning based collaborative modelling of heterogeneous data for few-shot fault diagnosis. <em>TAI</em>, 1-11. (<a href='https://doi.org/10.1109/TAI.2025.3577119'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot diagnosis has received extensive attention recently. Existing methods rarely consider the consistency within and between heterogeneous data, leading to suboptimal diagnosis performance. To address this issue, a contrastive learning based collaborative modelling for few-shot diagnosis is proposed. First of all, a heterogeneous data enhancement workflows with distribution consistency assessment is designed to acquire sufficient industrial process information, which can also mitigate the inconsistency between enhanced data and original data. Following this, convolutional networks with customized structures are used to extract the multimodal features from heterogeneous signals. After that, the collaborative modelling and diagnosis module is devised through the joint optimization of contrastive loss and cross entropy loss, which can shorten the distance of similar samples in feature space and retain cross structure consistency. Finally, the effectiveness and superiority of the proposed method are substantiated through simulated and the real world cases.},
  archive      = {J_TAI},
  author       = {Kai Zhong and Hengchang Zhu and Xiaoming Zhang and Darong Huang and Min Han},
  doi          = {10.1109/TAI.2025.3577119},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {6},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Contrastive learning based collaborative modelling of heterogeneous data for few-shot fault diagnosis},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep variational autoencoder based parameter learning of bayesian network with multiple latent variables. <em>TAI</em>, 1-15. (<a href='https://doi.org/10.1109/TAI.2025.3577601'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent systems could be increasingly powerful by applying probabilistic inferences over the dependence relations among observed and latent variables, which could be represented by the Bayesian network with multiple latent variables (BNML). As the critical task in BNML construction, parameter learning is fulfilled by extending the classic EM algorithm in most of the existing methods, but the time complexity is exponential to the number of latent variables. To address this issue, we first propose to reduce the number of latent variables by training a vector quantized variational autoencoder (VQVAE). Specifically, we incorporate the initial probability parameters in conditional probability tables (CPTs) of BNML as the regularization term of VQVAE to guarantee that the probability parameters after reduction are similar (i.e., consistent) to those before reduction. Then, we incorporate efficient gradient calculations to augment the EM algorithm and propose the efficient algorithm for parameter learning of the BN with reduced latent variables (BNRL). Finally, we present the efficient method for probabilistic inferences in BNRL by encoding evidence variable, decoding query variables and updating query variable values via back-propagation. Experimental results on real and synthetic BNs demonstrate that our method outperforms the state-of-the-art methods on efficiency and effectiveness.},
  archive      = {J_TAI},
  author       = {Xinran Wu and Kun Yue and Liang Duan and Hongbo Xie and Huashuai Liu},
  doi          = {10.1109/TAI.2025.3577601},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {6},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Deep variational autoencoder based parameter learning of bayesian network with multiple latent variables},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Successive halving based online ensemble selection for concept-drift adaptation. <em>TAI</em>, 1-15. (<a href='https://doi.org/10.1109/TAI.2025.3578305'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensemble learning is one of the most successful approaches for concept-drift adaptation due to its versatility and high predictive performance. However, a practical challenge in using ensembles for high-speed data stream mining is the associated large computational cost. In this paper, we introduce a computationally efficient heterogeneous ensemble classifier named SUHEN (Successive Halving Ensemble) which adapts to concept-drift using online ensemble selection. We model ensemble selection as a fixed budget best arm identification bandit problem and solve it using Successive Halving Algorithm (SHA). SUHEN identifies a single best performing member for a stream segment and utilizes it for training and prediction until a drift is detected. Upon detecting drift, SHA identifies the new best performer for the segment. As stream characteristics evolve, manually choosing a fixed SHA budget would be challenging. To this end, we extend SUHEN by posing budget selection as a hyperparameter tuning problem and solve it using meta-learning. Our evaluation on 20 benchmark datasets reveal that SUHEN provides accuracy statistically at par with state-of-the-art ensemble algorithms, while providing significant computational resource savings. This makes our proposal attractive for high-speed stream mining problems in resource-constrained settings.},
  archive      = {J_TAI},
  author       = {Jobin Wilson and Santanu Chaudhury and Brejesh Lall},
  doi          = {10.1109/TAI.2025.3578305},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {6},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Successive halving based online ensemble selection for concept-drift adaptation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep mixture weibull: An explainable AI approach for survival analysis with principle hidden competing risks. <em>TAI</em>, 1-16. (<a href='https://doi.org/10.1109/TAI.2025.3578302'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Survival analysis estimates the probability of survival times for subjects and has broad applications across various domains. Despite the wide-ranging applications of survival analysis across various domains, its successful implementation in critical sectors involving life safety remains challenging due to the lack of interpretability and transparency of existing advanced machine learning (ML) models. To address this, we propose Deep Mixture Weibull (DMW) model, which combines the flexibility of deep learning with the interpretability of Weibull distributions. In real-world scenarios where competing risks exist, the probability of event occurrence is naturally a combination of different underlying risk probabilities. Lever-aging this intuition, DMW models survival outcomes through multiple two-parameter Weibull components, each representing a principal hidden competing risk (PHCR). To tackle multimodal identifiability, we design a specialized loss function incorporating penalty terms for the shape and scale parameters of the Weibull model. Furthermore, expression weights for each component are determined by high-dimensional features and interpreted post hoc using Shapley values, enabling insight into how different PHCRs impact individual subjects. We validate the effectiveness of DMW through extensive experiments on multiple public benchmarks, demonstrating superior predictive accuracy and interpretability compared to state-of-the-art models.},
  archive      = {J_TAI},
  author       = {Jiaxiang Cheng and Guoqiang Hu and Yap-Peng Tan},
  doi          = {10.1109/TAI.2025.3578302},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {6},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Deep mixture weibull: An explainable AI approach for survival analysis with principle hidden competing risks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Event-triggered quantization-based predefined-time adaptive fuzzy control for quadrotor trajectory tracking. <em>TAI</em>, 1-9. (<a href='https://doi.org/10.1109/TAI.2025.3578011'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this letter, a predefined-time adaptive fuzzy trajectory tracking control based on an event-triggered quantization framework is proposed for a quadrotor with inertial uncertainty, full-state constraints, and actuator saturation. First, a double-threshold event-triggered quantization mechanism is proposed to adaptively adjust the discretization degree of the control signals, reducing the communication burden while balancing the control accuracy. Subsequently, the computational complexity and filter error problems are solved by constructing the command filter and filter error compensation mechanism. The unknown nonlinear dynamics of the quadrotor are handled through the approximation capability of an adaptive fuzzy logic system. In addition, an auxiliary signal and a smooth approximation function are combined to cope with actuator saturation. Using Lyapunov theory, the predefined-time stability of the system under full-state constraints is proven. Finally, the validity and superiority of the proposed algorithm have been verified through the simulation example.},
  archive      = {J_TAI},
  author       = {Zhimin Zhou and Lin Zhao},
  doi          = {10.1109/TAI.2025.3578011},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {6},
  pages        = {1-9},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Event-triggered quantization-based predefined-time adaptive fuzzy control for quadrotor trajectory tracking},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards robust nonlinear subspace clustering: A kernel learning approach. <em>TAI</em>, 1-13. (<a href='https://doi.org/10.1109/TAI.2025.3578585'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kernel-based subspace clustering, which addresses the nonlinear structures in data, is an evolving area of research. Despite noteworthy progressions, prevailing methodologies predominantly grapple with limitations relating to (i) the influence of predefined kernels on model performance; (ii) the difficulty of preserving the original manifold structures in the nonlinear space; (iii) the dependency of spectral-type strategies on the ideal block diagonal structure of the affinity matrix. To address these limitations, this paper presents a Data-driven Kernel Learning Model (DKLM), a novel paradigm for kernel-induced nonlinear subspace clustering. DKLM provides a data-driven approach that directly learns the kernel from the data’s self-representation, ensuring adaptive weighting and satisfying the multiplicative triangle inequality constraint, which enhances the robustness of the learned kernel. By leveraging this learned kernel, DKLM preserves the local manifold structure of data in a nonlinear space while promoting the formation of an optimal block-diagonal affinity matrix. A thorough theoretical examination of DKLM reveals its relationship with existing clustering paradigms. Comprehensive experiments on synthetic and real-world datasets demonstrate the effectiveness of the proposed method.},
  archive      = {J_TAI},
  author       = {Kunpeng Xu and Lifei Chen and Shengrui Wang},
  doi          = {10.1109/TAI.2025.3578585},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {6},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Towards robust nonlinear subspace clustering: A kernel learning approach},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DIFF-FECG: A conditional diffusion-based method for fetal ECG extraction from abdominal ECG. <em>TAI</em>, 1-13. (<a href='https://doi.org/10.1109/TAI.2025.3578007'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fetal electrocardiography (FECG) is a crucial tool for assessing fetal cardiac health and pregnancy status. Direct invasive FECG provides reliable fetal heart rate signals, but poses risks and is limited to use during labor. Conversely, non-invasive monitoring of the fetal heart is possible via abdominal electrocardiography (AECG), which detects fetal heart waveforms using electrodes positioned on the mother’s abdomen. However, this method is often subject to interference from maternal cardiac activity and other external sources. To address this issue, we propose a novel diffusion method, DIFF-FECG, aimed at improving the extraction of FECG signals from AECG recordings. This method leverages a condition-driven diffusion process to learn specific conditional probability distributions, enabling the effective separation of high-quality FECG signals from noisy AECG data. By adaptively managing the inherent non-Gaussian noise characteristics of MECG within the AECG, DIFF-FECG achieves more effective FECG reconstruction. Furthermore, the quality of the generated FECG signals is also enhanced by adding reconstruction loss and multiple reconstructions. Experimental results on two public databases demonstrate that the proposed DIFF-FECG method yields satisfactory results, with an average Pearson correlation coefficient of 0.922 for the estimated FECG. These findings underscore the potential of diffusion probabilistic models in advancing FECG signal extraction techniques, thereby contributing to improved fetal health monitoring.},
  archive      = {J_TAI},
  author       = {Zhenqin Chen and Yiwei Lin and Qiong Luo and Jinshan Xu},
  doi          = {10.1109/TAI.2025.3578007},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {6},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {DIFF-FECG: A conditional diffusion-based method for fetal ECG extraction from abdominal ECG},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using adversarial training to improve uncertainty quantification. <em>TAI</em>, 1-11. (<a href='https://doi.org/10.1109/TAI.2025.3578004'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The success of adversarial attack methods suggests a small input change may mislead a trained machine-learning model. For example, changing one pixel of an image may cause the trained model to misclassify this updated image. Uncertainty quantification is crucial for detecting misclassifications; hence, precise uncertainty quantification, meaning uncertainty estimates that closely align with prediction correctness, is essential. We assume that misclassified samples should exhibit high uncertainty while correctly classified samples should exhibit low uncertainty. To evaluate the performance of uncertainty quantification, we investigate the task of uncertainty-based misclassification detection under adversarial attack conditions. Our findings suggest that existing uncertainty quantification methods are unable to accurately identify misclassified predictions resulting from adversarial attacks due to training issues. We propose a simple adversarial training strategy for improving uncertainty quantification. Our results show that adversarial training improves the reliability of uncertainty quantification by better aligning uncertainty with prediction correctness. Specifically, we observe consistent improvements in misclassification detection performance, measured by AUROC and AUPR, across clean and adversarial samples. The code is available at https://github.com/kuanhuang0624/AdvUQ.},
  archive      = {J_TAI},
  author       = {Kuan Huang and Meng Xu and Yingfeng Wang},
  doi          = {10.1109/TAI.2025.3578004},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {6},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Using adversarial training to improve uncertainty quantification},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NeuroCrypt: A neuro symbolic AI ecosystem for advanced cryptographic data security and transmission. <em>TAI</em>, 1-10. (<a href='https://doi.org/10.1109/TAI.2025.3577605'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In response to the critical vulnerabilities exposed by quantum computing and AI-driven cryptanalysis in traditional encryption systems, this paper introduces NeuroCrypt—a neuro-symbolic AI framework that synergizes adaptive cryptography, decentralized governance, and post-quantum security. NeuroCrypt employs three AI groups: CryptAI (multi-algorithm encryption), GenAI (neuro-symbolic algorithm synthesis), and TestAI (adversarial validation), to dynamically generate and deploy quantum-resistant cryptographic techniques. The framework uniquely combines five-layer encryption (randomly ordered classical and AI-generated algorithms, e.g., lattice-chaotic hybrids) with metadata-driven security, where encrypted logic is distributed via Shamir’s Secret Sharing (SSS) over VPNs, eliminating key-exchange dependencies. A permissioned blockchain enforces tamper-proof updates validated by TestAI consensus (n/2+1 threshold), while dynamic threshold adaptation adjusts SSS shard requirements based on real-time threat levels. Evaluations demonstrate NeuroCrypt’s superiority: 2.3× higher entropy than AES-256, 94.3% shard survival under 30% compromise, and 220 ms encryption latency for 1 MB data on edge devices. The system’s lattice-based encryption (1024-dimensional) and frequent AI-driven updates resist Shor/Grover attacks, validated through simulated quantum oracles achieving $\mathcal{O}$(1038) operations for 256-bit keys. Compliance with GDPR, NIST PQC, and FIPS 140-2 ensures readiness for healthcare, fintech, and government applications. NeuroCrypt’s architecture—backwardcompatible with legacy systems and optimized for IoT/cloud ecosystems—sets a precedent for self-evolving security, offering a 15% storage overhead trade-off for metadata-driven keyless decryption. Future work will optimize edge-device performance and integrate 6G network protocols, establishing NeuroCrypt as a foundational framework for post-quantum cybersecurity.},
  archive      = {J_TAI},
  author       = {Tanish Singh Rajpal and Akshit Naithani},
  doi          = {10.1109/TAI.2025.3577605},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {6},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {NeuroCrypt: A neuro symbolic AI ecosystem for advanced cryptographic data security and transmission},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring topic trends in COVID-19 research literature using non-negative matrix factorization. <em>TAI</em>, 1-10. (<a href='https://doi.org/10.1109/TAI.2025.3579459'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we apply topic modeling using Non-Negative Matrix Factorization (NMF) on the COVID-19 Open Research Dataset (CORD-19) to uncover the underlying thematic structure and its evolution within the extensive body of COVID-19 research literature. NMF factorizes the document-term matrix into two non-negative matrices, effectively representing the topics and their distribution across the documents. This helps us see how strongly documents relate to topics and how topics relate to words. We describe the complete methodology which involves a series of rigorous pre-processing steps to standardize the available text data while preserving the context of phrases, and subsequently feature extraction using the term frequency-inverse document frequency (tf-idf), which assigns weights to words based on their frequency and rarity in the dataset. To ensure the robustness of our topic model, we conduct a stability analysis. This process assesses the stability scores of the NMF topic model for different numbers of topics, enabling us to select the optimal number of topics for our analysis. Through our analysis, we track the evolution of topics over time within the CORD-19 dataset. Our findings contribute to the understanding of the knowledge structure of the COVID-19 research landscape, providing a valuable resource for future research in this field.},
  archive      = {J_TAI},
  author       = {Divya Patel and Vansh Parikh and Om Patel and Agam Shah and Bhaskar Chaudhury},
  doi          = {10.1109/TAI.2025.3579459},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {6},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Exploring topic trends in COVID-19 research literature using non-negative matrix factorization},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Irony detection, reasoning and understanding in zero-shot learning. <em>TAI</em>, 1-14. (<a href='https://doi.org/10.1109/TAI.2025.3579452'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Irony is a powerful figurative language (FL) on social media that can potentially mislead various NLP tasks, such as recommendation systems, misinformation checks, and sentiment analysis. Understanding the implicit meaning of this kind of subtle language is an essential step to mitigate the negative impact of irony in NLP tasks. However, existing efforts are limited to domain-specific datasets and struggle to generalize across diverse real-world scenarios. Moreover, reasoning for model decisions that accurately capture semantic and affective meaning remains underexplored. To address these limitations, this paper proposes a conceptual framework called IDADP, which leverages Large language models(LLMs)’ in-context learning capabilities to detect irony and generate human-like explanations across diverse datasets and platforms without prior training on ironic samples. Extensive experiments on six widely used irony detection datasets, utilising two large language models (GPT and Gemini), demonstrate that IDADP consistently outperforms six competitive zero-shot baselines and approaches the performance of three fine-tuned supervised learning baselines. Additionally, we examine GPT’s ability to understand the true intent behind ironic text within the IDADP framework, highlighting its strong potential to recognize and interpret statements where the intended meaning differs from or contrasts with the literal meaning. Furthermore, we conduct qualitative analyses to identify remaining challenges. This work, in turn, opens an avenue for transparent decision-making in irony detection.},
  archive      = {J_TAI},
  author       = {Peiling Yi and Yuhan Xia and Yunfei Long},
  doi          = {10.1109/TAI.2025.3579452},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {6},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Irony detection, reasoning and understanding in zero-shot learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Illumination aware multi-scale attention fusion model for underwater image enhancement. <em>TAI</em>, 1-12. (<a href='https://doi.org/10.1109/TAI.2025.3580381'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the effects of light absorption and scattering in underwater environments, images captured underwater often suffer from reduced contrast, uneven lighting, blurring, color distortion, and other degradations. Many advanced methods struggle to balance detail preservation and enhancement, often over-enhancing the image. This paper introduces an illumination-aware, multi-scale, attention-based fusion network designed to address these challenges by mitigating degradations and retaining fine details. Our U-Net-based encoder-decoder model leverages features at multiple scales to extract both high-level spatial features, which aid in removing color casts and low-level texture details, restoring the texture, and eliminating blurriness, while incorporating illumination information through spatial feature transform. Furthermore, a fusion module utilizing multi-head attention combines features by detecting correlations among channels across all scales. We also introduce a multi-scale loss function that computes loss at all scales to optimize the preservation of global low-frequency contextual details and local high-frequency texture details. An additional color loss term aids in restoring color-accurate images by leveraging the LAB and LCH color spaces. We trained our architecture using 800 paired images from the UIEB dataset and 2,185 pairs from the EUVP dataset. Our architecture achieves PSNR of 31.83 dB, which is 4.11 dB higher than the present state-of-the-art method, and SSIM of 0.948. On the UIEB benchmark, the model achieves UIQM of 4.284 and UCIQE of 0.622 on reference images, while on non-reference images, it achieves UIQM of 4.138 and UCIQE of 0.586. The code is available at https://github.com/subudhi-badri/IMFEN.},
  archive      = {J_TAI},
  author       = {Ashutosh Chauhan and Dakshi Goel and Meghna Kapoor and Badri Narayan Subudhi and Vinit Jakhetiya},
  doi          = {10.1109/TAI.2025.3580381},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {6},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Illumination aware multi-scale attention fusion model for underwater image enhancement},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantasio: A generalized neural framework for solving 3D navier-stokes dynamics. <em>TAI</em>, 1-10. (<a href='https://doi.org/10.1109/TAI.2025.3581506'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partial Differential Equations form the cornerstone of numerous scientific and engineering domains, modeling phenomena such as fluid dynamics, heat transfer, and electro-magnetics. Traditional numerical solvers, while accurate, are computationally expensive and often impractical for real-time applications or high-dimensional systems. Recent advancements in Physics-Informed Neural Networks (PINNs) have demonstrated promise in addressing these limitations; however, existing PINN frameworks face challenges in achieving convergence, enforcing boundary conditions, and scaling to multivariate, highdimensional PDEs. This paper introduces Quantasio, a PINN-based framework that leverages a residual network-inspired architecture with domain-specific reparameterization to achieve efficient and accurate solutions to PDEs across diverse spatiotemporal scenarios and specially Navier-Stokes dynamics in 3 spatial dimensions. Quantasio addresses key limitations in traditional PINNs by incorporating adaptive loss weighting, advanced gradient stabilization techniques, and robust boundary condition enforcement. Its performance is evaluated on a wide range PDEs, including diffusion-reaction, wave equations, and fluid dynamics, demonstrating superior accuracy, achieving up to a 60% reduction in convergence time while maintaining physical consistency. Quantasio reduces peak GPU memory by 50%, and attains a lower residual compared to leading PINN and operator-learning baselines. Our experiments demonstrate robust handling of turbulent flows and complex geometries, positioning Quantasio as an efficient and scalable solver for real-time 3D Navier–Stokes dynamics, making it a versatile tool for real-time simulation in industrial and scientific applications.},
  archive      = {J_TAI},
  author       = {Soumick Sarker and Sudipto Chakraborty},
  doi          = {10.1109/TAI.2025.3581506},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {6},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Quantasio: A generalized neural framework for solving 3D navier-stokes dynamics},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Layer-wise adaptive freezing with spatial prompt learning for efficient fine-tuning in image classification. <em>TAI</em>, 1-13. (<a href='https://doi.org/10.1109/TAI.2025.3579458'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensemble feature selection combines feature subsets with diversity, potentially providing a better approximation of the optimal feature subset. While extensive research has focused on enhancing diversity among ensemble members, its critical role during the aggregation process remains underexplored. To address this gap, we propose a novel Recursive Ensemble Feature Selection (REFS) framework that explicitly incorporates diversity into the aggregation phase to improve both robustness and accuracy. The framework comprises three key components: (1) a randomization-based feature mapping strategy to generate diverse base feature selectors optimized for performance; (2) a quantitative diversity metric to evaluate the complementarity of these selectors; and (3) a fuzzy aggregation method that leverages order statistics, rank scores, and weight information to effectively integrate multiple ranked feature lists. Experimental evaluations on fifteen real-world datasets demonstrate that REFS consistently outperforms competitive methods in terms of classification accuracy and resilience to parameter variations. By explicitly integrating diversity into the aggregation process, REFS provides a more comprehensive and effective approach to feature selection, paving the way for improved predictive performance across diverse applications.},
  archive      = {J_TAI},
  author       = {Jiahui Wang and Qin Xu and Bo Jiang and Bin Luo},
  doi          = {10.1109/TAI.2025.3579458},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {6},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Layer-wise adaptive freezing with spatial prompt learning for efficient fine-tuning in image classification},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Latent variable modelling for controllable and diverse generation from large language models. <em>TAI</em>, 1-15. (<a href='https://doi.org/10.1109/TAI.2025.3581507'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conditional Variational Auto-Encoders (CVAEs) represent a powerful deep generative framework, utilizing latent variables (explicitly modelled hidden states) to capture underlying factors and govern the generation process accordingly. However, this idea is less explored in the era of Large Language Models (LLMs), facing challenges in structural differences between LLMs and traditional CVAEs as well as challenges in posterior collapse (homogeneous latent variables). In this work, we present the first attempt to extend decoder-only LLMs into encoder-decoder CVAEs, aimming at enhancing existing LLMs with flexible control via low-dimensional latent vectors. To achieve this, we introduce a novel optimization objective for effective latent variable modeling and propose a Gradient-only Skip (G-Skip) Connection, which jointly enhances generation controllability while preserving generation quality. Through experiments on AGNews, Yelp and DailyDialog, we validate the effectiveness of our method in achieving latent modelling and latent-guided language generation on the basis of Llama3-8B. Specifically, we establish new state-of-the-art performance in dialogue generation on the DailyDialog dataset, achieving a BERTScore of 88.30 and an FED score of 5.49.},
  archive      = {J_TAI},
  author       = {Jianfei Zhang and Bei Li and Zhuofan Chen and Chang Liu and Chen Li and Chenghua Lin and Wenge Rong},
  doi          = {10.1109/TAI.2025.3581507},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {6},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Latent variable modelling for controllable and diverse generation from large language models},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring mutual cross-modal attention for context-aware human affordance generation. <em>TAI</em>, 1-12. (<a href='https://doi.org/10.1109/TAI.2025.3581897'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human affordance learning investigates contextually relevant novel pose prediction such that the estimated pose represents a valid human action within the scene. While the task is fundamental to machine perception and automated interactive navigation agents, the exponentially large number of probable pose and action variations make the problem challenging and non-trivial. However, the existing datasets and methods for human affordance prediction in 2D scenes are significantly limited in the literature. In this paper, we propose a novel cross-attention mechanism to encode the scene context for affordance prediction by mutually attending spatial feature maps from two different modalities. The proposed method is disentangled among individual subtasks to efficiently reduce the problem complexity. First, we sample a probable location for a person within the scene using a variational autoencoder (VAE) conditioned on the global scene context encoding. Next, we predict a potential pose template from a set of existing human pose candidates using a classifier on the local context encoding around the predicted location. In the subsequent steps, we use two VAEs to sample the scale and deformation parameters for the predicted pose template by conditioning on the local context and template class. Our experiments show significant improvements over the previous baseline of human affordance injection into complex 2D scenes.},
  archive      = {J_TAI},
  author       = {Prasun Roy and Saumik Bhattacharya and Subhankar Ghosh and Umapada Pal and Michael Blumenstein},
  doi          = {10.1109/TAI.2025.3581897},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {6},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Exploring mutual cross-modal attention for context-aware human affordance generation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Retraction notice: Quantum-assisted activation for supervised learning in healthcare-based intrusion detection systems. <em>TAI</em>, 1. (<a href='https://doi.org/10.1109/TAI.2025.3582067'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TAI},
  author       = {N. Laxminarayana and N. Mishra and P. Tiwari and S. Garg and B.K. Behera and A. Farouk},
  doi          = {10.1109/TAI.2025.3582067},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {6},
  pages        = {1},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Retraction notice: Quantum-assisted activation for supervised learning in healthcare-based intrusion detection systems},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An enhanced aircraft fuselage defect detection model with hybrid logical-feature distillation. <em>TAI</em>, 1-11. (<a href='https://doi.org/10.1109/TAI.2025.3584026'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Small defects result in the loss of essential information during defect detection, and enhancing the detection accuracy of these minor defects is a widely researched direction, especially in the development of detection network that achieve high accuracy while simultaneously maintaining low model complexity. To strike a balance between accuracy and efficiency, this paper introduces a high-efficiency aircraft fuselage defect detection model. Firstly, we restructured a teacher model consisting of parallel backbone with Aux_IoU. This redesign enhances the detection of small defects by improving the characterization capability of the feature extraction network and implementing fine-grained bounding boxes. Secondly, to decrease the complexity of teacher model while preserving high accuracy, we introduce a hybrid logical-feature distillation framework. The student model is trained to assimilate the teacher’s feature information and logits through mask generative distillation (MGD) and logical distillation, respectively. Finally, to validate the effectiveness of proposed network, we conducted experiments on Aircraft_Fuselage_DET2023 dataset. The experimental results reveal that our student model achieves enhancements of 8.3% and 2.7% over the baseline YOLOv8n on mAP50 and mAP50:95, respectively. Furthermore, it demonstrates improvements of 0.5% and 0.2% compared to the teacher model, while simultaneously reducing the number of parameters and computational complexity by 47.3% and 53.9%. In comparison to mainstream object detection algorithms, our model achieved superior performance.},
  archive      = {J_TAI},
  author       = {Jiusheng Chen and Haoxiang Zha and Runxia Guo and Chao Huang and Jun Wu},
  doi          = {10.1109/TAI.2025.3584026},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {6},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {An enhanced aircraft fuselage defect detection model with hybrid logical-feature distillation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical reinforcement learning for mapless moving target navigation with communication interruption. <em>TAI</em>, 1-15. (<a href='https://doi.org/10.1109/TAI.2025.3584286'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep reinforcement learning (DRL) has shown significant potential in robot navigation, particularly for mapless moving target scenarios. Note that existing methods rely heavily on continuous communication with the target for trajectory prediction. When communication interruption (CI) occurs, the absence of real-time updates significantly reduces success rates and navigation efficiency. To bridge this gap, a novel framework is developed, namely, hierarchical reinforcement learning for CI (HRL-CI), which incorporates two key modules into the HRL architecture: adaptive sub-goal update and predicted trajectory fusion. Specifically, the adaptive sub-goal update module dynamically regulates the sub-goal update interval using the real-time comparison between the predicted and ground-truth trajectory, which constantly guarantees an opportune sub-goal adjustment for the navigation controller. The predicted trajectory fusion module exponentially weights multiple predicted trajectories to obtain the fused prediction, which reduces navigation sub-goal deviations caused by long-distance prediction errors. Comprehensive experiments demonstrate the superior performance of the HRL-CI framework, including a higher success rate, shorter navigation distance, and reduced navigation time. We’ll make our code and model weights publicly accessible at https://github.com/fzhz666/HRL-CI.},
  archive      = {J_TAI},
  author       = {Zhen Feng and Biao Luo and Hanxiao Li and Xiaodong Xu and Lin Xiao and Yuqian Zhao and Chunhua Yang and Weihua Gui},
  doi          = {10.1109/TAI.2025.3584286},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {6},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Hierarchical reinforcement learning for mapless moving target navigation with communication interruption},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient graph representation with anchor-graph transformer. <em>TAI</em>, 1-9. (<a href='https://doi.org/10.1109/TAI.2025.3584288'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To alleviate the local receptive issue of Graph Convolutional Network (GCN), Transformers have been exploited to capture the long-range dependence of nodes for graph data representation and learning. However, existing graph Transformers generally employ a regular self-attention module for all node-to-node message passing which needs to learn the affinities/relationships between all node’s pairs, leading to high computational cost issue. Also, they are usually sensitive to graph noises. To overcome this issue, we propose a novel graph Transformer architecture, termed AGFormer, by leveraging an anchor graph model. To be specific, AGFormer first obtains some representative anchors and then converts node-to-node message passing into anchor-to-anchor and anchor-to-node message passing processes. Thus, AGFormer performs much more efficiently and also robustly than regular node-to-node Transformers. Extensive experiments on several benchmark datasets demonstrate the benefits of the proposed AGFormer. Specifically, when the number of graph nodes reaches 15,000, AGFormer achieves a training speed that is three times faster than that of GraphTrans. Furthermore, AGFormers perform more robustly on the noised NCI109 dataset compared to GraphTrans.},
  archive      = {J_TAI},
  author       = {Ziyan Zhang and Fei Xu and Bo Jiang and Jin Tang},
  doi          = {10.1109/TAI.2025.3584288},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {6},
  pages        = {1-9},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Efficient graph representation with anchor-graph transformer},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learn to learn: A mirror meta-learning method for retinal disease diagnosis on fundus images. <em>TAI</em>, 1-15. (<a href='https://doi.org/10.1109/TAI.2025.3566082'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retinal diseases, such as glaucoma, age-related macular degeneration, and high myopia, are major contributors to global vision loss, emphasizing the need for early detection and intervention. Current deep learning approaches for diagnosing retinal diseases using fundus images primarily focus on single-disease classification due to the scarcity and expense of diverse datasets. This limitation restricts their generalization across multiple ocular diseases and impedes transfer learning to untrained disease types. In this paper, we introduce a novel Model-Agnostic Meta-Learning framework, called Mirror Meta-Learning (MML) , which incorporates an autoencoder module to supervise the backpropagation path in few-shot learning, enhancing model initialization and adaptation. MML’s effectiveness is validated using four publicly available retinal disease binary classification datasets and a proprietary high myopia dataset. In addition, MML demonstrates robustness when tested on three well-established few-shot learning datasets. Our results show the proposed model’s superiority in terms of performance and generalizability in ocular disease classification tasks.},
  archive      = {J_TAI},
  author       = {Haoran Peng and Jianqiang Li and Wenxiu Cheng and Linna Zhao and Yu Guan and Zhaosheng Li and Li Li and Xi Xu and Yo-Ping Huang},
  doi          = {10.1109/TAI.2025.3566082},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {5},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Learn to learn: A mirror meta-learning method for retinal disease diagnosis on fundus images},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). N-LIPO: Framework for diverse cooperative agent generation using policy compatibility. <em>TAI</em>, 1-15. (<a href='https://doi.org/10.1109/TAI.2025.3566067'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diverse training partners in multi-agent tasks are crucial for training a robust and adaptable cooperative agent. Prior methods often rely on state-action information to diversify partners’ behaviors, but this can lead to minor variations instead of diverse behaviors and solutions. We address this limitation by introducing a novel training objective based on “policy compatibility.” Our method learns diverse behaviors by encouraging agents within a team to be compatible with each other while being incompatible with agents from other teams. We theoretically prove that incompatible policies are inherently dissimilar, allowing us to use policy compatibility as a proxy for diversity. We call this method Learning Incompatible Policies for n-Player Cooperative Games (n-LIPO). We propose to further diversify individual policies by incorporating a mutual information objective using state-action information. We empirically demonstrate that n-LIPO effectively generates diverse joint policies in various two-player and multi-player cooperative environments. In a complex cooperative task, two-player multi-recipe Overcooked, we find that n-LIPO generates a population of behaviorally diverse partners. These populations are then used to train robust generalist agents that can generalize better than using baseline populations. Finally, we demonstrate that n-LIPO can be applied to a high-dimensional StarCraft Multi-Agent Challenge (SMAC) multi-player cooperative environment to discover diverse winning strategies when only a single goal exists. Additional visualization can also be accessed at https://sites.google.com/view/n-lipo/home.},
  archive      = {J_TAI},
  author       = {Rujikorn Charakorn and Poramate Manoonpong and Nat Dilokthanakul},
  doi          = {10.1109/TAI.2025.3566067},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {5},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {N-LIPO: Framework for diverse cooperative agent generation using policy compatibility},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generative agents in agent-based modeling: Overview, validation, and emerging challenges. <em>TAI</em>, 1-20. (<a href='https://doi.org/10.1109/TAI.2025.3566362'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advent of Generative Agents (GAs) based on Large Language Models (LLMs) has significantly influenced the evolution of Agent-Based Modeling (ABM), offering new perspectives across various domains, including engineering and social sciences. This paper provides an extensive overview of the integration of GAs into ABMs, emphasizing the advancements and emerging challenges in their validation. Traditional ABMs, characterized by their simplistic yet powerful approach to modeling complex systems, have been redefined with the introduction of GAs. This new generation of agents is often equipped with conversational capabilities. These agents, capable of simulating believable human behaviors and interactions, present unique opportunities and hurdles, especially in urban simulations and social dynamics. We explore the nuanced differences between traditional ABMs and ABMs populated by GAs—called GABMs. We delve into the state-of-the-art implementations of GAs, and review various validation methods. Through this comprehensive examination, we aim to shed light on the potential and limitations of GAs, advocating for the design of hybrid ABM-GABM approaches and systematic validation.},
  archive      = {J_TAI},
  author       = {Carlo Adornetto and Adrian Mora and Kai Hu and Leticia Izquierdo Garcia and Parfait Atchade-Adelomou and Gianluigi Greco and Luis Alberto Alonso Pastor and Kent Larson},
  doi          = {10.1109/TAI.2025.3566362},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {5},
  pages        = {1-20},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Generative agents in agent-based modeling: Overview, validation, and emerging challenges},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cooperative resilience in artificial intelligence multiagent systems. <em>TAI</em>, 1-11. (<a href='https://doi.org/10.1109/TAI.2025.3567371'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Resilience refers to the ability of systems to with-stand, adapt to, and recover from disruptive events. While studies on resilience have attracted significant attention across various research domains, the precise definition of this concept within the field of cooperative artificial intelligence remains unclear. This paper addresses this gap by proposing a clear definition of ‘cooperative resilience’ and outlining a methodology for its quantitative measurement. The methodology is validated in an environment with RL-based and LLM-augmented autonomous agents, subjected to environmental changes and the introduction of agents with unsustainable behaviors. These events are parameterized to create various scenarios for measuring cooperative resilience. The results highlight the crucial role of resilience metrics in analyzing how the collective system prepares for, resists, recovers from, sustains well-being, and transforms in the face of disruptions. These findings provide foundational insights into the definition, measurement, and preliminary analysis of cooperative resilience, offering significant implications for the broader field of AI. Moreover, the methodology and metrics developed here can be adapted to a wide range of AI applications, enhancing the reliability and effectiveness of AI in dynamic and unpredictable environments.},
  archive      = {J_TAI},
  author       = {Manuela Chacon-Chamorro and Luis Felipe Giraldo and Nicanor Quijano and Vicente Vargas-Panesso and César González and Juan Sebastián Pinzón and Rubén Manrique and Manuel Ríos and Yesid Fonseca and Daniel Gómez-Barrera and Mónica Perdomo-Pérez},
  doi          = {10.1109/TAI.2025.3567371},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {5},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Cooperative resilience in artificial intelligence multiagent systems},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TrumorGPT: Graph-based retrieval-augmented large language model for fact-checking. <em>TAI</em>, 1-15. (<a href='https://doi.org/10.1109/TAI.2025.3567369'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the age of social media, the rapid spread of misinformation and rumors has led to the emergence of infodemics, where false information poses a significant threat to society. To combat this issue, we introduce TrumorGPT, a novel generative artificial intelligence solution designed for fact-checking in the health domain. TrumorGPT aims to distinguish “trumors”, which are health-related rumors that turn out to be true, providing a crucial tool in differentiating between mere speculation and verified facts. This framework leverages a large language model (LLM) with few-shot learning for semantic health knowledge graph construction and semantic reasoning. TrumorGPT incorporates graph-based retrieval-augmented generation (GraphRAG) to address the hallucination issue common in LLMs and the limitations of static training data. GraphRAG involves accessing and utilizing information from regularly updated semantic health knowledge graphs that consist of the latest medical news and health information, ensuring that fact-checking by TrumorGPT is based on the most recent data. Evaluating with extensive healthcare datasets, TrumorGPT demonstrates superior performance in fact-checking for public health claims. Its ability to effectively conduct fact-checking across various platforms marks a critical step forward in the fight against health-related misinformation, enhancing trust and accuracy in the digital information age.},
  archive      = {J_TAI},
  author       = {Ching Nam Hang and Pei-Duo Yu and Chee Wei Tan},
  doi          = {10.1109/TAI.2025.3567369},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {5},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {TrumorGPT: Graph-based retrieval-augmented large language model for fact-checking},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). K-nearest neighbor algorithm based on the framework of ordered pair of normalized real numbers. <em>TAI</em>, 1-16. (<a href='https://doi.org/10.1109/TAI.2025.3566925'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The K-Nearest Neighbors (kNN) algorithm, a cornerstone of supervised learning, relies on similarity measures constrained by real-number-based distance metrics. A critical limitation of traditional kNN research lies in its confinement to the real-number domain, which inherently restricts its ability to model nonlinear feature interactions in high-dimensional data and amplifies sensitivity to feature redundancy and class imbalance. These limitations arise from the inherent linearity and unidimensional nature of real-number representations, which restrict their ability to model complex feature interdependencies. To transcend these limitations, this paper proposes OPNs-kNN, a novel framework grounded in Ordered Pairs of Normalized Real Numbers (OPNs). Departing from the conventional real-number paradigm, OPNs-kNN constructs feature pairs as multidimensional OPNs tuples and employs a generalized OPNs-valued metric to explicitly model nonlinear relationships, thereby addressing the inherent shortcomings of real-number-based kNN. Extensive experiments on nine UCI benchmark datasets (e.g., glass, wines, seeds) demonstrate that OPNs-kNN achieves statistically significant improvements in classification accuracy, precision, recall, and F1 score compared to traditional kNN and its enhanced variants. This work pioneers a non-real-number computational framework, proving that moving beyond real-number constraints enables more expressive representations of data relationships, opening new directions for designing robust machine learning models in complex domains.},
  archive      = {J_TAI},
  author       = {Yi Zheng and Xuanbin Ding and Xiang Zhao and Xiaoqin Pan and Lei Zhou},
  doi          = {10.1109/TAI.2025.3566925},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {5},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {K-nearest neighbor algorithm based on the framework of ordered pair of normalized real numbers},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Production disentanglement and exogenous analysis transformer for petroleum production prediction. <em>TAI</em>, 1-13. (<a href='https://doi.org/10.1109/TAI.2025.3566927'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Petroleum production prediction is a crucial task in reservoir monitoring and management, providing an indispensable basis for development scheme optimization. Most existing production prediction methods learn a joint representation for production dynamics using deep neural networks. However, these methods ignore the special temporal patterns of production dynamics and do not quantitatively analyze the impact of exogenous engineering measures on production. This may lead to insufficient generalization and guidance of the model in practical applications. To address these limitations, we propose a novel production analysis transformer for petroleum production prediction. Specifically, we leverage position enhancement and long-term interaction to explicitly capture the distinctive temporal patterns of production dynamics including local fluctuation and trend features. Furthermore, we establish covariate-level attention to evaluate the dynamic contribution of exogenous engineering measures to production. In this process, we design an adaptive aggregate mechanism that enables multi-head attention to generate a single attention response, thereby improving the legibility of attention maps in engineering applications while maintaining the diversity of feature learning. With this task-specific design, our model learns disentangled production patterns and quantified exogenous influences, thereby enabling accurate and insightful production prediction. Comprehensive experiments on two real-world datasets demonstrate the advantages of our method in production prediction and its significance in engineering guidance.},
  archive      = {J_TAI},
  author       = {Ji Chang and Yu Kang and Wenjun Lv},
  doi          = {10.1109/TAI.2025.3566927},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {5},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Production disentanglement and exogenous analysis transformer for petroleum production prediction},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightweight dynamic convolutional network for crowd counting based on curriculum reinforcement learning. <em>TAI</em>, 1-15. (<a href='https://doi.org/10.1109/TAI.2025.3566923'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In public spaces, high pedestrian concentrations usually lead to congestion and may even pose trampling risks. Upon reaching a specific density threshold, implementing control measures becomes necessary to regulate pedestrian inflows. Therefore, detecting and identifying crowded areas is crucial for pedestrian flow control. Crowd counting is a key technique for achieving this goal. Recently, researchers have dedicated significant efforts to designing convolutional neural networks with various architectures for solving this problem. However, the existing models have structures with high computing power requirements for extreme situations, making it difficult for them to run on edge devices such as surveillance computers. In this paper, we propose a lightweight crowd counting model with a dynamic convolutional kernel for the crowd counting task. The model is built via an encoder–decoderstructure. The encoder extracts high-quality features throughinverted residual layers implemented viaMobileNetV2, which are replaced by a dynamic convolutional kernel. The decoder generates a density map through upsampling and linear layers. A skip connection structure is added to facilitate information exchange between the codecs and reduce the loss of information. Moreover, a training strategy based on curriculum reinforcement learning is presented. This strategy facilitates the integration of samples from diverse datasets,and the difficulty level of each sampling step isdynamically adjusted with a reinforcement learning model. In addition, this strategy can be used to organize the training sequence in each iteration on the basis of sample complexity, thereby achieving enhanced training stability and improved model performance. Comprehensive experimental evidence demonstrates that our model produces superior outcomes to those of competing methods across several benchmark datasets.},
  archive      = {J_TAI},
  author       = {Yange Li and Fan Yu and Qun Chen},
  doi          = {10.1109/TAI.2025.3566923},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {5},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Lightweight dynamic convolutional network for crowd counting based on curriculum reinforcement learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards efficient multi-UAV air combat: An intention inference and sparse transmission based multi-agent reinforcement learning algorithm. <em>TAI</em>, 1-12. (<a href='https://doi.org/10.1109/TAI.2025.3567431'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing utilization of Unmanned Aerial Vehicles (UAVs) in military operations, multi-UAV air combat has been emerging as one of the most important modes for future warfare. How to achieve intelligent cooperative maneuver policies subject to limited information sharing caused by the communication constraints among UAVs is crucial for winning air combat. In this paper, we formulate the communication-constrained multi-UAV air combat problem as a Markov game and propose a novel Sparse Inferred Intention Sharing Multi-Agent Reinforcement Learning (SIIS-MARL) algorithm for improving the winning rate of multi-UAV air combat. Our proposed algorithm contains the following designs: An intention inference module that enables each UAV to infer the intentions of teammates through the Theory of Mind (ToM) network for improved cooperation among teammates, and an attention-based sparse transmission mechanism which utilizes the inferred intentions and encoded embeddings to learn communication weights of teammates for enabling efficient sparsity in communication without causing performance penalty. Simulation results validate the effectiveness of our proposed algorithm as compared with existing work.},
  archive      = {J_TAI},
  author       = {Jinchao Han and Yan Yan and Baoxian Zhang},
  doi          = {10.1109/TAI.2025.3567431},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {5},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Towards efficient multi-UAV air combat: An intention inference and sparse transmission based multi-agent reinforcement learning algorithm},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hierarchical deep reinforcement learning strategy for collective pursuit-evasion game with partial observations. <em>TAI</em>, 1-15. (<a href='https://doi.org/10.1109/TAI.2025.3566069'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the problem of Collective Pursuit-Evasion Game (C-PEG) with partial observation, aiming to enhance cooperation among cluster pursuers, reduce the game space, and optimize the overall pursuer strategy efficiency in complex dynamic environments. Firstly, we consider a distributed communication model suitable for cluster collaboration and model the multi-agent cooperative task as a Collective Decentralized Partially Observable Markov Decision Process (C-Dec POMDP). Then we propose a Hierarchical Regularization Game Multi-agent Deep Deterministic Policy Gradient (HRG-MADDPG) algorithm, which includes High-Level Strategy (HLS) and Low-Level Strategy (LLS). The HLS takes the current observation from the pursuers’ sensors and the pursuers’ status as inputs, and outputs target allocation strategies for the coalitions and individuals to guide the LLS in executing specific pursuit tasks. The LLS is further divided into centralized training and decentralized execution phases. In the centralized training phase, the guiding strategy provided by the HLS and the introduced regularization auxiliary term are combined to promote decision-making through the fusion of favorable situations and auxiliary terms. In the decentralized execution phase, a reliable policy improvement method based on partially observable information is designed. All in all, the HRG-MADDPG algorithm provides a reliable method for collective pursuit-evasion. It is trained in a single environment and further validated in multiple different test environments. Simulation results confirm the effectiveness of the proposed method, showing the adaptability, scalability, and rapid responsiveness of the proposed framework in various practical applications.},
  archive      = {J_TAI},
  author       = {Xiaoxiao Wang and Peng Yi and Yiguang Hong},
  doi          = {10.1109/TAI.2025.3566069},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {5},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {A hierarchical deep reinforcement learning strategy for collective pursuit-evasion game with partial observations},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mitigating bias in opportunistic screening for MACE with causal reasoning. <em>TAI</em>, 1-11. (<a href='https://doi.org/10.1109/TAI.2025.3567961'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mitigating population drift is vital for developing robust AI models for clinical use. While current methodologies focus on reducing demographic bias in disease predictions, they overlook the significant impact of chronic comorbidities. Addressing these complexities is essential to enhance predictive accuracy and reliability across diverse patient demographics, ultimately improving healthcare outcomes. We propose a causal reasoning framework to address selection bias in opportunistic screening for 1-year composite MACE risk using chest X-ray images. Training in high-risk primarily Caucasian patients (43% MACE event), the model was evaluated in a lower-risk emergency department setting (12.8% MACE event) and a relatively lower-risk external Asian patient population (23.81% MACE event) to assess selection bias effects. We bench-marked our approach against a high-performance disease classification model, a propensity score matching strategy, and a debiasing model for unknown biases. The causal+confounder framework achieved an AUC of 0.75 and 0.7 on Shift data and Shift external, outperforming baselines, and a comparable AUC of 0.7 on internal data despite penalties for confounders. It minimized disparities in confounding factors and surpassed traditional and state-of-the-art debiasing methods. Experimental data show that integrating causal reasoning and confounder adjustments in AI models enhances their effectiveness. This approach shows promise for creating fair and robust clinical decision support systems that account for population shifts, ultimately improving the reliability and ethical integrity of AI-driven clinical decision-making.},
  archive      = {J_TAI},
  author       = {Jialu Pi and Juan Maria Farina and Chieh-Ju Chao and Chadi Ayoub and Reza Arsanjani and Imon Banerjee},
  doi          = {10.1109/TAI.2025.3567961},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {5},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Mitigating bias in opportunistic screening for MACE with causal reasoning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Video-based human-posture monitoring from RGB-D cameras. <em>TAI</em>, 1-10. (<a href='https://doi.org/10.1109/TAI.2025.3566926'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Correct pose/posture is crucial in most human activities, and increasingly in using computer screens of many form factors. In this paper, we build a spatiotemporal reasoning infrastructure on top of standard Computer Vision (CV) algorithms to provide an alternate, much more accurate, faster method for tracking correct posture than pure deep learning (DL) methods. We use CV to determine poses of the 2D human stick models from RGB images, which are further enhanced using depth information (from RGB-D camera) to determine relevant angles and compare them against the standards. By applying our method to two very different posture applications (knowledge worker and taekwondo), we show that it outperforms all others, including machine learning, deep learning, and time series-based prediction. Furthermore, superior performance is seen not only in the estimation accuracy but also in the estimation speed.},
  archive      = {J_TAI},
  author       = {Pavana Pradeep Kumar and Krishna Kant and Francesco Di Rienzo and Carlo Vallati},
  doi          = {10.1109/TAI.2025.3566926},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {5},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Video-based human-posture monitoring from RGB-D cameras},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CORT: Class-oriented real-time tracking for embedded systems. <em>TAI</em>, 1-12. (<a href='https://doi.org/10.1109/TAI.2025.3567889'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ever-increasing use of artificial intelligence in visual perception tasks for autonomous systems has significantly contributed to advance the research on multi-object tracking, which is a function required in several real-time applications (e.g., autonomous driving, surveillance drones, robotics) to localize and follow the trajectory of multiple objects moving in front of a camera. Most of current tracking algorithms introduce complex heuristics and re-identification models to improve the tracking accuracy and reduce the number of identification switches, without particular attention to the timing performance, whereas other approaches are aimed at reducing response times by removing the re-identification phase, thus penalizing the tracking accuracy. This work proposes a new approach to multi-class object tracking that allows achieving smaller and more predictable execution times with respect to traditional approaches, without penalizing the tracking performance. The idea is to divide the problem of matching predictions with detections into a number of smaller sub-problems by splitting the Hungarian association matrix by class and invoking the second re-identification stage only when strictly necessary, thus applying it to a smaller number of elements. Splitting the matching problem into a number of smaller sub-problems also allows parallelizing the Hungarian algorithm, further reducing the execution time in multi-core processing platforms. The proposed solution was evaluated in complex urban scenarios with different types of objects (as cars, buses, and motorbikes), and different number of instances, showing the effectiveness of the multi-class approach in reducing execution times without penalizing performance, with respect to state of the art trackers.},
  archive      = {J_TAI},
  author       = {Edoardo Cittadini and Alessandro De Siena and Giorgio Buttazzo},
  doi          = {10.1109/TAI.2025.3567889},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {5},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {CORT: Class-oriented real-time tracking for embedded systems},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A systematic review on quantum machine learning applications in classification. <em>TAI</em>, 1-16. (<a href='https://doi.org/10.1109/TAI.2025.3567960'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification is a fundamental aspect of leveraging big data for decision-making across domains such as engineering, medicine, economics, and beyond. This systematic review explores the application of quantum machine learning (QML) to address the classification challenges. Despite the rising popularity of QML, challenges persist regarding its practical efficacy and applicability relative to classical methods. This study seeks to classify and analyse the application of QML across diverse domains. Employing a systematic methodology, a total of 23 research articles were chosen after applying rigorous selection criteria between the years 2013 to 2023. At first, 520 research articles were identified, and narrowed down to 296 papers, the abstracts of the papers have been read, 61 full-text papers have been studied, and ultimately 23 papers have been selected for review. A methodological approach was employed, involving the selection of relevant papers from reputable databases, evaluation of these papers, and the subsequent derivation of insights into the performance of QML in practical classification applications. Findings indicate that QML classifiers mostly achieved superior performance compared to conventional methods across accuracy, high-dimensional data management, and computational efficiency. However, challenges remain, including the limitations of noisy quantum hardware and the requirement for hybrid and innovative quantum algorithms. Analysis of current trends reveals significant progress in hybrid quantum-classical computational methods. To conclude, this analysis reveals QML’s revolutionary capabilities while noting its current shortcomings. This study provides a thorough overview for researchers investigating QML’s application to real-world classification problems, and it offers guidelines for future research endeavors.},
  archive      = {J_TAI},
  author       = {Ehsan Mohammadisavadkoohi and Niusha Shafiabady and James Vakilian},
  doi          = {10.1109/TAI.2025.3567960},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {5},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {A systematic review on quantum machine learning applications in classification},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Can LLM-augmented autonomous agents cooperate? an evaluation of their cooperative capabilities through melting pot. <em>TAI</em>, 1-10. (<a href='https://doi.org/10.1109/TAI.2025.3569192'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As artificial intelligence continues to advance, a key aspect of this progression is the development of Large Language Models (LLMs) and their capacity to enhance multi-agent artificial intelligence systems. This paper investigates the cooperative cabilities of Large Language Model-augmented Autonomous Agents (LAAs) using the well-known Melting Pot environments along with reference models such as GPT-4o, GPT-4o mini, GPT-4, and GPT-3.5. Preliminary results suggest that comprehensive LAA architectures significantly improve performance in Melting Pot’s multi-agent scenarios, outperforming reinforcement learning baselines in two out of three scenarios and surpassing a simpler Chain-of-Thought agent architecture in all scenarios. The Melting Pot environments are specifically designed to assess multi-agent systems, requiring agents to exhibit cooperative behavior to solve conditions effectively.},
  archive      = {J_TAI},
  author       = {Manuel Mosquera and Juan Sebastian Pinzón and Yesid Fonseca and Manuel Ríos and Nicanor Quijano and Luis Felipe Giraldo and Rubén Manrique},
  doi          = {10.1109/TAI.2025.3569192},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {5},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Can LLM-augmented autonomous agents cooperate? an evaluation of their cooperative capabilities through melting pot},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards trustworthy dialogue systems with advanced out-of-scope intent detection model. <em>TAI</em>, 1-11. (<a href='https://doi.org/10.1109/TAI.2025.3567212'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing demand for trustworthy dialogue systems emphasizes the need for consistently accurate responses to user inputs. The first step in developing a trustworthy dialogue system is detecting user inputs with the out-of-scope (OOS) intent. Advanced research on OOS intent detection enhances effectiveness by using data augmentation to generate numerous artificial OOS samples from a limited set of true OOS data, modelling its distribution for training. However, data augmentation presents challenges, including higher costs, increased time, and a greater risk of overfitting. Additionally, current studies treat the OOS intent as a homogeneous category equivalent to known intents within a classification framework, overlooking the inherent diversity of OOS intents. To tackle these challenges, we introduce a novel method called Anchor-Integrated Dynamic Out-of-scope Intent Learning (AIDOIL), which integrates the selected anchor to represent the OOS intent adapting to diverse inputs dynamically. The intent representations transform the global classification problem into a matching task that determines if a user input aligns with each intent. This eliminates the necessity to augment OOS data and accommodate the diversity of OOS intents through dynamic representation learning. We conducted extensive experiments on three public dialogue datasets, demonstrating that AIDOIL achieves an average 7.21% improvement in OOS detection accuracy, while maintaining an acceptable increase in training time.},
  archive      = {J_TAI},
  author       = {Qing Yin and Zhihua Wang and Liang Bai and Yunya Song and Dongling Xu and Xian Yang},
  doi          = {10.1109/TAI.2025.3567212},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {5},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Towards trustworthy dialogue systems with advanced out-of-scope intent detection model},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evidential reasoning rule learning. <em>TAI</em>, 1-10. (<a href='https://doi.org/10.1109/TAI.2025.3569495'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent decades, artificial intelligence (AI), particularly machine learning (ML), has achieved remarkable advancements. However, the practical implementation of ML in critical real-world applications remains constrained due to the concerns on building reliable ML model. To address this challenge, ensuring model reliability requires a focus on three major aspects: credibility, adaptability, and interpretability. To achieve these objectives in a unified way, a new reliable learning pattern which consists of training, adaptation, testing and second decision stage was proposed to extend the traditional training-testing pattern. Based on this framework, a new evidential reasoning rule learning (ER2L) strategy was developed, where individual-reliability is defined to tune the trained model for fitting the test sample better in adaptation stage and overall-reliability is introduced to measure the credibility of the model outputs for the second decision. Furthermore, due to ER2’s nature as a probabilistic inference engine, the model is interpretable. Building on ER2L, a new ML approach termed Naïve ER2 (NER2) was proposed. The experimental studies demonstrated that NER2 can obtain better performance by introducing individual-reliability for model tuning, whilst the overall-reliability can evaluate the credibility of model output reasonably.},
  archive      = {J_TAI},
  author       = {Zhiguo Zhou and Hui Liu},
  doi          = {10.1109/TAI.2025.3569495},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {5},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Evidential reasoning rule learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Derivation of back-propagation for graph convolutional networks using matrix calculus and its application to explainable artificial intelligence. <em>TAI</em>, 1-11. (<a href='https://doi.org/10.1109/TAI.2025.3569519'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper provides a comprehensive and detailed derivation of the backpropagation algorithm for graph convolutional neural networks using matrix calculus. The derivation is extended to include arbitrary element-wise activation functions and an arbitrary number of layers. The study addresses two fundamental problems, namely node classification and link prediction. To validate our method, we compare it with reverse-mode automatic differentiation. The experimental results demonstrate that the median sum of squared errors of the updated weight matrices, when comparing our method to the approach using reverse-mode automatic differentiation, falls within the range of 10-18 to 10-14. These outcomes are obtained from conducting experiments on a five-layer graph convolutional network, applied to a node classification problem on Zachary’s karate club social network and a link prediction problem on a drug-drug interaction network. Furthermore, we derive an element-wise solution for backpropagation in node classification using graph convolutional networks, demonstrating that it can achieve faster computation on large-scale graphs compared to reverse-mode automatic differentiation. Finally, we show how the derived closed-form solution can facilitate the development of explainable AI and sensitivity analysis.},
  archive      = {J_TAI},
  author       = {Yen-Che Hsiao and Rongting Yue and Abhishek Dutta},
  doi          = {10.1109/TAI.2025.3569519},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {5},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Derivation of back-propagation for graph convolutional networks using matrix calculus and its application to explainable artificial intelligence},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inadequacies of large language model benchmarks in the era of generative artificial intelligence. <em>TAI</em>, 1-18. (<a href='https://doi.org/10.1109/TAI.2025.3569516'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid rise in popularity of Large Language Models (LLMs) with emerging capabilities has spurred public curiosity to evaluate and compare different LLMs, leading many researchers to propose their own LLM benchmarks. Noticing preliminary inadequacies in those benchmarks, we embarked on a study to critically assess 23 state-of-the-art LLM benchmarks, using our novel unified evaluation framework through the lenses of people, process, and technology, under the pillars of benchmark functionality and integrity. Our research uncovered significant limitations, including biases, difficulties in measuring genuine reasoning, adaptability, implementation inconsistencies, prompt engineering complexity, evaluator diversity, and the overlooking of cultural and ideological norms in one comprehensive assessment. Our discussions emphasized the urgent need for standardized methodologies, regulatory certainties, and ethical guidelines in light of Artificial Intelligence (AI) advancements, including advocating for an evolution from static benchmarks to dynamic behavioral profiling to accurately capture LLMs’ complex behaviors and potential risks. Our study highlighted the necessity for a paradigm shift in LLM evaluation methodologies, underlining the importance of collaborative efforts for the development of universally accepted benchmarks and the enhancement of AI systems’ integration into society.},
  archive      = {J_TAI},
  author       = {Timothy R McIntosh and Teo Susnjak and Nalin Arachchilage and Tong Liu and Dan Xu and Paul Watters and Malka N Halgamuge},
  doi          = {10.1109/TAI.2025.3569516},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {5},
  pages        = {1-18},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Inadequacies of large language model benchmarks in the era of generative artificial intelligence},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Role-based one-hop neighborhood representation for link sign prediction in signed directed networks. <em>TAI</em>, 1-11. (<a href='https://doi.org/10.1109/TAI.2025.3569787'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Link sign prediction refers to predicting whether a pair of nodes in a network is connected by a positive or negative link. Regarding this typical and fundamental problem in signed network analysis, SELO (Subgraph Enconding via Linear Optimization) currently provides the state-of-art performance to the best of our knowledge. However, existing sign prediction algorithms commonly ignore the diversified structural roles of neighboring nodes and learn node embeddings by directly mirroring unsigned and undirected aggregators. To address these limitations, we propose a Role-based One-hop Neighborhood Representation (RONR) framework to predict link signs in signed directed networks, which outperforms state-of-the-art methods. The main novelties of our proposed approach lie in that i) only one-hop neighborhood information of the target link is required, ii) a node attribute assignment algorithm is given to distinguish the role of each node in the neighborhood, and iii) a specific efficient node feature aggregator is developed to learn subgraph embeddings. We conduct experiments on five real-world signed directed networks and evaluate the performances with AUC, F1, micro-F1, and macro-F1. The experimental results show that our proposed RONR achieves significantly better performances than previous feature-based, embedding-based, and subgraph pattern encoding methods, including the state-of-the-art method SELO.},
  archive      = {J_TAI},
  author       = {Zhihong Fang and Shaolin Tan and Qiu Fang and Zhe Li and Qing Gao},
  doi          = {10.1109/TAI.2025.3569787},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {5},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Role-based one-hop neighborhood representation for link sign prediction in signed directed networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep3BPP: Identification of blood-brain barrier penetrating peptides using word embedding feature extraction method and CNN-LSTM. <em>TAI</em>, 1-9. (<a href='https://doi.org/10.1109/TAI.2025.3567434'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To prevent different chemicals from entering the brain, the blood-brain barrier penetrating peptide (3BPP) acts as a vital barrier between the bloodstream and the central nervous system (CNS). This barrier significantly hinders the treatment of neurological and CNS disorders. 3BPP can get beyond this barrier, making it easier to enter the brain and essential for treating CNS and neurological diseases and disorders. Computational techniques are being explored because traditional laboratory tests for 3BPP identification are costly and time-consuming. In this work, we introduced a novel technique for 3BPP prediction with a hybrid deep learning model. Our proposed model, Deep3BPP, leverages the LSA, a word embedding method for peptide sequence extraction, and integrates CNN with LSTM (CNN-LSTM) for the final prediction model. Deep3BPP performance metrics show a remarkable accuracy of 97.42%, a Kappa value of 0.9257, and an MCC of 0.9362. These findings indicate a more efficient and cost-effective method of identifying 3BPP, which has important implications for researchers in the pharmaceutical and medical industries. Thus, this work offers insightful information that can advance both scientific research and the well-being of people overall.},
  archive      = {J_TAI},
  author       = {Md. Ashikur Rahman and Md Mamun Ali and Kawsar Ahmed and Imran Mahmud and Francis M. Bui and Li Chen and Mohammad Ali Moni},
  doi          = {10.1109/TAI.2025.3567434},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {5},
  pages        = {1-9},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Deep3BPP: Identification of blood-brain barrier penetrating peptides using word embedding feature extraction method and CNN-LSTM},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reduction of class activation uncertainty with background information. <em>TAI</em>, 1-15. (<a href='https://doi.org/10.1109/TAI.2025.3570282'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multitask learning is a popular approach to training high-performing neural networks with improved generalization. In this paper, we propose a background class to achieve improved generalization at a lower computation compared to multitask learning to help researchers and organizations with limited computation power. We also present a methodology for selecting background images and discuss potential future improvements. We apply our approach to several datasets and achieve improved generalization with much lower computation. Through the class activation mappings (CAMs) of the trained models, we observed the tendency towards looking at a bigger picture with the proposed model training methodology. Applying the vision transformer with the proposed background class, we receive state-of-the-art (SOTA) performance on CIFAR-10C, Caltech-101, and CINIC-10 datasets. Example scripts are available in the ‘CAM’ folder of the following GitHub repository: github.com/dipuk0506/UQ},
  archive      = {J_TAI},
  author       = {H M Dipu Kabir},
  doi          = {10.1109/TAI.2025.3570282},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {5},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Reduction of class activation uncertainty with background information},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging long-term multivariate history representation for time series forecasting. <em>TAI</em>, 1-15. (<a href='https://doi.org/10.1109/TAI.2025.3570676'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate Time Series (MTS) forecasting has a wide range of applications in both industry and academia. Recent advances in Spatial-Temporal Graph Neural Network (STGNN) have achieved great progress in modelling spatialtemporal correlations. Limited by computational complexity, most STGNNs for MTS forecasting focus primarily on short-term and local spatial-temporal dependencies. Although some recent methods attempt to incorporate univariate history into modeling, they still overlook crucial long-term spatial-temporal similarities and correlations across MTS, which are essential for accurate forecasting. To fill this gap, we propose a framework called the Long-term Multivariate History Representation (LMHR) Enhanced STGNN for MTS forecasting. Specifically, a Long-term History Encoder (LHEncoder) is adopted to effectively encode the long-term history into segment-level contextual representations and reduce point-level noise. A non-parametric Hierarchical Representation Retriever (HRetriever) is designed to include the spatial information in the long-term spatial-temporal dependency modelling and pick out the most valuable representations with no additional training. A Transformer-based Aggregator (TAggregator) selectively fuses the sparsely retrieved contextual representations based on the ranking positional embedding efficiently. Experimental results demonstrate that LMHR outperforms typical STGNNs by 10.72% on the average prediction horizons and state-of-the-art methods by 4.12% on several real-world datasets. Additionally, it consistently improves prediction accuracy by 9.8% on the top 10% of rapidly changing patterns across the datasets.},
  archive      = {J_TAI},
  author       = {Huiliang Zhang and Di Wu and Arnaud Zinflou and Stephane Dellacherie and Mouhamadou Makhtar Dione and Benoit Boulet},
  doi          = {10.1109/TAI.2025.3570676},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {5},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Leveraging long-term multivariate history representation for time series forecasting},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ranking time-frequency contrastive learning for multivariate time series classification. <em>TAI</em>, 1-10. (<a href='https://doi.org/10.1109/TAI.2025.3570665'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For multivariate time series classification, current research predominantly focuses on contrastive learning to acquire suitable representations. Despite their successes in enhancing accuracy and reducing label dependency, existing methods primarily concentrate on time-domain features, potentially neglecting the frequency-domain information inherent in time series. Additionally, the challenging problem of addressing the impact of false negative samples in contrastive learning remains unresolved. To tackle this, we propose a cross-modal architecture based on ranking time-frequency contrastive learning. This novel approach considers time-frequency consistency of time series, introducing an innovative time-frequency-based ranking loss to regulate the proximity between positive/negative samples and the anchor point, thereby mitigating issues related to false negatives. Extensive experiments validate the effectiveness of our proposed method in advancing multivariate time series classification},
  archive      = {J_TAI},
  author       = {Jidong Yuan and Lingyin Zhang and Weiqiang Jia and Jia Guo and Haiyang Liu and Jinfeng Wang},
  doi          = {10.1109/TAI.2025.3570665},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {5},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Ranking time-frequency contrastive learning for multivariate time series classification},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatio-temporal mamba dynamic graph convolutional recurrent network for traffic prediction. <em>TAI</em>, 1-14. (<a href='https://doi.org/10.1109/TAI.2025.3571378'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In intelligent transportation systems (ITS), traffic prediction has become a core issue in the field of artificial intelligence. Accurate traffic prediction is crucial for reducing congestion, improving travel efficiency, and enhancing traffic safety. However, the complex and dynamically changing spatiotemporal dependencies in traffic networks make the prediction task highly challenging. Most existing methods rely on selfattention mechanisms to capture these spatio-temporal dependencies, which often result in high computational complexity. Furthermore, although traffic systems can be modeled as graph structures, graph convolutional network (GCN), which effectively capture correlations between nodes, typically depend on predefined or adaptive adjacency matrices. These approaches struggle to cope with the highly dynamic nature of real-world traffic systems. To address these issues, we propose a spatio-temporal Mamba dynamic graph convolutional recurrent neural network (STMAGRN). This model first leverages the Mamba framework to extract spatio-temporal features from traffic sequences. The Mamba model, through its unique selective state space mechanism and linear time complexity, achieves efficient sequence processing. Next, we design a spatio-temporal memory module (STM), which identifies and extracts traffic pattern features most similar to the input data, and learns intrinsic representative traffic patterns from the data associated with each node. These patterns are then used to dynamically generate graph structures, providing GCN with real-time updated graph data. Finally, we combine GCN with recurrent neural networks (RNNs) to extract both spatial and temporal features simultaneously. We conducted extensive experiments on six real-world datasets, and the results demonstrate that STMAGRN significantly outperforms state-of-the-art methods in traffic prediction tasks.},
  archive      = {J_TAI},
  author       = {Xiaoyan Zhang and Yongqin Zhang and Xiangfu Meng},
  doi          = {10.1109/TAI.2025.3571378},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {5},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Spatio-temporal mamba dynamic graph convolutional recurrent network for traffic prediction},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SRLinear: Lightweight long-term time series forecasting via symbolic regression. <em>TAI</em>, 1-15. (<a href='https://doi.org/10.1109/TAI.2025.3571377'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long-term Time Series Forecasting (LTSF) plays a crucial role in various fields, including energy consumption and weather prediction. Recent advancements in deep learning, particularly transformer models, have significantly improved LTSF performance. However, these models often face criticism for their lack of transparency, limited interpretability, and high computational requirements, which can hinder their practical application. Simple linear models have emerged as a promising alternative, demonstrating excellent performance in LTSF while offering greater simplicity. Yet, as these models become more complex, they tend to lose their advantages. To address these challenges, we introduce SRLinear, a lightweight and interpretable LTSF framework based on symbolic regression. Our approach first breaks down time series data into seasonal and trend components, then divides these into smaller segments. We use symbolic regression to extract meaningful and interpretable features from these components, which are then combined and processed through a single linear layer for future predictions. This lightweight design ensures computational efficiency, while symbolic regression generates symbolic expressions, providing clear insights into the feature extraction process and enhancing model interpretability. We tested SRLinear on 8 real-world datasets, achieving state-of-the-art results on multiple benchmarks. Importantly, our framework produces highly interpretable features that can be easily visualized, enhancing the overall transparency of the prediction process. Our code is publicly available at https://github.com/fantasy-99/SRLinear.},
  archive      = {J_TAI},
  author       = {Hongbo Zhao and Hengzhe Zhang and Chutian Tian and Zhi Wei and Aimin Zhou},
  doi          = {10.1109/TAI.2025.3571377},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {5},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {SRLinear: Lightweight long-term time series forecasting via symbolic regression},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust peer-to-peer federated learning with deep reinforcement learning based client selection against data poisoning attacks. <em>TAI</em>, 1-10. (<a href='https://doi.org/10.1109/TAI.2025.3571872'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While existing strategies offer partial solutions, enhancing robustness in decentralized, peer-to-peer FL remains a critical challenge due to the lack of centralized oversight, the variability of client data quality, and the dynamic nature of client participation. In this paper, we propose a deep reinforcement learning (DRL) method for client selection in peer-to-peer FL, enhancing model robustness by choosing reliable peers. By framing client selection as a Markov Decision Process (MDP), our approach enables clients to identify trustworthy peers, effectively mitigating data poisoning attacks and improving the accuracy and resilience of the aggregated model. Our proposed method models client selection as an MDP, where each client’s state is derived from condensed representations of other peers’ models’ parameters. The clients leverage Deep Q-Networks (DQN) to adaptively refine peer selection, ensuring robustness against malicious behaviors. Our experimental configuration involved training a convolutional neural network on CIFAR-10, executing different types of data poisoning attacks. Our results, averaged across the accuracies from all clients, demonstrate that the proposed method consistently achieves 5-7% higher accuracy compared to baseline approaches without sophisticated selection mechanisms, and surpasses the state-of-the-art CBE3 algorithm by 2-3%. Furthermore, our method exhibits significantly more stable accuracy trends and reduced noise levels throughout training, indicating enhanced resilience and adaptability under dynamic and adversarial conditions.},
  archive      = {J_TAI},
  author       = {Keyvan Kazemi and Mohammad Hossein Badiei and Hamed Kebriaei},
  doi          = {10.1109/TAI.2025.3571872},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {5},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Robust peer-to-peer federated learning with deep reinforcement learning based client selection against data poisoning attacks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised domain adaptation with source data for estimating occupancy and recognizing activities in smart buildings. <em>TAI</em>, 1-15. (<a href='https://doi.org/10.1109/TAI.2025.3569517'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we create and develop several unsupervised domain adaptation (UDA) methods that use source data to estimate the number of occupants and recognize activities in smart buildings. The created and developed methods have direct access to the source data, and their goal is to mitigate domain shift between source and target environments and to deal with the challenge of costly and time-consuming data labeling. We create our own novel UDA method called ATDOC-DDC that combines two powerful domain invariant methods Auxiliary Target Domain-Oriented Classifier (ATDOC) and Deep Domain Confusion (DDC) for better adaptation and performance. We introduce the Virtual Adversarial Domain Adaptation (VADA) model which is a combination of domain adversarial training and a penalty term. On the one hand, domain adversarial training trains a model on source and target data, and a discriminator to distinguish between data coming from different domains. The goal of the model is to fool the discriminator by creating features that generalize for different domains. On the other hand, the penalty term is added to punish the violation of the cluster assumption. Moreover, we introduce Sliced Wasserstein Discrepancy (SWD) for UDA which uses task-specific decision boundary and Wasserstein metric to perform domain alignment between source and target environments. The SWD distance is used to measure the difference between data distributions of the two domains so that the model can update its weights to minimize the considered distance (data alignment). Also, we consider three Adaptive Feature Norm (AFN) approaches that adapt the feature norms of the models to allow information transferability between domains. The adapted methods are Hard Adaptive Feature Norm (HAFN), Stepwise Adaptive Feature Norm (SAFN), and SAFN with entropy minimization. In addition, data poisoning has been employed to evaluate the robustness of the considered methods using mislabeled data. The obtained scores prove the efficiency and robustness of the proposed method on activity recognition and occupancy estimation datasets.},
  archive      = {J_TAI},
  author       = {Jawher Dridi and Manar Amayri and Nizar Bouguila},
  doi          = {10.1109/TAI.2025.3569517},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {5},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Unsupervised domain adaptation with source data for estimating occupancy and recognizing activities in smart buildings},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An inversion-free fuzzy zeroing neural network under adaptive input range fuzzy scheme: Design, analysis, and application. <em>TAI</em>, 1-13. (<a href='https://doi.org/10.1109/TAI.2025.3570287'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a predefined-time robust inversion-free fuzzy zeroing neural network (PRIFZNN) model, which comprehensively considers computational complexity, convergence, and robustness. The PRIFZNN model achieves the lowest computational complexity among zeroing neural network (ZNN) models for solving similar problems. By avoiding the matrix inversion operation, it reduces the computational complexity to O(mn), whereas other ZNN models typically exhibit a complexity level of O(min(mn2,m2n)). To enhance the convergence and robustness of the PRIFZNN model, a piecewise predefined-time robust activation function and a novel adaptive input range fuzzy control scheme are proposed. The former provides predefined-time convergence and the ability to resist bounded noise, while the latter is employed to further improve the convergence rate. Moreover, the theoretical analysis section offers a detailed discussion of the convergence properties of the PRIFZNN model. It also derives the upper bound of the convergence time under bounded noise interference, thereby theoretically ensuring the robustness of the PRIFZNN model. Finally, numerical simulation studies on solving the time-varying Sylvester matrix equation show that the PRIFZNN model surpasses the comparative ZNN models in both convergence and robustness, while also validating the correctness of the theoretical analysis. Meanwhile, the PRIFZNN model is successfully applied to the path-tracking tasks of robotic manipulators, demonstrating its excellent practicality.},
  archive      = {J_TAI},
  author       = {Lin Xiao and Dan Wang and Qiuyue Zuo and Haibing Fan and Hang Cai},
  doi          = {10.1109/TAI.2025.3570287},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {5},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {An inversion-free fuzzy zeroing neural network under adaptive input range fuzzy scheme: Design, analysis, and application},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TransHD: Spatial transformer features extraction for HDC synergetic learning. <em>TAI</em>, 1-16. (<a href='https://doi.org/10.1109/TAI.2025.3570283'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI) relies on pattern recognition and classification algorithms to achieve accurate and efficient decision-making. Convolutional neural networks (CNNs) are the state-of-the-art for processing 2D image data, but their high computational and data requirements limit their use in resource-constrained environments. Hyperdimensional computing (HDC) offers a lightweight alternative, excelling in 1D tasks, but struggles to achieve competitive accuracy for 2D image classification. Hybrid frameworks combining HDC with CNNs have been proposed to improve accuracy but inherit the computational demands of deep learning, making them unsuitable for edge and IoT devices. To address this, we propose TransHD, a framework integrating lightweight spatial transformer networks (STNs) with HDC to enhance image classification performance while maintaining efficiency. TransHD achieves up to 9% higher accuracy than base HDC models on MNIST and Fashion-MNIST using only 30% of the training data, and reduces computational complexity by 2.5x through optimized STN feature map usage. On resource-constrained platforms like the Raspberry Pi 4, TransHD accelerates inference times by 3.4x and improves energy efficiency by 3.2x, with an accuracy trade-off of approximately 3% compared to CNNs. This study demonstrates the potential of combining HDC with STNs to develop efficient AI solutions for IoT and edge computing, where low energy consumption and computational efficiency are critical.},
  archive      = {J_TAI},
  author       = {Eman Hassan and Meriem Bettayeb and Yasmin Halawani and Paul R. Genssler and Huruy Tesfai and Yahya Zweiri and Hussam Amrouch and Leontios J. Hadjileontiadis and Hani Saleh and Baker Mohammad},
  doi          = {10.1109/TAI.2025.3570283},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {5},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {TransHD: Spatial transformer features extraction for HDC synergetic learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A review: Recent advancements in online private mode multi-object tracking. <em>TAI</em>, 1-20. (<a href='https://doi.org/10.1109/TAI.2025.3572854'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-object tracking (MOT) aims to establish connections between target objects throughout consecutive video frames to capture the complete trajectories of these moving objects. Due to the progress made in deep neural networks (DNN) and the growing need for intelligent video analysis, MOT has garnered considerable attention in “computer vision”. MOT exhibits scholarly and economic promise in various domains, including urban public security, military applications, self-driving technology, etc. Despite the diverse range of approaches researchers propose to address this challenge, it doesn’t remain easy due to changing objects’ appearances, significant occlusion, and non-linear motion patterns. Our review process provides fundamental insights into multi-object tracking. It covers essential aspects such as the basic workflow, different approaches to conducting the MOT task, challenges encountered, dataset requirements, evaluation metrics, and procedure for result submission to MOT and CodaLab servers. This study analyses the benefits and constraints of current strategies, techniques, and methods through a systematic review of the latest advancements in object detection and online private detection-based MOT algorithms published. Additionally, we present a quantitative comparison and analysis of experimental evidence of the top-performing MOT algorithms across various metrics. Finally, we propose future research directions by analyzing the commonalities among several methods demonstrating excellent performance.},
  archive      = {J_TAI},
  author       = {Shavantrevva Bilakeri and Karunakar A Kotegar},
  doi          = {10.1109/TAI.2025.3572854},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {5},
  pages        = {1-20},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {A review: Recent advancements in online private mode multi-object tracking},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). QSVM-QNN: Quantum support vector machine based quantum neural network learning algorithm for brain-computer interfacing systems. <em>TAI</em>, 1-12. (<a href='https://doi.org/10.1109/TAI.2025.3572852'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A brain-computer interface (BCI) system enables direct communication between the brain and external devices, offering significant potential for assistive technologies and advanced human-computer interaction. Despite progress, BCI systems face persistent challenges, including signal variability, classification inefficiency, and difficulty adapting to individual users in real time. In this study, we propose a novel hybrid quantum learning model, termed QSVM-QNN, which integrates a Quantum Support Vector Machine (QSVM) with a Quantum Neural Network (QNN), to improve classification accuracy and robustness in EEG-based BCI tasks. Unlike existing models, QSVM-QNN combines the decision boundary capabilities of QSVM with the expressive learning power of QNN, leading to superior generalization performance. The proposed model is evaluated on two benchmark EEG datasets, achieving high accuracies of 0.990 and 0.950, outperforming both classical and standalone quantum models. To demonstrate real-world viability, we further validated the robustness of QNN, QSVM, and QSVM-QNN against six realistic quantum noise models, including bit flip and phase damping. These experiments reveal that QSVM-QNN maintains stable performance under noisy conditions, establishing its applicability for deployment in practical, noisy quantum environments. Beyond BCI, the proposed hybrid quantum architecture is generalizable to other biomedical and time-series classification tasks, offering a scalable and noise-resilient solution for next-generation neurotechnological systems.},
  archive      = {J_TAI},
  author       = {Bikash K. Behera and Saif Al-Kuwari and Ahmed Farouk},
  doi          = {10.1109/TAI.2025.3572852},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {5},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {QSVM-QNN: Quantum support vector machine based quantum neural network learning algorithm for brain-computer interfacing systems},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Minimal neuron circuits —Part II: Integrators. <em>TAI</em>, 1-12. (<a href='https://doi.org/10.1109/TAI.2025.3572844'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neurons are the core building blocks of Spiking Neural Networks. This work presents a methodology for designing minimal neuron circuits using various types of devices. We postulate that Sodium ion channels show Type-N negative differential resistance. Consequently, we demonstrate multiple examples where a circuit or device showing Type-N negative differential resistance can fulfil the role of a Sodium channel. Similarly, we show that circuits and devices showing Type-S Negative Differential Resistance can fulfil the role of a Potassium channel for a neuron of the Integrator type. In part I, we present the methodology utilized in designing three novel minimal neuron circuits of the resonator type. In this part, we demonstrate a methodology to design neurons of the Integrator type, and we present eight novel minimal neurons of such type. We show that many combinations of N-type and S-type negative differential resistance circuits or devices can be used to construct minimal neuron circuits that mimic the INa,p+IK model. This work aims to supplement the understanding of how spiking neuron circuits relate to their biological counterparts, which is a necessary step towards building better brain-inspired systems.},
  archive      = {J_TAI},
  author       = {Amr Nabil and T. Nandha Kumar and Haider Abbas F. Almurib},
  doi          = {10.1109/TAI.2025.3572844},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {5},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Minimal neuron circuits —Part II: Integrators},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unveiling the convergence dynamics of a graph recommender system. <em>TAI</em>, 1-13. (<a href='https://doi.org/10.1109/TAI.2025.3572462'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNN) have shown performance on learning on structured data and found applications in different fields like biology, physics, transportation, e-commerce. However, the convergence dynamic of GNN models, particularly the ones for link prediction tasks, remains a challenge for better design. Existing approaches have shown that some simpler GNN architectures can be effective as complex ones when used for recommender system (recsys). This encourages the need to perceive the advantage of some components towards a model convergence. We built models for link prediction, specially recsys based on a single layer GNN and evaluate their convergence on real and generated graphs data. These recsys are based on a graph convolution layer with added scaling factor or activation function. Our theoretical and numerical results highlight the advantage of a scaling factor over an activation function. It means models which scale down features before the final output converge, compared to others. Besides, the ReLU activation function alone cannot compensate for the missing scaling factor. The takeaway and advantage of a scaling factor resides in its ability to change the direction of the hidden features vector.},
  archive      = {J_TAI},
  author       = {Adrien Njanko and Danda B. Rawat},
  doi          = {10.1109/TAI.2025.3572462},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {5},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Unveiling the convergence dynamics of a graph recommender system},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TRACE: Unlocking the potential of LLMs in time series forecasting for distributed energy resources. <em>TAI</em>, 1-14. (<a href='https://doi.org/10.1109/TAI.2025.3572853'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate power forecasting is essential to the safe operation of power systems. However, the massive distributed energy resources (DERs) data is characterized by both diversity and scarcity. Solving the power forecasting problem requires striking a balance between the model’s generalization ability and its capacity for few-shot learning (FSL). Traditional deep learning approaches are primarily designed for single entities, which limits their generalization capabilities and makes them ineffective in data-scarce scenarios. To address these challenges, we propose TRACE, a novel forecasting framework built on pretrained large language models (LLMs). By tracing and aligning the chain-of-thought (CoT) reasoning patterns, this approach bridges the extensive prior knowledge embedded in LLMs with the unique characteristics of the distributed energy resources power forecasting. Moreover, we introduce a Multi-agent Consistency framework in TRACE, which achieves thought refinement through collaboration, enhancing the stability of LLMs’ predictions and their ability to handle complex computational tasks, thereby improving prediction accuracy. Experimental results on public real-world datasets demonstrate that TRACE achieves prediction accuracy on par with state-of-the-art deep learning models, while significantly outperforming other baseline models in data-scarce scenarios.},
  archive      = {J_TAI},
  author       = {Yuxuan Chen and Haipeng Xie},
  doi          = {10.1109/TAI.2025.3572853},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {5},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {TRACE: Unlocking the potential of LLMs in time series forecasting for distributed energy resources},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modeling deep unfolded quantum machine learning framework. <em>TAI</em>, 1-11. (<a href='https://doi.org/10.1109/TAI.2025.3573303'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum machine learning models, like Quantum Neural Networks (QNN) and Quantum Support Vector Classifiers (QSVC), often struggle with overfitting, slow convergence, and suboptimal generalization across various datasets. This paper explores the advantages of integrating deep unfolding techniques into quantum models and develops a framework focusing on Deep Unfolded Variational Quantum Classifiers (DVQC), Deep Unfolded Quantum Neural Networks (DQNN), and Deep Unfolded QSVC (DQSVC). Our novel unfolding transforms quantum circuit training into a sequence of learnable layers, with each layer representing an optimization step that concurrently renews both circuit parameters and QNN hyperparameters. The proposed framework significantly improves training and test accuracy by dynamically adjusting learning rate, perturbations and other similar hyperparameters, particularly on complex datasets like Genomic and Breast Cancer. Our evaluation and experiment show that proposed DVQC and DQNN outperform baseline VQC and QNN, achieving 90% training accuracy and up to 20% higher test accuracy on Genomic and Adhoc datasets. DQSVC achieves 100% accuracy on Adhoc and 97% on Genomic datasets, surpassing the 90% test accuracy of traditional QSVC. Our implementation details will be publicly available.},
  archive      = {J_TAI},
  author       = {Shanika Iroshi Nanayakkara and Shiva Raj Pokhrel},
  doi          = {10.1109/TAI.2025.3573303},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {5},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Modeling deep unfolded quantum machine learning framework},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Boosting time-series domain adaptation via a time-frequency consensus framework. <em>TAI</em>, 1-12. (<a href='https://doi.org/10.1109/TAI.2025.3571869'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised Domain Adaptation (UDA) has proven to be effective in addressing the domain shift problem in computer vision. However, compared with visual applications, UDA for time series brings forth additional challenges. Potential domain shifts may have varying impacts on both time and frequency features, rendering conventional UDA methods less effective in this context. To address these challenges, we propose a Time-Frequency Consensus Domain Adaption (TFCDA) framework to enhance UDA methods for time-series data. TFCDA designs a frequency encoder, a trainable Time-Frequency Mapping (TFM), and a consensus loss, building upon conventional UDA methods to boost their performance. The TFM is trained on source domain data to learn the inherent time-frequency feature mapping, while the novel consensus loss ensures consistent feature transfer during UDA in the target domain, effectively reducing domain shifts in both time and frequency, and thus boosting overall performance. Experimental evaluations on four publicly available time-series datasets demonstrate TFCDA’s effectiveness in enhancing existing UDA methods for time-series data, highlighting its potential for real-world applications.},
  archive      = {J_TAI},
  author       = {Wenmian Yang and Mohamed Ragab and Min Wu and Sinno Jialin Pan and Guosheng Lin and Weijia Jia and Zhenghua Chen},
  doi          = {10.1109/TAI.2025.3571869},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {5},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Boosting time-series domain adaptation via a time-frequency consensus framework},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Implementation of FPGA-based neural network controller for reducing speed ripple for a PMSM-driven EV using MRAS speed estimator. <em>TAI</em>, 1-12. (<a href='https://doi.org/10.1109/TAI.2025.3571702'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The conventional model reference adaptive system (MRAS) employs a proportional-integral (PI) controller with a low-pass filter (LPF). However, the LPF and integrator add phase delay and DC drift, leading to inaccurate speed estimation. Furthermore, conventional MRAS suffers from poor speed estimation owing to the initial value of the integrator and the DC drift problem. In the proposed stator-current MRAS, the measured current from the reference model and the estimated current from the adaptive model were compared. A modified integrator (MI) was proposed that eliminates the initial value and reduces the DC drift problem during the practical implementation of an integrator. For accurate speed estimation and LPF elimination, this study proposes an artificial neural network (NN) controller as an adaptive mechanism of the MRAS (NNMRAS) speed estimator for the closed-loop control of permanent magnet synchronous motors (PMSMs) in electric vehicles (EVs) during the limp-home mode. For validation, the conventional MRAS (CMRAS), modified integrator-based MRAS (MIMRAS), and NNMRAS speed estimators for direct torque and flux control (DTFC) and space vector modulation-DTFC (SVM-DTFC) were used with standard parameters, such as standard deviation (SD), overshoot, and undershoot, at different reference speeds. A laboratory test setup using a 2.2 kW PMSM and the field-programmable gate array (FPGA)-based WAVECT WCU 300 controller was used to validate the effectiveness of the limp-home mode control.},
  archive      = {J_TAI},
  author       = {Sanjay Kumar Kakodia and Giribabu Dyanamina},
  doi          = {10.1109/TAI.2025.3571702},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {5},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Implementation of FPGA-based neural network controller for reducing speed ripple for a PMSM-driven EV using MRAS speed estimator},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging rationality labels for explainable claim check-worthiness. <em>TAI</em>, 1-11. (<a href='https://doi.org/10.1109/TAI.2025.3571707'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Determining the check-worthiness of claims is an integral process in fact-checking. Despite ongoing advancements in claim check-worthiness detection, there remains a notable gap of transparency in elucidating why a claim is deemed check-worthy. Addressing this gap, we introduce an explainable approach to claim check-worthiness by incorporating ‘rationality labels.’ Closely mirroring the complex decision-making process of human cognition, these labels evaluate claims on multiple aspects, including factual verifiability, societal impact, and the likelihood of causing public unrest. Unlike existing systems that provide simplistic binary judgments on check-worthiness, our framework, CheckMate, delves into the nuanced human-like reasoning behind the assessment of claim check-worthiness for fact-checking. We also introduce CheckIt, the first claim check-worthiness dataset of 5920 tweets with rationality labels. This multi-dimensional approach offers a significant advancement over traditional binary evaluation systems. We compare our proposed approach with several baseline systems and comprehensively analyze the results, including quantitative and qualitative comparisons. Our data and code can be found here.},
  archive      = {J_TAI},
  author       = {Megha Sundriyal and Md Shad Akhtar and Tanmoy Chakraborty},
  doi          = {10.1109/TAI.2025.3571707},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {5},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Leveraging rationality labels for explainable claim check-worthiness},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nuclei segmentation using multi-headed U-net and shearlet based unsharp masking. <em>TAI</em>, 1-11. (<a href='https://doi.org/10.1109/TAI.2025.3572849'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An automated nuclei segmentation is an important technique for understanding and analyzing cellular characteristics that eases computer-aided digital pathology and is useful for disease diagnosis. However, this task is difficult because of the diversity in nuclei size, blurry boundaries, and several imaging modalities. A convolutional neural network (CNN) based Multi-headed U-Net (M-UNet) framework has been proposed to address such issues. This architecture uses filters of different kernel sizes for multiple heads to extract multi-resolution features of an image. Shearlet based unsharp masking (SBUM) method is proposed for pre-processing which primarily emphasizes features like contours, boundaries, and minute details of the source image. In this paper, a hybrid loss function is formulated which includes intersection over union (IOU) loss and Dice loss along with binary cross entropy loss. The hybrid loss function is tried to be minimized by the optimization algorithm, and the higher metrics values during the testing phase represent better segmentation performance in the spatial domain. The proposed method yields superior segmentation images and quantitative findings as compared to the state-of-the-art nuclei segmentation techniques. The proposed technique attains IOU, F1Score, Accuracy, and Precision values of 0.8325, 0.9086, 0.9651, and 0.9001 respectively.},
  archive      = {J_TAI},
  author       = {Shivam Mishra and Amit Vishwakarma and Anil Kumar},
  doi          = {10.1109/TAI.2025.3572849},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {5},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Nuclei segmentation using multi-headed U-net and shearlet based unsharp masking},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IT2-ENFIS: Interval type-2 exclusionary neuro-fuzzy inference system, an attempt towards trustworthy regression learning. <em>TAI</em>, 1-15. (<a href='https://doi.org/10.1109/TAI.2025.3574299'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As machine learning technologies progress and are increasingly applied to critical and sensitive fields, the reliability issues of earlier technologies are becoming more evident. For the new generation of machine learning solutions, trustworthiness frequently takes precedence over performance when evaluating their applicability for specific applications. This manuscript introduces the IT2-ENFIS neuro-fuzzy model, a robust and trustworthy single-network solution specifically designed for data regression tasks affected by substantial label noise and outliers. The primary architecture applies interval type-2 fuzzy logic and the Sugeno inference engine. A meta-heuristic gradient-based optimizer (GBO), the Huber loss function, and the Cauchy M-estimator are employed for robust learning. IT2-ENFIS demonstrates superior performance on noise-contaminated datasets and excels in real-world scenarios, with excellent generalization capability and interpretability.},
  archive      = {J_TAI},
  author       = {Chuan Xue and Jianli Gao and Zhou Gu},
  doi          = {10.1109/TAI.2025.3574299},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {5},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {IT2-ENFIS: Interval type-2 exclusionary neuro-fuzzy inference system, an attempt towards trustworthy regression learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey on deep learning-based chinese font style transfer. <em>TAI</em>, 1-16. (<a href='https://doi.org/10.1109/TAI.2025.3574300'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, deep learning-based Chinese font style transfer has garnered extensive research. This field not only opens new possibilities for artistic creation but also provides powerful tools for generating personalized digital content, especially in the thriving era of AIGC. The complexity and diversity of Chinese characters pose significant challenges for font style transfer, prompting numerous solutions proposed by the research community. In light of these rapid advancements, we aim to provide a comprehensive review of the latest developments in Chinese font style transfer. Specifically, we first outline traditional methods, particularly those that existed before the emergence of deep learning techniques, to establish a theoretical foundation. Subsequently, we delve into the current mainstream deep learning methods, including Autoencoder, Generative Adversarial Networks (GANs) and Convolutional Neural Networks (CNNs), and their applications in Chinese font style transfer. While these methods have shown remarkable performance in handling the shapes, structures, and artistic styles of Chinese characters, they still face inherent challenges and limitations. Therefore, we propose an innovative set of solutions aimed at overcoming these obstacles and improving conversion effectiveness and practicality. This is the first comprehensive study on font style transfer methods based on deep learning technology. We hope to provide new ideas and directions for future research and application of Chinese font style transfer. The undertaking of this work enriches theoretical research on style transfer and offers substantial support for practical applications, possessing profound significance and widespread impact.},
  archive      = {J_TAI},
  author       = {Zheyong Ren and Yuhan Pan and Jieyan Chen and Lin Zhao and Ming Liao and Xuecheng Qian and Wei Gong},
  doi          = {10.1109/TAI.2025.3574300},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {5},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {A survey on deep learning-based chinese font style transfer},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). COSMIC: A novel contextualized orientation similarity metric incorporating consistency for NLG assessment. <em>TAI</em>, 1-15. (<a href='https://doi.org/10.1109/TAI.2025.3574292'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of Natural Language Generation (NLG) has undergone remarkable expansion, largely enabled by enhanced model architectures, affordable computing, and availability of large datasets. With NLG systems finding increasing adoption across many applications, the imperative to evaluate their performance has grown exponentially. However, relying solely on human evaluation for evaluation is non-scalable. To address this challenge, it is important to explore more scalable evaluation methodologies that can ensure the continued development and efficacy of NLG systems. Presently, only a few automated evaluation metrics are commonly utilized, with BLEU and ROUGE being the predominant choices. Yet, these metrics have faced criticism for their limited correlation with human judgment, their focus on surface-level similarity, and their tendency to overlook semantic nuances. While transformer metrics have been introduced to capture semantic similarity, our study reveals scenarios where even these metrics fail. Considering these limitations, we propose and validate a novel metric called “COSMIC”, which incorporates contradiction detection with contextual embedding similarity. To illustrate these limitations and showcase the performance of COSMIC, we conducted a case study using a fine-tuned LLAMA model to transform questions and short answers to declarative sentences. This task, despite its significance in generating Natural Language Inference datasets, has not received widespread exploration since 2018. Results show that COSMIC can capture cases of contradiction between the reference and generated text, while staying highly correlated with embeddings similarity when the reference and generated text are consistent and semantically similar. BLEU, ROUGE, and most transformer-based metrics demonstrate an inability to identify contradictions.},
  archive      = {J_TAI},
  author       = {Hadi Al Khansa and Mariette Awad},
  doi          = {10.1109/TAI.2025.3574292},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {5},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {COSMIC: A novel contextualized orientation similarity metric incorporating consistency for NLG assessment},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel multi-scale dynamic graph convolutional network for traffic data cognition. <em>TAI</em>, 1-13. (<a href='https://doi.org/10.1109/TAI.2025.3574655'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates traffic data cognitive modelling problem in real traffic scene by fully utilizing multiscale spatio-temporal dependence between multiple traffic nodes, along with a novel dynamic graph convolutional network. Most recently, the deep learning network model is weighed down by some practical problems focused on as follows: 1)The existing graph convolution operations typically aggregate information from the given k-hop neighbors; 2)How to model the similarity of traffic data patterns among these nodes given the spatio-temporal heterogeneity of traffic data. In this paper, we propose a novel hierarchical traffic data cognitive modelling framework called Multi-Scale Spatio-Temporal Dynamic Graph Convolutional Network architecture (MSST-DGCN). And, a multi-scale graph convolution module is firstly constructed to expand the receptive field of convolutional operations, by developing a novel sub-GCNs cumulative concatenation mechanism. Meanwhile, two specified dynamic graphs are designed to model the spatio-temporal correlation among these nodes from both a proximity and long-term perspective through a novel Gaussian calculation strategy, which are efficiently able to represent/cognize the dynamic similarity of traffic data patterns. Through a series of qualitative evaluations, the present model has the ability to perceive the traffic data pattern states of nodes. At last, two real world traffic datasets experiments are developed to show that the proposed approach achieves state-of-the-art traffic data cognitive performance.},
  archive      = {J_TAI},
  author       = {Jiyao An and Zhaohui Pu and Qingqin Liu and Lei Zhang and Md Sohel Rana},
  doi          = {10.1109/TAI.2025.3574655},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {5},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {A novel multi-scale dynamic graph convolutional network for traffic data cognition},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Boosting 3D point cloud registration by orthogonal self-ensemble learning. <em>TAI</em>, 1-10. (<a href='https://doi.org/10.1109/TAI.2025.3575036'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has significantly advanced the development of point cloud registration. However, in recent years, some methods have relied on additional sensor information or complex network designs to improve registration performance, which incurs considerable computational overhead. These methods often struggle to strike a reasonable balance between computational cost and performance gains. To address this, we propose a plug-and-play orthogonal self-ensemble module designed to enhance registration performance with minimal additional overhead. Specifically, we design a novel ensemble learning strategy to mine the complementary information within the extracted features of previous methods. Unlike most ensemble learning methods, our method does not set multiple complex models for performance enhancement. Instead, it only cascades a lightweight dual-branch network after the features extracted by the original model to obtain two sets of features with more diversity. To further reduce redundancy between features and prevent the degradation of the dual-branch network, we introduce an orthogonal constraint that ensures the features output by the two branches are more complementary. Finally, by concatenating the two sets of complementary features, the final enhanced features are obtained. Compared to the original features, these enhanced features thoroughly exploit the internal information and exhibit greater distinctiveness, leading to improved registration performance. To validate the effectiveness of our method, we plug it into GeoTransformer, resulting in consistent performance improvements across 3DMatch, KITTI, and ModelNet40 datasets. Moreover, our method is compatible with other performance-enhancing methods. In conjunction with the overlap prior in PEAL, GeoTransformer achieves a new state-of-the-art performance.},
  archive      = {J_TAI},
  author       = {Mingzhi Yuan and Ao Shen and Yingfan Ma and Jie Du and Qiao Huang and Manning Wang},
  doi          = {10.1109/TAI.2025.3575036},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {5},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Boosting 3D point cloud registration by orthogonal self-ensemble learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MALADY: Multiclass active learning with auction dynamics on graphs. <em>TAI</em>, 1-15. (<a href='https://doi.org/10.1109/TAI.2025.3575038'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Active learning enhances the performance of machine learning methods, particularly in low-label rate scenarios, by judiciously selecting a limited number of unlabeled data points for labeling, with the goal of improving the performance of an underlying classifier. In this work, we introduce the Multiclass Active Learning with Auction Dynamics on Graphs (MALADY) algorithm, which leverages an auction dynamics technique on similarity graphs for efficient active learning. In particular, the proposed algorithm incorporates an active learning loop using as its underlying semi-supervised procedure an efficient and effective similarity graph-based auction method consisting of upper and lower bound auctions that integrate class size constraints. In addition, we introduce a novel active learning acquisition function that incorporates the dual variable of the auction algorithm to measure the uncertainty in the classifier to prioritize queries near the decision boundaries between different classes. Overall, the proposed method can efficiently obtain accurate results using extremely small labeled sets containing just a few elements per class; this is crucial since labeled data is scarce for many applications. Moreover, the proposed technique can incorporate class size information, which improves accuracy even further. Lastly, using experiments on classification tasks and various data sets, we evaluate the performance of our proposed method and show that it exceeds that of comparison algorithms.},
  archive      = {J_TAI},
  author       = {Gokul Bhusal and Kevin Miller and Ekaterina Merkurjev},
  doi          = {10.1109/TAI.2025.3575038},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {5},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {MALADY: Multiclass active learning with auction dynamics on graphs},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parallel inductive shift learning based recommendation system. <em>TAI</em>, 1-13. (<a href='https://doi.org/10.1109/TAI.2025.3558183'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s world online services have revolutionized human activities and thus the consumers expect their service providers to make their online experiences more fruitful by recommending the relevant services to them. In this case, it becomes really challenging for the service providers to provide recommendation to a user whose information’s and preferences are unavailable. This issue is handled by cross domain approach which explores similar users across various domains in the same platform. However, the main concern with this cross domain approach is that the information needs to be available in any domain of one platform.Thus a multi-domain recommendation is designed to optimize the recommendation system performance by analyzing the information obtained from multiple platforms. However, existing multi-domain recommendation model has mainly two challenges. Firstly, there are no overlapping users to understand the similarities between them. Secondly, the transfer learning approach in multidomain allows the transfer of information from only the source to the target domain. Therefore, our proposed approach consider the Parallel Inductive Shift Learning(PISL) model to address these two above mentioned challenges. For the first challenge we have focused to identify the similarities between user-user and user-item by considering various features of user and item. For the next challenge, our proposed model analyzes the source and the target domain simultaneously and thus does a parallel transfer of information from the source to the target domain and vice versa. We have tested our model for 3 real-life movie and book datasets i.e. for the movie dataset we have used Movielens, Amazon, and Netflix dataset. In contrast, for the book dataset, we have used the Amazon, Good Reads, and Book Crossing dataset which proves to outperform the other state-of-the-art approaches.},
  archive      = {J_TAI},
  author       = {Nilufar Zaman and Angshuman Jana},
  doi          = {10.1109/TAI.2025.3558183},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Parallel inductive shift learning based recommendation system},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Human-in-the-loop formation-containment safe control for multi-agent systems via reinforcement learning. <em>TAI</em>, 1-14. (<a href='https://doi.org/10.1109/TAI.2025.3559040'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper designs the optimal formation containment safe tracking control protocol for nonlinear second-order multi-agent systems (MASs) with unknown dynamics. A human operator can interact with the tracking leader of MASs to improve security and communicate with other agent through the MASs network in an obstacle-laden environment. Primarily, adaptive neural networks are utilized to identify the unknown nonlinear dynamics parameter and ensure the identification state errors converge asymptotically. Additionally, the optimized safe control design incorporates an actor-critic architecture based on reinforcement learning (RL) to approximate the Hamilton-Jacobi-Bellman (HJB) equation for nonlinear MASs. This distributed security control of MASs achieves optimal tracking using only local connectivity information. Finally, the proposed optimal algorithm for MASs safe formation-containment control is verified with multiple unmanned aerial vehicle (UAV) systems in an unknown obstacle environment.},
  archive      = {J_TAI},
  author       = {Luning Yang and Pei Chi and Jiang Zhao and Yingxun Wang},
  doi          = {10.1109/TAI.2025.3559040},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Human-in-the-loop formation-containment safe control for multi-agent systems via reinforcement learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep residual learning of a probabilistic’ partial least squares model for predictive data analytics. <em>TAI</em>, 1-12. (<a href='https://doi.org/10.1109/TAI.2025.3560248'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, probabilistic latent variable models have played an important role in data analytics in various industrial application scenarios, such as process monitoring, fault diagnosis, and soft sensing. Inspired by the idea of lightweight deep learning, this paper proposes a new deep residual learning method for the probabilistic’ partial least squares model. Firstly, layer-wise probabilistic modeling is carried out to extract supervised latent variables in different hidden layers of the deep model using a well-designed expectation-maximization algorithm for parameter optimization. Through this layer-wise residual learning process, more target-related latent variables can be extracted, which are supervised by the outputs of the predictive model. Next, an additional probabilistic model is constructed for information fusion and further extraction of supervised latent variables which are highly related to the modeling target. In fact, this step can be considered as an ensemble learning strategy, which has great potentials in decreasing modeling error and reducing prediction uncertainty. A soft-sensing strategy is then developed for online prediction of key variables. The performance is evaluated using two industrial examples. Compared to the shallow probabilistic model, the performance of the deep model has been improved by 10%-20%.},
  archive      = {J_TAI},
  author       = {Zhiqiang Ge and Duxin Chen and Wenwu Yu},
  doi          = {10.1109/TAI.2025.3560248},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Deep residual learning of a probabilistic’ partial least squares model for predictive data analytics},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Incremental semi-supervised learning with adaptive locality preservation for high-dimensional data. <em>TAI</em>, 1-15. (<a href='https://doi.org/10.1109/TAI.2025.3560592'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Broad Learning System (BLS) has been widely researched and applied in the field of semi-supervised learning. However, current semi-supervised BLS methods rely on pre-defined graph structures. High-dimensional small-sample data, characterized by abundant redundant and noisy features with complex distribution patterns, often leads to the construction of poor-quality pre-defined graphs, thereby constraining the model’s performance. Additionally, the random generation of feature and enhancement nodes in BLS, combined with limited data labels, results in suboptimal model performance. To address these issues, this paper first proposes a Broad Learning System with Adaptive Locality Preservation (BLS-ALP). This method employs adaptive locality preservation constraints in the output space to ensure that similar samples share the same label, iteratively updating the graph structure. To further enhance the performance of BLS-ALP, an incremental ensemble framework (IBLS-ALP) is proposed. This framework effectively mitigates the impact of redundant and noisy features by using multiple random subspaces instead of the original high-dimensional space. Additionally, IBLS-ALP enhances the utilization of a small number of labels by incorporating residual labels, thereby significantly improving the model’s overall performance. Extensive experiments conducted on various high-dimensional small-sample datasets demonstrate that IBLS-ALP exhibits superior performance.},
  archive      = {J_TAI},
  author       = {Guojie Li and Zhiwen Yu and Kaixiang Yang and Ziwei Fan and C. L. Philip Chen},
  doi          = {10.1109/TAI.2025.3560592},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Incremental semi-supervised learning with adaptive locality preservation for high-dimensional data},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mixture-of-experts for open set domain adaptation: A dual-space detection approach. <em>TAI</em>, 1-11. (<a href='https://doi.org/10.1109/TAI.2025.3560590'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Open Set Domain Adaptation (OSDA) copes with the distribution and label shifts between the source and target domains simultaneously, performing accurate classification for known classes while identifying unknown class samples in the target domain. Most existing OSDA approaches, depending on the final image feature space of deep models, require manually-tuned thresholds, and may easily misclassify unknown samples as known classes. Mixture-of-Experts (MoE) could be a remedy. Within an MoE, different experts handle distinct input features, producing unique expert routing patterns for various classes in a routing feature space. As a result, unknown class samples may display different expert routing patterns to known classes. This paper proposes Dual-Space Detection, which exploits the inconsistencies between the image feature space and the routing feature space to detect unknown class samples without any threshold. A Graph Router is further introduced to better make use of the spatial information among the image patches. Experiments on three datasets validated the effectiveness and superiority of our approach.},
  archive      = {J_TAI},
  author       = {Zhenbang Du and Jiayu An and Yunlu Tu and Jiahao Hong and Dongrui Wu},
  doi          = {10.1109/TAI.2025.3560590},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Mixture-of-experts for open set domain adaptation: A dual-space detection approach},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EEG emotion recognition based on an implicit emotion regulatory mechanism. <em>TAI</em>, 1-13. (<a href='https://doi.org/10.1109/TAI.2025.3560593'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the main challenges in electroencephalography (EEG) emotion recognition is the lack of understanding of the biological properties of the brain and how they relate to emotions. To address this issue, this paper proposes an implicit emotion regulatory mechanism inspired contrastive learning framework (CLIER) for EEG emotion recognition. The framework simulates the complex relationship between emotions and the underlying neurobiological processes; to achieve this, the mechanism is mainly simulated through three parts. First, to leverage the inter-individual variability of emotional expression, the emotion features of the individual are captured by a dynamic connection graph in the subject-dependent setting. Subsequently, reverse regulation is simulated by contrast learning based on label information and data augmentation to capture more biologically specific emotional features. Finally, caused by the asymmetry between the left and right hemispheres of the human brain in response to emotions, brain lateralization mutual learning facilitates the fusion of the hemispheres in determining emotions. Experiments on SEED, SEED-IV, SEED-V, and EREMUS datasets show impressive results: 93.4% accuracy on SEED, 90.2% on SEED-IV, 82.46% on SEED-V, and 41.63% on EREMUS. Employing an identical experimental protocol, our model demonstrated superior performance relative to the majority of existing methods, thus showcasing its effectiveness in the realm of EEG emotion recognition.},
  archive      = {J_TAI},
  author       = {Dongdong Li and Zhishuo Jin and Yujun Shen and Zhe Wang and Suo Jiang},
  doi          = {10.1109/TAI.2025.3560593},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {EEG emotion recognition based on an implicit emotion regulatory mechanism},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ownership infringement detection for generative adversarial networks against model stealing. <em>TAI</em>, 1-12. (<a href='https://doi.org/10.1109/TAI.2025.3560921'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative adversarial networks (GANs) have shown remarkable success in image synthesis, making GAN models themselves commercially valuable to legitimate model owners. Therefore, it is critical to technically protect the intellectual property of GANs. Prior works need to tamper with the training set or training process to verify the ownership of a GAN. In this paper, we show that these methods are not robust to emerging model extraction attacks. Then, we propose a new method GAN-Guards which utilizes the common characteristics of a target model and its stolen models for ownership infringement detection. Our method can be directly applicable to all well-trained GANs as it does not require retraining target models. Extensive experimental results show that our new method achieves superior detection performance, compared to watermark-based and fingerprint-based methods. Finally, we demonstrate the effectiveness of our method with respect to the number of generations of model extraction attacks, the number of generated samples, and adaptive attacks.},
  archive      = {J_TAI},
  author       = {Hailong Hu and Jun Pang},
  doi          = {10.1109/TAI.2025.3560921},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Ownership infringement detection for generative adversarial networks against model stealing},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrating large language model for improved causal discovery. <em>TAI</em>, 1-13. (<a href='https://doi.org/10.1109/TAI.2025.3560927'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recovering the structure of causal graphical models from observational data is an essential yet challenging task for causal discovery in scientific scenarios. Domain-specific causal discovery usually relies on expert validation or prior analysis to improve the reliability of recovered causality, which is yet limited by the scarcity of expert resources. Recently, Large Language Models (LLM) have been used for causal analysis across various domain-specific scenarios, suggesting its potential as autonomous expert roles in guiding data-based structure learning. However, integrating LLMs into causal discovery faces challenges due to inaccuracies in LLM-based reasoning on revealing the actual causal structure. To address this challenge, we propose an error-tolerant LLM-driven causal discovery framework. The error-tolerant mechanism is designed three-fold with sufficient consideration on potential inaccuracies. In the LLM-based reasoning process, an accuracy-oriented prompting strategy restricts causal analysis to a reliable range. Next, a knowledge-to-structure transition aligns LLM-derived causal statements with structural causal interactions. In the structure learning process, the goodness-of-fit to data and adherence to LLM-derived priors are balanced to further address prior inaccuracies. Evaluation of eight real-world causal structures demonstrates the efficacy of our LLM-driven approach in improving data-based causal discovery, along with its robustness to inaccurate LLM-derived priors. Codes are available at https://github.com/tyMadara/LLM-CD.},
  archive      = {J_TAI},
  author       = {Taiyu Ban and Lyuzhou Chen and Derui Lyu and Xiangyu Wang and Qinrui Zhu and Qiang Tu and Huanhuan Chen},
  doi          = {10.1109/TAI.2025.3560927},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Integrating large language model for improved causal discovery},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel privacy-enhancing framework for low-dose CT denoising. <em>TAI</em>, 1-14. (<a href='https://doi.org/10.1109/TAI.2025.3561092'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL) has made significant advancements in tomographic imaging, particularly in low-dose computed tomography (LDCT) denoising. A recent trend involves servers training powerful models with enormous self-collected data and providing application programming interfaces (APIs) for users, such as Chat-GPT. To avoid model leakage, users are required to upload their data to the server. This approach is particularly advantageous for devices with limited computational capabilities, as it offloads computation to the server, easing the workload on the devices themselves. However, this way raises public concerns about the privacy disclosure risk. Hence, to alleviate related concerns, we propose to directly denoise LDCT in the encrypted domain to achieve privacy-preserving cloud services without exposing private data to the server. Concretely, we employ homomorphic encryption to encrypt private LDCT, which is then transferred to the server model trained with plaintext LDCT for further denoising. Since fundamental DL operations, such as convolution and linear transformation, cannot be directly used in the encrypted domain, we transform the fundamental mathematic operations in the plaintext domain into the operations in the encrypted domain. Moreover, we present two interactive frameworks for linear and nonlinear models, both of which can achieve lossless operating. In this way, the proposed methods can achieve two merits, the data privacy is well protected and the server model is free from the risk of model leakage. Moreover, we provide theoretical proof to validate the lossless property of our framework. Finally, experiments were conducted to demonstrate that the transferred contents are well protected and cannot be reconstructed.1},
  archive      = {J_TAI},
  author       = {Ziyuan Yang and Huijie Huangfu and Maosong Ran and Zhiwen Wang and Hui Yu and Mengyu Sun and Yi Zhang},
  doi          = {10.1109/TAI.2025.3561092},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {A novel privacy-enhancing framework for low-dose CT denoising},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reinforcement learning for efficient multi-agent task allocation in potential game model. <em>TAI</em>, 1-15. (<a href='https://doi.org/10.1109/TAI.2025.3562160'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The potential game has been widely used to describe multi-agent task allocation. However, The application of traditional game-theoretic algorithms has shown unsatisfactory performance in scenarios with a high agent count. For this, we employ reinforcement learning algorithm to enable each agent to independently make decision in response to other agents’ decisions and variations in the number of agents, ultimately working towards achieving a desired goal. First, we construct a potential game for multi-agent task allocation and design a corresponding utility function for each agent. Then, we propose a deep q-network algorithm based on graph neural network, and enhance the agent selection mechanism in this learning algorithm. During each iteration, a task is randomly selected for an agent from the participant set, and each agent updates its strategy accordingly. Finally, by comparing several representative game theoretical algorithms, the numerical simulations highlight the advantages and performance of our proposed GDQ-Net algorithm across various tasks and numbers of agents under the constructed model.},
  archive      = {J_TAI},
  author       = {Yuxing Xing and Caixia Chen and Jie Wu and Jie Chen},
  doi          = {10.1109/TAI.2025.3562160},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Reinforcement learning for efficient multi-agent task allocation in potential game model},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ARDIAL-BERT: Advancing multidialectal arabic named entity recognition through continual pretraining. <em>TAI</em>, 1-10. (<a href='https://doi.org/10.1109/TAI.2025.3562162'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Named Entity Recognition (NER) is among the main tasks of Natural Language Processing (NLP). NER is a critical and fundamental component for several NLP applications including Information Retrieval (IR), Question-Answering (QA) and Machine Translation (MT). While several NER models for formal languages such as English and Modern Standard Arabic (MSA) have emerged, Arabic dialects remain in their infancy. We noted that the most recent researches focused on the study of a single Arabic dialect, hence the absence of a perfect multidialectal NER model. In this paper, we present the ARDIAL-BERT, the first multidialectal NER model which was built upon a continuous pretraining and then a finetuning on Arabic dialect publicly available datasets grouped by region (Levantine, Maghrebi, Egyptian and Gulf). The model was built upon the last updated version of BERT transfer transformers after several experiments on various BERT NER models. We approached our contribution on two different tasks: first we built ARDIAL-NER, an Arabic multidialect dataset extracted from existing NER datasets. ARDIAL-NER was manually annotated and contains a total of 53,539 entities of 369,372 tokens composing 21683 sentences. Second, we conducted a continual pretraining process using additional unannotated data, and then we guided a finetuning on new annotated NER datasets. The continuous learning system can be applied at different levels: updating model parameters, incorporating new language data, and training on new labels. Our results demonstrate its effectiveness to varying degrees. Our approach showed that it exhibited a greater ability by achieving superior results compared with both baselines and previous models. This demonstrates the capabilities of grouping Arabic dialects by region and the good selection of data that matches well with the baseline transformers.},
  archive      = {J_TAI},
  author       = {Tahar Alimi and Rahma Boujelbene and Lamia Hadrich Belguith},
  doi          = {10.1109/TAI.2025.3562162},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {ARDIAL-BERT: Advancing multidialectal arabic named entity recognition through continual pretraining},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Phenotype and genotype based sample aware surrogate-assisted genetic programming in dynamic flexible job shop scheduling. <em>TAI</em>, 1-15. (<a href='https://doi.org/10.1109/TAI.2025.3562161'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Genetic programming (GP) has been widely applied to evolve scheduling heuristics for dynamic flexible job shop scheduling (DFJSS). However, the evaluation of GP individuals is computationally expensive, especially in large scale DFJSS scenarios. A k-nearest neighbor (KNN) based surrogate has been successfully used to reduce individual evaluation time for GP by predicting the fitness of an individual with the most similar sample in KNN. Particularly, the phenotypes of GP individuals have been utilised to generate samples for KNN-based surrogates with a precondition that the fitness of individuals with the same phenotype is the same or similar. However, their real fitness may differ greatly due to different input decision situations for fitness calculations in DFJSS. Thus, only considering phenotypes of GP individuals to extract samples could decrease the accuracy of KNN surrogates. This paper proposes a KNN-based surrogate assisted GP algorithm by considering both the phenotype and genotype of GP individuals to generate samples. Specifically, a genotypic characterisation based on terminal frequency is designed to measure the similarity of individual genotypes. The results show that with the same training time, the proposed algorithm can converge fast and achieve better scheduling heuristics than the state-of-the-art algorithms in most examined scenarios. With the same number of generations, the proposed algorithm can obtain comparable performance but only needs about one third training time of baseline GP. The effectiveness of the proposed algorithm is also verified from different aspects, e.g., relation between genotype correlation and fitness difference of individuals, and population diversity.},
  archive      = {J_TAI},
  author       = {Luyao Zhu and Fangfang Zhang and Xiaodong Zhu and Ke Chen and Mengjie Zhang},
  doi          = {10.1109/TAI.2025.3562161},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Phenotype and genotype based sample aware surrogate-assisted genetic programming in dynamic flexible job shop scheduling},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Model selection of anomaly detectors in the absence of labeled validation data. <em>TAI</em>, 1-10. (<a href='https://doi.org/10.1109/TAI.2025.3562505'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection is the task of identifying abnormal samples in large unlabeled datasets. Although the advent of foundation models has produced powerful zero-shot anomaly detection methods, their deployment in practice is often hindered by the absence of labeled validation data—without it, detection performance cannot be evaluated reliably. In this work, we propose SWSA (Selection With Synthetic Anomalies): a general-purpose framework to select image-based anomaly detectors without labeled validation data. Instead of collecting labeled validation data, we generate synthetic anomalies from a small support set of normal images without using any training or fine-tuning. Our synthetic anomalies are then used to create detection tasks that compose a validation framework for model selection. In an empirical study, we evaluate SWSA with three types of synthetic anomalies and on two selection tasks: model selection of image-based anomaly detectors and prompt selection for CLIP-based anomaly detection. SWSA often selects models and prompts that match selections made with a ground-truth validation set, outperforming baseline selection strategies.},
  archive      = {J_TAI},
  author       = {Clement Fung and Chen Qiu and Aodong Li and Maja Rudolph},
  doi          = {10.1109/TAI.2025.3562505},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Model selection of anomaly detectors in the absence of labeled validation data},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fuzzy information quantity measurement and feature selection by macrogranular entropy. <em>TAI</em>, 1-15. (<a href='https://doi.org/10.1109/TAI.2025.3562839'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is an important data preprocessing process in artificial intelligence, which aims to eliminate redundant features while retaining essential features. Measuring feature significance and relevance between features is a significant challenge. Fuzzy information entropy is an extension of Shannon entropy. It is widely used for quantifying the information of fuzzy divisions. However, it has significant limitations, notably the lack of monotonicity in fuzzy conditional entropy measure of decision uncertainty in the feature selection process. We introduce a novel measurement Macrogranular Entropy (ME) and construct some generalized forms, such as conditional macrogranular entropy, mutual macrogranular information, and joint macrogranular entropy. The conditional macrogranular entropy exhibits monotonicity when measuring decision uncertainty. Additionally, we propose two feature selection algorithms: one based on Monotonic Conditional Macrogranular Entropy (MCME), and the other based on the Degree of Symmetric Association (ADSA). The ADSA algorithm and the MCME algorithm are compared against eight other feature selection algorithms through a series of experiments. The comparison was conducted based on classification performance using SVM and NB classifiers, as well as evaluation metrics including F1-score and Recall. In terms of all four evaluation metrics, ADSA and MCME achieved the top two rankings, respectively. Specifically, on the NB and SVM classifiers, the ADSA algorithm improves the average accuracy by 12.22% and 2.88% compared to the original feature set, while MCME improves the accuracy by 10.07% and 1.01%, respectively. Experimental comparisons demonstrate that ADSA algorithm effectively removes redundant information from the dataset during feature selection.},
  archive      = {J_TAI},
  author       = {Zhilin Zhu and Chucai Zhang and Jianhua Dai},
  doi          = {10.1109/TAI.2025.3562839},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Fuzzy information quantity measurement and feature selection by macrogranular entropy},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online multi-label streaming feature selection with missing features by dual-space consistency information measurement. <em>TAI</em>, 1-14. (<a href='https://doi.org/10.1109/TAI.2025.3563139'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label feature selection is critical to address the challenges of high dimensionality and computational complexity in multi-label learning. However, in some practical applications, a more complex challenge is the dynamic generation of features, known as streaming features. Although some scholars have studied multi-label streaming feature selection methods, the problem of missing features during dynamic feature generation in multi-label data is rarely considered. Hence, we propose an online multi-label streaming feature selection method for multilabel data containing missing features by dual-space consistency information measurement. Firstly, we construct the dual-space consistency information measurement, which can effectively capture the relationships between features and labels. Specifically, we consider it from the perspective of instance correlation, and propose a fuzzy α-tolerance relation in the feature space to directly deal with missing features, and introduce an improved neighbour similarity relation in the label space to capture the instance similarity between the label combinations. Secondly, based on the dual-space consistency information, we further introduce the consistency gain index to help identify those features with important information during the streaming feature selection process. Thirdly, by combining online significance analysis, online relevance analysis, and online redundancy analysis, a new streaming feature selection framework is constructed, which can comprehensively evaluate the newly arrived features in terms of strong consistency, weak consistency and irrelevance, so as to identify the most representative features in the continuously arriving feature streams. Finally, a series of comparative experiments on multiple benchmark datasets demonstrate the effectiveness and superiority of our proposed method.},
  archive      = {J_TAI},
  author       = {Jianhua Dai and Jie Wang},
  doi          = {10.1109/TAI.2025.3563139},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Online multi-label streaming feature selection with missing features by dual-space consistency information measurement},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Is perceptual encryption secure? a security benchmark for perceptual encryption methods. <em>TAI</em>, 1-10. (<a href='https://doi.org/10.1109/TAI.2025.3563438'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Perceptual encryption methods are the key enablers for protecting image privacy for deep learning-based applications in the cloud. In perceptual encryption, the image content is obfuscated such that the deep learning models can work on the obfuscated data. The key advantage of perceptual encryption over holomorphic encryption is that, unlike holomorphic encryption, the feature required by the target deep learning model is preserved in the encrypted data. Therefore, the model is not required to be retrained on the encrypted data. Recently, a significant number of perceptual encryption methods have been proposed in the literature, each improving over the others. In this paper, we perform a detailed security analysis of three best-known perceptual encryption methods, namely, Adversarial Visual Information Hiding, Learnable Encryption, and Encryption-then-Compression methods designed to protect the privacy of images. We proposed a new GAN-based security evaluation framework to successfully reconstruct the original images encrypted by these methods, showing clear security flaws. We conducted extensive experiments using different datasets and deep learning models. The results show significant vulnerabilities in the existing key-based perceptual encryption methods. The source code of our work is available at the given link: https://github.com/umesh-21/Benchmark to perceptual encryption.},
  archive      = {J_TAI},
  author       = {Umesh Kashyap and Sudev Kumar Padhi and Sk. Subidh Ali},
  doi          = {10.1109/TAI.2025.3563438},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Is perceptual encryption secure? a security benchmark for perceptual encryption methods},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal biometric recognition system based on feature-level fusion of dorsal finger crease and finger knuckle print. <em>TAI</em>, 1-13. (<a href='https://doi.org/10.1109/TAI.2025.3563315'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biometric system identifies individuals by utilizing their behavioral or physical traits. A multimodal biometric system is one of the best choices to overcome the numerous problems including vulnerability to environmental impacts, sensitivity to spoof attacks, non-universality, and intra-class variations problems associated with unimodal biometric system. Hand based biometrics is a swiftly growing field of research. This paper proposes a multimodal biometric system based on hand modalities, which combines the extracted information of dorsal finger crease and finger knuckle print. Dorsal finger crease with a small image dimension is a newly explored biometric trait with a highly distinctive pattern and can be used as a reliable identifier in biometric system. To the best of our knowledge, it is the first time to integrate the dorsal finger crease with finger knuckle print for more secure and better recognition performance of the proposed multimodal biometric system. Additionally, we developed a dorsal finger image acquisition device to construct a novel dataset, USM-FCKP, which simultaneously captures dorsal finger crease and finger knuckle print images. For feature extraction, an efficient texture descriptor, Circular Shift Combination Local Binary Pattern (CSC-LBP) is applied, and compared its performance with other LBP variants, including Basic-LBP, Uniform-LBP, Orthogonal Difference-LBP, and Symmetric Inline Matrix-LBP. Furthermore, feature-level fusion is performed, and a Support Vector Machine (SVM) classifier is employed to evaluate the effectiveness of the proposed dataset and multimodal biometric system. Experimental results demonstrate that the proposed multimodal approach achieves superior recognition performance compared to unimodal methods.},
  archive      = {J_TAI},
  author       = {Imran Riaz and Ahmad Nazri Ali and Haidi Ibrahim and Ilyas Ahmad Huqqani},
  doi          = {10.1109/TAI.2025.3563315},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Multimodal biometric recognition system based on feature-level fusion of dorsal finger crease and finger knuckle print},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient transformer inference through hybrid dynamic pruning. <em>TAI</em>, 1-14. (<a href='https://doi.org/10.1109/TAI.2025.3563144'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the world of deep learning, transformer models have become very significant, leading to improvements in many areas from understanding language to recognizing images, covering a wide range of applications. Despite their success, the deployment of these models in real-time applications, particularly on edge devices, poses significant challenges due to their computational intensity and memory demands. To overcome these challenges, we introduce a novel Hybrid Dynamic Pruning (HDP) technique, an efficient algorithm-architecture co-design approach that accelerates transformers using head sparsity, block sparsity and approximation to reduce computations in attention and reduce memory access. With the observation of the huge redundancy in attention scores and attention heads, we propose a novel integer-based block pruning to prune unimportant blocks in the attention matrix at run time. We also propose integerbased head pruning to detect and prune unimportant heads at an early stage at run time. Also, we propose an approximation method that reduces attention computations. To efficiently support these methods with lower latency, we propose the HDP Accelerator (HDPA) as a co-processor architecture, synthesized in two configurations—HDPA-edge and HDPA-server—to meet the needs of mobile and server platforms. Extensive experiments with different transformer models and benchmarks demonstrate that HDPA-server achieves 481× and 381× speedup in attention layer computation over Intel i7-1185G7 CPU and NVIDIA T4 GPU, respectively. Compared to other state-of-the-art accelerators, HDPA achieves 1.26× to 2.08× higher throughput, 1.3× to 18× greater MAC efficiency, and 1.1× to 5.1× improved energy efficiency, when normalized to the same computational load.},
  archive      = {J_TAI},
  author       = {Ghadeer A. Jaradat and Mohammed F. Tolba and Ghada Alsuhli and Hani Saleh and Mahmoud Al-Qutayri and Thanos Stouraitis},
  doi          = {10.1109/TAI.2025.3563144},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Efficient transformer inference through hybrid dynamic pruning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamics analysis and control of memristor-based hopfield neural networks under electromagnetic radiation. <em>TAI</em>, 1-11. (<a href='https://doi.org/10.1109/TAI.2025.3562833'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As is well known, the widespread use of electrical equipment, the solar storm or malicious attacks may result in a large or even strong electromagnetic radiation (ER) in the actual environment. Hopfield neural network (HNN) is a computational model that has been widely applied in multiple fields, but its dynamic characteristics after exposure to ER have not been systematically considered. With that in mind, this paper investigates the dynamics analysis and control for a class of memristor-based HNNs (MHNNs) under the influence of ER. Firstly, a new type of MHNNs model that is affected by ER is proposed, in which a resulting current is introduced to simulate the effects of ER. On this basis, some sufficient criteria for the boundedness of system states and stability strategies are given based on the Lyapunov function method. Subsequently, the synchronization control problem of the driving-response MHNNs under the influence of ER is studied by using Lyapunov stability theory and some inequality techniques. The stabilization and synchronization controller frameworks proposed in this paper can respectively achieve exponential, finite-time, and fixed-time stability and synchronization by adjusting parameter conditions. Three simulation experiments have verified the effectiveness of the above criteria and control strategies. Finally, based on the fixed-time synchronization control scheme, the theoretical results of this paper are applied to the image encryption.},
  archive      = {J_TAI},
  author       = {Mingxin Wang and Song Zhu and Weiwei Luo and Zhen Zhang and Chaoxu Mu},
  doi          = {10.1109/TAI.2025.3562833},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Dynamics analysis and control of memristor-based hopfield neural networks under electromagnetic radiation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RSMBSP-DON: RNA-small molecule binding sites prediction by dual-path feature extraction and one-dimensional multi-scale feature fusion network. <em>TAI</em>, 1-9. (<a href='https://doi.org/10.1109/TAI.2025.3564243'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the significant differences between the structural and sequence information of RNA, accurately predicting RNA-small molecule binding sites by utilizing these two attributes remains a challenging task. This study introduces a novel network for predicting RNA-small molecule binding sites, employing a two-stage approach that integrates feature extraction and fusion processes. On one hand, in order to capture the diverse characteristic information of RNA, a dual-path feature extraction module is proposed to extract features from both short-range and long-range perspectives, by incorporating convolutional and attention networks. On the other hand, a one-dimensional multi-scale feature fusion module, consisting of parallel one-dimensional convolutional kernels, is proposed to extract feature information at multiple granularities and to effectively integrate the features of nucleotides on the RNA chain and their neighboring nucleotides. Experimental results demonstrate that RSMBSP-DON is competitive with some recently reported methods. All datasets and resource codes are available at https://github.com/zhlSunLab/RSMBSP-DON.},
  archive      = {J_TAI},
  author       = {Xiao Yang and Zhan-Li Sun and Mengya Liu and Zhigang Zeng and Kin-Man Lam and Xin Wang},
  doi          = {10.1109/TAI.2025.3564243},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  pages        = {1-9},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {RSMBSP-DON: RNA-small molecule binding sites prediction by dual-path feature extraction and one-dimensional multi-scale feature fusion network},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Location, neighborhood, and semantic guidance network for RGB-D co-salient object detection. <em>TAI</em>, 1-14. (<a href='https://doi.org/10.1109/TAI.2025.3564238'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Red–green–blue-depth (RGB-D) deep learning-based co-salient object detection (Co-SOD) automatically detects and segments common salient objects in images. However, this computationally intensive model cannot be run on mobile devices. To help overcome this limitation, this article proposes a localization, neighborhood, and semantic guidance network (LNSNet) with knowledge distillation (KD), called LNSNet-S*, for RGB-D Co-SOD to minimize the number of parameters and improve the accuracy. Apart from their backbone networks, the LNSNet student (LNSNet-S) and teacher (LNSNet-T) models use the same structure to capture similarity knowledge in category, channel, and pixel-point dimensions to train an LNSNet-S with KD for superior lightweight performance. For optimization, a positioning path progressive activation uses hierarchical transformers to fuse features from low to high levels, generating class activation localization maps using the fused bimodal information to obtain location information. The high-level neighborhood-guidance information is then used to guide the low-level features. Next, a multisource semantic enhancement embedding module progressively fuses multiscale cross-modal semantic information guided by class-activated localization information. A class-based progressive triplet loss facilitates the transfer of category, channel, and pixel-point information. Extensive experiments demonstrated the effectiveness and robustness of the novel LNSNet-S* in different sizes, and significant improvements were observed. The smallest LNSNet-S* model reduced the number of parameters by more than 92% compared to that of LNSNet-T, requiring only 15.9 M parameters. The code has been publicly released at https://github.com/Wang-5ying/LNSNet.},
  archive      = {J_TAI},
  author       = {Wujie Zhou and Bingying Wang and Xiena Dong and Caie Xu and Fangfang Qiang},
  doi          = {10.1109/TAI.2025.3564238},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Location, neighborhood, and semantic guidance network for RGB-D co-salient object detection},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ECG_DEEPNet: A novel approach for delineation and classification of electrocardiogram signal based on ensemble deep-learning. <em>TAI</em>, 1-15. (<a href='https://doi.org/10.1109/TAI.2025.3564603'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advancements in telehealth monitoring technology have enabled the collection of vast quantities of electrophysiological signals, including the electrocardiogram (ECG) which contains critical diagnostic information about cardiac diseases. There are two main key challenges in the automatic classification of cardiac rhythms. First, addressing the specific characteristics of irregular heartbeats is critical for accurate classification. Second, the low frequency of ECG signals combined with noise interference makes it particularly difficult to efficiently detect abnormal electrical activity in the heart. To solve this issue, this paper proposes an Ensemble deep-learning model, ECG_DEEPNet architecture to enhance the delineation of ECG signals with improved accuracy for better diagnosis in telemedicine monitoring systems. The presented technique consists of a feature extraction stage using a convolutional neural network (CNN) and a sequence processing stage using a combination of gated recurrent units (GRU) and bidirectional long short-term memory (BiLSTM) networks. The proposed method is divided into four parts: firstly, the signal preprocessing, secondly waveform segmentation, thirdly classification of ECG signals and lastly results are evaluated on the proposed model. The proposed technique was tested and trained using standard LUDB and QT database (QTDB) containing annotation of a waveform for accurate classification of ECG wave components. The presented technique shows the average accuracy of 99.82%, 98.50%, and 97.42% for QRS, P, and T on the QTDB database, and 99.96%, 98.82%, and 99.47% on LUDB dataset respectively, for classification and delineation of ECG signals. The proposed technique achieves better performance compared to state-of-the-art methods, which results in a better diagnosis of heart-related problems.},
  archive      = {J_TAI},
  author       = {Neenu Sharma and Deepak Joshi},
  doi          = {10.1109/TAI.2025.3564603},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {ECG_DEEPNet: A novel approach for delineation and classification of electrocardiogram signal based on ensemble deep-learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Empirical evaluation of public HateSpeech datasets. <em>TAI</em>, 1-14. (<a href='https://doi.org/10.1109/TAI.2025.3564605'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the extensive communication benefits offered by social media platforms, numerous challenges must be addressed to ensure user safety. One of the most significant risks faced by users on these platforms is targeted hatespeech. Social media platforms are widely utilized for generating datasets employed in training and evaluating machine learning algorithms for hatespeech detection. However, existing public datasets exhibit numerous limitations, hindering the effective training of these algorithms and leading to inaccurate hatespeech classification. This study provides a systematic empirical evaluation of several public datasets commonly used in automated hatespeech classification. Through rigorous analysis, we present compelling evidence highlighting the limitations of current hatespeech datasets. Additionally, we conduct a range of statistical analyses to elucidate the strengths and weaknesses inherent in these datasets. This work aims to advance the development of more accurate and reliable machine learning models for hatespeech detection by addressing the dataset limitations identified.},
  archive      = {J_TAI},
  author       = {Sardar Jaf and Basel Barakat},
  doi          = {10.1109/TAI.2025.3564605},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Empirical evaluation of public HateSpeech datasets},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive head pruning for attention mechanism in the maritime domain. <em>TAI</em>, 1-12. (<a href='https://doi.org/10.1109/TAI.2025.3558724'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce a novel and synergistic approach that combines attention mechanisms, LVENet for image visibility enhancement, and a tailored head pruning method for Multi-Head Self Attention (MHSA) models, specifically engineered for AACN (Attention Augmented Convolutional Network) and BoTNet (Bottleneck Transformers). The integration of these techniques aims to comprehensively address the challenges associated with object detection in the maritime domain. The attention mechanism selectively emphasizes critical areas of the image, Low-Visibility Enhancement Network (LVENet) enhances visibility under challenging conditions, and the head pruning method optimizes model efficiency and simplicity. Employing meticulous selection and evaluation, our approach achieves precise head pruning without compromising detection performance. Validation using common and maritime datasets underscores the effectiveness of our approach. The results showcase a substantial reduction in epoch time by over 30%, while enhancing accuracy, improving computational efficiency, and streamlining model complexity. This innovation facilitates deployment in challenging maritime scenarios.},
  archive      = {J_TAI},
  author       = {Walid Messaoud and Rim Trabelsi and Adnane Cabani and Fatma Abdelkefi},
  doi          = {10.1109/TAI.2025.3558724},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Adaptive head pruning for attention mechanism in the maritime domain},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prescribed performance resilient motion coordination with Actor–Critic reinforcement learning design for UAV-USV systems. <em>TAI</em>, 1-15. (<a href='https://doi.org/10.1109/TAI.2025.3564900'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we develop a virtual vehicle scheme to solve the coordination control problem under denial-of-service (DoS) attacks for heterogeneous vehicles. This system includes an unmanned surface vessel (USV) in distress, sharing kinematic data, and a helicopter receiving data from the latter through wireless communication. Specifically, we carefully develop an estimator to model the unmeasurable states of the USV in the presence of DoS attacks. The virtual vehicle concept is then utilized to generate a velocity reference output for the helicopter to follow. To achieve preset tracking performances, the cascade structure of the helicopter is exploited, where the backstepping control strategy is used via a barrier Lyapunov function. To handle input constraints, auxiliary systems are built to bridge the association between input saturation errors and performance constraints. Furthermore, to mitigate the saturation effect of bounded inputs and model uncertainties in the attitude dynamics, a fixed-time reinforcement learning (FT-RL) control algorithm is designed according to actor-critic strategy. Stability analysis is thoroughly studied with the help of Lyapunov stability where sufficient conditions for the whole closed-loop system have been obtained. Numerical simulations have been shown to validate the proposed coordination strategy.},
  archive      = {J_TAI},
  author       = {Jawhar Ghommam and Maarouf Saad and Mohammad H. Rahman and Quanmin Zhu},
  doi          = {10.1109/TAI.2025.3564900},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Prescribed performance resilient motion coordination with Actor–Critic reinforcement learning design for UAV-USV systems},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dual perspective of reinforcement learning for imposing policy constraints. <em>TAI</em>, 1-14. (<a href='https://doi.org/10.1109/TAI.2025.3564898'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model-free reinforcement learning methods lack an inherent mechanism to impose behavioural constraints on the trained policies. Although certain extensions exist, they remain limited to specific types of constraints, such as value constraints with additional reward signals or visitation density constraints. In this work we unify these existing techniques and bridge the gap with classical optimization and control theory, using a generic primal-dual framework for value-based and actor-critic reinforcement learning methods. The obtained dual formulations turn out to be especially useful for imposing additional constraints on the learned policy, as an intrinsic relationship between such dual constraints (or regularization terms) and reward modifications in the primal is revealed. Furthermore, using this framework, we are able to introduce some novel types of constraints, allowing to impose bounds on the policy’s action density or on costs associated with transitions between consecutive states and actions. From the adjusted primal-dual optimization problems, a practical algorithm is derived that supports various combinations of policy constraints that are automatically handled throughout training using trainable reward modifications. The proposed DualCRL method is examined in more detail and evaluated under different (combinations of) constraints on two interpretable environments. The results highlight the efficacy of the method, which ultimately provides the designer of such systems with a versatile toolbox of possible policy constraints.},
  archive      = {J_TAI},
  author       = {Bram De Cooman and Johan Suykens},
  doi          = {10.1109/TAI.2025.3564898},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {A dual perspective of reinforcement learning for imposing policy constraints},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ProLLaMA: A protein large language model for multi-task protein language processing. <em>TAI</em>, 1-12. (<a href='https://doi.org/10.1109/TAI.2025.3564914'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in Protein Language Models (PLMs) have transformed protein engineering, yet unlike their counterparts in Natural Language Processing (NLP), current PLMs exhibit a fundamental limitation: they excel in either Protein Language Understanding (PLU) or Protein Language Generation (PLG), but rarely both. This fragmentation hinders progress in protein engineering. To bridge this gap, we introduce ProLLaMA, a multitask protein language model enhanced by the Evolutionary Protein Generation Framework (EPGF). We construct a comprehensive instruction dataset containing approximately 13 million samples with over 11,000 superfamily annotations to facilitate better modeling of sequence-function landscapes. We leverage a two-stage training approach to develop ProLLaMA, a multitask LLM with protein domain expertise. Our EPGF addresses the mismatch between statistic language modeling and biological constraints through three innovations: a multi-dimensional interpretable scorer, hierarchical efficient decoding, and a probabilistic-biophysical joint selection mechanism. Extensive experiments demonstrate that ProLLaMA excels in both unconditional and controllable protein generation tasks, achieving superior structural quality metrics compared to existing PLMs. Additionally, ProLLaMA demonstrates strong understanding capabilities with a 67.1% exact match rate in superfamily prediction. EPGF significantly enhances the biological viability of generated sequences, as evidenced by improved biophysical scores (+4.3%) and structural metrics (+14.5%).},
  archive      = {J_TAI},
  author       = {Liuzhenghao Lv and Zongying Lin and Hao Li and Yuyang Liu and Jiaxi Cui and Calvin Yu-Chian Chen and Li Yuan and Yonghong Tian},
  doi          = {10.1109/TAI.2025.3564914},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {ProLLaMA: A protein large language model for multi-task protein language processing},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantization-based 3D-CNNs through circular gradual unfreezing for DeepFake detection. <em>TAI</em>, 1-13. (<a href='https://doi.org/10.1109/TAI.2025.3564903'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the dynamic domain of synthetic media, deepfakes challenge the trust in digital communication. The identification of manipulated content is essential to ensure the authenticity of shared information. Recent advances in deepfake detection focused on developing sophisticated CNN-based approaches. However, these approaches remain anchored within the continuous feature space, potentially missing manipulative signatures that might be more salient in a discrete domain. For this task, we propose a new strategy which combines insights from both continuous and discrete spaces for enhanced deepfake detection. Our hypothesis is that deepfakes may lie closer to a discrete space, potentially revealing hidden patterns that are not evident in continuous representations. In addition, we propose a new gradual-unfreezing technique, employed into the proposed framework in order to slowly adapt the network parameters to align with the new combined representation. Via comprehensive experimentation, it is highlighted the efficiency of the proposed approach, in comparison to state-of-the-art deepfake detection strategies.},
  archive      = {J_TAI},
  author       = {Emmanuel Pintelas and Ioannis E. Livieris and Panagiotis Pintelas},
  doi          = {10.1109/TAI.2025.3564903},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Quantization-based 3D-CNNs through circular gradual unfreezing for DeepFake detection},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sub-network knowledge injection and transferable parameter updating strategy for continual learning of vision-and-language tasks. <em>TAI</em>, 1-11. (<a href='https://doi.org/10.1109/TAI.2025.3564915'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The external environment of the real world is often filled with various types of multimodal information that are highly dynamic and unpredictable. Therefore, intelligent systems need to continuously learn and retain knowledge. Continual learning (CL) provides a foundation for vision-and-language (VaL) models to adapt to the changes in the real world. Existing research on CL for VaL models mainly focus on preserving memory stability to overcome catastrophic forgetting. However, it is difficult for existing methods to flexibly adapt to the dynamic growth of external information. In this paper, we propose a generic approach that appropriately attenuates and employs old memories in parameter distributions to improve learning plasticity. We propose a new parameter-sharing CL method that combines adaptive parameter update strategies with network pruning to enhance the plasticity of VaL models during the continual learning process. When learning a new task, we utilize the pruned model for learning new tasks. And then we employ the sub-network parameter initialization updating strategy to transfer the most similar important knowledge from learned tasks. Subsequently, to strength the stability of the model, we further update the model parameters, adjusting old memories to better adapt to new task learning. Experiments on a series of VaL tasks have shown that our proposed method outperforms the compared methods in improving model plasticity, and is more stable than existing parameter sharing methods.},
  archive      = {J_TAI},
  author       = {Jiong Wang and Qing Zhang and Jie Liu and Kaifeng Nie and Ze Zhang and Linqi Song and Yinqiao Li},
  doi          = {10.1109/TAI.2025.3564915},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Sub-network knowledge injection and transferable parameter updating strategy for continual learning of vision-and-language tasks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-tropical cyclone trajectory prediction method based on density maps with memory and data fusion. <em>TAI</em>, 1-13. (<a href='https://doi.org/10.1109/TAI.2025.3564911'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tropical cyclones (TCs) are destructive weather systems, and the accurate prediction of the trajectory of TCs is crucial. Previous studies have focused mainly on trajectory prediction for individual TCs, which can not take into account the interaction between different TCs, affecting the prediction performance. To address this problem, this study proposed an innovative method for multi-TC trajectory prediction based on a density map. Instead of predicting the location of a TC directly, the paper first predicts the density map of a sea area, and then obtain TC centers from the predicted density maps. In the first step, a relation extraction module is proposed in order to analyze the interaction between multiple TCs. Further, a three-dimensional cloud feature extraction module was designed to enhance the ability to use three-dimensional cloud structural information on TCs via feature extraction and the fusion of density maps, satellite images, and environmental data. In addition, a long short-term memory fusion module was designed to adaptively select important historical information, which improves the ability to extract long-term spatio-temporal dependencies. In the second step, those density map pixels with extreme values are identified as TC centers. The proposed method was verified by experiments using Gridsat, IBTrACS, and ERA5 datasets. The results show that the mean distance error of TC trajectory prediction is reduced by 10.0%, 10.7%, 10.5%, and 11.7% for overall performance, and 21.5%, 18.0%, 19.1% and 19.8% for multi-TC scenario in the six-, 12-,18-, and 24-hour predictions compared with state-of-the-art prediction models.},
  archive      = {J_TAI},
  author       = {Dongfang Ma and Zhaoyang Ma and Chengying Wu and Jianmin Lin},
  doi          = {10.1109/TAI.2025.3564911},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {A multi-tropical cyclone trajectory prediction method based on density maps with memory and data fusion},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing facial expression recognition with AI agents: A semi-supervised guided adaptive β-VAE coupled with interval type-2 fuzzy classifier. <em>TAI</em>, 1-16. (<a href='https://doi.org/10.1109/TAI.2025.3565225'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial Expression Recognition (FER) is a complex task, hindered by subtle distinctions between expression classes, significant variability within each class, and external influences like identity, pose, age, and ethnicity. As a result, achieving pure expression encodings that are resilient to exogenous factors proves elusive, thereby compromising the downstream classification tasks. This study presents a novel intelligent facial expression recognition scheme that mitigates the impact of external confounders by integrating disentangled representation learning with fuzzy logic. Building on Adaptive β-VAE [1] as a backbone, we develop a semi-supervised Guided Adaptive β Variational Autoencoder (GA-β-VAE) capable of isolating expression features from exogenous factors. Specifically, the adaptive β-VAE is augmented with two additional branches: a deformable PCA-based secondary decoder that disentangles expression-irrelevant transformations from the core expression content, and an adversarial excitation–inhibition branch that forces the “target” (expression) latent variables to be informative only of expressions. This yields well-separated, expression-centric embeddings that are subsequently processed by an Interval Type-2 (IT2) fuzzy classification unit to predict the corresponding expression classes. By avoiding reliance on paired data or explicit annotations, this approach offers a scalable and flexible solution for FER. Experimental evaluations on benchmark datasets (CK+, FER+, and RAF-DB) demonstrate the framework’s effectiveness in addressing the challenges posed by exogenous factors, achieving superior accuracy and interpretability compared to state-of-the-art methods.},
  archive      = {J_TAI},
  author       = {Mohd Aquib and Nishchal K. Verma and M. Jaleel Akhtar},
  doi          = {10.1109/TAI.2025.3565225},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Enhancing facial expression recognition with AI agents: A semi-supervised guided adaptive β-VAE coupled with interval type-2 fuzzy classifier},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EncryptFlow: Efficient and lossless image encryption network based on normalizing flows. <em>TAI</em>, 1-14. (<a href='https://doi.org/10.1109/TAI.2025.3565483'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared to cryptographic image encryption schemes, neural networks (NN) based image encryption schemes exhibit a significantly larger key space and offer enhanced capabilities for parallel processing of image data. However, most existing NN-based image encryption schemes suffer from high time complexity in generating random keys, and their decryption processes often fail to fully recover the plaintext images without loss. In this paper, we first propose a normalizing flows based encryption network, called EncryptFlow, designed to achieve efficient and lossless image encryption. Normalizing flows employ a special coupling structure to couple the partitioned data, thereby establishing interdependence among them. Specifically, we utilize coupling structures (e.g. additive coupling) that allows the image blocks to alternately encrypt each other during forward propagation. Additionally, we devise a key generation algorithm that produces sub-keys tailored for each layer of the encryption network. The proposed EncryptFlow network seamlessly integrates both encryption and decryption functionalities, leveraging the XOR operation as the encryption function within each layer. The experimental results and comparative analyses indicate that EncryptFlow can encrypt 256 × 256 grayscale images with an average time of merely 0.047s, and similarly, it requires only 0.188s to encrypt color images of the same dimensions.},
  archive      = {J_TAI},
  author       = {Menglin Yang and Dong Xie and Guiting Zhang and Fulong Chen and Taochun Wang and Peng Hu},
  doi          = {10.1109/TAI.2025.3565483},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {EncryptFlow: Efficient and lossless image encryption network based on normalizing flows},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CoT-drive: Efficient motion forecasting for autonomous driving with LLMs and chain-of-thought prompting. <em>TAI</em>, 1-15. (<a href='https://doi.org/10.1109/TAI.2025.3564594'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate motion forecasting is crucial for safe autonomous driving (AD). This study proposes CoT-Drive, a novel approach that enhances motion forecasting by leveraging large language models (LLMs) and a chain-of-thought (CoT) prompting method. We introduce a teacher-student knowledge distillation strategy to effectively transfer LLMs’ advanced scene understanding capabilities to lightweight language models (LMs), ensuring that CoT-Drive operates in real-time on edge devices while maintaining comprehensive scene understanding and generalization capabilities. By leveraging CoT prompting techniques for LLMs without additional training, CoT-Drive generates semantic annotations that significantly improve the understanding of complex traffic environments, thereby boosting the accuracy and robustness of predictions. Additionally, we present two new scene description datasets, Highway-Text and Urban-Text, designed for fine-tuning lightweight LMs to generate context-specific semantic annotations. Comprehensive evaluations of five real-world datasets demonstrate that CoT-Drive outperforms existing models, highlighting its effectiveness and efficiency in handling complex traffic scenarios. Overall, this study is the first to consider the practical application of LLMs in this field. It pioneers the training and use of a lightweight LLM surrogate for motion forecasting, setting a new benchmark and showcasing the potential of integrating LLMs into AD systems.},
  archive      = {J_TAI},
  author       = {Haicheng Liao and Hanlin Kong and Bonan Wang and Chengyue Wang and Wang Ye and Zhengbing He and Chengzhong Xu and Zhenning Li},
  doi          = {10.1109/TAI.2025.3564594},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {CoT-drive: Efficient motion forecasting for autonomous driving with LLMs and chain-of-thought prompting},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DrugMAP: Deep multimodal transformers for drug-target mechanism of action prediction. <em>TAI</em>, 1-14. (<a href='https://doi.org/10.1109/TAI.2025.3565671'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of new drugs is an expensive and time-consuming process, often hindered by the lack of reliable models to predict drug-target interactions (DTIs) and their mechanisms of action (MoA). Existing deep learning-based methods for DTI prediction typically focus only on binary classification of interactions, overlooking the complex mechanisms underlying these interactions. Moreover, the absence of comprehensive datasets for modeling MoA further complicates this task. To address these limitations, we introduce DrugMAP, a novel multimodal deep learning model that integrates graph neural networks and transformer-based architectures to predict both DTIs and their MoA. We construct a large-scale dataset from multiple public sources, adding a new level of complexity by including detailed MoA annotations for thousands of drug-target pairs. DrugMAP simultaneously leverages the molecular and atomic-level structures of drugs and target proteins, utilizing multi-representational encoders for enhanced feature extraction. Experimental results show that DrugMAP outperforms state-of-the-art models for both DTI and MoA prediction across multiple benchmark datasets. Our model achieves a 3.5% improvement in AUC for MoA prediction, demonstrating its potential for guiding drug discovery and understanding adverse drug events. The model and dataset are available at https://github.com/JUCompBio/DTI-MOA},
  archive      = {J_TAI},
  author       = {Rangan Das and Swadesh Jana and Anannyo Dey and Pascal Le Corre and Marc Cuggia and Ujjwal Maulik and Sanghamitra Bandopadhyay},
  doi          = {10.1109/TAI.2025.3565671},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {4},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {DrugMAP: Deep multimodal transformers for drug-target mechanism of action prediction},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EMPOWER-KARE: Deep prompt learning for knowledge-aware response generation in clinical counseling and legal support conversations. <em>TAI</em>, 1-10. (<a href='https://doi.org/10.1109/TAI.2025.3548628'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate the effect of external domain knowledge while generating responses in clinical counseling and legal support conversations for crime victims. To facilitate this task, we propose EMPOWER, a novel dual-tier dEep proMPt learning framework for knOWledge-aware rEsponse geneRation task. EMPOWER first learns the knowledge-attributed deep prompt to generate the relevant knowledge grounded on conversational context and, in the next step, it learns response-attributed deep prompt grounded on conversational context and the learned knowledge-attributed deep prompt to guide the knowledge-aware response generation. To develop EMPOWER, we introduce KARE, a novel dataset consisting of 5,000 Knowledge-grounded clinicAl counseling and legal suppoRt convErsations, specifically focused on crime victims. Experiments demonstrate that our proposed method significantly outperforms the state-of-the-art baseline approaches, achieving improvements of 11.50% in BLEU-4, 28.5% in Knowledge-F1, and 11.6% in BERTScore on the proposed dataset. Further analysis also shows the promising abilities of EMPOWER for knowledge-aware response generation task in clinical counseling and legal support conversations.},
  archive      = {J_TAI},
  author       = {Priyanshu Priya and Armita Mani Tripathi and Deeksha Varshney and Mauajama Firdaus and Asif Ekbal},
  doi          = {10.1109/TAI.2025.3548628},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {EMPOWER-KARE: Deep prompt learning for knowledge-aware response generation in clinical counseling and legal support conversations},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). C2RS: Multimodal knowledge graph completion with cross-modal consistency and relation semantics. <em>TAI</em>, 1-13. (<a href='https://doi.org/10.1109/TAI.2025.3548621'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal knowledge graph completion (MKGC) is a popular research topic in recent years. However, existing methods rarely consider the alignment of different entity modalities in the process of multimodal fusion, and often lack sufficient attention to the semantic information conveyed by relations, thus resulting in unsatisfactory completion performance. To address these two issues, we propose a new multimodal knowledge graph completion model called C2RS. This model first designs a cross-modal consistency contrastive learning task to align different entity modalities for accurate entity representation. Then, C2RS develops a relation semantic encoding module based on the distributions of knowledge graph triples to extract the semantic information of relations for comprehensive relation representation. Finally, we encode the candidate triples with a triple encoder, and identify the correct entities through a scoring function to complete the multimodal knowledge graph. According to the extensive experiments on three public MKGC datasets, C2RS obviously outperforms the baseline methods. The code of C2RS is available at https://github.com/ADMIS-TONGJI/C2RS.},
  archive      = {J_TAI},
  author       = {Yulou Shu and Wengen Li and Jiaqi Wang and Yichao Zhang and Jihong Guan and Shuigeng Zhou},
  doi          = {10.1109/TAI.2025.3548621},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {C2RS: Multimodal knowledge graph completion with cross-modal consistency and relation semantics},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive hierarchical graph cut for multi-granularity out-of-distribution detection. <em>TAI</em>, 1-10. (<a href='https://doi.org/10.1109/TAI.2025.3550473'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on a significant yet challenging task: out-of-distribution detection (OOD detection), which aims to distinguish and reject test samples with semantic shifts, so as to prevent models trained on in-distribution (ID) data from producing unreliable predictions. Although previous works have had decent success, they are ineffective for real-world challenging applications since these methods regard all unlabeled data as OOD data and ignore the case that different datasets have different label granularity. For example, “cat” on CIFAR-10 and “tabby cat” on Tiny-ImageNet share the same semantics but have different labels due to various label granularity. To this end, in this paper, we propose a novel Adaptive Hierarchical Graph Cut network (AHGC) to deeply explore the semantic relationship between different images. Specifically, we construct a hierarchical KNN graph to evaluate the similarities between different images based on the cosine similarity. Based on the linkage and density information of the graph, we cut the graph into multiple subgraphs to integrate these semantics-similar samples. If the labeled percentage in a subgraph is larger than a threshold, we will assign the label with the highest percentage to unlabeled images. To further improve the model generalization, we augment each image into two augmentation versions, and maximize the similarity between the two versions. Finally, we leverage the similarity score for OOD detection. Extensive experiments on two challenging benchmarks (CIFAR-10 and CIFAR-100) illustrate that in representative cases, AHGC outperforms state-of-the-art OOD detection methods by 81.24% on CIFAR-100 and by 40.47% on CIFAR-10 in terms of “FPR95”.},
  archive      = {J_TAI},
  author       = {Xiang Fang and Arvind Easwaran and Blaise Genest and Ponnuthurai Nagaratnam Suganthan},
  doi          = {10.1109/TAI.2025.3550473},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Adaptive hierarchical graph cut for multi-granularity out-of-distribution detection},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lorentz-equivariant quantum graph neural network for high-energy physics. <em>TAI</em>, 1-11. (<a href='https://doi.org/10.1109/TAI.2025.3554461'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid data surge from the high-luminosity Large Hadron Collider introduces critical computational challenges requiring novel approaches for efficient data processing in particle physics. Quantum machine learning, with its capability to leverage the extensive Hilbert space of quantum hardware, offers a promising solution. However, current quantum graph neural networks (GNNs) lack robustness to noise and are often constrained by fixed symmetry groups, limiting adaptability in complex particle interaction modeling. This paper demonstrates that replacing the classical Lorentz Group Equivariant Block modules in LorentzNet with a dressed quantum circuit significantly enhances performance despite using ≈5.5 times fewer parameters. Additionally, quantum circuits effectively replace MLPs by inherently preserving symmetries, with Lorentz symmetry integration ensuring robust handling of relativistic invariance. Our Lorentz-Equivariant Quantum Graph Neural Network (Lorentz-EQGNN) achieved 74.00% test accuracy and an AUC of 87.38% on the Quark-Gluon jet tagging dataset, outperforming the classical and quantum GNNs with a reduced architecture using only 4 qubits. On the Electron-Photon dataset, Lorentz-EQGNN reached 67.00% test accuracy and an AUC of 68.20%, demonstrating competitive results with just 800 training samples. Evaluation of our model on generic MNIST and FashionMNIST datasets confirmed Lorentz-EQGNN’s efficiency, achieving 88.10% and 74.80% test accuracy, respectively. Ablation studies validated the impact of quantum components on performance, with notable improvements in background rejection rates over classical counterparts. These results highlight Lorentz-EQGNN’s potential for immediate applications in noise-resilient jet tagging, event classification, and broader data-scarce HEP tasks.},
  archive      = {J_TAI},
  author       = {Md Abrar Jahin and Md. Akmol Masud and Md Wahiduzzaman Suva and M. F. Mridha and Nilanjan Dey},
  doi          = {10.1109/TAI.2025.3554461},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Lorentz-equivariant quantum graph neural network for high-energy physics},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CWPFormer: Towards high-performance visual place recognition for robot with cross-weight attention learning. <em>TAI</em>, 1-10. (<a href='https://doi.org/10.1109/TAI.2025.3538818'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an important component of robot localization and navigation, visual place recognition (VPR) has made significant improvements in the past few decades. Most existing state-of-the-art VPR methods face the following challenges: 1) Aiming only for performance with ideal conditions while overlooking real-world conditions; 2) The existing VPR paradigm, struggling to reconcile the transfer gap between upstream pre-training and downstream fine-tuning; 3) Deeper networks produce high-dimensional parameters in the model training that results in lower efficient of models. To address those problems, we propose a high-performance visual place recognition framework for robot navigation tasks. Concretely, our framework is composed of three major modules: 1) based on vision transformer (ViT), we design a siamese Cross-weight Pyramid Transformer (CWPFormer) backbone for image feature extraction. First, we integrate feature reconstruction and content cognition by inserting a feature pyramid phase into pre-training. Second, we establish weight correlation and sharing between feature downsampling and upsampling that offers multi-stage supervision to fine-tuning. 2) We found that the attention map has high similarity between heads, and the high-dimensional data processing based on the ViT leads to computational redundancy. To cope with this problem, we present a cascaded hash attention (CHA) module to feed the hash attention head with different complete feature splits, which not only saves the computational cost but also improves the attention diversity. 3) Besides, we adopt a Bayesian learning scheme with a dynamically constructed similarity matrix to learn one-dimensional compact hash codes to improve recognition accuracy. Exhaustive experiments demonstrate the superiority of our proposed VPR approach on datasets and real-world environments. Our code is available: https://github.com/CV4RA/CWPFormer.},
  archive      = {J_TAI},
  author       = {Zhenyu Li and Pengjie Xu and Tianyi Shang},
  doi          = {10.1109/TAI.2025.3538818},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {2},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {CWPFormer: Towards high-performance visual place recognition for robot with cross-weight attention learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploiting gaussian noise variance for dynamic differential poisoning in federated learning. <em>TAI</em>, 1-17. (<a href='https://doi.org/10.1109/TAI.2025.3540030'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emerging field of Federated Learning (FL) is reshaping privacy-preserved data analysis and decision support mechanisms within several critical infrastructure (CIs) sectors such as autonomous transportation, energy, and healthcare. To shield sensitive operational and client data from privacy attackers, Differential Privacy (DP) has been proposed to integrate on top of the FL process. Yet, we identify that integrating Gaussian noise for achieving DP guarantee can inadvertently create a new vector for differential model poisoning attacks in FL. Moreover, exploiting the variance in Gaussian noise enables attackers to camouflage their activities within the legitimate noise of the system, a significant yet largely overlooked security flaw in the differentially private federated learning (DPFL) framework. Addressing this research gap, we introduce a novel adaptive model poisoning through episodic loss memorization (α-MPELM) technique. This method enables attackers to dynamically inject adversarial noise into the differentially private local model parameters. The technique has a dual purpose: hindering the optimal convergence of the global FL model and simultaneously avoiding detection by the anomaly detectors. Our evaluation of the α-MPELM attack reveals its capability to deceive Norm, Accuracy, and Mix anomaly detection algorithms, surpassing the conventional random malicious device (RMD) attacks with attack accuracy improvements of 6.8%, 12.6%, and 13.8%, respectively. Additionally, we introduce a reinforcement learning-based DP level selection strategy, rDP, as an effective countermeasure against α-MPELM attack. Our empirical findings confirm that this defense mechanism steadily progresses to an optimal policy.},
  archive      = {J_TAI},
  author       = {Md Tamjid Hossain and Shahriar Badsha and Hung La and Shafkat Islam and Ibrahim Khalil},
  doi          = {10.1109/TAI.2025.3540030},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {2},
  pages        = {1-17},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Exploiting gaussian noise variance for dynamic differential poisoning in federated learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). KnowZRel: Common sense knowledge-based zero-shot relationship retrieval for generalised scene graph generation. <em>TAI</em>, 1-11. (<a href='https://doi.org/10.1109/TAI.2025.3544177'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A scene graph is a key image representation in visual reasoning. The generalisability of Scene Graph Generation (SGG) methods is crucial for reliable reasoning and real-world applicability. However, imbalanced training datasets limit this, underrepresenting meaningful visual relationships. Current SGG methods using external knowledge sources face limitations due to these imbalances or restricted relationship coverage, impacting their reasoning and generalisation capabilities. We propose a novel neurosymbolic approach that integrates data-driven object detection with heterogeneous knowledge graph-based object refinement and zero-shot relationship retrieval, highlighting the loosely coupled synergy between neural and symbolic components. This combination addresses the limitations of imbalanced training datasets in scene graph generation and enables effective prediction of unseen visual relationships. Objects are detected using a region-based deep neural network and refined based on their positional and structural similarity, followed by retrieval of pairwise visual relationships using a heterogeneous knowledge graph. The redundant and irrelevant visual relationships are discarded based on the similarity of relationship labels and node embeddings. Finally, the visual relationships are interlinked to generate the scene graph. The employed heterogeneous knowledge graph combines diverse knowledge sources, offering rich common sense knowledge about objects and their interactions in the world. Our method, evaluated using the benchmark Visual Genome dataset and zero-shot recall (zR@K) metric, shows a 59.96% improvement over existing state-of-the-art methods, highlighting its effectiveness in generalised SGG. The object refinement step effectively improved the object detection performance by 57.1%. Additional evaluation using the GQA dataset confirms the cross-dataset generalisability of our method. We also compared various knowledge sources and embedding models to determine an optimal combination for zero-shot SGG. The source code is available at https://github.com/jaleedkhan/zsrr-sgg.},
  archive      = {J_TAI},
  author       = {M. Jaleed Khan and John G. Breslin and Edward Curry},
  doi          = {10.1109/TAI.2025.3544177},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {2},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {KnowZRel: Common sense knowledge-based zero-shot relationship retrieval for generalised scene graph generation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning models for realistic multicomponent signal modulation classification. <em>TAI</em>, 1-10. (<a href='https://doi.org/10.1109/TAI.2025.3546190'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we study the application of three recent computer vision architectures to the classification of the modulation type of single- and dual-component signals, making emphasis on their usage in a realistic context by simultaneously considering a wide variety of modulations while varying the number of components. In order to do so, we first generate synthetic signal reception data of 15 modulation types, used for training and testing small variants of these models, chosen such that throughput is maximized and latency minimized, since we consider the context of a time-sensitive application. Given enough training compute, and in the single-component case, all convolutional models obtain an accuracy of 95% or more when signal-to-noise ratio (SNR) is at least 0 dB, and one variant obtains 90% accuracy at -3 dB. In the dual-component case, convolutional models manage upwards of 95% when SNR is at least 12 dB, and more than 90% when SNR is at least 6 dB. Finally, we also measure their throughput and latency as a function of batch size (important parameters for applications such as radar and communication systems), with a convolutional model variant yielding the highest throughput at 14432 samples per second. Based on the obtained results, our work paves the way towards the classification of modern complex modulation schemes and provides selection rules for the most appropriate algorithm depending on the performance feature to be optimized (such as throughput and size).},
  archive      = {J_TAI},
  author       = {Agustín M. Galante-Cerviño and Alberto Martínez-Fernández and Adrián Colomer and Valery Naranjo and Carlos García-Meca},
  doi          = {10.1109/TAI.2025.3546190},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {2},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Deep learning models for realistic multicomponent signal modulation classification},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Response generation honeypot with anti-detection capabilities for IoT botnet lifecycle detection. <em>TAI</em>, 1-15. (<a href='https://doi.org/10.1109/TAI.2024.3509812'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread use of edge computing, the security issues on the edge side of IoT within the cloud-edge-device architecture are becoming increasingly severe, particularly with the growing threat posed by botnets. Existing research on IoT botnet detection primarily focuses on identifying infected devices, with significantly less emphasis on detecting the botnet scanning and propagation phases. Recognizing the importance of early detection to protect devices and networks, this paper introduces RGPot-a novel honeypot based on a generative response model designed to detect the lifecycle of IoT botnets. RGPot consists of two core components: an interaction response module and a lifecycle detection module. In the Interaction Response Module, Generative Adversarial Networks (GANs) are employed to train models capable of generating responses to various types of request data. This enables RGPot to effectively simulate real IoT devices and provide tailored responses to deceive potential attackers. In the Lifecycle Detection Module, a multi-layer Long Short-Term Memory (LSTM) network is utilized to comprehensively detect the stages of an IoT botnet’s lifecycle, facilitating the precise identification of the stage at which the detected traffic data is located. To evaluate the efficacy of RGPot, we created a controlled experimental environment to assess its ability to capture IoT botnets and detect traffic data. The experimental results validate RGPot’s capability in botnet capture and anti-detection, with an accuracy of 98.81% in detecting botnet lifecycles and a reduction in false positives of approximately 5%.},
  archive      = {J_TAI},
  author       = {Hao Tang and Hui He and Yuming Feng and Junxiong Meng and Weizhe Zhang},
  doi          = {10.1109/TAI.2024.3509812},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {12},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Response generation honeypot with anti-detection capabilities for IoT botnet lifecycle detection},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AI-based framework for discriminating human-authored and AI-generated text. <em>TAI</em>, 1-15. (<a href='https://doi.org/10.1109/TAI.2024.3516713'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning techniques are increasingly adept at distinguishing between human-written and AI-generated text. This study presents a deep learning-based text classification system to discern the source of text—whether it’s generated by AI or authored by a human. We compiled a comprehensive and diverse dataset incorporating existing datasets, real-time tweets, and synthetic data generated by cutting-edge AI models such as Google Bard and OpenAI’s ChatGPT. Seven deep learning techniques including Convolutional Neural Networks (CNN), Artificial Neural Networks (ANN), Recurrent Neural Networks (RNN), Long Short-Term Memory networks (LSTM), Gated Recurrent Unit (GRU), Bidirectional LSTM (BiLSTM), and Bidirectional RNN (BiRNN) and four text embedding techniques namely One-hot, Word2Vec, TF-IDF, and BERT, are employed to perform 28 experiments (4*7). Our findings exhibit outstanding performance across all models. BERT-based models notably outshine the others, with BERT-CNN achieving the highest accuracy of 98.87%, an MCC of 0.9742, and an F1 measure of 0.9916. Following closely, Bert-BiLSTM attained an accuracy, MCC, and F1 score of 98.77%, 0.9720, and 0.9909, respectively. This paper demonstrates the effectiveness of deep learning approaches in distinguishing between human and AI-generated text, with potential applications in automated content moderation, detection of AI-generated spam, and safeguarding the authenticity of user-generated content.},
  archive      = {J_TAI},
  author       = {Mudasir Ahmad Wani and Ahmed A. Abd El-Latif and Mohammad ELAffendi and Amir Hussain},
  doi          = {10.1109/TAI.2024.3516713},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {12},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {AI-based framework for discriminating human-authored and AI-generated text},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cooperative game-based intelligent actions making for constrained multi-agent system. <em>TAI</em>, 1-10. (<a href='https://doi.org/10.1109/TAI.2024.3522866'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an intelligent action-making model for constrained multi-agent systems (MAS) with cooperative games is proposed. This model aims to prevent system breakdowns triggered by the large number of agents, a prevalent dilemma in MAS across various practical situations. A widely accepted issue in the domain is that reinforcement learning methods require vast amounts of training data, which can be costly and time-intensive to acquire. Notably, existing game theory methods present challenges, including incomplete information about the agents’ current strategies and the reliance on computationally intensive solutions to determine equilibrium points. To address these concerns, several novel contributions are offered in this paper. First, a new intelligent action-making model designed for large-scale MAS is introduced, ensuring effectiveness and efficiency. Second, system robustness and adaptability in intricate scenarios, especially under saturation constraints, are enhanced through the incorporation of forward prediction for more precise action-making. Additionally, a method to generate a hybrid task coalition, accounting for limited execution capabilities, is devised considering multitask constraints. This strategy aims to mitigate the lag in coalition formation due to the expansive dimensionality of action spaces in conventional methods. Simulations conducted with nine agents attest to the efficiency of the proposed model.},
  archive      = {J_TAI},
  author       = {Dengxiu Yu and Jiahui Zhai and Xiaoyue Jin and Li Liu and Zhen Wang},
  doi          = {10.1109/TAI.2024.3522866},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {12},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Cooperative game-based intelligent actions making for constrained multi-agent system},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Expanding horizons of level diversity via multi-objective evolutionary learning. <em>TAI</em>, 1-12. (<a href='https://doi.org/10.1109/TAI.2024.3489534'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the generation of diverse game levels has gained increasing interest, contributing to a richer and more engaging gaming experience. A number of level diversity metrics have been proposed in literature, which are naturally multi-dimensional, leading to conflicted, complementary, or both relationships among these dimensions. However, existing level generation approaches often fail to comprehensively assess diversity across those dimensions. This paper aims to expand horizons of level diversity by considering multi-dimensional diversity when training generative models. We formulate the model training as a multi-objective learning problem, where each diversity metric is treated as a distinct objective. Furthermore, a multi-objective evolutionary learning framework that optimises multiple diversity metrics simultaneously throughout the model training process is proposed. Our case study on the commonly used benchmark Super Mario Bros . demonstrates that our proposed framework can enhance multi-dimensional diversity and identify a Pareto front of generative models, which provides a range of tradeoffs among playability and two representative diversity metrics, including a content-based one and a player-centered one. Such capability enables decision-makers to make informed choices when selecting generators accommodating a variety of scenarios and the diverse needs of players and designers.},
  archive      = {J_TAI},
  author       = {Qingquan Zhang and Ziqi Wang and Yuchen Li and Keyuan Zhang and Bo Yuan and Jialin Liu},
  doi          = {10.1109/TAI.2024.3489534},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {11},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Expanding horizons of level diversity via multi-objective evolutionary learning},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Identifying unique spatial-temporal bayesian network without markov equivalence. <em>TAI</em>, 1-10. (<a href='https://doi.org/10.1109/TAI.2024.3483188'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying vanilla Bayesian network to model spatial-temporal causality can be a critical yet challenging task. Different Markovian-equivalent directed acyclic graphs would be identified if the identifiability is not satisfied. To address this issue, Directed Cyclic Graph [1] is proposed to drop the directed acyclic constraint. But it does not always hold, and cannot model dynamical time-series process. Then, Full Time Graph [2] is proposed with introducing high-order time delay. Full Time Graph has no Markov equivalence class by assuming no instantaneous effects. But, it also assumes that the causality is invariant with varying time, that is not always satisfied in the spatio-temporal scenarios. Thus, in this work, a Spatial-Temporal Bayesian Network (STBN) is proposed to theoretically model the spatial-temporal causality from the perspective of information transfer. STBN explains the disappearance of network structure X → Z → Y and X ← Z ← Y by the principle of information path blocking. And finally, the uniqueness of STBN is proved. Based on this, a High-order Causal Entropy (HCE) algorithm is also proposed to uniquely identify STBN under time complexity O(n 3 τ max ), where n is the number of variables and τ max is the maximum time delay. Numerical experiments are conducted with comparison to other baseline algorithms. The results show that HCE algorithm obtains state-of-the-art identification accuracy. The code is available at Supplemental Material, and one may check and run it to reproduce the results.},
  archive      = {J_TAI},
  author       = {Mingyu Kang and Duxin Chen and Ning Meng and Gang Yan and Wenwu Yu},
  doi          = {10.1109/TAI.2024.3483188},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {10},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Identifying unique spatial-temporal bayesian network without markov equivalence},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). From routine to reflection: Pruning neural networks in communication-efficient federated learning. <em>TAI</em>, 1-10. (<a href='https://doi.org/10.1109/TAI.2024.3462300'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Communication-efficient federated learning benefits from neural network pruning, as it speeds up training and reduces model size. However, existing pruning techniques may not be optimally suited for joint model training in federated learning, particularly regarding the choice of pruning sites and the sequence of pruning operations. In this work, we explore server-side pruning using a similarity-based approach, contrasting it with methods that prune on either the clients or the server. Our method uses global model parameters to calculate the difference between global and local models, guiding the pruning process. We also examine how the order of pruning affects performance. Experimental results show that our method maintains model performance in non-IID settings while reducing communication overhead by 50%-70%. To simulate a realistic FL setup, we run server-side pruning on a CPU, increasing CPU involvement, distributing client workloads, and reducing energy consumption.},
  archive      = {J_TAI},
  author       = {Jiaming Pei and Wei Li and Shahid Mumtaz},
  doi          = {10.1109/TAI.2024.3462300},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {From routine to reflection: Pruning neural networks in communication-efficient federated learning},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An optimized neural network for efficient resource utilization and enhanced accuracy in magnetic field prediction. <em>TAI</em>, 1-11. (<a href='https://doi.org/10.1109/TAI.2024.3462301'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The article presents a deep learning approach which enables numerical calculation of magnetic fields in various electromagnetic devices. In comparison to the finite element analysis (FEA) method, the trained model demonstrates a significantly faster computation speed. The accuracy of representing information within the solution domain is enhanced through the use of a bitmap technique. A shifted window-based self-attention (SW-MSA) mechanism is employed to analyze device information within the solution domain. Considering the non-negativity property of magnetic flux density, the Softplus activation function is incorporated into the neural network model, resulting in the proposed Softplus-Enhanced Swin-Unet (SESU). Moreover, magnetic field prediction is conducted for three types of electromagnetic devices: coils, transformers, and motors. Compared to commonly used Convolutional Neural Network (CNN) and Vision Transformer (ViT) models, this approach achieves a minimum of 10-fold improvement in prediction accuracy while reducing computational resource consumption by 35%. The proposed method is validated through FEA and comparative experiments.},
  archive      = {J_TAI},
  author       = {Xinsheng Yang and Zining Wang and Lingyue Wang and Rentian Zhang and Guizhi Xu and Qingxin Yang},
  doi          = {10.1109/TAI.2024.3462301},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {9},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {An optimized neural network for efficient resource utilization and enhanced accuracy in magnetic field prediction},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Defending learning systems against mean-shift perturbations. <em>TAI</em>, 1-13. (<a href='https://doi.org/10.1109/TAI.2024.3422929'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evasion attacks on cyber-enabled machine learning (ML) models have recently gained significant traction for their ability to swiftly compel ML models to deviate from their original decisions without substantially affecting model accuracy during the testing phase. In this article, we initially present a meticulously formulated theoretical framework for a novel and potent evasion attack, leveraging mean-shift perturbation. This attack demonstrates remarkable efficiency in deceiving a wide array of ML models. Subsequently, the urgency of fortifying against such evasion attacks is underscored. It’s worth noting that existing defenses are predominantly model-driven, and their efficacy diminishes when concurrently deployed as a universal defense against both poisoning and evasion attacks. Moreover, empirical evidence from various studies suggests that a single defense mechanism falls short in safeguarding learning models against the myriad forms of adversarial attacks. To alleviate these challenges, we introduced Adaptive Ensemble of Filters (AEF), a defense framework characterized by its robust, transferable, model-agnostic, input distribution-independent, and cross-model-supportive nature. The AEF strategically selects filters to safeguard a target ML model from various well-known poisoning (e.g., Metapoison) and evasion (utilizing mean-shift perturbations, JSMA, FGSM, PGD, BIM, and C&amp;W) attacks, establishing itself as a universal defense against diverse adversarial attacks. Theoretical analysis assures the existence of optimal filter ensembles across different input distributions and adversarial attack landscapes, without encountering mode collapses and vanishing gradients. Our claims are substantiated through validation on three publicly available image datasets—MNIST, CIFAR-10, and EuroSAT.},
  archive      = {J_TAI},
  author       = {Arunava Roy and Dipankar Dasgupta},
  doi          = {10.1109/TAI.2024.3422929},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {7},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Defending learning systems against mean-shift perturbations},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LibriSQA: A novel dataset and framework for spoken question answering with large language models. <em>TAI</em>, 1-12. (<a href='https://doi.org/10.1109/TAI.2024.3427069'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While Large Language Models (LLMs) have demonstrated impressive performance across various domains and tasks, they still struggle with multimodal tasks, particularly the Spoken Question Answering (SQA) task, which requires precise alignment and deep interaction between speech and text. In this paper, we address the SQA challenge by curating a novel freeform and open-ended SQA dataset, LibriSQA, which is composed of 214k SQA pairs covering a wide range of topics. It consists of two parts. Part I is designed for natural conversational formats and Part II focuses on multiple-choice questions with answers and analytical segments. Considering the limited availability of speech-text LLMs, we propose a lightweight, end-to-end framework to perform the SQA task on the LibriSQA dataset, achieving significant results. By transforming Automatic Speech Recognition (ASR) into the SQA format, we further demonstrate the framework’s capability in handling ASR tasks. Our empirical findings support the idea that LLMs can effectively align and comprehend speech information, paving the way for the development of universal multimodal LLMs. Our LibriSQA dataset can be found at https://github.com/ZihanZhaoSJTU/LibriSQA.},
  archive      = {J_TAI},
  author       = {Zihan Zhao and Yiyang Jiang and Heyang Liu and Yu Wang and Yanfeng Wang},
  doi          = {10.1109/TAI.2024.3427069},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {7},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {LibriSQA: A novel dataset and framework for spoken question answering with large language models},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimizing neural network training: A markov chain approach for resource conservation. <em>TAI</em>, 1-14. (<a href='https://doi.org/10.1109/TAI.2024.3413688'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The additional resource consumption generated during the repeated training processes of neural networks, including time and computational power costs, is a problem of significant concern. We, therefore, propose a method that utilizes Markov Chain to predict the training outcomes of neural networks with the same structure. This method’s training is based on prior experience to optimize the parameter adjustment process, thereby reducing the number of times training must be started from scratch and lowering time costs. By predicting training outcomes and reducing forward and backward propagation computations, among other factors, computational resource consumption significantly decreases. Simultaneously, since Markov Chain represents a clear mathematical model, the properties of probability transition offer greater interpretability compared to traditional methods. In an era where explainable artificial intelligence is equally crucial, a more transparent training method could have greater application potential in many important scenarios. The dual benefits they provide exemplify the advantage of our approach. Regarding the critical part, we have theoretically and experimentally demonstrated that, under certain conditions, the neural network training process possesses Markov property and becomes a Markov process after clustering.},
  archive      = {J_TAI},
  author       = {Ke Wang and Xianting Huang and Cong Tan and Siu-Ming Yiu and Zicong Chen and Xiaolin Lei},
  doi          = {10.1109/TAI.2024.3413688},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {6},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Optimizing neural network training: A markov chain approach for resource conservation},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust real-time audio-visual speech enhancement based on DNN and GAN. <em>TAI</em>, 1-10. (<a href='https://doi.org/10.1109/TAI.2024.3366141'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The human auditory cortex contextually integrates audio-visual (AV) cues to better understand speech in a cocktail party situation. Recent studies have shown that AV speech enhancement (SE) models can significantly improve speech quality and intelligibility in low signal-to-noise ratios ( SNR &lt; −5dB ) environments compared to audio-only (A-only) SE models. However, despite substantial research in the area of AV SE, development of real-time processing models that can generalise across various types of visual and acoustic noises remains a formidable technical challenge. This paper introduces a novel framework for low-latency, speaker-independent AV SE. The proposed framework is designed to generalise to visual and acoustic noises encountered in real world settings. In particular, a generative adversarial network (GAN) is proposed to address the issue of visual speech noise including poor lighting in real noisy environments. In addition, a novel real-time AV SE based on a deep neural network is proposed. The model leverages the enhanced visual speech from the GAN to deliver robust SE. The effectiveness of the proposed framework is evaluated on synthetic AV datasets using objective speech quality and intelligibility metrics. Furthermore, subjective listening tests are conducted using real noisy AV corpora. The results demonstrate that the proposed real-time AV SE framework improves the mean opinion score by 20% as compared to state-of-the-art SE approaches including recent DNN based AV SE models.},
  archive      = {J_TAI},
  author       = {Mandar Gogate and Kia Dashtipour and Amir Hussain},
  doi          = {10.1109/TAI.2024.3366141},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {2},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Robust real-time audio-visual speech enhancement based on DNN and GAN},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel conditional wasserstein deep convolutional generative adversarial network. <em>TAI</em>, 1-13. (<a href='https://doi.org/10.1109/TAI.2023.3288851'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative Adversarial Networks (GAN) and their several variants have not only been used for adversarial purposes but also used for extending the learning coverage of different AI/ML models. Most of these variants are unconditional and do not have enough control over their outputs. Conditional GANs (CGANs) have the ability to control their outputs by conditioning their generator and discriminator with an auxiliary variable (such as class label s, and text description s). However, CGANs have several drawbacks such as unstable training , non-convergence and multiple mode collapse s like other unconditional basic GANs (where the discriminator s are classifier s). DCGANs, WGANs, and MMDGANs enforce significant improvements to stabilize the GAN training although have no control over their outputs. We developed a novel conditional Wasserstein GAN model, called CWGAN ( a.k.a RD-GAN named after the initials of the authors' surnames ) that stabilizes GAN training by replacing relatively unstable JS divergence with Wasserstein-1 distance while maintaining better control over its outputs. We have shown that the CWGAN can produce optimal generator s and discriminator s irrespective of the original and input noise data distributions. We presented a detailed formulation of CWGAN and highlighted its salient features along with proper justifications. We showed the CWGAN has a wide variety of adversarial applications including preparing fake images through a CWGAN-based deep generative hashing function and generating highly accurate user mouse trajectories for fooling any underlying mouse dynamics authentications (MDAs). We conducted detailed experiments using well-known benchmark datasets in support of our claims.},
  archive      = {J_TAI},
  author       = {Arunava Roy and Dipankar Dasgupta},
  doi          = {10.1109/TAI.2023.3288851},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {6},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {A novel conditional wasserstein deep convolutional generative adversarial network},
  year         = {2023},
}
</textarea>
</details></li>
</ul>

</body>
</html>
