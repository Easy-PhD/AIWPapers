<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TIFS</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tifs">TIFS - 49</h2>
<ul>
<li><details>
<summary>
(2025). Mind the faulty keccak: A practical fault injection attack scheme apply to all phases of ML-KEM and ML-DSA. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2025.3607242'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {ML-KEM and ML-DSA are NIST-standardized lattice-based post-quantum cryptographic algorithms. In both algorithms, KECCAK is the designated hash algorithm extensively used for deriving sensitive information, making it a valuable target for attackers. In the field of fault injection attacks, few works targeted KECCAK, and they have not fully explored its impact on the security of ML-KEM and ML-DSA. Consequently, many attacks remain undiscovered. In this article, we first identify various fault vulnerabilities of KECCAK that determine the (partial) output by manipulating the control flow under a practical loop-abort model. Then, we systematically analyze the impact of a faulty KECCAK output and propose six attacks against ML-KEM and five attacks against ML-DSA, including key recovery, signature forgery, and verification bypass. These attacks cover the key generation, encapsulation, decapsulation, signing, and verification phases, making our scheme the first to apply to all phases of ML-KEM and ML-DSA. The proposed attacks are validated on the C implementations of the PQClean library’s ML-KEM and ML-DSA running on embedded devices. Experiments show that the required loop-abort faults can be realized on ARM Cortex-M0+, M3, M4, and M33 microprocessors with low-cost electromagnetic fault injection settings, achieving a success rate of 89.5%. Once the fault injection is successful, all proposed attacks can succeed with a probability of 100%.},
  archive      = {J_TIFS},
  author       = {Yuxuan Wang and Jintong Yu and Shipei Qu and Xiaolin Zhang and Xiaowei Li and Chi Zhang and Dawu Gu},
  doi          = {10.1109/TIFS.2025.3607242},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {9},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Mind the faulty keccak: A practical fault injection attack scheme apply to all phases of ML-KEM and ML-DSA},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GraphBGP: BGP anomaly detection based on dynamic graph learning. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2025.3607239'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting anomalous BGP (Border Gateway Protocol) messages is critical for securing inter-domain routing systems over autonomous system (AS)-level networks. The dynamic nature of routing policies, massive scale of global routes, and incomplete global topology visibility make BGP anomalies exceptionally challenging to identify—let alone trace back to malicious or misconfigured ASes. To effectively overcome these barriers, this paper proposes GraphBGP, a novel BGP anomaly detection method that dynamically constructs real-time AS-level topologies, achieves precise anomaly detection and classification, and accurately traces malicious or misconfigured ASes. Specifically, to address the evolving nature of BGP routing status, GraphBGP constructs an attributed AS-level graph that dynamically integrates node and edge attributes. It intelligently tracks BGP updates to refresh this graph efficiently. Leveraging this enriched, up-to-date representation, GraphBGP employs tailored detection and tracing models grounded in graph convolutional networks (GCNs), enabling precise anomaly identification and source tracing. Comprehensive experiments with real-world and synthetic datasets demonstrate that GraphBGP achieves state-of-the-art anomaly detection accuracy while significantly reducing inference time, even under partial BGP network visibility. Furthermore, GraphBGP precisely traces malicious or misconfigured ASes within a short time period of 7 milliseconds after anomaly detection, enabling rapid mitigation.},
  archive      = {J_TIFS},
  author       = {Zheng Wu and Yanbiao Li and Xin Wang and Zulong Diao and Weibei Fan and Fu Xiao and Gaogang Xie},
  doi          = {10.1109/TIFS.2025.3607239},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {9},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {GraphBGP: BGP anomaly detection based on dynamic graph learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised domain adaptation person re-identification: Bridged by feature fusion transitional domain. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2025.3607258'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of unsupervised domain adaptation person re-identification (UDA Reid) is to achieve feature space alignment between the source domain and the target domain, so that the Reid model can effectively match pedestrians in the target domain. Creating the transitional domain is an effective approach, but existing models often have difficulty synthesizing transitional domains with sufficiently public features. To tackle this challenge, we propose an innovative approach named feature fusion transitional domain (F2TD-Reid), which comprises two essential components: the dictionary fusion module (DFM) and the transitional domain attention module (TDAM). Among them, the DFM utilizes a feature fusion to extract and reconstruct pedestrian images from instances, focusing on capturing the essential visual elements within the images. For the TDAM, it further refines the feature extraction of instance points through an innovative weighted attention mechanism. These two modules optimize the generation process of scaling factors, thereby facilitating the transfer of knowledge between the source domain and the target domain. Through a series of comparative experiments, we verify the superiority of the F2TD-Reid method in solving UDA Reid. The code is available at https://github.com/1x-x/F2TD-Reid.},
  archive      = {J_TIFS},
  author       = {Qing Tian and Xiang Liu and Jixin Sun and Jun Wan and Zhen Lei},
  doi          = {10.1109/TIFS.2025.3607258},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {9},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Unsupervised domain adaptation person re-identification: Bridged by feature fusion transitional domain},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing GCN robustness against structural attacks via adaptive spectrum filtering. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2025.3607260'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Convolutional Networks (GCNs) are currently the most widely used method for processing graph-structured data. However, recent research has revealed that the performance of GCNs dramatically decreases when confronted with adversarial attacks. This severely hinders their application in security-critical domains. Therefore, the development of GCNs that are resilient to adversarial attacks has emerged as a prominent research focus. Despite this, most current defense models with complex network architectures and optimization objectives are typically designed based on specific feature assumptions or attack manifestations, and do not enhance the inherent robustness of GCNs. They also overlook the changes induced by perturbations of varying intensities and the difference in attack phenomenon across different datasets. In response to this, we have delved into the impact of adversarial attacks on the spectrum, and propose an effective adaptive robust spectrum filter GCN (ASF-GCN). This approach enhances the robustness of GCN models through adaptive filtering without introducing additional conditional assumptions. We theoretically analyze that graphs have different robust frequency intervals under different conditions, validating the necessity of adaptive filtering. Additionally, we elucidate the role of degree distribution and maximum eigenvalue in adaptation. Extensive experiments on real-world graphs reveal that our model surpasses other defense models in overall performance.},
  archive      = {J_TIFS},
  author       = {Jin Fan and Zheyu Wang and Zehao Wang and Jiajun Yang and Huifeng Wu and Jia Wu},
  doi          = {10.1109/TIFS.2025.3607260},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {9},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Enhancing GCN robustness against structural attacks via adaptive spectrum filtering},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ADDR: Anomaly detection and distortion restoration for 3D adversarial point cloud. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2025.3607243'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing adoption of 3D point cloud in applications like autonomous driving has heightened concerns about their vulnerability to adversarial attacks. Existing defense methods face two fundamental challenges: ineffective detection of imperceptible adversarial examples and poor restoration of severely distorted point cloud. In this paper, we present ADDR, an end-to-end defense framework that integrates Binary Geometric Feature Anomaly Detection (BGFAD) and Distorted point cloud Restoration (DPCR). BGFAD employs a dual threshold mechanism combining global distance statistics and local curvature analysis to detect both substantial and imperceptible adversarial perturbations. DPCR leverages attention enhanced feature encoding to reconstruct missing geometric structures while preserving semantic integrity through bidirectional Chamfer loss optimization. Our framework uniquely bridges traditional geometric priors with deep learning mechanisms, achieving attack-agnostic defense without classifier retraining. Extensive experiments on ModelNet40, ShapeNet and ScanObjectNN datasets demonstrate state-of-the-art performance, with about 12% higher robustness against structural attacks and 6× better restoration fidelity than existing methods. ADDR maintains real-time processing capabilities while reducing adversarial success rates to <5% across diverse attacks. The code is available at https://github.com/whwh456/ADDR.},
  archive      = {J_TIFS},
  author       = {Hao Wang and Jian Liu and Qiang Xu and Dong Wang and Kaiju Li},
  doi          = {10.1109/TIFS.2025.3607243},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {9},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {ADDR: Anomaly detection and distortion restoration for 3D adversarial point cloud},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SightCVC: An efficient and compatible multi-chain transaction protocol in heterogeneous blockchain systems. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2025.3607247'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the popularity of cross-chain transactions in heterogeneous blockchain systems, scalability has become a critical challenge. To overcome this, researchers propose to establish virtual channels, which move cross-chain transactions off the blockchain, enabling instant transaction confirmation between users and improving the system throughput. However, existing off-chain cross-chain transaction schemes encounter the following issues: (i) they are incompatible with non-Turing complete blockchain systems; (ii) they are incapable of accessing authentic information from blockchain systems. These issues have a dual impact on the cross-chain transaction, affecting its compatibility and dispute resolutions among mutually distrustful users. To alleviate these issues, this paper introduces SightCVC, a novel cross-chain payment protocol. The core of SightCVC is a new smart contract, which facilitates unrestricted off-chain transactions among mutually distrustful users in heterogeneous blockchain systems. It only requires off-chain protocol of the blockchain system involved in the transactions to support a Turing complete scripting language, which resolves the compatibility issue. Meanwhile, it can securely retrieve the real information from the blockchain systems, significantly improving the effectiveness of dispute resolution and enforcing the privacy of cross-chain transactions. We conduct a thorough security analysis within the Universal Composability framework to validate that SightCVC can achieve consensus at each stage. We implement and deploy SightCVC on the experimental networks of Ripple and Ethereum. Comprehensive evaluations demonstrate that SightCVC is able to effectively handle the disputes and reduce the system costs by approximately 64% compared to existing solutions. Its superiority becomes more evidence when the number of transactions increases.},
  archive      = {J_TIFS},
  author       = {Haonan Yang and Tianwei Zhang and Zuobin Ying and Runjie Yang and Wanlei Zhou},
  doi          = {10.1109/TIFS.2025.3607247},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {9},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {SightCVC: An efficient and compatible multi-chain transaction protocol in heterogeneous blockchain systems},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The gradient puppeteer: Adversarial domination in gradient leakage attacks through model poisoning. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2025.3607271'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Federated Learning (FL), clients share gradients with a central server while keeping their data local. However, malicious servers could deliberately manipulate the models to reconstruct clients’ data from shared gradients, posing significant privacy risks. Although such Active Gradient Leakage Attacks (AGLAs) have been widely studied, they suffer from two severe limitations: (i) coverage: no existing AGLAs can reconstruct all samples in a batch from the shared gradients; (ii) stealthiness: no existing AGLAs can evade principled checks of clients. In this paper, we address these limitations with two core contributions. First, we introduce a new theoretical analysis approach, which uniformly models AGLAs as backdoor poisoning. This analysis approach reveals that the core principle of AGLAs is to bias the gradient space to prioritize the reconstruction of a small subset of samples while sacrificing the majority, which theoretically explains the above limitations of existing AGLAs. Second, we propose Enhanced Gradient Global Vulnerability (EGGV), the first AGLA that achieves complete attack coverage while evading client-side detection. In particular, EGGV employs a gradient projector and a jointly optimized discriminator to assess gradient vulnerability, steering the gradient space toward the point most prone to data leakage. Extensive experiments show that EGGV achieves complete attack coverage and surpasses state-of-the-art (SOTA) with at least a 43% increase in reconstruction quality (PSNR) and a 45% improvement in stealthiness (D-SNR).},
  archive      = {J_TIFS},
  author       = {Kunlan Xiang and Haomiao Yang and Meng Hao and Shaofeng Li and Haoxin Wang and Zikang Ding and Wenbo Jiang and Tianwei Zhang},
  doi          = {10.1109/TIFS.2025.3607271},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {9},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {The gradient puppeteer: Adversarial domination in gradient leakage attacks through model poisoning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing the security of one-tap authentication services via dynamic application identification. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2025.3607232'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The One-Tap Authentication (OTAuth) service enables users to quickly log in or sign up for app accounts using their phone number. OTAuth provides a more secure and convenient alternative to password-based and Short Message Service (SMS)-based authentication schemes. Consequently, the OTAuth service has been adopted by numerous Mobile Network Operators (MNOs) worldwide. However, a high severity vulnerability remains unaddressed in the OTAuth service, which allows an attacker to access a victim’s various app accounts, posing a significant risk to user privacy and data security. In this paper, we present LoadShow, which, to the best of our knowledge, is the first security-enhanced OTAuth scheme to address this vulnerability. We propose a novel dynamic application identification technique that aims to address the root cause of this vulnerability, i.e., the inability of MNOs to distinguish between different applications on the same device. Specifically, application identification is based on the hardware load side-channel and captures the unique CPU and GPU load characteristics of applications through the sequence of timing values of fingerprinting functions. We evaluate the effectiveness of LoadShow by accuracy, False Positive Rate (FPR), and True Positive Rate (TPR). We also evaluate its multi-platform compatibility on devices with different architectures and models. LoadShow achieves over 90% accuracy, with a TPR exceeding 90% and an FPR below 1%. The evaluation results demonstrate LoadShow’s capability to effectively differentiate between applications on a device, defend against app impersonation attacks, and reliably identify legitimate applications.},
  archive      = {J_TIFS},
  author       = {Di Liu and Dawei Li and Yuxiao Guo and Ying Guo and Ruinan Hu and Jianwei Liu and Song Bian and Xuhua Ding and Yizhong Liu and Zhenyu Guan},
  doi          = {10.1109/TIFS.2025.3607232},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {9},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Enhancing the security of one-tap authentication services via dynamic application identification},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Model extraction for image denoising networks. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2025.3607269'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model Extraction (ME) replicates the performance of another entity’s pretrained model without authorization. While extensively studied in image classification, object detection and other tasks, ME for image restoration has been scarcely studied despite its broad applications. This paper presents a novel ME framework for image denoising networks, a fundamental one in image restoration. The framework tackles unique challenges like the black-box nature of the victim model, limiting access to its parameters, gradients, and outputs, and the difficulty of acquiring data that matches the original noise distribution while having adequate diversity. Our solution involves simulating the victim’s noise conditions to transform clean images into noisy ones and introducing loss functions to optimize the generator and substitute model. Experiments show that our method closely approximates the victim model’s performance and improves generalization in some scenarios. To the best of our knowledge, this work is the first to address ME in the field of image restoration, paving the way for future research in this area.},
  archive      = {J_TIFS},
  author       = {Huan Teng and Yuhui Quan and Yong Xu and Jun Huang and Hui Ji},
  doi          = {10.1109/TIFS.2025.3607269},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {9},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Model extraction for image denoising networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identifying adversarial cyber-activity in operational technology environments using bayesian networks. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2025.3607241'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Operational technology (OT) systems face increasing cybersecurity risks from adversarial behavior. This paper describes the development of a Bayesian network risk model to enhance the comprehension of observable cyber-events caused by malicious activity in OT environments. The core of the Bayesian network is a process model that characterizes the stages of adversary behavior. The remainder of the model leverages the MITRE ATT&CK® for Industrial Control Systems (ICS) taxonomy, which includes tactics and techniques that may be used by the adversary. The observables provide evidence for adversary behavior through the intermediary technique and tactic nodes. One challenge in constructing this model is a lack of open-source data from cyber-attacks on OT systems. This paper demonstrates the use of both historical data and expert knowledge to construct the Bayesian network. The historical data was obtained from open-source reporting of 27 cyber-attacks affecting OT systems. The expert knowledge was obtained from a panel of subject matter experts with experience in a variety of OT cybersecurity roles and responsibilities. Finally, the Bayesian network is demonstrated using two historical case studies: the Darkside ransomware attack on the Colonial Pipeline and the destructive cyber-attack targeting the Thyssenkrupp blast furnace. By using this approach, OT cybersecurity professionals can better identify and characterize adversarial behavior in their systems to enable risk-informed investigations and interruptions before impact occurs.},
  archive      = {J_TIFS},
  author       = {Lee T. Maccarone and Dennis M. Buede and Scott T. Bowman and Pawel Ambrozewicz and Charles D. Burdick and J. Connor Grady and Shaw X. Wen},
  doi          = {10.1109/TIFS.2025.3607241},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {9},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Identifying adversarial cyber-activity in operational technology environments using bayesian networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PCSR: Enabling cross-modal semantic retrieval with privacy preservation. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2025.3607246'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-modal semantic retrieval systems face significant privacy risks due to storing plaintext data on cloud servers. We propose PCSR, a privacy-preserving framework enabling semantic search directly on encrypted high-dimensional data. It consists of three essential modules: a cross-modal encoder, an approximate nearest neighbor (ANN) search algorithm, and an encryption algorithm. Specifically, we utilize CLIP, a deep neural network model, to extract features of images and texts. We design two ANN search methods for high-dimensional feature vectors by utilizing the space partitioning technique and Singular Value Decomposition algorithms, respectively. Furthermore, we employ adapted Random Matrix Multiplication (RMM) for efficient and secure vector similarity computations. Our rigorous security analysis demonstrates that our proposed schemes are secure. We conduct experiments on four datasets and systematically compare the performance of different encrypted retrieval methods. The superior performance validates the feasibility and efficiency of our proposed schemes.},
  archive      = {J_TIFS},
  author       = {Hanqi Zhang and Yandong Zheng and Chang Xu and Liehuang Zhu and Can Zhang},
  doi          = {10.1109/TIFS.2025.3607246},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {9},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {PCSR: Enabling cross-modal semantic retrieval with privacy preservation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conjunctive keyword search with dynamic group-user. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2025.3607238'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to ensure data security and improve data usability, searchable encryption has been widely used in cloud computing systems. However, the evil single users with search privileges bring heavy privacy threats to the system. Threshold searchable encryption provides a collaborative search service for group users; a single user cannot search for ciphertext. However, the threshold searchable encryption based on the Shamir secret sharing mechanism cannot achieve flexible user dynamic since the Lagrange interpolation polynomial for recovering the secret value changes with the group user add or delete, resulting in the ciphertext or trapdoor containing Lagrange interpolation formula needs to be recreated. In this paper, the conjunctive keyword search with dynamic group-user scheme (CKSDGU) is proposed to realize group-user flexible addition and deletion. The proposed CKSDGU scheme can match successfully without the data owner resetting ciphertext and the original data user generating trapdoors. In addition, multi-keyword conjunctive retrieval is implemented in the CKSDGU scheme, and group users can search the target ciphertexts that contain all users’ query keyword sets. The security analysis illustrates that the CKSDGU scheme can resist chosen keyword attacks and keyword guessing attacks. The performance analysis presents that our scheme has considerable overhead and efficient computational cost in the user dynamic stage.},
  archive      = {J_TIFS},
  author       = {Nan Gao and Kai Fan and Zhen Zhao and Willy Susilo and Zhoutong Xiong and Hui Li},
  doi          = {10.1109/TIFS.2025.3607238},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {9},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Conjunctive keyword search with dynamic group-user},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stealthy and effective clean-label backdoor attack via adaptive frequency-domain suppression and trigger combination. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2025.3607257'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Neural Networks (DNNs) remain vulnerable to backdoor attacks. These attacks are pernicious when attackers inject a trigger into the input data without altering its ground-truth label, known as clean-label backdoor attacks. The effectiveness and stealth of existing clean-label backdoor attacks rely on access to global training data, making them resource-intensive and impractical. This paper introduces a novel clean-label backdoor attack that achieves high attack success rates (ASR) while maintaining exceptional stealth under realistic constraints. Unlike prior approaches focused on spatial differences between clean and poisoned data, a key novelty of the new attack is the suppression of high-frequency components in the frequency domain, which minimizes human-detectable contrasts and enhances trigger imperceptibility. Moreover, we employ an affine combination of static and adaptive triggers, effectively balancing their strengths to maximize ASR. Surrogate models are designed to simulate victim model behavior and auxiliary models are applied to extract the spatial and frequency features of the static triggers, enabling trigger design with minimal knowledge of the victim model. Our attack achieves a higher ASR than state-of-the-art backdoor attacks while maintaining higher benign accuracy across various models and datasets. It also demonstrates strong resistance against the latest defense mechanisms, including STRIP, SentiNet, neural cleanse, fine-pruning, and ANP.},
  archive      = {J_TIFS},
  author       = {Chaoying Yuan and Jingpeng Bai and Shumei Yuan and Ni Wei},
  doi          = {10.1109/TIFS.2025.3607257},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {9},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Stealthy and effective clean-label backdoor attack via adaptive frequency-domain suppression and trigger combination},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BESA: Boosting encoder stealing attack with perturbation recovery. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2025.3608665'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To boost the encoder stealing attack under the perturbation-based defense that hinders the attack performance, we propose a boosting encoder stealing attack with perturbation recovery named BESA. It aims to overcome perturbation-based defenses. The core of BESA consists of two modules: perturbation detection and perturbation recovery, which can be combined with canonical encoder stealing attacks. The perturbation detection module utilizes the feature vectors obtained from the target encoder to infer the defense mechanism employed by the service provider. Once the defense mechanism is detected, the perturbation recovery module leverages the well-designed generative model to restore a clean feature vector from the perturbed one. Through extensive evaluations based on various datasets, we demonstrate that BESA significantly enhances the surrogate encoder accuracy of existing encoder stealing attacks by up to 24.63% when facing state-of-the-art defenses and combinations of multiple defenses.},
  archive      = {J_TIFS},
  author       = {Xuhao Ren and Haotian Liang and Yajie Wang and Chuan Zhang and Zehui Xiong and Liehuang Zhu},
  doi          = {10.1109/TIFS.2025.3608665},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {9},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {BESA: Boosting encoder stealing attack with perturbation recovery},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward open-world network intrusion detection via open recognition and inspection. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2025.3608666'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning is promising in open-world network intrusion detection, but current deep learning-based methods mainly focus on open recognition with properties that may not always hold and significantly neglect the inspection of unknown samples, increasing open space risks and manual inspection overhead for deployed models. To address these challenges in real-world environments, we propose a novel system, ORI, designed to tackle two critical tasks: 1) open recognition, including classifying known class samples while recognizing unknown ones, and 2) inspection, involving further inspecting samples recognized as unknown. Specifically, we reformulate open recognition as a binary classification task and propose a density-based method to recognize low-density samples as unknown while classifying known class samples with a closed-world classifier, thereby minimizing the risk associated with open spaces. To reduce the inspection overhead of samples recognized as unknown, we treat unknown sample inspection as a constrained clustering task, using a few manually inspected samples as constraints, and then assign labels to the remaining unknown samples via clustering. We evaluate our system against established open recognition and unknown sample inspection baselines through extensive experiments on three public datasets. Additionally, we simulated a security analyst inspecting unknown samples labeled by ORI. The experimental results demonstrate that ORI accurately classifies known class samples, recognizes unknown samples, and effectively labels samples recognized as unknown, enhancing both open recognition and inspection capabilities.},
  archive      = {J_TIFS},
  author       = {Lei Du and Yuhan Chai and Yan Jia and Binxing Fang and Hao Li and Zhaoquan Gu},
  doi          = {10.1109/TIFS.2025.3608666},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {9},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Toward open-world network intrusion detection via open recognition and inspection},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Privacy-preserving universal adversarial defense for black-box models. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2025.3609104'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) are increasingly used in critical applications such as identity authentication and autonomous driving, where robustness against adversarial attacks is crucial. These attacks can exploit minor perturbations to cause significant prediction errors, making it essential to enhance the resilience of DNNs. Traditional defense methods often rely on access to detailed model information, which raises privacy concerns, as model owners may be reluctant to share such data. In contrast, existing black-box defense methods fail to offer a universal defense against various types of adversarial attacks. To address these challenges, we introduce DUCD, a universal black-box defense method that does not require access to the target model’s parameters or architecture. Our approach involves distilling the target model by querying it with data, creating a white-box surrogate while preserving data privacy. We further enhance this surrogate model using a certified defense based on randomized smoothing and optimized noise selection, enabling robust defense against a broad range of adversarial attacks. Comparative evaluations between the certified defenses of the surrogate and target models demonstrate the effectiveness of our approach. Experiments on multiple image classification datasets show that DUCD not only outperforms existing black-box defenses but also matches the accuracy of white-box defenses, all while enhancing data privacy and reducing the success rate of membership inference attacks.},
  archive      = {J_TIFS},
  author       = {Qiao Li and Cong Wu and Jing Chen and Zijun Zhang and Kun He and Ruiying Du and Xinxin Wang and Qingchuang Zhao and Yang Liu},
  doi          = {10.1109/TIFS.2025.3609104},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {9},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Privacy-preserving universal adversarial defense for black-box models},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tactics and techniques text classification based on adversarial contrastive learning and meta-path. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2025.3609218'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tactics and techniques information in Cyber Threat Intelligence (CTI) represent the objectives of attackers and the means through which these objectives are achieved. The classification of tactics and techniques descriptions in CTI has been extensively studied to assist security experts in interpreting attack patterns. Although many recent studies have applied various deep learning methods to enhance classification performance, they mainly focus on improving performance from an average or top perspective. However, the imbalance between tactical and technical tag samples, as well as text sparsity, may lead to poor model performance, which has been under-explored. To address these issues, we propose a new tactics and techniques classification model based on adversarial contrastive learning and meta-path (TTC-ACLM). In TTC-ACLM, a novel text representation learning module is first designed. It includes pre-trained language model (PLM) and contrastive adversarial methods, which can better adapt to categories with smaller sample sizes while obtaining better text representations. Then, heterogeneous information networks are used to model the rich relationships between texts and labels (tactics and techniques), which can merge additional information, e.g., processes and tools, to address text sparsity. Next, we defined a meta-path based classifier learning module that maps text, tactics, and meta-path based context to a set of classifiers, which are applied to the text representation generated by the text representation module for better classification. Finally, the classification performance is further improved through the tactics and techniques correlation enhancement matrix. Through in-depth research, we demonstrate that the proposed model can effectively address the impact of sample imbalance and text sparsity. Extensive experimental results indicate that TTC-ACLM achieves state-of-the-art performance.},
  archive      = {J_TIFS},
  author       = {Yuchun Han and Weiping Wang and Zhe Qu and Shigeng Zhang},
  doi          = {10.1109/TIFS.2025.3609218},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {9},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Tactics and techniques text classification based on adversarial contrastive learning and meta-path},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedG3FA: Three-stage GAN-aided target feature alignment for secure data sharing in federated learning system. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2025.3609664'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) allows distributed clients to train model collaboratively without sharing the original data. However, using private model updates often makes traditional FL systems susceptible to privacy leakage problem. In addition, the performance of existing FL methods is often limited by statistical heterogeneity problem. In order to solve both privacy leakage and statistical heterogeneity problems, we propose a three-stage targeted feature alignment FL framework named FedG3FA. In the first stage, each client trains a generator through generative adversarial training and the generator will be utilized for data interaction instead of private model. After that, in the second stage, the generators will be aligned by our proposed Domain Pulling Network and then aggregated to a global one. Finally, in the third stage, the global generator will be used to train the private model for each client. The effectiveness of our method is verified on medical care and computer vision scenarios including five datasets. The experimental results suggest that our method not only achieves a high level of privacy protection performance, but also remains competitive classification accuracy.},
  archive      = {J_TIFS},
  author       = {Qingxia Li and Yuchen Jiang and Ray Y. Zhong and Xiaochun Cao},
  doi          = {10.1109/TIFS.2025.3609664},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {9},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {FedG3FA: Three-stage GAN-aided target feature alignment for secure data sharing in federated learning system},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedPN: Lightweight privacy-preserving federated learning with hardness of learning periodic neurons. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2025.3609663'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) is a distributed machine learning paradigm that facilitates model training across multiple devices without exposing private feature data. One of the primary challenges in FL is achieving a privacy protection guaranteed by theory often compromise computational and communication efficiency such as cryptographic-based methods. To address the trade-off between privacy preservation and efficiency, this paper introduces FedPN, a novel privacy-preserving approach that leverages periodic neuron technique, ensuring both enhanced privacy and efficient model training. Specifically, we propose a lightweight obfuscation mechanism integrated into the model’s input layer, where a specialized obfuscation layer is designed to ensure privacy, exploiting the synergistic interaction between convolutional operations and nonlinear activation functions to enhance feature extraction. We further integrate this privacy protection mechanism into FL model training, where the obfuscation layer is shared globally among all clients, aiming to achieve an optimal trade-off between the learnability and confidentiality of obfuscated features. In contrast to Homomorphic Encryption, our approach eliminates the need for heavy homomorphic operations, maintaining a practical level of training efficiency. Our theoretical analysis proves an exponentially negligible privacy guarantee against successful feature reconstruction attacks, with the success probability bounded by o(γ−m), where the frequency parameter γ > 1 and dimension of obfuscated vector m > 0. In addition, extensive experiments show that FedPN significantly enhances defence against feature reconstruction, while maintaining comparable efficiency and accuracy to existing approaches such as Differential Privacy.},
  archive      = {J_TIFS},
  author       = {Wenyuan Yang and Hongjian Xing and Zhun Zhang and Hanlin Gu and Lixin Fan and Xiaochun Cao},
  doi          = {10.1109/TIFS.2025.3609663},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {9},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {FedPN: Lightweight privacy-preserving federated learning with hardness of learning periodic neurons},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hypergraph-driven anomaly detection in dynamic noisy graphs. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2025.3610063'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As interactions among elements in applications such as social networks, transaction networks, and IP-IP networks dynamically evolve, anomaly detection in dynamic graphs to mitigate potentially threatening interactions has become increasingly important. Existing methods often assume noise-free graph structures and primarily focus on monitoring structural changes to discover anomalies. Regrettably, practical applications often involve inaccurate information, individual non-response and dropout, and sampling biases. These factors contribute to the pervasiveness of dynamic noisy graphs that encompass structural noises, making anomaly detection more challenging. To address this issue, we propose a novel Hypergraph-driven Anomaly Detection Framework (HADF), which resists the interference of structural noises and adapts to dynamic noisy graphs. HADF consists of a hyper encoder and an embedding enhancer. The hyper encoder leverages inter-edge correlations to generate hyperedges and design their resistant weights, further employing hypergraph convolutional layers to extract the basic hyper-embeddings of edges. The embedding enhancer exploits temporal structural correlation and reconstructs multi-head attention to achieve noise-resistant enhancement of basic hyper-embeddings. Extensive experiments show that our proposed HADF can realize resistance to structural noises and outperform state-of-the-art methods in identifying anomalous edges in dynamic noisy graphs.},
  archive      = {J_TIFS},
  author       = {Guanghua Liu and Chenlong Wang and Zhiguo Gong and Jia Zhang and Shuqi Tang and Huan Wang},
  doi          = {10.1109/TIFS.2025.3610063},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {9},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Hypergraph-driven anomaly detection in dynamic noisy graphs},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ArcGen: Generalizing neural backdoor detection across diverse architectures. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2025.3610254'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Backdoor attacks pose a significant threat to the security and reliability of deep learning models. To mitigate such attacks, one promising approach is to learn to extract features from the target model and use these features for backdoor detection. However, we discover that existing learning-based neural backdoor detection methods do not generalize well to new architectures not seen during the learning phase. In this paper, we analyze the root cause of this issue and propose a novel black-box neural backdoor detection method called ARCGEN. Our method aims to obtain architecture-invariant model features, i.e., aligned features, for effective backdoor detection. Specifically, in contrast to existing methods directly using model outputs as model features, we introduce an additional alignment layer in the feature extraction function to further process these features. This reduces the direct influence of architecture information on the features. Then, we design two alignment losses to train the feature extraction function. These losses explicitly require that features from models with similar backdoor behaviors but different architectures are aligned at both the distribution and sample levels. With these techniques, our method demonstrates up to 42.5% improvements in detection performance (e.g., AUC) on unseen model architectures. This is based on a large-scale evaluation involving 16,896 models trained on diverse datasets, subjected to various backdoor attacks, and utilizing different model architectures. Our code is available at https://github.com/SeRAlab/ArcGen.},
  archive      = {J_TIFS},
  author       = {Zhonghao Yang and Cheng Luo and Daojing He and Yiming Li and Yu Li},
  doi          = {10.1109/TIFS.2025.3610254},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {9},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {ArcGen: Generalizing neural backdoor detection across diverse architectures},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fairness-aware client selection and payment determination for differentially private federated learning. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2025.3610241'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) mitigates data leakage by sharing only local machine learning models instead of raw data. However, it remains vulnerable to differential attacks. Differential Privacy (DP) addresses this concern by introducing noise to make it challenging for adversaries to reconstruct training samples. Nonetheless, clients often have varying attitudes toward data privacy, quantified by their privacy budgets. Low privacy budgets indicate the stringent privacy requirements of clients, requiring high compensations to incentivize their participation. Focusing solely on privacy budgets, however, can introduce selection bias, potentially compromising model generalization. Therefore, it is essential to emphasizes the fairness of client participation, ensuring that clients with lower privacy budgets also have opportunities to contribute to the training process. To tackle the above challenges, this paper formulates a novel DP-based incentive problem in FL, aiming to optimize the utilities of both the server and the clients. Specifically, we propose an auction mechanism that jointly selects participants based on their heterogeneous privacy budgets and determines appropriate payments. The proposed auction mechanism is proven to achieve several desirable properties, including computational efficiency, individual rationality, budget balance, truthfulness, and guaranteed optimization performance. Finally, simulation results validate the effectiveness of the proposed mechanism.},
  archive      = {J_TIFS},
  author       = {Xin Zhao and Xiumin Wang and Weiwei Lin and Wing W. Y. Ng and Kai Liu},
  doi          = {10.1109/TIFS.2025.3610241},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {9},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Fairness-aware client selection and payment determination for differentially private federated learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SSME: A semi-supervised specific emitter identification method with manifold enhancement. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2025.3610246'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of Internet of Things (IoT) devices generates substantial data that supports deep learning, significantly advancing intelligent specific emitter identification (SEI) technology. However, challenges such as labeling costs and privacy concerns limit the availability of labeled samples, thereby constraining deep model training. To address this problem, this paper focuses on enhancing the data manifold structure through deep feature information, proposing a semi-supervised SEI method named SSME. A well-structured manifold makes the model capture underlying patterns and relationships within the data more effectively, leading to more accurate and generalizable classification boundaries. First, to maximize the use of supervision information from limited labeled samples, we design a supervised cross-class contrastive (SCCC) loss, which increases the feature distance between anchor samples and cross-class samples based on their labels, achieving better manifold separation of different categories. Second, we propose an instance neighborhood matching regularization (INMR) loss that captures the neighborhood of weakly and strongly augmented samples of unlabeled instances within the feature space. By aligning these neighborhood representations, neighborhood-to-neighborhood consistency learning is achieved, enhancing the structural consistency and smoothness of local manifolds. Evaluated on ADS-B and XSRP datasets across diverse settings, our method demonstrates superior performance over existing approaches. Notably, even with only five labeled samples per class, it surpasses supervised baselines by 24.82% and 12.55% on the respective datasets.},
  archive      = {J_TIFS},
  author       = {Hanlin Wang and Shuyuan Yang and Zhixi Feng},
  doi          = {10.1109/TIFS.2025.3610246},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {9},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {SSME: A semi-supervised specific emitter identification method with manifold enhancement},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diffusion prediction and control of negative information on simplicial complexes using physics-informed neural networks. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2025.3611070'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The inadequacy of traditional binary interaction networks in characterizing information flow processes within higher-order structures has driven growing research focus toward higher-order networks. Considering reporting mechanism and the dynamics of network scale, this paper proposes a susceptible-infected-quarantine-removed-empty (SIQRE) negative information diffusion model on simplicial complexes. An optimal control strategy, taking into account the system gain, is then implemented. The existence and stability of equilibria, and bi-stability between invasion threshold and persistence threshold are derived. Experiments on synthetic and empirical simplicial complexes reveal the dynamic behavior of the system with discontinuous phase transitions, backward bifurcation and periodic oscillations. An increase in the birth rate makes the system more susceptible to outbreaks of negative information, while the opposite is true for the death rate. Reporting mechanism suppresses discontinuous phase transition. And the synergistic application of preventive and corrective strategies demonstrates superior cost-effectiveness in system control compared to their isolated implementation. Additionally, an identifiability analysis of the model is conducted. Finally, the model parameters are inversely estimated and the diffusion dynamics are predicted using physics-informed neural networks (PINNs) across three instances, and the optimal control is subsequently performed, validating the effectiveness of both the proposed model and the control strategy.},
  archive      = {J_TIFS},
  author       = {Ying Jing and Youguo Wang and Qiqing Zhai and Zhangfei Zhou and Haojie Hou},
  doi          = {10.1109/TIFS.2025.3611070},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {9},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Diffusion prediction and control of negative information on simplicial complexes using physics-informed neural networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CRCT: Compact ring confidential transactions based on sum arguments. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2025.3611150'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ring Confidential Transactions (RingCT) is a classic cryptographic protocol for anonymous transactions on blockchains, currently used in the popular anonymous cryptocurrency Monero. The proof size of RingCT transactions is linearly related to the ring size, which limits the use of larger ring sizes due to the significant communication overhead it incurs. However, reducing the ring size also leads to decreased anonymity. Therefore, in recent years, many studies have focused on optimizing the proof sizes for RingCT, with the latest known solutions reducing the proof size to be logarithmic with the ring size. In this paper, we propose a new compact RingCT protocol (CRCT) for smaller proof sizes. To this end, we first design three extended schemes of the Sum Argument (CRYPTO’21), which are used to generate logarithmic-sized proofs for three distinct zero-knowledge arguments, respectively. We then introduce a new zero-knowledge proof scheme called the Difference Argument. It is used to prove that one has the knowledge of two secret values, with their difference being public. Based on these schemes, we construct our CRCT protocol, whose proof size is independent of the ring size and logarithmic with the number of source accounts. We provide concrete constructions and security proofs for the proposed cryptographic schemes. The experimental results demonstrate that CRCT exhibits significant advantages in computational efficiency and proof size over existing solutions when dealing with large ring sizes and moderate numbers of source accounts.},
  archive      = {J_TIFS},
  author       = {Junke Duan and Wei Wang and Licheng Wang and Lize Gu and Liehuang Zhu},
  doi          = {10.1109/TIFS.2025.3611150},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {9},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {CRCT: Compact ring confidential transactions based on sum arguments},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PREXP: Uncovering and exploiting security-sensitive objects in the linux kernel. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2025.3611149'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Security-Sensitive Objects (SSOs) are often critical components in the exploitation of Linux kernel memory corruption vulnerabilities. While existing research has advanced SSOs identification and classification, there remains a significant gap in systematically understanding how these objects can be effectively exploited in real-world security analysis. To address this challenge, we present PREXP, a novel approach to analyzing SSOs exploitability and automating the transformation of Proof-of-Concept (PoC) into exploitable states. Our approach encompasses three key techniques: (1) capability analysis and attribute modeling of vulnerable object (2) extraction and filtering of target SSOs and (3) automatically augmenting PoCs with SSO-specific code to create exploitation capabilities. To evaluate our approach, we tested our prototype on 30 public CVEs, successfully parsing vulnerable object in 22 cases (73.3%) and achieving accurate SSO matches in 18 (60.0%). PREXP outperformed state-of-the-art tools such as SCAVY and AlphaEXP in structure-matching, and enabled the generation of new Control Flow Hijacking Primitives (CFHPs) for 3 previously unexploited vulnerabilities, demonstrating its practical value in real-world exploit development.},
  archive      = {J_TIFS},
  author       = {Zuxin Chen and Yaowen Zheng and Hong Li and Siyuan Li and Weijie Wang and Dongliang Fang and Zhiqiang Shi and Limin Sun},
  doi          = {10.1109/TIFS.2025.3611149},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {9},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {PREXP: Uncovering and exploiting security-sensitive objects in the linux kernel},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Channel-robust RF fingerprint identification for multi-antenna 5G user equipments. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2025.3611154'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radio frequency fingerprint (RFF) is a promising solution for realizing secure and efficient device identification. However, the accuracy of currently existing solutions suffer from multipath effects in practical scenarios. In this paper, we provide a robust RFF identification method that leverages channel state information (CSI) feedback to counteract the effect of the channel on the extracted RFF features. A straightforward zero-forcing (ZF) equalization fails to fully decouple RF impairments from the channel, making conventional approaches ineffective. To overcome this challenge, we utilize the potential of multi-antenna and introduce a new device-specific feature called Relative-RFF (R-RFF), which represents the relation between different RF chains in a multi-antenna transmitter. We propose an enhanced ZF post-equalization algorithm to eliminate the multipath channels and preserve the users’ R-RFF to the greatest extent. We evaluate the robustness of R-RFF under various channel conditions and noise levels and the performance of R-RFF in terms of identification accuracy under different channel scenarios. The results show that the proposed R-RFF method can achieve an identification accuracy of 91.2% for 70 devices in tapped delay line channel with a signal-to-noise ratio (SNR) of 30 dB.},
  archive      = {J_TIFS},
  author       = {Hongyi Luo and Guyue Li and Alessandro Brighente and Mauro Conti and Yuexiu Xing and Aiqun Hu and Xianbin Wang},
  doi          = {10.1109/TIFS.2025.3611154},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {9},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Channel-robust RF fingerprint identification for multi-antenna 5G user equipments},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimized sparse vector aggregation under local differential privacy. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2025.3611115'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In crowdsourcing applications, gathering and analyzing users’ strong positive (1) or negative (-1) reactions to a large number of items is crucial for improving service quality, particularly in recommendation systems. However, protecting users’ privacy while handling diverse sparse patterns in contexts with a large dimension size d poses significant challenges for efficient and privacy-preserving data aggregation. To address these challenges, in this paper, we propose an optimized k-sparse vector mean estimation scheme under Local Differential Privacy (LDP), ensuring that each user’s entire set of up to k private values from {−1, 1} satisfies ε-LDP. Specifically, our proposed scheme employs a seed mining technique in conjunction with PRNG Randomizer, which allows users to send their data only once while enabling the server to accurately estimate any value’s mean in the domain. Our scheme achieves an asymptotically optimal error of O( 1/ε√n ), equivalent to that of a 1-sparse case, while also ensuring efficient communication costs. The communication cost remains at a minimal level of O(1) (only 2 bytes per user’s report) for smaller k values and scales to O(k) for larger k, due to efficient binning strategies. Extensive experimental results confirm that our results align with theoretical expectations, demonstrating that our scheme not only preserves user privacy but also ensures higher accuracy compared to other schemes.},
  archive      = {J_TIFS},
  author       = {Ellen Z. Zhang and Yunguo Guan and Rongxing Lu and Harry Zhang},
  doi          = {10.1109/TIFS.2025.3611115},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {9},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Optimized sparse vector aggregation under local differential privacy},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UDFed: A universal defense scheme for various poisoning attacks on federated learning. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2025.3611126'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL), as a distributed machine learning paradigm with privacy protection, has garnered significant attention since it prevents the exchange of raw local data. However, FL remains vulnerable to poisoning attacks, including data contamination and gradient manipulation. Moreover, attackers may launch individual or collusive attacks, complicating the identification of malicious clients. To address these challenges, we propose a universal poisoning defense framework incorporating three key strategies. First, we decouple client identities from gradients through anonymous obfuscation and enhance privacy with differential noise injection. Second, we detect potential detect potential collusive attackers via a joint similarity-based approach. Third, we apply an iterative low rank approximation-based anomaly detection to amplify discrepancies between benign and malicious clients and progressively filter out attackers. We theoretically demonstrate that anonymous obfuscation can enhance the privacy protection capability of differential privacy. Additionally, experimental results further validate that our scheme is comparable to or outperforms state-of-the-art defense methods against a variety of data and model poisoning attacks.},
  archive      = {J_TIFS},
  author       = {Jieyi Deng and Congduan Li and Nanfeng Zhang and Jingfeng Yang and Jun Gao},
  doi          = {10.1109/TIFS.2025.3611126},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {9},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {UDFed: A universal defense scheme for various poisoning attacks on federated learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ARBiBench: Benchmarking and analyzing adversarial robustness of binarized convolutional neural networks. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2025.3611094'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Binarized convolutional neural networks (BCNNs), which restrict the weights and activations of the model to +1 or −1, provide notable reductions in memory requirements and enhanced model inference speed during deployment. Current research on BCNNs primarily revolves around addressing the performance degradation resulting from binarization. However, the investigation of the effects of extreme discretization on the robustness of BCNNs has been largely overlooked, despite its critical relevance to real-world applications. To this end, we propose ARBiBench, a comprehensive benchmark for evaluating the adversarial robustness of BCNNs in the image classification task. The key contributions of ARBiBench include: 1) systematically evaluating the robustness of seven influential BCNN methods across various architectures; 2) rigorous validation of diverse adversarial attack methods; and 3) novel empirical findings showing that BCNNs exhibit weaker robustness than full-precision networks on small datasets but surprisingly stronger robustness on large-scale datasets. Leveraging Information Bottleneck theory, we further demonstrate how data scale and model capacity collectively determine BCNNs’ adversarial robustness. These findings not only challenge conventional assumptions about BCNN security, but also provide new insights for developing robust yet efficient neural network architectures.},
  archive      = {J_TIFS},
  author       = {Jiehua Zhang and Peng Zhao and Li Liu and Bowen Peng and Zhen Liu and Longguang Wang and Yingmei Wei},
  doi          = {10.1109/TIFS.2025.3611094},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {9},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {ARBiBench: Benchmarking and analyzing adversarial robustness of binarized convolutional neural networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-centric robust training for defending against transfer-based adversarial attacks. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2025.3611148'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transfer-based adversarial attacks pose a severe threat to real-world deep learning systems since they do not require access to target models. Adversarial training (AT), which is recognized as the most effective defense against white-box attacks, also ensures high robustness against (black-box) transfer-based attacks. However, AT suffers from significant computational overhead because it repeatedly generates adversarial examples (AEs) throughout the entire training process. In this paper, we demonstrate that such repeated generation is unnecessary to achieve robustness against transfer-based attacks. Instead, pre-generating AEs all at once before training is sufficient, as proposed in our new defense paradigm called Data-Centric Robust Training (DCRT). DCRT employs clean data augmentation and adversarial data augmentation techniques to enhance the dataset before training. Our experimental results show that DCRT outperforms widely-used AT techniques (e.g., PGD-AT, TRADES, EAT, and FAT) in terms of transfer-based black-box robustness and even surpasses the top-1 defense on RobustBench when combined with common model-centric techniques. We also highlight additional benefits of DCRT, such as improved training efficiency and class-wise fairness. Our code will be available on GitHub.},
  archive      = {J_TIFS},
  author       = {Yulong Yang and Ruiqi Cao and Xiang Ji and Qiwei Tian and Chenhao Lin and Zhengyu Zhao and Qian Li and Le Yang and Hongshan Yang and Chao Shen},
  doi          = {10.1109/TIFS.2025.3611148},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {9},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Data-centric robust training for defending against transfer-based adversarial attacks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Traceable access control encryption with parallel multiple sanitizers. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2025.3611076'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Access control encryption (ACE) is an innovative cryptographic primitive that realizes fine-grained read/write control of data and protects data privacy and security while facilitating the effective flow of information. However, existing ACE schemes face several limitations: 1) Inability to adequately mitigate the risks of a single point of failure in the sanitizer. 2) Lack of an effective accountability mechanism for disputes arising during the sanitization process. To solve these problems, this paper proposes the notion of traceable access control encryption with parallel multiple sanitizers for the first time and designs a specific structure of traceable parallel ACE to prevent the single point of failure, effectively deter abnormal sanitizer behaviors, and optimize system performance. Additionally, computationally intensive operations in the encryption and decryption processes are outsourced to third-party servers, resulting in a significant reduction of computational overhead. Furthermore, theoretical analysis and experimental simulations validate the effectiveness of the proposed scheme. Comprehensive security analysis demonstrates its no-read security under the decisional q-parallel Bilinear Diffie-Hellman Exponent (BDHE) assumption and its no-write security under the Discrete Logarithm (DL) assumption, ensuring its reliability in practical applications.},
  archive      = {J_TIFS},
  author       = {Wei Luo and Qinghe Duan and Chengzhe Lai},
  doi          = {10.1109/TIFS.2025.3611076},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {9},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Traceable access control encryption with parallel multiple sanitizers},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DPDeno: A post-processing framework for releasing differentially private spatio-temporal mobility features. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2025.3611106'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The spatio-temporal (ST) mobility patterns derived from trajectory data are crucial for applications such as location-based services and urban analytics. However, releasing these mobility features raises significant privacy concerns, as they may expose sensitive personal location information. Differential privacy (DP) is widely used to safeguard individual privacy during data releases, but existing methods for releasing ST features often suffer from utility loss because their high dimensionality requires injecting substantial noise to meet privacy guarantees. Several recent approaches attempt to address this issue by reducing noise in differentially private spatio-temporal (DPST) features, but they either discard valuable information while compressing noisy data representations or rely solely on restrictive road network topology constraints, resulting in only modest utility improvements. In this paper, we present DPDeno, a post-processing framework designed to significantly enhance the utility of DPST features. First, DPDeno generates synthetic trajectory datasets using public information (e.g., road network data) and applies existing DP methods to create paired DPST (noisy) and ST (clean) features. It then trains a spatio-temporal graph autoencoder (STGAE), which models each feature as a graph, with road segments as nodes and transitions over time as edges. By minimizing node- and edge-level reconstruction losses between the noisy and clean pairs, STGAE learns to refine DPST inputs toward the structural consistency of their clean counterparts, thereby improving their practical utility. The trained model is then used to post-process real DPST features. Importantly, DPDeno preserves the original DP guarantee, as STGAE is trained solely on synthetic data generated from public sources without accessing any private information. Experimental results on two real-world trajectory datasets show that DPDeno significantly improves both the statistical accuracy and practical usability of released mobility features.},
  archive      = {J_TIFS},
  author       = {Xinyue Sun and Xiaoyu Liu and Qingqing Ye and Haibo Hu and Renyu Yang and Hui He and Weizhe Zhang},
  doi          = {10.1109/TIFS.2025.3611106},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {9},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {DPDeno: A post-processing framework for releasing differentially private spatio-temporal mobility features},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring causal information bottleneck for adversarial defense. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2025.3611108'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information bottleneck (IB) is a promising defense solution against adversarial attacks on deep neural networks. However, these methods often suffer from spurious correlations. A correlation exists between the prediction and the non-robust features, yet it does not reflect the causal relationship well. Such spurious correlations induce the neural networks to learn fragile and incomprehensible (non-robust) features. This issue limits its potential for further improving adversarial robustness. This paper addresses this issue by incorporating causal inference into the IB-based defense framework. Specifically, we propose a novel defense method that use the instrumental variables to enhance the adversarial robustness. Our proposed method divides the features into two parts for causal effect estimation: robust and non-robust features. The robust features relate to understanding semantic information, and the non-robust features link to the vulnerable style information. By employing this framework, the IB method can mitigate the influence of non-robust features and extract the robust features linking to the semantic information of objects. We conduct a thorough analysis of the effectiveness of our proposed method. Notably, the experiments on MNIST, FashionMNIST, CIFAR-10, CIFAR-100, and Tiny-ImageNet demonstrate that our method significantly boosts the adversarial robustness against multiple adversarial attacks compared to previous methods. Our regularization method can improve adversarial robustness in both natural and adversarial training frameworks. Besides, CausalIB can be applied to both Convolutional Neural Networks and Vision Transformers as a plug-and-play module. Our code is available at https://github.com/HydrogenWasser/CausalIB.},
  archive      = {J_TIFS},
  author       = {Jun Yan and Huan Hua and Weiquan Huang and Xi Fang and Wancheng Ge and Jiancheng Yang and Yongwei Wang},
  doi          = {10.1109/TIFS.2025.3611108},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {9},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Exploring causal information bottleneck for adversarial defense},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SF2Net: Sequence feature fusion network for palmprint verification. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2025.3611692'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently global features are usually extracted directly from local patterns in palmprint verification. Furthermore, sequence features for palmprint verification are only used as local features, but the properties of sequence features are not fully utilized. To solve this issue, this paper introduces Sequence Feature Fusion Network (SF2Net) for palmprint verification. SF2Net proposes a new paradigm: using stable and spatially correlated sequence features as an intermediate bridge to generate robust global representations. SF2Net’s core mechanism is to first extract fine-grained local features that are then converted into sequence features by a sequence feature extractor (SFE). Finally, the sequence features are used as a superior input to capture high-quality global features. By fusing multi-order texture-based local features with globally extracted sequence features, SF2Net achieves superior discrimination. To ensure high accuracy even with limited training data, a hybrid loss function is proposed, which integrate a cross-entropy loss and a triplet loss. Triplet loss effectively optimizes feature separation by explicitly considering negative samples. Extensive experiments on multiple publicly available palmprint datasets demonstrate that SF2Net achieves state-of-the-art (SOTA) performance. Remarkably, even with a small training-to-testing ratio (1:9), SF2Net achieves 100% accuracy, surpassing SOTA methods under several benchmark datasets. The code is released at https://github.com/20201422/SF2Net.},
  archive      = {J_TIFS},
  author       = {Yunlong Liu and Lu Leng and Ziyuan Yang and Andrew Beng Jin Teoh and Bob Zhang},
  doi          = {10.1109/TIFS.2025.3611692},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {9},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {SF2Net: Sequence feature fusion network for palmprint verification},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Digital scapegoat: An incentive deception model for resisting unknown APT stealing attacks on critical data resource. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2025.3611653'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is a challenging problem to resist unknown advanced persistent threats (APTs) on stealing data resources in an information system of critical infrastructures, because APT attackers have very specific objectives and compromise the system stealthily and slowly. We observe that it is a necessary condition for APT attackers to achieve their campaigns via controlling unknown Trojans to access and exfiltrate critical files. We present a theoretical model called Digital Scapegoat (abbreviated as DS-IDep) that constructs an Incentive Deception defense schema to hijack the attacker’s access to critical files and redirect it to avatar files without awareness. We propose a FlipIDep Game model (GF) and a Markov Game model (GM) to characterize completely the payoffs, equilibria, and best strategies from the perspective of the attacker and the defender respectively. We also design an exponential risk propagation model to evaluate the ability of DS-IDep to eliminate stealing impact when the risk is propagated between states. Theoretically, we can achieve the objective of stealing impact elimination (LK<0.001) when the ratio of incentive deception exceeds 0.7 (η>0.7) and the probability of an attack operation bypassing the defense surface is less than 0.1 (r* × μ <0.1) under Stackelberg strategies. We develop a kernel-level incentive deception defense surface according to the theoretical parameters of the DS-IDep. The experimental results show that DS-IDep can resist APT stealing attacks from unknown Trojans. We also evaluate the DS-IDep in five well-known software applications. It demonstrates that DS-IDep can address unknown attacks from compromised software with less than 10% performance overhead.},
  archive      = {J_TIFS},
  author       = {Xiaochun Yun and Guangjun Wu and Shuhao Li and Qige Song and Zixian Tang and Zhenyu Cheng},
  doi          = {10.1109/TIFS.2025.3611653},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {9},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Digital scapegoat: An incentive deception model for resisting unknown APT stealing attacks on critical data resource},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature reconstruction: Far field EM side-channel attacks in complex environment. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2025.3611788'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Far Field EM Side-Channel Attacks (FEM-SCAs) have emerged as a realistic security threat to widely deployed RF-integrated IoT edge devices. In mixed-signal chips, side-channel leakage may unintentionally couple with transmission signals and be emitted via the on-chip antenna, potentially allowing adversaries to extract sensitive information from the victim at long distances. However, in practical scenarios, far field EM traces captured at long distances usually suffer from noise and interference, which makes the attack less efficient or sometimes even unfeasible. In this paper, we propose a Domain-Adversarial ReFeature Nueral Network (DAR-NN) to facilitate “noisy-clean” adaptation for far field EM traces captured at long distances. By integrating a DAE model with two deep-learning classifiers as regularization terms, the proposed DAR-NN model can reconstruct features of traces obtained remotely in complex environments, thereby achieving a more efficient FEM-SCA. We first test our model by using a publicly available dataset and show that it is feasible to extract the AES key from 141 traces captured at 15 m distance to the victim, which is 58.7% more efficient than existing methods with 80% less profiling data. Afterwards, we set up a more complex experimental environment with a HackRF radio serving as an interference source. We show that the proposed model can still extract the key by using around 2K traces at 15 m even in the presence of 25% active interference, while the state-of-the-art model fails under same conditions.},
  archive      = {J_TIFS},
  author       = {Huanyu Wang and Dalin He and Deng Tuo and Junnian Wang},
  doi          = {10.1109/TIFS.2025.3611788},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {9},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Feature reconstruction: Far field EM side-channel attacks in complex environment},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unveiling malware visual patterns: A self-analysis perspective. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2025.3611649'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread usage of Microsoft Windows has unfortunately led to a surge in malware, posing a serious threat to the security and privacy of millions of users. In response, the research community has mobilized, with numerous efforts dedicated to strengthening defenses against these threats. The primary goal of these techniques is to detect malicious software early, preventing attacks before any damage occurs. However, many of these methods either claim that packing has minimal impact on malware detection or fail to address the reliability of their approaches when applied to packed samples. Consequently, they are not capable of assisting victims in handling packed programs or recovering from the damages caused by untimely malware detection. To address these challenges, we propose VisUnpac, a static analysis-based data visualization framework for bolstering attack prevention while aiding recovery post-attack by unveiling malware patterns and offering more detailed information including both malware class and family. Our method includes unpacking packed malware programs, calculating local similarity descriptors based on basic blocks, enhancing correlations between descriptors, and refining them by minimizing noises to obtain self-analysis descriptors. Moreover, we employ machine learning to learn the correlations of self-analysis descriptors through architectural learning for final classification. Our comprehensive evaluation of VisUnpac based on a freshly gathered dataset with over 27,106 samples confirms its capability in accurately classifying malware programs with a precision of 99.7%. Additionally, VisUnpac reveals that most antivirus products in VirusTotal can not handle packed samples properly or provide precise malware classification information. We also achieve over 97% space savings compared to existing data visualization based methods.},
  archive      = {J_TIFS},
  author       = {Fangtian Zhong and Qin Hu and Yili Jiang and Jiaqi Huang and Xiuzhen Cheng},
  doi          = {10.1109/TIFS.2025.3611649},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {9},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Unveiling malware visual patterns: A self-analysis perspective},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing model generalization for efficient cross-device side-channel analysis. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2025.3611696'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL)-based techniques have garnered significant attention as an innovative method for profiled side-channel analysis (SCA). Despite their proven effectiveness, recent studies have highlighted challenges faced by DL-based profiled attacks in a more realistic portability threat model, where two devices are used respectively for profiling and the attack. In this paper, we propose a novel approach for cross-device attack by incorporating the Denoising Diffusion Probabilistic Model (DDPM) to develop a generalized model. Additionally, an adaptive multi-task loss is employed to balance multiple training objectives that respectively focus on model generalization and precision. We evaluate our strategy on five cross-device SCA datasets. The experimental results show that, compared to baseline methods, our approach achieves significantly enhanced performance, as measured by the number of traces required to recover the secret key. Specifically, on a more challenging dataset obtained from three SAKURA-G evaluation boards, our method successfully recovers the secret key using approximately 300 traces, whereas baseline methods fail to guarantee a successful cross-device attack even with 5,000 traces. Furthermore, our method demonstrates remarkably enhanced attack efficiency, reducing attack time by over an hour compared to the baselines.},
  archive      = {J_TIFS},
  author       = {Yimeng Chen and Bo Wang and Changshan Su and Ao Li and Yuxing Tang and Gen Li},
  doi          = {10.1109/TIFS.2025.3611696},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {9},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Enhancing model generalization for efficient cross-device side-channel analysis},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal string sanitization against strategic attackers. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2025.3610245'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Strings (sequences of elements) are often disseminated to support applications, e.g., in bioinformatics, web analysis, and transportation. Unfortunately, this may expose sensitive patterns that model confidential knowledge. Concealing the occurrences of sensitive patterns in a string (e.g., by deleting some elements) while minimizing the associated quality loss has been the objective of several string sanitization methods. However, real-world attackers are likely to possess background knowledge about the string, e.g., an individual’s genome sequence is almost identical to a reference genome sequence. In addition, it is good security practice to assume that the attacker will know the algorithm that has been used to sanitize the string (Kerckhoffs’ principle). Yet, all existing methods fail to protect strings against such attackers, risking privacy breaches in critical applications. In our work, we consider for the first time how to defend against strategic attackers who possess such knowledge. To achieve this, we propose a novel framework to sanitize a string by probabilistically replacing carefully selected patterns. As part of this framework, we design three mathematical programming algorithms which compute the optimal replacement probabilities under different objectives and constraints, offering different privacy gain / quality loss tradeoffs. Our algorithms protect against strategic attackers using new concepts and measures, protect sensitive patterns of any length, and can construct one or more optimally sanitized strings that can be used in applications such as frequent pattern mining. Our experiments using five real-world datasets from different domains show that all our algorithms are substantially more effective than a natural baseline (e.g., they offer up to 2 times more privacy when they are configured to incur the same quality loss, and up to 3 times lower quality loss when they are configured to offer the same privacy). They also show that two “hybrid” algorithms that we propose, based on combining elements of the above algorithms, inherit the advantages of their constituent algorithms. These results, coupled with the generality of our approach, make our algorithms practical and beneficial for deployment.},
  archive      = {J_TIFS},
  author       = {Pengxin Bian and George Theodorakopoulos and Solon P. Pissis and Grigorios Loukides},
  doi          = {10.1109/TIFS.2025.3610245},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {9},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Optimal string sanitization against strategic attackers},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). JMA: A general algorithm to craft nearly optimal targeted adversarial examples. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2025.3611121'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of the approaches proposed so far to craft targeted adversarial examples against Deep Learning classifiers are highly suboptimal and typically rely on increasing the likelihood of the target class, thus implicitly focusing on one-hot encoding settings. In this paper, a more general, theoretically sound, targeted attack is proposed, which resorts to the minimization of a Jacobian-induced Mahalanobis distance term, taking into account the effort (in the input space) required to move the latent space representation of the input sample in a given direction. The minimization is solved by exploiting the Wolfe duality theorem, reducing the problem to the solution of a Non-Negative Least Square (NNLS) problem. The proposed algorithm (referred to as JMA) provides an optimal solution to a linearised version of the adversarial example problem originally introduced by Szegedy et al. The results of the experiments confirm the generality of the proposed attack which is proven to be effective under a wide variety of output encoding schemes. Noticeably, JMA is also effective in a multi-label classification scenario, being capable to induce a targeted modification of up to half the labels in complex multi-label classification scenarios, a capability that is out of reach of all the attacks proposed so far. As a further advantage, JMA requires very few iterations, thus resulting more efficient than existing methods.},
  archive      = {J_TIFS},
  author       = {Benedetta Tondi and Wei Guo and Niccolò Pancino and Mauro Barni},
  doi          = {10.1109/TIFS.2025.3611121},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {9},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {JMA: A general algorithm to craft nearly optimal targeted adversarial examples},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fine-grained and class-incremental malicious account detection in ethereum via dynamic graph learning. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2025.3612194'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ethereum serves as the cornerstone for value transfer in Web 3.0, providing a decentralized and efficient trust mechanism for global connectivity. However, the anonymity of Ethereum undermines market regulatory capabilities, leading to frequent malicious behaviors such as Ponzi Scheme, Money Laundering, and Phishing. Therefore, in the face of the diverse and continuously emerging malicious behaviors, implementing fine-grained detection is crucial for maintaining the prosperous development of the blockchain ecosystem. In this paper, we propose FiMAD, a fine-grained and class-incremental malicious account detection framework based on dynamic graph learning. Specifically, we first propose a general graph structure called Dynamic Account Relation Graph (DARG), which dynamically models Ethereum accounts from a continuous-time perspective. Then, we design a cascade graph feature extraction method to capture deep temporal evolution patterns and neighbor interaction features in DARG. Next, we construct a pre-training universal encoder to transform account features into high-dimensional embeddings, followed by fine-tuning the model classifier with a few labeled samples, enabling accurate fine-grained detection and rapid updates for incremental classes. We conduct extensive experiments using real Ethereum data. The results demonstrate that FiMAD outperforms state-of-the-art (SOTA) methods in fine-grained detection across five typical scenarios: class-incremental, full data, new malicious accounts, imbalanced data, and binary classification. In the class-incremental scenario, FiMAD improves the Macro-F1 by up to 26.4% compared to SOTA methods.},
  archive      = {J_TIFS},
  author       = {Hanbiao Du and Meng Shen and Yang Liu and Zheng Che and Jinhe Wu and Wei Wang and Liehuang Zhu},
  doi          = {10.1109/TIFS.2025.3612194},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {9},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Fine-grained and class-incremental malicious account detection in ethereum via dynamic graph learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detection of unknown attacks through encrypted traffic: A gaussian prototype-aided variational autoencoder framework. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2025.3612141'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The identification of encrypted network traffic presents a pivotal challenge in detecting unknown malicious traffic. Unlike closed-set identification, which primarily classifies known traffic classes, detecting unknown malicious traffic necessitates both accurate classification of known traffic and the identification of previously unseen traffic classes. Existing methods often face difficulties in effectively constraining the distribution size of known classes in the representation space and frequently misclassifying unknown classes as known. To address these challenges, we propose Open-Detect, a robust theoretical framework for detecting unknown malicious traffic, which leverages advanced deep learning techniques, such as variational autoencoders and Gaussian prototypes. Open-Detect introduces two primary constraints: a generative constraint, which enhances intra-class compactness, and a discriminative constraint, which optimizes inter-class separation. These constraints collectively mitigate the risks of misclassifying known classes and failing to detect unknown classes. In Open-Detect, network flows are transformed into grayscale images, and each known traffic class is mapped to a unique Gaussian prototype in the latent space. This design ensures tight clustering of samples within the same class and clear separation of samples between different classes. The detection of unknown malicious traffic is performed based on the distance between samples and these prototypes. Extensive experiments conducted on multiple publicly available datasets substantiate the efficacy of Open-Detect. The results reveal significant improvements in intra-class compactness and inter-class separation, enabling superior performance in both closed-world and open-world scenarios, particularly for detecting unknown malicious traffic. Our code is available at: https://github.com/niebikong/Open-Detect.},
  archive      = {J_TIFS},
  author       = {Qianwei Meng and Jing Tao and Qingjun Yuan and Guangsong Li and Yongjuan Wang and Bing Gao and Siqi Lu},
  doi          = {10.1109/TIFS.2025.3612141},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {9},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Detection of unknown attacks through encrypted traffic: A gaussian prototype-aided variational autoencoder framework},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detecting DeFi fraud with a graph-transformer language model. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2025.3612184'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of blockchain technology, the widespread adoption of smart contracts—particularly in decentralized finance (DeFi) applications—has introduced significant security challenges, such as reentrancy attacks, phishing, and Sybil attacks. To address these issues, we propose a novel model called TrxGNNBERT, which combines Graph Neural Network (GNN) and the Transformer architecture to effectively handle both graph-structured and textual data. This combination enhances the detection of suspicious transactions and accounts on blockchain platforms like Ethereum. TrxGNNBERT was pre-trained using a masked language model (MLM) on a dataset of 60,000 Ethereum transactions by randomly masking the attributes of nodes and edges, thereby capturing deep semantic relationships and structural information. In this work, we constructed transaction subgraphs, using a GNN module to enrich the embedding representations, which were then fed into a Transformer encoder. The experimental results demonstrate that TrxGNNBERT outperforms various baseline models—including DeepWalk, Trans2Vec, Role2Vec, GCN, GAT, GraphSAGE, CodeBERT, GraphCodeBERT, Zipzap and BERT4ETH—in detecting suspicious transactions and accounts. Specifically, TrxGNNBERT achieved an accuracy of 0.755 and an F1 score of 0.756 on the TrxLarge dataset; an accuracy of 0.903 and an F1 score of 0.894 on the TrxSmall dataset; and an accuracy of 0.790 and an F1 score of 0.781 on the AddrDec dataset. We also explored different pre-training configurations and strategies, comparing the performance of encoder-based versus decoder-based Transformer structures. The results indicate that pre-training improves downstream task performance, with encoder-based structures outperforming decoder-based ones. Through ablation studies, we found that node-level information and subgraph structures are critical for achieving optimal performance in transaction classification tasks. When key features were removed, the model performance declined considerably, demonstrating the importance of each component of our method. These findings offer valuable insights for future research, suggesting further improvements in node attribute representation and subgraph extraction.},
  archive      = {J_TIFS},
  author       = {Wei Ma and Junjie Shi and Jiaxi Qiu and Cong Wu and Jing Chen and Lingxiao Jiang and Shangqing Liu and Yang Liu and Xiang Yang},
  doi          = {10.1109/TIFS.2025.3612184},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {9},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Detecting DeFi fraud with a graph-transformer language model},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LMAE4Eth: Generalizable and robust ethereum fraud detection by exploring transaction semantics and masked graph embedding. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2025.3612149'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As Ethereum confronts increasingly sophisticated fraud threats, recent research seeks to improve fraud account detection by leveraging advanced pre-trained Transformer or self-supervised graph neural network. However, current Transformer-based methods rely on context-independent, numerical transaction sequences, failing to capture semantic of account transactions. Furthermore, the pervasive homogeneity in Ethereum transaction records renders it challenging to learn discriminative account embeddings. Moreover, current self-supervised graph learning methods primarily learn node representations through graph reconstruction, resulting in suboptimal performance for node-level tasks like fraud account detection, while these methods also encounter scalability challenges. To tackle these challenges, we propose LMAE4Eth, a multi-view learning framework that fuses transaction semantics, masked graph embedding, and expert knowledge. We first propose a transaction-token contrastive language model (TxCLM) that transforms context-independent numerical transaction records into logically cohesive linguistic representations, and leverages language modeling to learn transaction semantics. To clearly characterize the semantic differences between accounts, we also use a token-aware contrastive learning pre-training objective, which, together with the masked transaction model pre-training objective, learns high-expressive account representations. We then propose a masked account graph autoencoder (MAGAE) using generative self-supervised learning, which achieves superior node-level account detection by focusing on reconstructing account node features rather than graph structure. To enable MAGAE to scale for large-scale training, we propose to integrate layer-neighbor sampling into the graph, which reduces the number of sampled vertices by several times without compromising training quality. Additionally, we initialize the account nodes in the graph with expert-engineered features to inject empirical and statistical knowledge into the model. Finally, using a cross-attention fusion network, we unify the embeddings of TxCLM and MAGAE to leverage the benefits of both. We evaluate our method against 15 baseline approaches on three datasets. Experimental results show that our method outperforms the best baseline by over 10% in F1-score on two of the datasets. Furthermore, we observe from three datasets that the proposed method demonstrates strong generalization ability compared to previous work. Our source code is avaliable at: https://github.com/lmae4eth/LMAE4Eth.},
  archive      = {J_TIFS},
  author       = {Yifan Jia and Yanbin Wang and Jianguo Sun and Ye Tian and Peng Qian},
  doi          = {10.1109/TIFS.2025.3612149},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {9},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {LMAE4Eth: Generalizable and robust ethereum fraud detection by exploring transaction semantics and masked graph embedding},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using random forests for efficient identification of decoys under link flooding attacks in SDNs. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2025.3612159'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software-defined networks (SDNs) face significant challenges from link flooding attacks (LFAs), where malicious bots flood towards a limited number of hidden hosts, known as decoys, at a low rate. Efficient decoy identification is crucial for mitigating LFAs and is more resource-efficient than traditional bot detection methods, given the smaller number of decoys compared to bots. This paper proposes a novel decoy identification mechanism (DIM) that utilizes the SDN controller to generate forwarding rules for critical switches, enabling them to classify and report decoy addresses effectively. DIM addresses the challenges of minimizing communication overhead between the controller and data plane while maintaining high classification accuracy. It optimizes critical switch selection by partitioning the network into smaller areas, which reduces communication costs while maximizing monitoring efficiency. Within each area, DIM pre-trains random forest (RF) models for the selected switches and generates their respective binary-encoded forwarding rules. These rules empower the switches to identify decoy addresses in LFA traffic at line speed. The identified addresses are then reported back to DIM for further analysis. Theoretical analysis demonstrates that DIM scales efficiently in terms of time and space complexity. Our evaluation with the NS-3 simulator—using real CAIDA traffic and a synthesized topology of over 30,000 nodes—shows DIM achieves 98.3% decoy identification accuracy, outperforming state-of-the-art models like LSTM and CNN in both accuracy and speed. Tests under routing changes and moving target defense scenarios confirm DIM’s robustness and adaptability, highlighting its practical effectiveness against LFAs.},
  archive      = {J_TIFS},
  author       = {Wenjie Yu and Boyang Zhou},
  doi          = {10.1109/TIFS.2025.3612159},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {9},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Using random forests for efficient identification of decoys under link flooding attacks in SDNs},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finite-time nonfragile h∞ consensus fuzzy filtering for multi-UAV target estimation against selective-data-based network attacks. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2025.3598938'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex environments pose significant challenges to the consensus estimation of ground targets by multiple unmanned aerial vehicles (multi-UAVs) with limited sensing capabilities. This paper addresses the design of an H∞ consensus fuzzy filter over a finite-time horizon, that is subject to selective network attacks and stochastic incomplete measurements. First, a novel selective-data-based (SDB) network attack model is proposed. Unlike conventional models, this model is constructed from the attacker’s perspective to mimic attacks that target high-value data, thereby maximizing its destructive potential. Second, incomplete measurements, arising from factors such as limited UAV sensing ranges and target motion, are modeled by using a set of random variables to characterize the stochastic nature of data loss. Furthermore, an H∞ consensus fuzzy filter is developed to achieve precise consensus estimation of the target with finite-time performance, thereby forming a unified attack-defense architecture. Sufficient conditions for the existence of such a filter are established in the form of linear matrix inequalities (LMIs), from which the filter gains can be derived. Finally, the effectiveness and superiority of the proposed design are validated through both numerical simulations and physical experiments.},
  archive      = {J_TIFS},
  author       = {Kunzhong Miao and Chang Wang and Yifeng Niu and Hong Zhang and Huangzhi Yu},
  doi          = {10.1109/TIFS.2025.3598938},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {8},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Finite-time nonfragile h∞ consensus fuzzy filtering for multi-UAV target estimation against selective-data-based network attacks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CoSwinVIT: A vision transformer for enhanced uniform spectrum response in specific emitter identification. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2025.3565999'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Specific emitter identification (SEI) is a security authentication technology by utilizing radio frequency fingerprinting (RFF) features. However, current mainstream RFF feature extraction methods based on neural networks (NNs) generally suffer from poor interpretability and difficulties in architecture optimization. To address these issues, we propose a novel convolution-enhanced swin vision transformer (CoSwinVIT) that combines filter characteristics of NN architectures to achieve a uniform spectrum response. Specifically, we treat the NN used in SEI tasks as filters and investigate their filter characteristics by applying Fourier transforms to hidden vectors. Through spectral analysis, we found that different NN architectures exhibit significantly different responses to the signal spectrum. This affects the model’s sensitivity to specific frequency bands of the signal, thereby influencing its accuracy (Acc). Subsequently, by integrating the filtering properties of swin vision transformer (SwinVIT) and convolutional neural network (CNN), we achieve a uniform spectral response design. Finally, to evaluate the performance of the CoSwinVIT architecture, we design both a supervised learning algorithm and a contrastive learning-based self-supervised algorithm. Experimental results on a real-world automatic dependent surveillance-broadcast (ADS-B) and wireless fidelity (WiFi) dataset indicate that CoSwinVIT provides a more uniform spectrum response. Under supervised learning, the proposed CoSwinVIT obtains the accuracies of 98.6% and 99.8% on the ADS-B and WiFi datasets, respectively. Under self-supervised learning with 5% and 10% labeled data, the accuracies of 73.6% and 86.3% are achieved on the ADS-B dataset, and the accuracies of 81.6% and 91.5% are achieved on the WiFi dataset. These results surpass the state-of-the-art (SOTA) methods used in the SEI tasks.},
  archive      = {J_TIFS},
  author       = {Yuting Lei and Dingzhao Li and Mingyuan Shao and Shaohua Hong and Haixin Sun},
  doi          = {10.1109/TIFS.2025.3565999},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {4},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {CoSwinVIT: A vision transformer for enhanced uniform spectrum response in specific emitter identification},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2015). Online learning anti-jamming cognitive radio network for green clouds - Withdrawn. <em>TIFS</em>, 1. (<a href='https://doi.org/10.1109/TIFS.2015.2417835'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Withdrawn.},
  archive      = {J_TIFS},
  author       = {Meikang Qiu and Hai Su and Gang Quan and Xiao Qin},
  doi          = {10.1109/TIFS.2015.2417835},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {3},
  pages        = {1},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Online learning anti-jamming cognitive radio network for green clouds - Withdrawn},
  year         = {2015},
}
</textarea>
</details></li>
</ul>

</body>
</html>
