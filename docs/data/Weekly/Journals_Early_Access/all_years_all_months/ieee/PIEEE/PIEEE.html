<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>PIEEE</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="pieee">PIEEE - 19</h2>
<ul>
<li><details>
<summary>
(2025). Cooperative perception for automated driving: A survey of algorithms, applications, and future directions. <em>PIEEE</em>, 1-27. (<a href='https://doi.org/10.1109/JPROC.2025.3608874'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cooperative perception (CP) has emerged as an important research topic in connected and automated transportation systems, significantly enhancing situational awareness in challenging conditions such as limited communication bandwidth, harsh weather, and poor lighting. By sharing and aggregating data from multiple sources—including vehicles, roadside units (RSUs), and other infrastructure—CP addresses critical issues like occlusion and long-range perception in complex environments. This article provides a comprehensive review of existing CP methodologies, evaluating their effectiveness across diverse scenarios and fusion layers. We investigate approaches ranging from early to late collaboration strategies, highlighting how multimodal sensing at the network level can improve detection accuracy, system robustness, and adaptability. Additionally, we review publicly available datasets, identifying key gaps in their coverage of heterogeneous sensors, adverse conditions, and large-scale spatial scenarios. Finally, we propose actionable future research directions, including advanced algorithms for adverse environments, adaptive fusion strategies for heterogeneous sensors, and the integration of emerging technologies such as high-definition (HD) maps, large language models (LLMs), and end-to-end frameworks. These advancements aim to ensure reliability, interoperability, and scalability for real-world connected and automated vehicle (CAV) applications.},
  archive      = {J_PIEEE},
  author       = {Chuheng Wei and Guoyuan Wu and Matthew J. Barth},
  doi          = {10.1109/JPROC.2025.3608874},
  journal      = {Proceedings of the IEEE},
  month        = {10},
  pages        = {1-27},
  shortjournal = {Proc. IEEE},
  title        = {Cooperative perception for automated driving: A survey of algorithms, applications, and future directions},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep-learning-empowered super resolution: A comprehensive survey and future prospects. <em>PIEEE</em>, 1-41. (<a href='https://doi.org/10.1109/JPROC.2025.3613233'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Super-resolution (SR) has garnered significant attention within the computer vision community, driven by advances in deep learning (DL) techniques and the growing demand for high-quality visual applications. With the expansion of this field, numerous surveys have emerged. Most existing surveys focus on specific domains, lacking a comprehensive overview of this field. Here, we present an in-depth review of diverse SR methods, encompassing single-image SR (SISR), video SR (VSR), stereo SR (SSR), and light field SR (LFSR). We extensively cover over 150 SISR methods, nearly 70 VSR approaches, and approximately 30 techniques for SSR and LFSR. We analyze methodologies, datasets, evaluation protocols, empirical results, and complexity. In addition, we conducted a taxonomy based on each backbone structure according to the diverse purposes. We also explore valuable yet understudied open issues in the field. We believe that this work will serve as a valuable resource and offer guidance to researchers in this domain. To facilitate access to related work, we created a dedicated repository available at https://github.com/AVC2-UESTC/Holistic-Super-Resolution-Review},
  archive      = {J_PIEEE},
  author       = {Le Zhang and Ao Li and Qibin Hou and Ce Zhu and Yonina C. Eldar},
  doi          = {10.1109/JPROC.2025.3613233},
  journal      = {Proceedings of the IEEE},
  month        = {10},
  pages        = {1-41},
  shortjournal = {Proc. IEEE},
  title        = {Deep-learning-empowered super resolution: A comprehensive survey and future prospects},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Protecting the mixed-signal domain: Secure ADCs for internet of things devices. <em>PIEEE</em>, 1-19. (<a href='https://doi.org/10.1109/JPROC.2025.3605535'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analog-to-digital converters (ADCs) are a standard building block of most Internet of Things (IoT) devices, used to convert between analog signals of the physical world and digital values for efficient storage and computation. While decades of research have explored methods to optimize the traditional power, performance, and area parameters of these circuits, a new requirement has emerged in the last five years for ADCs—security. Due to the deployment of these devices at the edge outside of a trusted computing base, there is a potential for various eavesdropping and tampering attacks. This can have a severe impact on the privacy and integrity of sensor data, which cannot be corrected for through the secure design of other blocks that follow the front end. In this article, we explore the recent work in ADC security and analyze what has been accomplished as well as what remains to be done for the successful deployment of secure ADCs in commercial systems.},
  archive      = {J_PIEEE},
  author       = {Maitreyi Ashok and Ruicong Chen and Taehoon Jeong and Anantha P. Chandrakasan and Hae-Seung Lee},
  doi          = {10.1109/JPROC.2025.3605535},
  journal      = {Proceedings of the IEEE},
  month        = {9},
  pages        = {1-19},
  shortjournal = {Proc. IEEE},
  title        = {Protecting the mixed-signal domain: Secure ADCs for internet of things devices},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The in-orbit performance of chinese first FengYun rainfall mission FY-3G. <em>PIEEE</em>, 1-24. (<a href='https://doi.org/10.1109/JPROC.2025.3605964'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In April 2023, China launched its first precipitation measurement satellite, FengYun-3G (FY-3G), to accurately measure the spatial and vertical structures of precipitation in the middle and lower latitudes of Earth. Equipped with advanced instruments, including a dual-frequency precipitation radar (DPR), a microwave radiometer, a visible and infrared (IR) imager, and a radio occultation sounder with reflectometry, FY-3G is designed for simultaneous measurements of precipitation, atmospheric temperature/moisture profiles, and cloud properties while capturing land and sea imaging at the same time. Additionally, it carries a polarized multiangle imager (PMAI) as an experimental payload to enhance the understanding of cloud microphysics. Six months after its launch, FY-3G has successfully completed the in-orbit commissioning phase. The detailed evaluation of the performance and the functionality of the platform as well as the instruments is presented in this article. Calibration and validation processes are also discussed. Since the end of 2023, sensor-dependent data records have been carefully validated and made available for public use. As the first of two planned precipitation missions in the FengYun satellite series, FY-3G offers independent and high-quality data on the occurrence, type, and intensity of precipitation, complementing the current observations made by the Global Precipitation Measurement satellite. This mission is expected to significantly advance the global understanding of precipitation dynamics, mechanisms, and the water cycle.},
  archive      = {J_PIEEE},
  author       = {Peng Zhang and Jian Shang and Lin Chen and Shuze Jia and Honggang Yin and Shengli Wu and Wenqiang Lu and Hanlie Xu and Haofei Wang and Yixuan Shou and Guangzhen Cao and Sijie Chen and Manyun Lin and Aijun Zhu and Songyan Gu and Xiangang Zhao},
  doi          = {10.1109/JPROC.2025.3605964},
  journal      = {Proceedings of the IEEE},
  month        = {9},
  pages        = {1-24},
  shortjournal = {Proc. IEEE},
  title        = {The in-orbit performance of chinese first FengYun rainfall mission FY-3G},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep reinforcement learning for distribution system operations: A tutorial and survey. <em>PIEEE</em>, 1-29. (<a href='https://doi.org/10.1109/JPROC.2025.3599840'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid evolution of modern electric power distribution systems into complex networks of interconnected active devices, distributed generation (DG), and storage poses increasing difficulties for system operators. The large-scale integration of distributed energy resources (DERs) and the rapid exchange of measurement data via communication networks present major opportunities for advancing grid operations but also introduce greater uncertainty, higher data dimensionality, more complex network and device models, and challenging control and optimization problems. Deep reinforcement learning (DRL) algorithms are promising in addressing these challenges. However, they have not been effectively adapted for power systems applications, requiring extensive customization for implementation and evaluation. This has resulted in reproducibility challenges and a steep learning curve for researchers new to applying DRL algorithms to the power systems domain. To bridge these gaps, this tutorial aims to serve as a valuable resource for researchers interested in exploring learning-based algorithms to operate active power distribution networks. Specifically, this work presents a generalized process for translating sequential decision-making problems in power distribution systems into Markov decision process (MDP) formulations, illustrated through concrete grid service examples. Additionally, we introduce a simple environment design strategy to develop and evaluate example DRL algorithms for distribution system applications, complete with an included code repository to guide users through environment construction.},
  archive      = {J_PIEEE},
  author       = {Daniel Glover and Gayathri Krishnamoorthy and Hongda Ren and Anamika Dubey and Assefaw Gebremedhin},
  doi          = {10.1109/JPROC.2025.3599840},
  journal      = {Proceedings of the IEEE},
  month        = {8},
  pages        = {1-29},
  shortjournal = {Proc. IEEE},
  title        = {Deep reinforcement learning for distribution system operations: A tutorial and survey},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spaceborne GNSS-R bistatic radar remote sensing, CYGNSS, and future missions. <em>PIEEE</em>, 1-19. (<a href='https://doi.org/10.1109/JPROC.2025.3583997'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Global Navigation Satellite System Reflectometry (GNSS-R) is a relatively new type of radar developed for remote sensing of the Earth surface. It uses GNSS navigation signals such as those transmitted by the Global Positioning System (GPS) constellation of satellites as the radar transmitter. The radar receiver measures alterations in the navigation signal caused by scattering from the Earth surface. The nature of those alterations contains information about the surface, which can be retrieved. The general theory of GNSS-R remote sensing and its historical development is presented, followed by a detailed assessment of the performance and capabilities of the first dedicated spaceborne GNSS-R science mission, NASA’s Cyclone Global Navigation Satellite System (CYGNSS). Numerous follow-on GNSS-R missions are also noted that have either already been launched or are scheduled to be soon. A wide range of science data products and scientific applications of the CYGNSS data are examined. Developments that are currently underway in GNSS-R technology are summarized, and their potential impact on the capabilities of future GNSS-R missions is discussed.},
  archive      = {J_PIEEE},
  author       = {Christopher Ruf and Scott Gleason},
  doi          = {10.1109/JPROC.2025.3583997},
  journal      = {Proceedings of the IEEE},
  month        = {7},
  pages        = {1-19},
  shortjournal = {Proc. IEEE},
  title        = {Spaceborne GNSS-R bistatic radar remote sensing, CYGNSS, and future missions},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Day-to-day traffic flow dynamics with mixed autonomy considering link-level penetration rate evolution of autonomous vehicles. <em>PIEEE</em>, 1-20. (<a href='https://doi.org/10.1109/JPROC.2025.3562946'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The imminent integration of autonomous vehicles (AVs) with human-driven vehicles (HVs) presents a significant transport paradigm shift, making it imperative to understand traffic flow dynamics in a mixed autonomy scenario for effective traffic management and harnessing the benefits of AVs. This study focuses on investigating the mixed autonomy of day-to-day traffic flow dynamics, leveraging its unique advantages to capture the mixed traffic flow evolution over multiple days, considering individual travelers’ route choices based on past experiences and current conditions. Although some studies have explored the day-to-day dynamics with mixed autonomy, the evolutionary process of the link-level AV penetration rate is usually ignored in the existing literature. In this study, we investigate the mixed autonomy of day-to-day dynamics considering the link-level penetration rate evolution of AVs. In our proposed approach, HV-based travelers use predictions from the advanced traveler information system (ATIS) along with their past route travel time (RTT) data to make route predictions for the current day and subsequently select their routes. Conversely, AV-based travelers employ advanced communication and coordination techniques to predict HV-based travelers’ route choices when ATIS broadcasts its prediction, and then make system-optimal route choices. We develop an optimization model and design a customized Armijo rule-based improved gradient projection (IGP) algorithm to obtain the optimal AV flows. Through numerical experiments, we validate the effectiveness of our approach. The systematic analysis of day-to-day dynamics in mixed traffic environments enhances our understanding of the intricate interactions between AVs and HVs, especially for long-term transport systems planning and management with day-to-day dynamics.},
  archive      = {J_PIEEE},
  author       = {Zelin Wang and Zhiyuan Liu and Yuqian Lin and Yicheng Zhang and Qixiu Cheng},
  doi          = {10.1109/JPROC.2025.3562946},
  journal      = {Proceedings of the IEEE},
  month        = {7},
  pages        = {1-20},
  shortjournal = {Proc. IEEE},
  title        = {Day-to-day traffic flow dynamics with mixed autonomy considering link-level penetration rate evolution of autonomous vehicles},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High revisit-rate tropical cyclone observations from the NASA TROPICS satellite constellation mission. <em>PIEEE</em>, 1-25. (<a href='https://doi.org/10.1109/JPROC.2025.3582502'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {New satellite constellations to provide high-resolution atmospheric observations from microwave (MW) sounders operating in low-Earth orbit are now coming online and are providing operationally useful data. The first of these missions, the NASA Time-Resolved Observations of Precipitation structure and storm Intensity with a Constellation of Smallsats (TROPICS) Earth Venture (EVI-3) mission, was successfully launched into orbit on May 7 and 25, 2023 (Eastern Daylight Time, two CubeSats in each of the two launches). TROPICS is now providing nearly all-weather observations of 3-D temperature and humidity, as well as cloud ice and precipitation horizontal structure, at high temporal resolution to conduct high-value science investigations of tropical cyclones (TCs). TROPICS is providing rapid-refresh MW measurements (median refresh rate of better than 60 min early in the mission with four functional CubeSats, and now approximately 70–90 min with three functional CubeSats) over the tropics that can be used to observe the thermodynamics of the troposphere and precipitation structure for storm systems at the mesoscale and synoptic scale over the entire storm lifecycle. Hundreds of high-resolution images of TCs have been captured thus far by the TROPICS mission, revealing the detailed structure of the eyewall and surrounding rain bands. The new 205-GHz channel in particular (together with a traditional channel near 92 GHz) is providing new information on the inner storm structure, and, coupled with the relatively frequent revisit and low downlink latency, is already informing TC analysis at operational centers. Here, we present an overview of the TROPICS mission after two years of successful science operations with a focus on the suite of geophysical (Level 2) products (atmospheric vertical temperature and moisture profiles, instantaneous surface rain rate, and TC intensity) and the science investigations that have been enabled by these new measurements.},
  archive      = {J_PIEEE},
  author       = {William J. Blackwell and Scott A. Braun and George R. Alvey and Robert Atlas and Ralf Bennartz and Jessica Braun and Kerri Cahoy and Ruiyao Chen and Galina Chirokova and Brittany Dahl and James Darlow and Mark DeMaria and Michael Diliberto and Jason P. Dunion and Patrick Duran and Thomas J. Greenwald and Sarah Griffin and Zachary Griffith and Derrick Herndon and Jeffrey D. Hawkins and Satya Kalluri and C. Kidd and Min-Jeong Kim and R. Vincent Leslie and Frank Marks and Toshi Matsui and W. McCarty and Adam Milstein and Glenn Perras and Michael L. Pieper and Robert Rogers and Christopher Velden and Yalei You and Nick V. Zorn},
  doi          = {10.1109/JPROC.2025.3582502},
  journal      = {Proceedings of the IEEE},
  month        = {7},
  pages        = {1-25},
  shortjournal = {Proc. IEEE},
  title        = {High revisit-rate tropical cyclone observations from the NASA TROPICS satellite constellation mission},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). No more traffic tickets: A tutorial to ensure traffic-rule compliance of automated vehicles. <em>PIEEE</em>, 1-30. (<a href='https://doi.org/10.1109/JPROC.2025.3570483'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imagine an automated vehicle violating a traffic rule and, by that, causing an accident. This would not only be devastating for a responsible operator, but more importantly, each such incident would erode the trust of the public in automated vehicles. Fortunately, compliance with traffic rules can be fully controlled, unless other traffic participants breach them—this causality obviously makes it possible for responsible operators to avoid liability claims. Traffic rules can be seen as guardrails for automated driving and should take center stage. Unfortunately, this is currently not the case. Many traffic rules are typically implicitly embedded in various fragments of the software stack of automated vehicles. Instead, the considered traffic rules should be explicitly and centrally provided. Adherence to traffic rules should also be ensured by formal methods to gain the trust needed in the public. This article provides all the steps required to achieve this goal. Due to the interdisciplinary nature of this topic (law, engineering, and computer science), we aim to address a broad audience by focusing on the governing principles of the presented methods, and we refer to more technical works for details.},
  archive      = {J_PIEEE},
  author       = {Matthias Althoff and Sebastian Maierhofer and Gerald Würsching and Yuanfei Lin and Florian Lercher and Roland Stolz},
  doi          = {10.1109/JPROC.2025.3570483},
  journal      = {Proceedings of the IEEE},
  month        = {6},
  pages        = {1-30},
  shortjournal = {Proc. IEEE},
  title        = {No more traffic tickets: A tutorial to ensure traffic-rule compliance of automated vehicles},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Digital phenotyping and feature extraction on smartphone data for depression detection. <em>PIEEE</em>, 1-26. (<a href='https://doi.org/10.1109/JPROC.2025.3542324'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smartphones are widely used as portable data collectors for wearable and healthcare sensors that can passively collect data streams related to the environment, health status, and behaviors. Recent research shows that the collected data can be used to monitor not only the physical states but also the mental health of individuals. However, extracting the features of digital phenotypes that characterize major depressive disorder (MDD) is technically challenging and may raise significant privacy concerns. Addressing such challenges has become the focus of many researchers. This article provides a comprehensive analysis of several key issues related to ubiquitous sensing to aid in detecting MDD. Specifically, this article analyzes existing methodologies and feature extraction algorithms used to detect possible MDD through digital phenotyping from smartphone data. In particular, five types of features are summarized and explained, namely, location, movement, rhythm, sleep, and social and device usage. Finally, related limitations and challenges are discussed to provide paths for further research and engineering.},
  archive      = {J_PIEEE},
  author       = {Minqiang Yang and Edith C. H. Ngai and Xiping Hu and Bin Hu and Jiangchuan Liu and Erol Gelenbe and Victor C. M. Leung},
  doi          = {10.1109/JPROC.2025.3542324},
  journal      = {Proceedings of the IEEE},
  month        = {3},
  pages        = {1-26},
  shortjournal = {Proc. IEEE},
  title        = {Digital phenotyping and feature extraction on smartphone data for depression detection},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncrewed vehicles in 6G networks: A unifying treatment of problems, formulations, and tools. <em>PIEEE</em>, 1-35. (<a href='https://doi.org/10.1109/JPROC.2025.3541949'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uncrewed vehicles (UVs) functioning as autonomous agents are anticipated to play a crucial role in the sixth generation (6G) of wireless networks. Their seamless integration, cost-effectiveness, and additional controllability through motion planning make them an attractive deployment option for a wide range of applications, both as assets in the network e.g., mobile base stations (BSs) and as consumers of network services (e.g., autonomous delivery systems). However, despite their potential, the convergence of UVs and wireless systems brings forth numerous challenges that require attention from both academia and industry. This article then aims to offer a comprehensive overview, encompassing the transformative possibilities as well as the significant challenges associated with UV-assisted next-generation wireless communications. Considering the diverse landscape of possible application scenarios, problem formulations, and mathematical tools related to UV-assisted wireless systems, the underlying core theme of this article is the unification of the problem space, providing a structured framework to understand the use cases, problem formulations, and necessary mathematical tools. Overall, this article sets forth a clear understanding of how UVs can be integrated in the 6G ecosystem, paving the way toward harnessing the full potential at this intersection.},
  archive      = {J_PIEEE},
  author       = {Winston Hurst and Spilios Evmorfos and Athina Petropulu and Yasamin Mostofi},
  doi          = {10.1109/JPROC.2025.3541949},
  journal      = {Proceedings of the IEEE},
  month        = {3},
  pages        = {1-35},
  shortjournal = {Proc. IEEE},
  title        = {Uncrewed vehicles in 6G networks: A unifying treatment of problems, formulations, and tools},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial general intelligence (AGI)-native wireless systems: A journey beyond 6G. <em>PIEEE</em>, 1-39. (<a href='https://doi.org/10.1109/JPROC.2025.3526887'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Building the next-generation wireless systems that could support services such as the metaverse, digital twins (DTs), and holographic teleportation is challenging to achieve exclusively through incremental advances to conventional wireless technologies like metasurfaces or holographic antennas. While the 6G concept of artificial intelligence (AI)-native networks promises to overcome some of the limitations of existing wireless technologies, current developments of AI-native wireless systems rely mostly on conventional AI tools such as auto-encoders and off-the-shelf artificial neural networks. However, those tools struggle to manage and cope with the complex, nontrivial scenarios faced in real-world wireless environments and the growing quality-of-experience (QoE) requirements of the aforementioned, emerging wireless use cases. In contrast, in this article, we propose to fundamentally revisit the concept of AI-native wireless systems, equipping them with the common sense necessary to transform them into artificial general intelligence (AGI)-native systems. Our envisioned AGI-native wireless systems acquire common sense by exploiting different cognitive abilities such as reasoning and analogy. These abilities in our proposed AGI-native wireless system are mainly founded on three fundamental components: a perception module, a world model, and an action-planning component. Collectively, these three fundamental components enable the four pillars of common sense that include dealing with unforeseen scenarios through horizontal generalizability, capturing intuitive physics, performing analogical reasoning, and filling in the blanks. Toward developing these components, we start by showing how the perception module can be built through abstracting real-world elements into generalizable representations. These representations are then used to create a world model, founded on principles of causality and hyperdimensional (HD) computing. Specifically, we propose a concrete definition of a world model, viewing it as an HD causal vector space that aligns with the intuitive physics of the real world—a cornerstone of common sense. In addition,we discuss how this proposed world model can enable analogical reasoning and manipulation of the abstract representations. Then, we show how the world model can drive an action-planning feature of the AGI-native network. In particular, we propose an intent-driven and objective-driven planning method that can maneuver the AGI-native network to plan its actions. These planning methods are based on brain-inspired frameworks such as integrated information theory and hierarchical abstractions that play a crucial role in enabling human-like decision-making. Next, we explain how an AGI-native network can be further exploited to enable three use cases related to human users and autonomous agent applications: 1) analogical reasoning for the next-generation DTs; 2) synchronized and resilient experiences for cognitive avatars; and 3) brain-level metaverse experiences exemplified by holographic teleportation. Finally, we conclude with a set of recommendations to ignite the quest for AGI-native systems. Ultimately, we envision this article as a roadmap for the next generation of wireless systems beyond 6G.},
  archive      = {J_PIEEE},
  author       = {Walid Saad and Omar Hashash and Christo Kurisummoottil Thomas and Christina Chaccour and Mérouane Debbah and Narayan Mandayam and Zhu Han},
  doi          = {10.1109/JPROC.2025.3526887},
  journal      = {Proceedings of the IEEE},
  month        = {3},
  pages        = {1-39},
  shortjournal = {Proc. IEEE},
  title        = {Artificial general intelligence (AGI)-native wireless systems: A journey beyond 6G},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning power flow models and constraints from time-synchronized measurements: A review. <em>PIEEE</em>, 1-32. (<a href='https://doi.org/10.1109/JPROC.2025.3548935'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Key operational and protection functions of power systems (e.g., optimal power flow scheduling and control, state estimation (SE), protection, and fault location) rely on the availability of models to represent the system’s behavior under different operating conditions. Power system models require knowledge of the components’ electrical parameters and the system topology. However, these data may be inaccurate for several reasons (e.g., inaccurate information of components datasheets and/or outdated topological information). The deployment of time synchronization in phasor measurement units (PMUs) and remote terminal units (RTUs) enables the collection of large datasets of synchronized measurements to infer power system models and learn associated power flow constraints. Within this context, this article presents a comprehensive review of measurement-based estimation methods for power flow models using time-synchronized measurements. It begins by exploring advancements in time dissemination technologies and the characterization of uncertainties in PMUs and instrument transformers (ITs), along with their implications for parameter estimation. This article then examines the power system parameter estimation problem, highlighting key techniques and methodologies. In the following, this article focuses on measurement models for state-independent power flow model estimation, including line parameters, admittance matrices, topology, and joint state-parameter estimation. Finally, this article discusses recent approaches for estimating state-dependent power flow models, with particular reference to linearized power flow approximations because of their large use in control applications.},
  archive      = {J_PIEEE},
  author       = {Rahul K. Gupta and Paolo Attilio Pegoraro and Ognjen Stanojev and Ali Abur and Carlo Muscas and Gabriela Hug and Mario Paolone},
  doi          = {10.1109/JPROC.2025.3548935},
  journal      = {Proceedings of the IEEE},
  month        = {3},
  pages        = {1-32},
  shortjournal = {Proc. IEEE},
  title        = {Learning power flow models and constraints from time-synchronized measurements: A review},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A vision, survey, and roadmap toward space communications in the 6G and beyond era. <em>PIEEE</em>, 1-37. (<a href='https://doi.org/10.1109/JPROC.2024.3512934'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Satellite communications (SatComs) have recently been through a renaissance, both technologically and entrepreneurially. Ambitious plans have already come into fruition with the operation of low-Earth orbit (LEO) constellations including thousands of satellites and supported by state of the art but proprietary technologies, such as active antenna arrays and intersatellite links (ISLs). In this context, this article aims to provide a forward-looking vision of use cases and a deep dive into technological enablers that will be prominent in space communications beyond 2030. In parallel, it motivates how open standards can play a role in delivering affordable communication services in space. Starting from the 5G plans for nonterrestrial networks, we provide a survey and roadmap toward artificial intelligence (AI)-supported satellite systems, space-enabled quantum networks, and joint communications and positioning (JCAP) for space missions and interplanetary exploration.},
  archive      = {J_PIEEE},
  author       = {Konstantinos Ntontin and Eva Lagunas and Jorge Querol and Junaid ur Rehman and Joel Grotz and Symeon Chatzinotas and Björn Ottersten},
  doi          = {10.1109/JPROC.2024.3512934},
  journal      = {Proceedings of the IEEE},
  month        = {1},
  pages        = {1-37},
  shortjournal = {Proc. IEEE},
  title        = {A vision, survey, and roadmap toward space communications in the 6G and beyond era},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantum information processing, sensing, and communications: Their myths, realities, and futures. <em>PIEEE</em>, 1-51. (<a href='https://doi.org/10.1109/JPROC.2024.3510394'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent advances in quantum information processing, sensing, and communications are surveyed with the objective of identifying the associated knowledge gaps and formulating a roadmap for their future evolution. Since the operation of quantum systems is prone to the deleterious effects of decoherence, which manifests itself in terms of bit-flips, phase-flips, or both, the pivotal subject of quantum error mitigation is reviewed both in the presence and absence of quantum coding. The state of the art, knowledge gaps, and future evolution of quantum machine learning (QML) are also discussed, followed by a discourse on quantum radar systems and briefly hypothesizing about the feasibility of integrated sensing and communications (ISAC) in the quantum domain (QD). Finally, we conclude with a set of promising future research ideas in the field of ultimately secure quantum communications with the objective of harnessing ideas from the classical communications field.},
  archive      = {J_PIEEE},
  author       = {Lajos Hanzo and Zunaira Babar and Zhenyu Cai and Daryus Chandra and Ivan B. Djordjevic and Balint Koczor and Soon Xin Ng and Mohsen Razavi and Osvaldo Simeone},
  doi          = {10.1109/JPROC.2024.3510394},
  journal      = {Proceedings of the IEEE},
  month        = {1},
  pages        = {1-51},
  shortjournal = {Proc. IEEE},
  title        = {Quantum information processing, sensing, and communications: Their myths, realities, and futures},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Federated edge learning for 6G: Foundations, methodologies, and applications. <em>PIEEE</em>, 1-39. (<a href='https://doi.org/10.1109/JPROC.2024.3509739'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI) is envisioned to be natively integrated into the sixth-generation (6G) mobile networks to support a diverse range of intelligent applications. Federated edge learning (FEEL) emerges as a vital enabler of this vision by leveraging the sensing, communication, and computation capabilities of geographically dispersed edge devices to collaboratively train AI models without sharing raw data. This article explores the pivotal role of FEEL in advancing both the “wireless for AI” and “AI for wireless” paradigms, thereby facilitating the realization of scalable, adaptive, and intelligent 6G networks. We begin with a comprehensive overview of learning architectures, models, and algorithms that form the foundations of FEEL. We, then, establish a novel task-oriented communication principle to examine key methodologies for deploying FEEL in dynamic and resource-constrained wireless environments, focusing on device scheduling, model compression, model aggregation, and resource allocation. Furthermore, we investigate the domain-specific optimizations of FEEL to facilitate its promising applications, ranging from wireless air-interface technologies to mobile and the Internet of Things (IoT) services. Finally, we highlight key future research directions for enhancing the design and impact of FEEL in 6G.},
  archive      = {J_PIEEE},
  author       = {Meixia Tao and Yong Zhou and Yuanming Shi and Jianmin Lu and Shuguang Cui and Jianhua Lu and Khaled B. Letaief},
  doi          = {10.1109/JPROC.2024.3509739},
  journal      = {Proceedings of the IEEE},
  month        = {12},
  pages        = {1-39},
  shortjournal = {Proc. IEEE},
  title        = {Federated edge learning for 6G: Foundations, methodologies, and applications},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Wireless 6G connectivity for massive number of devices and critical services. <em>PIEEE</em>, 1-23. (<a href='https://doi.org/10.1109/JPROC.2024.3484529'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared to the generations up to 4G, whose main focus was on broadband and coverage aspects, 5G has expanded the scope of wireless cellular systems toward embracing two new types of connectivity: massive machine-type communications (mMTCs) and ultrareliable low-latency communications (URLLCs). This article discusses the possible evolution of these two types of connectivity within the umbrella of 6G wireless systems. This article consists of three parts. The first part deals with the connectivity for a massive number of devices. While mMTC research in 5G predominantly focuses on the problem of uncoordinated access in the uplink for a large number of devices, the traffic patterns in 6G may become more symmetric, leading to closed-loop massive connectivity. One of the drivers for this type of traffic pattern is distributed/decentralized learning and inference. The second part of this article discusses the evolution of wireless connectivity for critical services. While latency and reliability are tightly coupled in 5G, 6G will support a variety of safety-critical control applications with different types of timing requirements, as evidenced by the emergence of metrics related to information freshness and information value. In addition, ensuring ultrahigh reliability for safety-critical control applications requires modeling and estimation of the tail statistics of the wireless channel, queue length, and delay. The fulfillment of these stringent requirements calls for the development of novel artificial intelligence (AI)-based techniques, incorporating optimization theory, explainable AI (XAI), generative AI, and digital twins (DTs). The third part analyzes the coexistence of massive connectivity and critical services. Specifically, we consider scenarios in which a massive number of devices need to support traffic patterns of mixed criticality. This is followed by a discussion about the management of wireless resources shared by services with different criticality.},
  archive      = {J_PIEEE},
  author       = {Anders E. Kalor and Giuseppe Durisi and Sinem Coleri and Stefan Parkvall and Wei Yu and Andreas Mueller and Petar Popovski},
  doi          = {10.1109/JPROC.2024.3484529},
  journal      = {Proceedings of the IEEE},
  month        = {11},
  pages        = {1-23},
  shortjournal = {Proc. IEEE},
  title        = {Wireless 6G connectivity for massive number of devices and critical services},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Joint Source–Channel coding: Fundamentals and recent progress in practical designs. <em>PIEEE</em>, 1-32. (<a href='https://doi.org/10.1109/JPROC.2024.3477331'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic-and task-oriented communication has emerged as a promising approach to reducing the latency and bandwidth requirements of the next-generation mobile networks by transmitting only the most relevant information needed to complete a specific task at the receiver. This is particularly advantageous for machine-oriented communication of high-data-rate content, such as images and videos, where the goal is rapid and accurate inference, rather than perfect signal reconstruction. While semantic-and task-oriented compression can be implemented in conventional communication systems, joint source–channel coding (JSCC) offers an alternative end-to-end approach by optimizing compression and channel coding together, or even directly mapping the source signal to the modulated waveform. Although all digital communication systems today rely on separation, thanks to its modularity, JSCC is known to achieve higher performance in finite blocklength scenarios and to avoid cliff and the leveling-off effects in time-varying channel scenarios. This article provides an overview of the information theoretic foundations of JSCC, surveys practical JSCC designs over the decades, and discusses the reasons for their limited adoption in practical systems. We then examine the recent resurgence of JSCC, driven by the integration of deep learning techniques, particularly through DeepJSCC, highlighting its many surprising advantages in various scenarios. Finally, we discuss why it may be time to reconsider today’s strictly separate architectures and reintroduce JSCC to enable high-fidelity, low-latency communications in critical applications such as autonomous driving, drone surveillance, or wearable systems.},
  archive      = {J_PIEEE},
  author       = {Deniz Gündüz and Michèle A. Wigger and Tze-Yang Tung and Ping Zhang and Yong Xiao},
  doi          = {10.1109/JPROC.2024.3477331},
  journal      = {Proceedings of the IEEE},
  month        = {11},
  pages        = {1-32},
  shortjournal = {Proc. IEEE},
  title        = {Joint Source–Channel coding: Fundamentals and recent progress in practical designs},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The evolution of applications, hardware design, and channel modeling for terahertz (THz) band communications and sensing: Ready for 6G?. <em>PIEEE</em>, 1-32. (<a href='https://doi.org/10.1109/JPROC.2024.3412828'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For decades, the terahertz (THz) frequency band had been primarily explored in the context of radar, imaging, and spectroscopy, where multi-gigahertz (GHz) and even THz-wide channels and the properties of THz photons offered attractive target accuracy, resolution, and classification capabilities. Meanwhile, the exploitation of the THz band for wireless communication had originally been limited due to several reasons:1) no immediate need for such high data rates available via THz bands and 2) challenges in designing sufficiently high-power THz systems at reasonable cost and efficiency, leading to what was often referred to as “the THz gap.” Over the recent decade, advances on many fronts have drastically changed the THz landscape. First, the evolution from 5G-to 6G-grade wireless systems dictates the need to support novel bandwidth-hungry applications and services for both data transfer i.e., eXtended Reality (XR), the Metaverse, and vast modeling needs of artificial intelligence (AI) and machine learning (ML), as well as centimeter-precision sensing and classification (i.e., for standalone position location, vehicle-to-everything (V2X), or unmanned aerial vehicle (UAV) tracking). Second, substantial progress in THz hardware has been achieved, offering promise that the THz technology gap will be closed. Hence, THz-band wireless communication seems inevitably an essential part of the future networking technology landscape in the coming decades. To design efficient THz systems, the peculiarities of THz hardware and THz channels need to be understood and accounted for. This roadmap paper first reviews the evolution of the hardware design approaches for THz systems, including electronic, photonic, and plasmonic approaches, and the understanding of the THz channel itself, in diverse scenarios, ranging from common indoors and outdoors scenarios to intrabody and outer space environments. This article then summarizes the lessons learned during this multidecade process and the cutting-edge state-of-the-art findings, including novel methods to quantify power efficiency, which will become more important in making design choices. Finally, this article presents the authors’ perspective and insights on how the evolution of THz systems design will continue toward enabling efficient THz communications and sensing solutions as an integral part of next-generation wireless systems.},
  archive      = {J_PIEEE},
  author       = {Josep M. Jornet and Vitaly Petrov and Hua Wang and Zoya Popović and Dipankar Shakya and Jose V. Siles and Theodore S. Rappaport},
  doi          = {10.1109/JPROC.2024.3412828},
  journal      = {Proceedings of the IEEE},
  month        = {7},
  pages        = {1-32},
  shortjournal = {Proc. IEEE},
  title        = {The evolution of applications, hardware design, and channel modeling for terahertz (THz) band communications and sensing: Ready for 6G?},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
