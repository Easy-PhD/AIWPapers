<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TROB</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="trob">TROB - 21</h2>
<ul>
<li><details>
<summary>
(2025). Integration of robot and scene kinematics for sequential mobile manipulation planning. <em>TROB</em>, 1-20. (<a href='https://doi.org/10.1109/TRO.2025.3605261'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a Sequential Mobile Manipulation Planning (SMMP) framework that can solve long-horizon multi-step mobile manipulation tasks with coordinated whole-body motion, even when interacting with articulated objects. By abstracting environmental structures as kinematic models and integrating them with the robot's kinematics, we construct an Augmented Configuration Apace (A-Space) that unifies the previously separate task constraints for navigation and manipulation, while accounting for the joint reachability of the robot base, arm, and manipulated objects. This integration facilitates efficient planning within a tri-level framework: a task planner generates symbolic action sequences to model the evolution of A-Space, an optimization-based motion planner computes continuous trajectories within A-Space to achieve desired configurations for both the robot and scene elements, and an intermediate plan refinement stage selects action goals that ensure long-horizon feasibility. Our simulation studies first confirm that planning in A-Space achieves an 84.6% higher task success rate compared to baseline methods. Validation on real robotic systems demonstrates fluid mobile manipulation involving (i) seven types of rigid and articulated objects across 17 distinct contexts, and (ii) long-horizon tasks of up to 14 sequential steps. Our results highlight the significance of modeling scene kinematics into planning entities, rather than encoding task-specific constraints, offering a scalable and generalizable approach to complex robotic manipulation.},
  archive      = {J_TROB},
  author       = {Ziyuan Jiao and Yida Niu and Zeyu Zhang and Yangyang Wu and Yao Su and Yixin Zhu and Hangxin Liu and Song-Chun Zhu},
  doi          = {10.1109/TRO.2025.3605261},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {1-20},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Integration of robot and scene kinematics for sequential mobile manipulation planning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design, modeling, and experiment of a 3-DoF miniature plate piezoelectric robot. <em>TROB</em>, 1-20. (<a href='https://doi.org/10.1109/TRO.2025.3605254'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The piezoelectric plate robot driven by traveling waves (TWs) boasts a compact structure and excellent load-bearing capacity. However, vibration coupling across the plate restricts its freedom of movement, along with issues such as poor straight-line motion and a large turning radius. Inspired by octopus locomotion, we designed a three-degree-of-freedom (3-DoF) piezoelectric plate robot using a 0.7 mm metal plate. Through drive region division and dynamic modeling, our design achieves fully controllable motion in any planar direction, providing the highest DoF among TW driven plate robots. Weighing just 14.2g, it is lighter and easier to fabricate compared to other 3-DoF piezoelectric robots. The robot demonstrated 3-DoF movement capabilities, climbing (16.5°), dragging (20 g), and carrying (180 g), and can bear over 5,000 times its own body weight. A wireless drive prototype with closed-loop control reduced trajectory errors by more than 80% compared to open-loop control. Experiments involving high-curvature path movement, confined-space “search and rescue” and light focusing highlight its potential in extreme environments and high-precision tasks.},
  archive      = {J_TROB},
  author       = {Yuanshuai Ding and Yongmao Pei},
  doi          = {10.1109/TRO.2025.3605254},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {1-20},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Design, modeling, and experiment of a 3-DoF miniature plate piezoelectric robot},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RUMI: Rummaging using mutual information. <em>TROB</em>, 1-20. (<a href='https://doi.org/10.1109/TRO.2025.3605251'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents Rummaging Using Mutual Information (RUMI), a method for online generation of robot action sequences to gather information about the pose of a known movable object in visually-occluded environments. Focusing on contact-rich rummaging, our approach leverages mutual information between the object pose distribution and robot trajectory for action planning. From an observed partial point cloud, RUMI deduces the compatible object pose distribution and approximates the mutual information of it with workspace occupancy in real time. Based on this, we develop an information gain cost function and a reachability cost function to keep the object within the robot's reach. These are integrated into a model predictive control (MPC) framework with a stochastic dynamics model, updating the pose distribution in a closed loop. Key contributions include a new belief framework for object pose estimation, an efficient information gain computation strategy, and a robust MPC-based control scheme. RUMI demonstrates superior performance in both simulated and real tasks compared to baseline methods.},
  archive      = {J_TROB},
  author       = {Sheng Zhong and Nima Fazeli and Dmitry Berenson},
  doi          = {10.1109/TRO.2025.3605251},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {1-20},
  shortjournal = {IEEE Trans. Robot.},
  title        = {RUMI: Rummaging using mutual information},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tip-growing robots: Design, theory, application. <em>TROB</em>, 1-20. (<a href='https://doi.org/10.1109/TRO.2025.3608701'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Growing robots apically extend through material eversion or deposition at their tip. This endows them with unique capabilities such as follow the leader navigation, long-reach, inherent compliance, and large force delivery bandwidth. Tip-growing robots can therefore conform to sensitive, intricate, and difficult-to-access environments. This review paper categorizes, compares, and critically evaluates state-of-the-art growing robots with emphasis on their designs, fabrication processes, actuation and steering mechanisms, mechanics models, controllers, and applications. Finally, the paper discusses the main challenges that the research area still faces and proposes future directions.},
  archive      = {J_TROB},
  author       = {Shamsa Al Harthy and S.M.Hadi Sadati and Cédric Girerd and Sukjun Kim and Alessio Mondini and Zicong Wu and Brandon Saldarriaga and Carlo A. Seneci and Barbara Mazzolai and Tania K. Morimoto and Christos Bergeles},
  doi          = {10.1109/TRO.2025.3608701},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {1-20},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Tip-growing robots: Design, theory, application},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Curb-tracker: An integrated curb following system for autonomous vehicles. <em>TROB</em>, 1-20. (<a href='https://doi.org/10.1109/TRO.2025.3608695'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Curb following is a critical technology for autonomous road sweeping vehicles. However, existing solutions face two primary challenges: unreliable curb detection and inefficient motion generation. Unreliable curb detection stems from the wide variability in curb dimensions and types, as well as interference from roadside features such as vegetation and infrastructure. Inefficient motion generation occurs when existing methods prioritize tracking accuracy while neglecting task completion efficiency, leading to prolonged operation times. To address these challenges, we propose Curb-Tracker, an integrated curb-following system designed for autonomous vehicles operating in diverse road environments. Firstly, we develop a robust and adaptive curb detection algorithm that leverages a 2.5D elevation map of the local environment and dynamically adjusts key parameters online to ensure reliable detection across varying scenarios. Secondly, to achieve accurate and efficient curb-aligned motion generation, we leverage Model Predictive Contouring Control (MPCC) as a tailored framework specifically designed for the curb-following task to generate an optimal control sequence for the vehicle to maintain a specified lateral offset from the curb while maximizing travel progress along it. The proposed system has been implemented on a Hunter 2.0, a front-wheel Ackerman-steering mobile robot, and has been validated through extensive experiments in both Gazebo simulation and real-world environments. Experimental results demonstrate the effectiveness, adaptability, and robustness of the proposed system across a wide range of road scenarios. Video of real-world experiments is available at https://youtu.be/H1xaV6QdJ10.},
  archive      = {J_TROB},
  author       = {Jiahao Liang and Yuanzhe Wang and Guohao Peng and Zhenyu Wu and Danwei Wang},
  doi          = {10.1109/TRO.2025.3608695},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {1-20},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Curb-tracker: An integrated curb following system for autonomous vehicles},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tactile robotics: An outlook. <em>TROB</em>, 1-20. (<a href='https://doi.org/10.1109/TRO.2025.3608686'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotics research has long sought to give robots the ability to perceive the physical world through touch in an analogous manner to many biological systems. Developing such tactile capabilities is important for numerous emerging applications that require robots to co-exist and interact closely with humans. Consequently, there has been growing interest in tactile sensing, leading to the development of various technologies, including piezoresistive and piezoelectric sensors, capacitive sensors, magnetic sensors, and optical tactile sensors. These diverse approaches utilise different transduction methods and materials to equip robots with distributed sensing capabilities, enabling more effective physical interactions. These advances have been supported in recent years by simulation tools that generate largescale tactile datasets to support sensor designs and algorithms to interpret and improve the utility of tactile data. The integration of tactile sensing with other modalities, such as vision, as well as with action strategies for active tactile perception highlights the growing scope of this field. To further the transformative progress in tactile robotics, a holistic approach is essential. In this outlook article, we examine several challenges associated with the current state of the art in tactile robotics and explore potential solutions to inspire innovations across multiple domains, including manufacturing, healthcare, recycling and agriculture.},
  archive      = {J_TROB},
  author       = {Shan Luo and Nathan F. Lepora and Wenzhen Yuan and Kaspar Althoefer and Gordon Cheng and Ravinder Dahiya},
  doi          = {10.1109/TRO.2025.3608686},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {1-20},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Tactile robotics: An outlook},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quasi-dynamic crowd vetting: Collaborative detection of malicious robots in dynamic communication networks. <em>TROB</em>, 1-17. (<a href='https://doi.org/10.1109/TRO.2025.3608702'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We are interested in the problem where robots traverse through an environment modeled by a graph of discrete sites, and an unknown subset of the multi-robot team is malicious. Previous works require that each robot gathers information about the trustworthiness of all other robots, called trust observations, which can be time consuming in large networks. This paper decreases the time required to estimate trustworthiness by building upon an algorithm that leverages the concept of ‘Crowd Vetting’ and the opinion of trusted neighbors. This allows each robot to estimate trust in dynamic scenarios, where the team size, robot neighborhoods, and robot legitimacy can change. In particular, we employ an assumption that there exists quasi-dynamic time periods, where if a robot's legitimacy remains fixed for a sufficient length of time, its trustworthiness can be characterized. In this setting, we develop a closed-form expression for the critical number of time-steps required for our algorithm to successfully identify the true legitimacy of each robot within a specified failure probability. We show that the number of time-steps required for robots to correctly estimate the trust of all other robots increases logarithmically with the number of robots when robots do not leverage neighboring opinions, called the Direct Protocol. Conversely, for most general graph topologies, the number of time-steps required remains constant as the number of robots increases when our proposed algorithm, called quasi-Dynamic Crowd Vetting (DCV), is used, for a fixed ratio of legitimate to malicious robots. Finally, our theoretical results are successfully validated through simulated persistent surveillance tasks where robots maintain a desired distribution of robots over sites in the environment.},
  archive      = {J_TROB},
  author       = {Matthew Cavorsi and Frederik Mallmann-Trenn and David Saldaña and Stephanie Gil},
  doi          = {10.1109/TRO.2025.3608702},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {1-17},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Quasi-dynamic crowd vetting: Collaborative detection of malicious robots in dynamic communication networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Plan optimal collision-free trajectories with non-convex cost functions using graphs of convex sets. <em>TROB</em>, 1-20. (<a href='https://doi.org/10.1109/TRO.2025.3610175'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recently developed approach to motion planning in Graphs of Convex Sets (GCS) provides an efficient framework for computing shortest-distance collision-free paths using convex optimization. This new motion planner is notably more computationally efficient than popular sampling-based motion planners, but it does not support non-convex cost functions. This paper develops a novel motion planning algorithm, Graph of Convex Sets with General Costs (GCSGC), to solve this problem. A given non-convex cost function is accurately approximated by a multiple-layer ReLU neural network and the configuration space is decomposed into a set of linear-cost regions using the hidden layers of the neural network. These linear-cost regions are intersected with a set of collision-free regions, and the resulting collision-free linear-cost regions are intersected to form the vertices and edges of the motion planner's underlying graph structure. The edge costs have a closed-form solution within each collision-free linear-cost region, but it is non-convex, so the McCormick relaxation is applied to convexify the edge costs. Finally, a graph pre-processing technique is developed to compute a representative graph structure that acts as a heuristic for the edge costs of the underlying GCS and then simplify the underlying graph structure by removing cycles and high-cost paths, which can significantly improve the efficiency of the planner and quality of the produced trajectories. The proposed motion planner is first validated in a 2D configuration space with comparisons between different sized neural networks with and without pre-processing, comparisons between optimal trajectories from GCSGC with shortest-distance trajectories, and comparisons between GCSGC and GCS-SLP. The GCSGC planner is further validated in a complex 7D configuration space by comparing to state-of-the-art multi-query (PRM*, GCS-SLP) and single-query (TrajOpt, BIT*, AIT*, RRT*) planners. The results show that the proposed motion planner is very competitive in terms of computational efficiency, trajectory cost, and memory footprint. Two physical experiments further validate the effectiveness of the proposed motion planner in real-world motion planning applications.},
  archive      = {J_TROB},
  author       = {Charles L. Clark and Biyun Xie},
  doi          = {10.1109/TRO.2025.3610175},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {1-20},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Plan optimal collision-free trajectories with non-convex cost functions using graphs of convex sets},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unilateral active knee exoskeleton to assist individuals with hemiparesis – A pilot study. <em>TROB</em>, 1-14. (<a href='https://doi.org/10.1109/TRO.2025.3610187'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most individuals who experience a stroke exhibit several sensorimotor impairments that limit their independence in everyday activities. Hemiparetic gait is frequently characterized by reduced knee flexion in swing due to knee stiffness or muscle weakness and knee hyperextension or knee buckling in the stance phase. Recently, unilateral-powered orthoses have been designed to overcome the limitations of the passive knee-ankle-foot orthoses. This study presents a unilateral Active Knee Orthosis Exoskeleton, AKO-$\beta$, endowed with a series elastic actuator and designed to assist the knee in flexion and extension movements. The paper describes the system mechatronic design and its characterization on the bench, the control system, and pilot experiments with three post-stroke participants. The device has a weight of 1.78 kg on the user's leg, with a lateral encumbrance of 76 mm. The pilot experiments aimed to verify the effects of the exoskeleton assistance in hemiparetic gait patterns. When walking with the device, participants on average increased the knee flexion on the paretic side by 18.70 deg (+44.9%) during swing and decreased knee hyperextension in stance by 4.50 deg, compared to walking without it. Overall, when walking with the exoskeleton, subjects showed improved Gait Variable Score of the paretic knee profile by 37.5% compared to walking without it. The temporal and spatial gait symmetry indexes did not show clear changes, although an improvement in symmetry was observed in two of the three participants. These preliminary results suggest the potential benefits of the unilateral Active Knee Orthosis exoskeleton to enhance and restore mobility in individuals with hemiparetic gait.},
  archive      = {J_TROB},
  author       = {Andrea Pergolini and Clara Beatriz Sanz-Morère and Chiara Livolsi and Matteo Fantozzi and Filippo Dell'Agnello and Tommaso Ciapetti and Alessandro Maselli and Andrea Baldoni and Emilio Trigili and Simona Crea and Nicola Vitiello},
  doi          = {10.1109/TRO.2025.3610187},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A unilateral active knee exoskeleton to assist individuals with hemiparesis – A pilot study},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Anytime probabilistically constrained provably convergent online belief space planning. <em>TROB</em>, 1-20. (<a href='https://doi.org/10.1109/TRO.2025.3610176'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Taking into account future risk is essential for an autonomously operating robot to find online not only the best but also a safe action to execute. In this paper, we build upon the recently introduced formulation of probabilistic belief-dependent constraints. In our methodology safety can be materialized with any general belief-dependent operator we call payoff. We present an anytime approach employing the Monte Carlo Tree Search (MCTS) method in continuous domains in terms of states, actions and observations and general-belief dependent reward and payoff operators. Unlike previous approaches, our method ensures safety anytime with respect to the currently expanded search tree without relying on the convergence of the search. We prove convergence in probability with an exponential rate of a version of our algorithms and study proposed techniques via extensive simulations. Even with a tiny number of tree queries, the best action found by our approach is much safer than the baseline. Moreover, our approach constantly yields better than the baseline action in terms of objective function. This is because we revise the values and statistics maintained in the search tree and remove from them the contribution of the pruned actions. We rigorously show that our cleaning routine is necessary. Without it, at the limit of convergence of MCTS, an infinite amount of sampled dangerous actions can be detrimental to the objective function.},
  archive      = {J_TROB},
  author       = {Andrey Zhitnikov and Vadim Indelman},
  doi          = {10.1109/TRO.2025.3610176},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {1-20},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Anytime probabilistically constrained provably convergent online belief space planning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High-efficiency vector field by time-optimal spatial iterative learning. <em>TROB</em>, 1-20. (<a href='https://doi.org/10.1109/TRO.2025.3610174'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel model-free spatial iterative learning (IL) framework to enhance the efficiency of vector field (VF) navigation for mobile robots. By integrating the idea of iterative learning control (ILC) with VF, this framework utilizes historical data to enhance navigation efficiency significantly, reducing traversal time and expanding the applicability of IL to rapid navigation. Importantly, it has low time complexity with $O(n)$ per iteration, where $n$ denotes the waypoints number, preventing the significant computational overhead caused by the increasing waypoints in existing methods, which often exceeds $O(n^{2})$, making it well-suited for real-time planning. Moreover, the approach is inherently model-free, leaning on historical data, thus enabling agile navigation with limited reliance on intricate model details. The paper presents a comprehensive theoretical analysis of the stability, time optimality, time complexity, parameter insensitivity, robustness, and usage. Extensive simulations and experiments highlight its efficiency, promising a transformative impact on mobile robot navigation through the proposed IL.},
  archive      = {J_TROB},
  author       = {Shuli Lv and Yan Gao and Quan Quan},
  doi          = {10.1109/TRO.2025.3610174},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {1-20},
  shortjournal = {IEEE Trans. Robot.},
  title        = {High-efficiency vector field by time-optimal spatial iterative learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predictive body awareness in soft robots: A bayesian variational autoencoder fusing multimodal sensory data. <em>TROB</em>, 1-16. (<a href='https://doi.org/10.1109/TRO.2025.3610170'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting the causal flow by fusing multimodal perception is fundamental for constructing the bodily awareness of soft robots. However, forming such a predictive model while fusing the multimodal sensory data of soft robots remains challenging and less explored. In this study, we leverage the free energy principle within a Bayesian probabilistic deep learning framework to merge visual, pressure, and flex sensing signals. Our proposed multimodal association mechanism enhances the fusion process, establishing a robust computational methodology. We train the model using a newly collected dataset that captures the grasping dynamics of a soft gripper equipped with multimodal perception capabilities. By incorporating the current state and image differences, the forward model can predict the soft gripper's physical interaction and movement in the image flow, which amounts to imagining future motion events. Moreover, we showcase effective predictions across modalities as well as for grasping outcomes. Notably, our enhanced variational autoencoder approach can pave the way for unprecedented possibilities of bodily awareness in soft robotics.},
  archive      = {J_TROB},
  author       = {Shuyu Wang and Dongling Liu and Changzeng Fu and Xiaoming Yuan and Peng Shan and Victor C.M. Leung},
  doi          = {10.1109/TRO.2025.3610170},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Predictive body awareness in soft robots: A bayesian variational autoencoder fusing multimodal sensory data},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards accurate, efficient and robust RGB-D simultaneous localization and mapping in challenging environments. <em>TROB</em>, 1-20. (<a href='https://doi.org/10.1109/TRO.2025.3610173'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual Simultaneous Localization and Mapping (SLAM) is crucial to many applications such as self-driving vehicles and robot tasks. However, it is still challenging for existing visual SLAM approaches to achieve good performance in low-texture or illumination-changing scenes. In recent years, some researchers have turned to edge-based SLAM approaches to deal with the challenging scenes, which are more robust than feature-based and direct SLAM methods. Nevertheless, existing edge-based methods are computationally expensive and inferior than other visual SLAM systems in terms of accuracy. In this study, we propose EdgeSLAM, a novel RGB-D edge-based SLAM approach to deal with challenging scenarios that is efficient, accurate, and robust. EdgeSLAM is built on two innovative modules: efficient edge selection and adaptive robust motion estimation. The edge selection module can efficiently select a small set of edge pixels, which significantly improves the computational efficiency without sacrificing the accuracy. The motion estimation module improves the system's accuracy and robustness by adaptively handling outliers in motion estimation. Extensive experiments were conducted on TUM RGBD, ICL-NUIM and ETH3D datasets, and experimental results show that EdgeSLAM significantly outperforms five state-of-the-art (SOTA) methods in terms of efficiency, accuracy, and robustness, which achieves 29.17% accuracy improvements with a high processing speed of up to 120 FPS and a high positioning success rate of 97.06%.},
  archive      = {J_TROB},
  author       = {Hui Zhao and Fuqiang Gu and Jianga Shang and Xianlei Long and Jiarui Dou and Chao Chen and Huayan Pu and Jun Luo},
  doi          = {10.1109/TRO.2025.3610173},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {1-20},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Towards accurate, efficient and robust RGB-D simultaneous localization and mapping in challenging environments},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Time-varying foot placement control for humanoid walking on swaying rigid surface. <em>TROB</em>, 1-20. (<a href='https://doi.org/10.1109/TRO.2025.3612326'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Locomotion on dynamic rigid surface (i.e., rigid surface accelerating in an inertial frame) presents complex challenges for controller design, which are essential to address for deploying humanoid robots in dynamic real-world environments such as moving trains, ships, and airplanes. This paper introduces a real-time, provably stabilizing control approach for humanoid walking on periodically swaying rigid surface. The first key contribution is an analytical extension of the classical angular momentum-based linear inverted pendulum model from static to swaying grounds whose motion period may be different than the robot's gait period. This extension results in a time-varying, nonhomogeneous robot model, which is fundamentally different from the existing pendulum models. We synthesize a discrete footstep control law for the model and derive a new set of sufficient stability conditions that verify the controller's stabilizing effect. Finally, experiments conducted on a Digit humanoid robot, both in simulations and on hardware, demonstrate the framework's effectiveness in addressing bipedal locomotion on swaying ground, even under uncertain surface motions and unknown external pushes.},
  archive      = {J_TROB},
  author       = {Yuan Gao and Victor Paredes and Yukai Gong and Zijian He and Ayonga Hereid and Yan Gu},
  doi          = {10.1109/TRO.2025.3612326},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {1-20},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Time-varying foot placement control for humanoid walking on swaying rigid surface},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatio-temporal motion retargeting for quadruped robots. <em>TROB</em>, 1-20. (<a href='https://doi.org/10.1109/TRO.2025.3600123'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents a motion retargeting approach for legged robots, aimed at transferring the dynamic and agile movements to robots from source motions. In particular, we guide the imitation learning procedures by transferring motions from source to target, effectively bridging the morphological disparities while ensuring the physical feasibility of the target system. In the first stage, we focus on motion retargeting at the kinematic level by generating kinematically feasible whole-body motions from keypoint trajectories. Following this, we refine the motion at the dynamic level by adjusting it in the temporal domain while adhering to physical constraints. This process facilitates policy training via reinforcement learning, enabling precise and robust motion tracking. We demonstrate that our approach successfully transforms noisy motion sources, such as hand-held camera videos, into robot-specific motions that align with the morphology and physical properties of the target robots. Moreover, we demonstrate terrain-aware motion retargeting to perform BackFlip on top of a box. We successfully deployed these skills to four robots with different dimensions and physical properties in the real world through hardware experiments.},
  archive      = {J_TROB},
  author       = {Taerim Yoon and Dongho Kang and Seungmin Kim and Jin Cheng and Minsung Ahn and Stelian Coros and Sungjoon Choi},
  doi          = {10.1109/TRO.2025.3600123},
  journal      = {IEEE Transactions on Robotics},
  month        = {8},
  pages        = {1-20},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Spatio-temporal motion retargeting for quadruped robots},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust and scalable multi-robot localization using stereo UWB arrays. <em>TROB</em>, 1-18. (<a href='https://doi.org/10.1109/TRO.2025.3587854'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In environments where robots operate with limited global navigation satellite system accessibility, ultra-wideband (UWB) localization technology is a popular auxiliary solution to assist visual.inertial odometry systems. However, current UWB approaches lack 3D pairwise localization capability and suffer from rapidly declining localization update rates as the network scales, limiting their effectiveness for swarm robotic applications. This paper presents a novel UWB sensor that enables 3D pairwise localization and a localization scheme that can deliver robust, scalable, and accurate position awareness for multi-robot systems. Our approach begins with calibrating intrinsic UWB errors from hardware deviations and propagation effects, yielding high-accuracy distance and direction measurements. Using these measurements, we perform distributed relative localization through inter- and intra-node cooperation by integrating UWB and inertial measurement unit data. To enable swarm-scale operation, our platform implements the signal-multiplexing network ranging (SM-NR) protocol to maximize update rates and network capacity. Experimental results show that our approach achieves centimeter-level localization accuracy at high update rates (100 Hz for UWB only), validating its robustness, scalability, and accuracy for robotic applications.},
  archive      = {J_TROB},
  author       = {Hanying Zhao and Lingwei Xu and Yi Li and Feiyang Wen and Haoran Gao and Changwu Liu and Jincheng Yu and Yu Wang and Yuan Shen},
  doi          = {10.1109/TRO.2025.3587854},
  journal      = {IEEE Transactions on Robotics},
  month        = {7},
  pages        = {1-18},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Robust and scalable multi-robot localization using stereo UWB arrays},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). 3D-printable crease-free origami vacuum bending actuators for soft robots. <em>TROB</em>, 1-15. (<a href='https://doi.org/10.1109/TRO.2025.3588726'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While vacuum-based bending actuation offers benefits such as safety and compactness in soft robotics, it is often overlooked due to its limited actuation pressure, which restricts both bending angle and force output. This study presents a crease-free, origami-inspired vacuum bending actuator that advances both state-of-the-art vacuum bending actuators and traditional origami deformation principles by introducing orderly self-folding through optimized stiffness distribution. Achieved through finite element method (FEM), this design provides several advantages: (i) Self-folding allows for high bending angles (up to 138$^{\circ }$) in a compact form. (ii) The crease-free design facilitates 3D printing from a single soft material using a consumer-level fused filament fabrication (FFF) printer, specifically thermoplastic polyurethane (TPU) with a Shore hardness of 60A, potentially higher flexibility and durability. (iii) The compact configuration enables modular design, supporting reconfiguration as demonstrated in adaptable locomotion soft robots. (iv) The large bending angles allow the actuator to wrap around objects, offering extensive contact compared to other designs. This capability, combined with its vacuum-driven mechanism, enables synergy with self-closing suction cups in an octopus-like vacuum gripper, providing large versatility and grasping force for handling a wide range of objects, from small, irregular shapes to larger, flat items.},
  archive      = {J_TROB},
  author       = {Zhanwei Wang and Huaijin Chen and Syeda Shadab Zehra Zaidi and Ellen Roels and Hendrik Cools and Bram Vanderborght and Seppe Terryn},
  doi          = {10.1109/TRO.2025.3588726},
  journal      = {IEEE Transactions on Robotics},
  month        = {7},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Robot.},
  title        = {3D-printable crease-free origami vacuum bending actuators for soft robots},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-level similarity approach for single-view object grasping: Matching, planning, and fine-tuning. <em>TROB</em>, 1-19. (<a href='https://doi.org/10.1109/TRO.2025.3588720'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Grasping unknown objects from a single view has remained a challenging topic in robotics due to the uncertainty of partial observation. Recent advances in large-scale models have led to benchmark solutions such as GraspNet-1Billion. However, such learning-based approaches still face a critical limitation in performance robustness for their sensitivity to sensing noise and environmental changes. To address this bottleneck in achieving highly generalized grasping, we abandon the traditional learning framework and introduce a new perspective: similarity matching, where similar known objects are utilized to guide the grasping of unknown target objects. We newly propose a method that robustly achieves unknown-object grasping from a single viewpoint through three key steps: 1) Leverage the visual features of the observed object to perform similarity matching with an existing database containing various object models, identifying potential candidates with high similarity; 2) Use the candidate models with pre-existing grasping knowledge to plan imitative grasps for the unknown target object; 3) Optimize the grasp quality through a local fine-tuning process. To address the uncertainty caused by partial and noisy observation, we propose a multi-level similarity matching framework that integrates semantic, geometric, and dimensional features for comprehensive evaluation. Especially, we introduce a novel point cloud geometric descriptor, the C-FPFH descriptor, which facilitates accurate similarity assessment between partial point clouds of observed objects and complete point clouds of database models. In addition, we incorporate the use of large language models, introduce the semi-oriented bounding box, and develop a novel point cloud registration approach based on plane detection to enhance matching accuracy under single-view conditions. Real-world experiments demonstrate that our proposed method significantly outperforms existing benchmarks in grasping a wide variety of unknown objects in both isolated and cluttered scenarios, showcasing exceptional robustness across varying object types and operating environments.},
  archive      = {J_TROB},
  author       = {Hao Chen and Takuya Kiyokawa and Zhengtao Hu and Weiwei Wan and Kensuke Harada},
  doi          = {10.1109/TRO.2025.3588720},
  journal      = {IEEE Transactions on Robotics},
  month        = {7},
  pages        = {1-19},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A multi-level similarity approach for single-view object grasping: Matching, planning, and fine-tuning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A propagation perspective on recursive forward dynamics for systems with kinematic loops. <em>TROB</em>, 1-20. (<a href='https://doi.org/10.1109/TRO.2025.3593081'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We revisit the concept of constraint embedding as a means for dealing with kinematic loop constraints during dynamics computations for rigid-body systems. Specifically, we consider the local loop constraints emerging from common actuation sub-mechanisms in modern robotics systems (e.g., geared motors, differential drives, and four-bar mechanisms). As a complementary perspective to prior work on constraint embedding, we present an analysis that generalizes the traditional concepts of joint models and motion/force subspaces between individual rigid bodies to generalized joint models and motion/force subspaces between groups of rigid bodies subject to loop constraints. We then use these generalized concepts to derive the constraint-embedded recursive forward dynamics algorithm using multi-handle articulated bodies. We demonstrate the broad applicability of the generalized joint concepts by showing how they also lead to the constraint-embedding-based recursive algorithm for inverse dynamics. Lastly, we benchmark our open-source implementation in C++ for the forward dynamics algorithm against state-of-the-art, sparsity-exploiting algorithms. Our alternative derivation is intended to make the constraint embedding methodology more accessible to the broader robotics community, while the benchmarking study clarifies the relative strengths and limitations of constraint embedding versus sparsity-exploiting methods. Indeed, our benchmarking validates that constraint embedding outperforms the non-recursive alternative in cases involving local kinematic loops.},
  archive      = {J_TROB},
  author       = {Matthew Chignoli and Nicholas Adrian and Sangbae Kim and Patrick M. Wensing},
  doi          = {10.1109/TRO.2025.3593081},
  journal      = {IEEE Transactions on Robotics},
  month        = {7},
  pages        = {1-20},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A propagation perspective on recursive forward dynamics for systems with kinematic loops},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ProxQP: An efficient and versatile quadratic programming solver for real-time robotics applications and beyond. <em>TROB</em>, 1-19. (<a href='https://doi.org/10.1109/TRO.2025.3577107'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convex Quadratic programming (QP) has become a core component in the modern engineering toolkit, particularly in robotics, where QP problems are legions, ranging from real-time whole-body controllers to planning and estimation algorithms. Many of those QPs need to be solved at high frequency. Meeting timing requirements requires taking advantage of as many structural properties as possible for the problem at hand. For instance, it is generally crucial to resort to warm-starting to exploit the resemblance of consecutive control iterations. While a large range of off-the-shelf QP solvers is available, only a few are suited to exploit problem structure and warm-starting capacities adequately. In this work, we propose the ProxQP algorithm, a new and efficient QP solver that exploits QP structures by leveraging primal-dual augmented Lagrangian techniques. For convex QPs, ProxQP features a global convergence guarantee to the closest feasible QP, an essential property for safe closed-loop control. We illustrate its practical performance on various standard robotic and control experiments, including a real-world closed-loop model predictive control application. While originally tailored for robotics applications, we show that ProxQP also performs at the level of state of the art on generic QP problems, making ProxQP suitable for use as an off-the-shelf solver for regular applications beyond robotics.},
  archive      = {J_TROB},
  author       = {Antoine Bambade and Fabian Schramm and Sarah El-Kazdadi and Stéphane Caron and Adrien Taylor and Justin Carpentier},
  doi          = {10.1109/TRO.2025.3577107},
  journal      = {IEEE Transactions on Robotics},
  month        = {6},
  pages        = {1-19},
  shortjournal = {IEEE Trans. Robot.},
  title        = {ProxQP: An efficient and versatile quadratic programming solver for real-time robotics applications and beyond},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CRANE: A redundant, multi-degree-of-freedom computed tomography robot for heightened needle dexterity within a medical imaging bore. <em>TROB</em>, 1-20. (<a href='https://doi.org/10.1109/TRO.2024.3364986'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computed Tomography (CT) image guidance enables accurate and safe minimally invasive treatment of diseases, including cancer and chronic pain, with needle-like tools via a percutaneous approach. The physician incrementally inserts and adjusts the needle with intermediate images due to the accuracy limitation of free-hand adjustment and patient physiological motion. Scanning frequency is limited to minimize ionizing radiation exposure for the patient and physician. Robots can provide high positional accuracy and compensate for physiological motion with fewer scans. To accomplish this, the robots must operate within the confined imaging bore while retaining sufficient dexterity to insert and manipulate the needle. This paper presents CRANE: CT Robotic Arm and Needle Emplacer, a CT-compatible robot with a design focused on system dexterity that enables physicians to manipulate and insert needles within the scanner bore as naturally as they would be able to by hand. We define abstract and measurable clinically motivated metrics for in-bore dexterity applicable to general-purpose intra-bore image-guided needle placement robots, develop an automatic robot planning and control method for intra-bore needle manipulation and device setup, and demonstrate the redundant linkage design provides dexterity across various human morphology and meets the clinical requirements for target accuracy during an in-situ evaluation.},
  archive      = {J_TROB},
  author       = {Dimitrious Schreiber and Zhaowei Yu and Taylor Henderson and Derek Chen and Alexander Norbash and Michael C. Yip},
  doi          = {10.1109/TRO.2024.3364986},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {1-20},
  shortjournal = {IEEE Trans. Robot.},
  title        = {CRANE: A redundant, multi-degree-of-freedom computed tomography robot for heightened needle dexterity within a medical imaging bore},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
