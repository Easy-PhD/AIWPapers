<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>MRA</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="mra">MRA - 21</h2>
<ul>
<li><details>
<summary>
(2025). The robotic circulating nurse. <em>MRA</em>, 2-14. (<a href='https://doi.org/10.1109/MRA.2025.3599719'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Mobile service robotics is a promising technology for assisting hospital workflows, thereby relieving clinical staff from cumbersome tasks and battling today’s ongoing problem of severe personnel shortages. To that end, we present the world’s first robotic circulating nurse (RCN), a novel mobile robotic assistance system, which aims to support clinicians during surgical interventions by autonomously executing tasks within nonsterile areas of the operating room (OR) environment. A core use case of the RCN is the collection, opening, and handing over of sterilely packaged surgical materials, for which we describe our approach to robotic design and behavior implementation. Technical evaluation tests show that our RCN prototype reliably handles the end-to-end workflow for providing requested materials to the surgical team. The practical feasibility and user acceptance of the approach were confirmed during a user study conducted with the OR nursing team at a German university hospital. As a main focus of this article, the hygienic robotic handover of surgical materials was evaluated, yielding an overall success rate of 98.71%. While the execution speed is still in need of improvement, our RCN received highly favorable ratings with regard to relevance, usability, reliability, and hygiene. This underlines the high potential of the RCN concept for addressing the staff shortage problem and for upholding today’s high standard of surgical patient care.},
  archive  = {J},
  author   = {Lukas Bernhard and Oskar Baumann and Carl Scheppach and Patrik Schwingenschlögl and Clemens Kössler and Waldemar Haag and Carolin Müller and Hubertus Feussner and Alois Knoll and Dirk Wilhelm},
  doi      = {10.1109/MRA.2025.3599719},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {9},
  pages    = {2-14},
  title    = {The robotic circulating nurse},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A benchmarking study of vision-based robotic grasping algorithms: A comparative analysis. <em>MRA</em>, 2-12. (<a href='https://doi.org/10.1109/MRA.2025.3603931'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {We present a benchmarking study of vision-based robotic grasping algorithms and provide a comparative analysis. In particular, we compare two machine learning (ML)-based and two analytical algorithms using an existing benchmarking protocol from the literature and determine the algorithms’ strengths and weaknesses under different experimental conditions. These conditions include variations in lighting, background textures, cameras with different noise levels, and grippers. We also run analogous experiments in simulations and with real robots and present the discrepancies. Some experiments were also run in two different laboratories using the same protocols to further analyze the repeatability of our results. We believe that this study, comprising 5,040 experiments, provides important insights into the role and challenges of systematic experimentation in robotic manipulation, and guides the development of new algorithms by considering the factors that could impact the performance. The experiment recordings and our benchmarking software are publicly available.},
  archive  = {J},
  author   = {Bharath K. Rameshbabu and Sumukh S. Balakrishna and Brian Flynn and Vinayak Kapoor and Adam Norton and Holly Yanco and Berk Calli},
  doi      = {10.1109/MRA.2025.3603931},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {9},
  pages    = {2-12},
  title    = {A benchmarking study of vision-based robotic grasping algorithms: A comparative analysis},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sex robots and the AI act: Opening the regulatory discussion. <em>MRA</em>, 2-7. (<a href='https://doi.org/10.1109/MRA.2025.3590611'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The emergence of sex robots—human-like machines offering sexual and emotional services—has ignited contentious debates over their societal impact. Advocates glorify their potential to provide companionship, meet sexual needs, and diversify intimate experiences, while critics warn of risks, including the perpetuation of harmful stereotypes, hindered human connections, and threats to data protection. Against this backdrop, questions arise about the adequacy of existing regulations to address the societal implications of these novel human–robot interactions. Considering these questions and societal implications, this article examines the regulatory challenges surrounding sex robots, specifically exploring their potential inclusion under the AI Act (AIA). As a landmark legislative framework, the AIA establishes minimum standards for developing and deploying artificial intelligence (AI) systems across the European Union (EU), emphasizing their trustworthiness and alignment with fundamental rights. Although sex robots are not explicitly referenced in the AIA, their AI functionalities could position them within multiple risk categories defined by the AIA, each with distinct legal obligations. By analyzing these legal classifications and the corresponding obligations for manufacturers, this article lays the groundwork for an initial regulatory framework to oversee sex robots, ensuring their safe integration into society.},
  archive  = {J},
  author   = {Carlotta Rigotti and Eduard Fosch-Villaronga},
  doi      = {10.1109/MRA.2025.3590611},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {8},
  pages    = {2-7},
  title    = {Sex robots and the AI act: Opening the regulatory discussion},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). X-HAZOP: A family of techniques for ethical hazard analysis of assistive robots. <em>MRA</em>, 2-9. (<a href='https://doi.org/10.1109/MRA.2025.3590612'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Determining the ethical acceptability of assistive robots is a complex task, not least because the ethical hazards of such systems manifest differently across different demographics. Users of these robots are potentially likely to be already marginalized by technology and, thus, vulnerable to a wider range of ethical hazards than other demographics. Adequate assessment and mitigation of the robot’s ethical hazards therefore requires creativity, collaboration, and a range of diverse perspectives. This article presents X-hazard and operability analysis (X-HAZOP), a family, or toolbox, of techniques for conducting ethical hazard analysis of an assistive robot by utilizing structured facilitated workshops. We present the findings from multiple workshops, demonstrating that the use of X-HAZOP techniques with a suitably diverse group of participants improves creation of accessible descriptions of the robot, aids understanding, and leads to an effective identification of a range of ethical hazards.},
  archive  = {J},
  author   = {Catherine Menon and Austen Rainer and Patrick Holthaus and Sílvia Moros and Gabriella Lakatos},
  doi      = {10.1109/MRA.2025.3590612},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {8},
  pages    = {2-9},
  title    = {X-HAZOP: A family of techniques for ethical hazard analysis of assistive robots},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Impacts of design and behavior on the acceptance of anthropomorphic service robots: Statistical modeling of post-experiment questionnaire responses. <em>MRA</em>, 2-11. (<a href='https://doi.org/10.1109/MRA.2025.3590613'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Acceptance of robotics in customer service is complex as modern robots have brought about increasingly natural dialogue with users. Prior research has established significant relationships with respect to usefulness and ease of use in modeling acceptance of robots. However, a systematic understanding of the causal relationships between the design and behavior of robots and their acceptance is lacking. In this paper, we use questionnaire responses from 146 participants as part of a publicly available dataset in affective computing in HRI to analyze acceptance of service robots. After validating the framework used in the study, we observe significant relationships with respect to anthropomorphism, transparency, liability, and morality. We find no differences in acceptance based on anthropomorphism. We find that neither transparent communication nor failures resulting in liability issues cause significant changes in acceptance. We find that overtly immoral behavior by robots is more harmful to acceptance than moral behavior is beneficial. Our results are surprising, and crucial for understanding user perceptions of robots based on design and behavioral factors.},
  archive  = {J},
  author   = {Tyler Yankee and Naveen Ramachandra Reddy and Charles Thorpe and Sumona Mondal},
  doi      = {10.1109/MRA.2025.3590613},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {8},
  pages    = {2-11},
  title    = {Impacts of design and behavior on the acceptance of anthropomorphic service robots: Statistical modeling of post-experiment questionnaire responses},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Drone landing performance in windy conditions: Comparing the vertical and horizontal landing approaches with the EAGLES port. <em>MRA</em>, 2-18. (<a href='https://doi.org/10.1109/MRA.2025.3577158'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Drone docking stations promote efficient operations of drones, but they usually support only one vehicle and are accessible primarily through vertical landing. These limitations hinder multidrone operations and result in challenges for fast precise docking, particularly under severe wind conditions. This article assesses the EAGLES Port, which uses a horizontal landing approach to address these challenges, and makes a performance comparison between horizontal and vertical landing through analysis of wind tunnel data with manually controlled drones. Results show that horizontal landing decreases the average landing duration by 35.58% and can achieve 59.67% faster docking compared to vertical landing in optimal conditions. The system also provides near-zero position error at docking and supports multiple drones. These advantages stem from improved flight stability, quicker alignment with landing targets, and a 2.8× higher average velocity compared to vertical landing. These results indicate that vertical landing is better suited for missions with wider landing zones and where delays in landing have mild consequences, whereas horizontal landing excels in scenarios where rapid accurate landings are critical.},
  archive  = {J},
  author   = {Iuri Barros and Yoshito Okada and Kenjiro Tadakuma and Masahiro Watanabe and Masashi Konyo and Kazunori Ohno and Yoshiki Yokota and Ranulfo Bezerra and Satoshi Tadokoro},
  doi      = {10.1109/MRA.2025.3577158},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {7},
  pages    = {2-18},
  title    = {Drone landing performance in windy conditions: Comparing the vertical and horizontal landing approaches with the EAGLES port},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FLEXIV: Adaptive locomotion via morphological changes in a flexible track vehicle. <em>MRA</em>, 2-12. (<a href='https://doi.org/10.1109/MRA.2025.3577162'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Flexible and adaptive tracked robots show the capacity to navigate in unstructured terrain, with a passive adaption of the track or a morphology change for terrain adaptation. Extending the concept to one in which the morphology can be actively changed has the potential to increase the capabilities of a locomoting robot while reducing the need for complex controllers and onboard navigation systems. This article introduces FLEXIV, a 232-g untethered robotic vehicle with flexible, magnet-equipped tracks that achieves adaptive locomotion across diverse geometries of ferrous terrains with appropriate transitioning of its track shape from circular to oblong. By modulating the configuration of a track loop, the robot can adjust its driving capability, such as traction and steering ability, to optimize its behavior to the terrain. This deformable robot is combined with an autonomous controller that leverages only robot posture information through inertial measurement units (IMUs) for terrain estimation to autonomously adapt the robot’s configuration to the environment. This enables the robot to autonomously navigate complex terrains, including diverse slopes and steps, and offers recovery actions for extreme falls.},
  archive  = {J},
  author   = {Sareum Kim and Daniil Filimonov and Josie Hughes},
  doi      = {10.1109/MRA.2025.3577162},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {7},
  pages    = {2-12},
  title    = {FLEXIV: Adaptive locomotion via morphological changes in a flexible track vehicle},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Museum touring through an augmented reality-enhanced robotic assistant: Improving learnability and memory retention. <em>MRA</em>, 2-9. (<a href='https://doi.org/10.1109/MRA.2025.3577178'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {While museums traditionally cater to visual perception, some are adopting novel approaches to aid visitors with impairments. In recent years, robot-based tour guides have become a popular museum attraction. Instead of traditional guides, special-purpose robots assist people and allow for more engaging multimodal touring. While promising, such robotics guides tend to prioritize efficiency and safety over inclusivity, focusing on collision avoidance and movement. At the same time, accessibility challenges magnified by different approaches to learning and disabilities remain underexplored. To tackle this issue, we propose to enhance robotic touring with augmented reality (AR) to overlay additional information onto a visitor’s view. Previous research suggests that AR can improve learning, knowledge retention, and accessibility, particularly when traditional approaches are impractical. Consequently, we integrated AR with a Lindsey robotic guiding system specifically designed to work in an open environment. Next, we tested the hypothesis that AR-enhanced robot guides improve learning and memory retention. A user study with 21 participants found that augmenting the robotic tour guide with AR can improve the learning outcomes of museum visitors.},
  archive  = {J},
  author   = {James Tombling and Sławomir K. Tadeja and Thomas Bohné},
  doi      = {10.1109/MRA.2025.3577178},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {7},
  pages    = {2-9},
  title    = {Museum touring through an augmented reality-enhanced robotic assistant: Improving learnability and memory retention},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time localization scoring for challenging industrial environments: Practical experiments with bluepath robotics. <em>MRA</em>, 2-14. (<a href='https://doi.org/10.1109/MRA.2025.3584350'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Autonomous mobile robots (AMRs) are revolutionizing industries by enhancing flexibility and efficiency, particularly in dynamic environments, such as automotive manufacturing. These environments pose challenges due to their constantly changing layouts, unpredictable obstacles, and varying conditions, which impact the performance of localization systems. This article presents a novel real-time localization scoring architecture to address these challenges by quantifying the confidence in a robot’s positioning system. The proposed localization score improves map reconciliation, manages sensor interference, adapts navigation strategies, and enhances traffic coordination. Extensive experimental studies, including real-world deployment in an operational automotive production factory, demonstrate the robustness, accuracy, and adaptability of the developed localization score algorithm. The results showcase its potential to significantly enhance the operational efficiency and reliability of AMRs in industrial settings.},
  archive  = {J},
  author   = {Abdurrahman Yilmaz and Umut Dumandag and Aydin Cagatay Sari and Ismail Hakki Savci and Hakan Temeltas},
  doi      = {10.1109/MRA.2025.3584350},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {7},
  pages    = {2-14},
  title    = {Real-time localization scoring for challenging industrial environments: Practical experiments with bluepath robotics},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey on soft robot adaptability: Implementations, applications, and prospects [Survey]. <em>MRA</em>, 2-14. (<a href='https://doi.org/10.1109/MRA.2025.3584346'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Soft robots, compared to rigid robots, possess inherent advantages, including higher degrees of freedom, compliance, and enhanced safety, which have contributed to their increasing application across various fields. Among these benefits, adaptability is particularly noteworthy. In this article, adaptability in soft robots is categorized into external and internal adaptability. External adaptability refers to the robot’s ability to adjust, either passively or actively, to variations in environments, object properties, geometries, and task dynamics. Internal adaptability refers to the robot’s ability to cope with internal variations, such as manufacturing tolerances or material aging, and to generalize control strategies across different robots. As the field of soft robotics continues to evolve, the significance of adaptability has become increasingly pronounced. In this review article, we summarize various approaches to enhancing the adaptability of soft robots, including design, sensing, and control strategies. Additionally, we assess the impact of adaptability on applications such as surgery, wearable devices, locomotion, and manipulation. We also discuss the limitations of soft robotics adaptability and prospective directions for future research. By analyzing adaptability through the lenses of implementation, application, and challenges, this article aims to provide a comprehensive understanding of this essential characteristic in soft robotics and its implications for diverse applications.},
  archive  = {J},
  author   = {Zixi Chen and Di Wu and Qinghua Guan and David Hardman and Federico Renda and Josie Hughes and Thomas George Thuruthel and Cosimo Della Santina and Barbara Mazzolai and Huichan Zhao and Cesare Stefanini},
  doi      = {10.1109/MRA.2025.3584346},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {7},
  pages    = {2-14},
  title    = {A survey on soft robot adaptability: Implementations, applications, and prospects [Survey]},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cooperative aerial robot inspection challenge: A benchmark for heterogeneous multi-uncrewed-aerial-vehicle planning and lessons learned. <em>MRA</em>, 2-13. (<a href='https://doi.org/10.1109/MRA.2025.3584341'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {We propose the Cooperative Aerial Robot Inspection Challenge (CARIC), a simulation-based benchmark for motion planning algorithms in heterogeneous multi-uncrewed-aerial-vehicle (UAV) systems. CARIC features UAV teams with complementary sensors, realistic constraints, and evaluation metrics prioritizing inspection quality and efficiency. It offers a ready-to-use perception-control software stack and diverse scenarios to support the development and evaluation of task allocation and motion planning algorithms. Competitions using CARIC were held at the 2023 IEEE Conference on Decision and Control (CDC) and the IROS 2024 Workshop on Multi-Robot Perception and Navigation, attracting innovative solutions from research teams worldwide. This article examines the top three teams from CDC 2023, analyzing their exploration, inspection, and task allocation strategies while drawing insights into their performance across scenarios. The results highlight the task’s complexity and suggest promising research directions in cooperative multi-UAV systems. The simulation framework, including the source code and detailed instructions, is publicly available at https://ntu-aris.github.io/caric.},
  archive  = {J},
  author   = {Muqing Cao and Thien-Minh Nguyen and Shenghai Yuan and Andreas Anastasiou and Angelos Zacharia and Savvas Papaioannou and Panayiotis Kolios and Christos G. Panayiotou and Marios M. Polycarpou and Xinhang Xu and Mingjie Zhang and Fei Gao and Boyu Zhou and Ben M. Chen and Lihua Xie},
  doi      = {10.1109/MRA.2025.3584341},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {7},
  pages    = {2-13},
  title    = {Cooperative aerial robot inspection challenge: A benchmark for heterogeneous multi-uncrewed-aerial-vehicle planning and lessons learned},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Harnessing robotics for european union forest habitats monitoring: Toward a robotic-assisted framework for standardized field surveys. <em>MRA</em>, 2-10. (<a href='https://doi.org/10.1109/MRA.2025.3584343'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {This paper presents a novel approach to forest habitat monitoring using robotics and advanced data analysis techniques. We introduce a quadrupedal robot with LiDAR and onboard cameras to collect detailed data about forest structure and composition. The data is then processed using a combination of data analysis techniques and machine learning algorithms to perform a comprehensive dendrometric and floristic survey. Our approach provides an efficient and accurate method for assessing the ecological health of forest ecosystems. This work contributes to the ongoing efforts in habitat conservation and offers a promising tool for future environmental monitoring tasks.},
  archive  = {J},
  author   = {Simone Tolomei and Giovanni Di Lorenzo and Franco Angelini and Leopoldo de Simone and Emanuele Fanfarillo and Tiberio Fiaschi and Silvia Cannucci and Simona Maccherini and Paolo Remagnino and Claudia Angiolini and Manolo Garabini},
  doi      = {10.1109/MRA.2025.3584343},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {7},
  pages    = {2-10},
  title    = {Harnessing robotics for european union forest habitats monitoring: Toward a robotic-assisted framework for standardized field surveys},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Soft pneumatic gripper with interchangeable fingertips by using reversible polymers: The GraspBerry, a raspberry picking case study. <em>MRA</em>, 2-10. (<a href='https://doi.org/10.1109/MRA.2025.3577167'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Fingerprints primarily enhance grasping by modulating friction, as the surface pattern affects the friction needed for effective grasping and manipulation. A versatile gripper was developed with a more realistic distal phalange inspired by the human index finger for improved berry gripping performance. The soft pneumatic gripper was fabricated out of a Diels-Alder–based self-healing polymer, leveraging its thermally reversible nature for introducing interchangeable fingertips. Various fingertips were developed with different patterns for optimized grasping of fruits of different shape, size, and stiffness, depending on the type of fruit, level of ripeness, and variations in weather and climate conditions of each harvest season. The fingertips can be mounted and removed easily from the distal phalange of the pneumatic finger by welding and manual disassembly. The gripper was optimized for picking raspberries, exploiting the innovative interchangeable fingertips. The same gripper could successfully harvest berries of different levels of ripeness thanks to three types of interchangeable fingertips with different patterns. The performance of the different fingertips was evaluated in the lab on a physical twin of a raspberry and a 67% success rate was obtained in the field by switching them on the spot to optimize the grasp to the different ripeness level of the berries. The GraspBerry paves the way for the design of versatile grippers with adaptable grasping performance by switching the fingertips for accurate and reliable grasp on different types of crops throughout the various harvesting seasons all year round.},
  archive  = {J},
  author   = {Francesca Furia and Niccolò Pagliarani and Kai Junge and Ellen Roels and Seppe Terryn and Bram Vanderborght and Joost Brancart and Josie Hughes and Matteo Cianchetti},
  doi      = {10.1109/MRA.2025.3577167},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {7},
  pages    = {2-10},
  title    = {Soft pneumatic gripper with interchangeable fingertips by using reversible polymers: The GraspBerry, a raspberry picking case study},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bridging ethics and reality: Integrating thought experiments and empirical insights in robot ethics. <em>MRA</em>, 2-8. (<a href='https://doi.org/10.1109/MRA.2025.3584352'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The integration of robots into daily life introduces complex ethical, legal, and social implications (ELSI) stemming from their interactions with humans. Social robots can operate in environments rich with cultural norms, emotions, and social cues, raising critical questions about privacy, trust, and safety. In this paper, we explore how the interdisciplinary field of robot ethics can address these challenges through a hybrid methodological concept that combines thought experiments and empirical research. Thought experiments offer a platform for systematically analyzing ethical dilemmas, while empirical methods provide real-world insights to validate and refine these theoretical frameworks. The paper particularly emphasizes the utilization of living labs as dynamic environments for testing and integrating ethical design principles into robot design to ensure robots align with ethical expectations and legal standards.},
  archive  = {J},
  author   = {Yueh-Hsuan Weng and David Torabi and Jim Torresen and Zonghao Dong and Yasuhisa Hirata},
  doi      = {10.1109/MRA.2025.3584352},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {7},
  pages    = {2-8},
  title    = {Bridging ethics and reality: Integrating thought experiments and empirical insights in robot ethics},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PhysioSense: An open source multimodal monitoring framework for human movement and behavior analysis. <em>MRA</em>, 2-10. (<a href='https://doi.org/10.1109/MRA.2025.3577169'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Accurate assessment of human movement and behavior is essential in fields such as ergonomics, rehabilitation, and human-robot interaction. This paper presents PhysioSense, an open-source framework for synchronized multi-modal data acquisition and management. Built on the Lab Streaming Layer (LSL), PhysioSense integrates heterogeneous data streams from kinematic, dynamic, and physiological sensors in real time, ensuring millisecond-level synchronization. Unlike general-purpose tools such as LabVIEW, OpenSignals, or ROS, PhysioSense is specifically tailored to human-centric research, offering a streamlined interface for sensor configuration, recording, visualization, and data export. The framework’s modular design supports extensibility and reproducibility, making it suitable for a range of experimental setups. Two case studies—an ergonomics analysis and a drilling task assessment—demonstrate the framework’s capabilities in real-world scenarios. PhysioSense addresses key challenges in multi-sensor integration and paves the way for more accessible and scalable movement analysis in both research and applied settings.},
  archive  = {J},
  author   = {Ilias El Makrini and Tom Turcksin and Taner Incirci and Elias Thiery and Stijn Kindt and Rossana Lovecchio and Hoang-Long Cao and Menthy Denayer and Erard Lamine and Stijn Huysentruyt and Tom Verstraten and Bram Vanderborght},
  doi      = {10.1109/MRA.2025.3577169},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {7},
  pages    = {2-10},
  title    = {PhysioSense: An open source multimodal monitoring framework for human movement and behavior analysis},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A biomimetic and energy-efficient leg design for a humanoid robot: An exclusively linear-actuated implementation. <em>MRA</em>, 2-16. (<a href='https://doi.org/10.1109/MRA.2025.3559801'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The mobility and manipulation of bipedal humanoid robots always depend on their legs, which account for balance and may substantially accelerate energy consumption, especially when the lower body is expected to be stationary. To this end, this article presents a biomimetic and energy-efficient design for bipedal robots’ legs and extensively demonstrates its performance on the developed prototype. From a biomimetic perspective, human walking data are captured at first, and the range of motion, speed, and coupling relationship of various joints are analyzed. The skeletal and muscular structures of each joint are then dissected and imitated by mechanism synthesis, where a novel locking mechanism inspired by the biological structure of the knee joint is integrated. To better evaluate the energy consumption capability of legged robots, we propose a new metric—dynamic power of the system (DPoS)—and experimentally prove its rationality. The effectiveness and superiority of our design are ultimately validated through the comparative experiments on both our prototype and the off-the-shelf counterpart.},
  archive  = {J},
  author   = {Junyang Wang and XueAi Li and Fenglei Ni and Baoshi Cao and Le Qi and Hong Liu and Xiangji Wang and Teng Zhang},
  doi      = {10.1109/MRA.2025.3559801},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {4},
  pages    = {2-16},
  title    = {A biomimetic and energy-efficient leg design for a humanoid robot: An exclusively linear-actuated implementation},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automated behavior planning for fruit tree pruning via redundant robot manipulators: Addressing the behavior planning challenge. <em>MRA</em>, 2-12. (<a href='https://doi.org/10.1109/MRA.2025.3559797'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Pruning is an essential agricultural practice for orchards. Proper pruning can promote healthier growth and optimize fruit production throughout the orchard’s lifespan. Robot manipulators have been developed as an automated solution for this repetitive task, which typically requires seasonal labor with specialized skills. While previous research has primarily focused on the challenges of perception, the complexities of manipulation are often overlooked. These challenges involve planning and control in both joint and Cartesian spaces to guide the end effector through intricate, obstructive branches. Our work addresses the behavior planning challenge for a robotic pruning system, which entails a multilevel planning problem in environments with complex collisions. In this article, we formulate the planning problem for a high-dimensional robotic arm in a pruning scenario, investigate the system’s intrinsic redundancies, and propose a comprehensive pruning workflow that integrates perception, modeling, and holistic planning. In our experiments, we demonstrate that more comprehensive planning methods can significantly enhance the performance of the robotic manipulator. Finally, we implement the proposed workflow on a real-world robot. As a result, this work complements previous efforts on robotic pruning and motivates future research and development in planning for pruning applications.},
  archive  = {J},
  author   = {Gaoyuan Liu and Bas Boom and Naftali Slob and Yuri Durodié and Ann Nowé and Bram Vanderborght},
  doi      = {10.1109/MRA.2025.3559797},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {4},
  pages    = {2-12},
  title    = {Automated behavior planning for fruit tree pruning via redundant robot manipulators: Addressing the behavior planning challenge},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Natural multimodal fusion-based Human–Robot interaction: Application with voice and deictic posture via large language model. <em>MRA</em>, 2-11. (<a href='https://doi.org/10.1109/MRA.2025.3543957'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Translating human intent into robot commands is crucial for the future of service robots in an aging society. Existing human‒robot interaction (HRI) systems relying on gestures or verbal commands are impractical for the elderly, due to difficulties with complex syntax or sign language. To address the challenge, this article introduces a multimodal interaction framework that combines voice and deictic posture information to create a more natural HRI system. Visual cues are first processed by the object detection model to gain a global understanding of the environment, and then bounding boxes are estimated based on depth information. By using a large language model (LLM) with voice-to-text commands and temporally aligned selected bounding boxes, robot action sequences can be generated, while key control syntax constraints are applied to avoid potential LLM hallucination issues. The system is evaluated on real-world tasks with varying levels of complexity, using a Universal Robots UR3e manipulator. Our method demonstrates significantly better HRI performance in terms of accuracy and robustness. To benefit the research community and the general public, we made our code and design open source.},
  archive  = {J},
  author   = {Yuzhi Lai and Shenghai Yuan and Youssef Nassar and Mingyu Fan and Atmaraaj Gopal and Arihiro Yorita and Naoyuki Kubota and Matthias Rätsch},
  doi      = {10.1109/MRA.2025.3543957},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {3},
  pages    = {2-11},
  title    = {Natural multimodal fusion-based Human–Robot interaction: Application with voice and deictic posture via large language model},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Autonomous ultraviolet-C disinfection and wiping robot: Assessment in a hospital environment. <em>MRA</em>, 2-12. (<a href='https://doi.org/10.1109/MRA.2025.3543958'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {This article explores the advent of an innovative autonomous robot designed to enhance hospital disinfection through targeted wiping and ultraviolet-C (UV-C) irradiation methods. The urgency for such advancements has been underscored by the COVID-19 pandemic, which revealed challenges, such as low compliance rates, physical fatigue, labor shortages, and heightened risk of pathogen exposure for disinfection workers. Traditional disinfection approaches, including UV-C irradiation mobile robots and hydrogen peroxide vapor methods, while effective, fall short in addressing obstacles like shaded areas and surface contaminants. To bridge this gap, we introduce a novel robot that combines physical wiping to remove contaminants with targeted UV-C irradiation for areas less amenable to wiping. Our development efforts have centered on optimizing disinfection efficacy and ensuring the robot’s reliability for practical applications in real-world hospitals. The performance and usability of this autonomous disinfection robot were thoroughly assessed at Pohang St. Mary’s Hospital, demonstrating its potential to transform hospital disinfection practices by complementing traditional disinfection tasks with advanced robotic assistance.},
  archive  = {J},
  author   = {Jaewon Byun and Joonsub Byun and Junsu Kang and Inje Yi and Jungwoo Lee and Kyoungseok Noh and Jongchan Kim and Youngho Choi and Goobong Chung and Sangrok Oh and Keehoon Kim},
  doi      = {10.1109/MRA.2025.3543958},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {3},
  pages    = {2-12},
  title    = {Autonomous ultraviolet-C disinfection and wiping robot: Assessment in a hospital environment},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reconfigurable modular soft actuator using origami structures with self-healing materials: Several technological opportunities for robotic applications. <em>MRA</em>, 2-13. (<a href='https://doi.org/10.1109/MRA.2025.3533386'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Modular designs in soft robots enable repair and reconfiguration, making soft modular robots suitable for applications where resilience, flexibility, and adaptability are critical. This paper introduces a modular soft robot (MSR) based on origami actuator modules that are manufactured from reversible polymers, e.g., self-healing polymers. This work highlights three key innovations enabled by reversible polymers for MSRs. First, their reversible bonding capacity can be utilized to create high-strength interfaces between modules relying on strong covalent bonds. These interfaces can bond and debond on demand through temperature control. This reversible joining principle is downscalable and enables reconfiguration. Second, their reversible crosslinks allow for origami-based manufacturing in the solid state, involving sequential folding and binding. This process transforms 2D structures into covalently bonded and airtight 3D structures. Finally, these reversible bonds introduce a self-healing capacity to the MSRs, enabling recovery from macroscopic damages. All of these innovations are demonstrated experimentally on modular vacuum origami-based actuator modules, showing successful self-healing and reconfiguration capabilities.},
  archive  = {J},
  author   = {Lisbeth Mena and Seppe Terryn and Bram Vanderborght and Concepcion A. Monje},
  doi      = {10.1109/MRA.2025.3533386},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {2},
  pages    = {2-13},
  title    = {Reconfigurable modular soft actuator using origami structures with self-healing materials: Several technological opportunities for robotic applications},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrating software-less reflex mechanisms into soft robots and a versatile gripper: A new bistable method. <em>MRA</em>, 2-13. (<a href='https://doi.org/10.1109/MRA.2025.3537831'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {While most soft pneumatic grippers that operate with a single control parameter (such as pressure or airflow) are limited to a single grasping modality, this article introduces a new method for incorporating multiple grasping modalities into vacuum-driven soft grippers. This is achieved by combining stiffness manipulation with a bistable mechanism. The system features a bistable dome structure with a central suction cup and a set of vacuum bending actuators. Designed and optimized using fluid and structure modeling in finite element analysis, it offers three grasping modes: two reflex mechanisms (force- and contact-triggered) and one with active control. All modes rely on the structural buckling of the bistable dome, but differ in how this snap behavior is activated, by force, contact, or active control. Adjusting the airflow tunes the energy barrier of the bistable mechanism, enabling changes in triggering sensitivity and allowing swift transitions between grasping modes. This results in an exceptional versatile gripper, capable of handling a diverse range of objects with varying sizes, shapes, stiffness, and roughness, controlled by a single parameter, airflow, and its interaction with objects.},
  archive  = {J},
  author   = {Zhanwei Wang and Huaijin Chen and Hendrik Cools and Bram Vanderborght and Seppe Terryn},
  doi      = {10.1109/MRA.2025.3537831},
  journal  = {IEEE Robotics & Automation Magazine},
  month    = {2},
  pages    = {2-13},
  title    = {Integrating software-less reflex mechanisms into soft robots and a versatile gripper: A new bistable method},
  year     = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
